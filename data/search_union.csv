Source;DOI;Url;Title;Year;Author;Abstract;First Round Decision;First Round Reason;Exclusion Criteria;Second Round Decision;Second Round Notes;Argumentation;Case Focus (Common Law);Statutes focus (Civil Law);Is Ontology;Formalization (Type of Logic);Reacts To Changes in the law;Mentions Conversion;Level of Automation on Creation;Human Understandability;Level of Involvment by legal practitioners in the creation of the methodology;BPC mentioned;Purpose;Demonstrated in Domain (This does not preclude genearl applicability);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/MODELS.2015.7338275;;Model-driven regulatory compliance: A case study of “Know Your Customer” regulations;2015;"Sunkle, Sagar; Kholkar, Deepali; Kulkarni, Vinay";Modern enterprises face an unprecedented regulatory regime. Industry governance, risk, and compliance (GRC) solutions are document-oriented and expert-driven. Formal compliance checking techniques in contrast attempt to provide ways for rigorous modeling and analysis of regulatory compliance but miss out on holistic GRC perspective due to missing integration between diverse set of (semi-) formal models. We show that streamlining regulatory compliance using multiple purposive models of various aspects of regulations, it is possible to leverage both the rigor of formal techniques and the holistic enterprise GRC perspective. Our contributions are twofold. First, we present a model-driven architecture based on a conceptual model of integrated GRC that is capable of addressing key challenges of regulatory compliance. Second, using Know Your Customer regulations in Indian context as a case study, we demonstrate the utility of this architecture. Initial results with KYC regulations are promising and point to further work in model-driven regulatory compliance.;Yes;;;Yes;;No;No;Yes;No;(Defeasible Reasoning)-Prolog;Yes;No;Manual;Not optimized;"""domain experts""";"""Challenging""";Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2009.4;;Governance Requirements Extraction Model for Legal Compliance Validation;2009;"Hassan, Waël; Logrippo, Luigi";We present a model-based approach to extract governance requirements from the law and enterprise regulations, to formal specifications. This is the first step of an end-to-end implemented methodology for validating legal compliance of enterprises to law through logic models. Our UML-based Governance Extraction Model (GEM) is able to extract many legal and enterprise requirements, particularly business process and access-control requirements. Examples from Canadian and USA financial and privacy laws are provided. As a result of our extraction process, logic analyzers were shown to be able to detect compliance faults.;Yes;;;Yes;;No;No;Yes;Yes;UML;No;No;Manual;Not optimized;No;Yes;Compliance;Finance, Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2008.8;;Requirements and compliance in legal systems: a logic approach;2008;"Hassan, Wa ël; Logrippo, Luigi";It is shown that the concepts of requirements and implementation exist in normative systems, in particular in law, and are similar to homologous concepts in software engineering. Concepts of compliance and conformance are also similar in the two areas. Further, it is shown how a logic analyzer such as Alloy can be used in order to verify legal compliance by checking consistency between legal and enterprise requirements. Examples are taken from privacy law and financial reporting law.;Yes;;;Yes;;No;No;Yes;Yes;non-modal, first order predicate logic;No;No;Manual;Not optimized;No;Yes;Compliance;Finance, Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2009.3;;Checking Existing Requirements for Compliance with Law Using a Production Rule Model;2009;"Maxwell, Jeremy C.; Antón, Annie I.";To ensure legal compliance, requirements engineers need tools to determine existing software requirements' compliance with relevant law. We propose using a production rule model for requirements engineers to query as they check software requirements for legal compliance. In this paper, we perform a case study using our approach to evaluate the iTrust Medical Records System requirements for compliance with the u.s. Health Insurance Portability and Accountability Act (HIPAA). We identifY 12 new compliance requirements beyond the 63 functional requirements with which we began our analysis.;Yes;;;Yes;;No;No;Yes;No;Prolog;No;No;Manual;Includes visualisation;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2013.6671346;;Legal requirements analysis and modeling with the measured compliance profile for the goal-oriented requirement language;2013;"Rashidi-Tabrizi, Rouzbahan; Mussbacher, Gunter; Amyot, Daniel";As demonstrated by a benchmark HIPPA case study, the Measured Compliance Profile for the Goal-oriented Requirement Language (GRL) is used to formalize legal text with GRL in order to make it amenable to compliance analysis. This formalization is based on guidelines yielding a goal model that can be analyzed for compliance with the jUCMNav tool with the help of real-world measurements captured by indicators in the goal model. For usability reasons, the legal text may also be specified in a tabular representation and subsequently transformed into a goal model by jUCMNav.;Yes;;;Yes;;No;No;Yes;No;Goal Model;Explicit Limitation;From Tabular Representation?;Semi-Automatied;Includes visualisation;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE59067.2024.00065;;Enhancing Legal Compliance and Regulation Analysis with Large Language Models;2024;Hassani, Shabnam;This research explores the application of Large Language Models (LLMs) for automating the extraction of requirement-related legal content in the food safety domain and checking legal compliance of regulatory artifacts. With Industry 4.0 revolutionizing the food industry and with the General Data Protection Regulation (GDPR) reshaping privacy policies and data processing agreements, there is a growing gap between regulatory analysis and recent technological advancements. This study aims to bridge this gap by leveraging LLMs, namely BERT and GPT models, to accurately classify legal provisions and automate compliance checks. Our findings demonstrate promising results, indicating LLMs' significant potential to enhance legal compliance and regulatory analysis efficiency, notably by reducing manual workload and improving accuracy within reasonable time and financial constraints.;Yes;;;No;No actual intermediate law representation besides the original text;No;;;;LLM;Explicit Limitation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/DASC-PICom-DataCom-CyberSciTec.2017.115;;Modular Norm Models: A Lightweight Approach for Modeling and Reasoning about Legal Compliance;2017;"Mandal, Sayonnha; Gandhi, Robin; Siy, Harvey";Complying with legal regulatory requirements in privacy and security is necessary for critical software systems. Analysis of complex and voluminous legal text can benefit from the automation and traceability of logic-based models. We propose such a model based on norms. Norms are legal rights and associated duties expressed in regulatory documents. Such norm models help reason about available rights and required duties based on the satisfiability of situations, a state-of-affair, in a given scenario. But model extraction from natural language as well as compliance reasoning in complex scenarios needs subject matter expertise. Our method enables modular norm model extraction and reasoning. For extraction, using the theory of frame-semantics we construct two foundational norm templates that cover Hohfeld's concepts of claim-right and its jural correlative, duty. Template instantiations from legal text result in a repeatable method for extraction of modular norm models. For reasoning, we introduce the notion of a super-situation. Super-situations contain other norm models. Compliance results from a modular norm are propagated to its containing super-situation, which in turn participates in other modular norms. This modularity allows on-demand incremental modeling and reasoning using simpler model primitives than previous approaches.;Yes;;;Yes;;No;No;Yes;No;Nòmos Extension;No;No;Automatic (frame-semantics);Not optimized;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2010.5625356;;Law, logic and business processes;2010;Governatori, Guido;Since its inception one of the aims of legal informatics has been to provide tools to support and improve the day to day activities of legal and normative practice and a better understanding of legal reasoning. The internet revolutions, where more and more daily activities are routinely performed with the support of ITC tools, offers new opportunities to legal informatics. We argue that the current technology begins to be mature enough to embrace in the challenge to make intelligent ICT support widespread in the legal and normative domain. In this paper we examine a logical model to encode norms and we use the formalisation of relevant law and regulations for regulatory compliance for business processes.;Yes;;;Yes;;No;No;Yes;No;Novel: Process Compliance Language (PCL): Modified Deontic Logic + Defeasible Logic;No;No;Manual;Not optimized;No;Yes;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2010.5625358;;A method to acquire compliance monitors from regulations;2010;Breaux, Travis D.;"Developing software systems in heavily regulated industries requires methods to ensure systems comply with regulations and law. A method to acquire finite state machines (FSM) from stakeholder rights and obligations for compliance monitoring is proposed. Rights and obligations define what people are permitted or required to do; these rights and obligations affect software requirements and design. The FSM allows stakeholders, software developers and compliance officers to trace events through the invocation of rights and obligations as pre- and post-conditions. Compliance is monitored by instrumenting runtime systems to report these events and detect violations. Requirements and software engineers specify the rights and obligations, and apply the method using three supporting tasks: 1) identify under-specifications, 2) balance rights with obligations, and 3) generate finite state machines. Preliminary validation of the method includes FSMs generated from U.S. healthcare regulations and tool support to parse these specifications and generate the FSMs.";Yes;New idea: FSM;;Yes;;No;No;Yes;No;Finite Statemachine;No;As a process, maps Knowledge Transformation Language (KTL) statements to formal logic and then to the final FSM;Mostly automatic (Assuming KTL as input);Not optimized;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/EDOC.2011.37;;Making Business Processes Compliant to Standards and Regulations;2011;Papazoglou, Michael P.;Compliance regulations require enterprises to review their SOA applications to ensure that they satisfy the set of relevant compliance requirements. Despite an increasing number of methods and tools, organizations have a pressing need for a comprehensive compliance framework to help them ensure that their business processes comply with requirements set forth by regulations, laws, and standards. In this paper we explain how to cope with business process compliance requirements and present a framework to capture and manage compliance requirements. We introduce a declarative Compliance Request Language for specifying compliance requirements. We also examine a set of compliance patterns to support the definition of frequently recurring compliance requirements in association with business processes. This approach enables the application of automated tools for compliance analysis and verification.;Yes;;;Yes;;No;No;Yes;No;Compliance Request Language (CRL) can be mapped to Linear/Metric Temporal Logic (LTL/MTL);No;Into TLT/MLT;"Automatic conversion to TLT/MLT; Rest Manual";Yes, CRL optimized for human optimization;No;Yes;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE59067.2024.00013;;Defining a Model for Content Requirements from the Law: An Experience Report;2024;"Ceci, Marcello; Bianculli, Domenico; Briand, Lionel C.";This paper reports on the experience of building a content model in collaboration with a national financial supervisory authority, with the goal of automating the compliance checking activity performed by the agents of the supervisory authority on fund documentation. The work is focused on modelling content requirements found in the law, i.e., deontic rules prescribing that some information is contained in an official document. For such requirements, the main modelling effort revolves around the required content and its information types. We therefore designed a process to build a content model, elaborating design criteria for the model which partly depend on the use case encompassing compliance checking. We built the content model through iterative interactions between a knowledge engineer and domain experts designed to ensure that the model is not limited to representing only the letter of the law, but rather represents the relevant distinctions in the practice of compliance checking. We drew lessons learned regarding the need for setting up classification criteria for information types and handling the trade-off between expressivity and maintainability of the model.;Yes;;;Yes;;No;No;Yes;Non-formal;Non-formal;No;No;Manual;Not optimized;Yes (collab with national financial supervisory authority;No (not process, rather document checking);Compliance;Finance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE59067.2024.00051;;Rethinking Legal Compliance Automation: Opportunities with Large Language Models;2024;"Hassani, Shabnam; Sabetzadeh, Mehrdad; Amyot, Daniel; Liao, Jain";As software-intensive systems face growing pressure to comply with laws and regulations, providing automated support for compliance analysis has become paramount. Despite advances in the Requirements Engineering (RE) community on legal compliance analysis, important obstacles remain in developing accurate and generalizable compliance automation solutions. This paper highlights some observed limitations of current approaches and examines how adopting new automation strategies that leverage Large Language Models (LLMs) can help address these shortcomings and open up fresh opportunities. Specifically, we argue that the examination of (textual) legal artifacts should, first, employ a broader context than sentences, which have widely been used as the units of analysis in past research. Second, the mode of analysis with legal artifacts needs to shift from classification and information extraction to more end-to-end strategies that are not only accurate but also capable of providing explanation and justification. We present a compliance analysis approach designed to address these limitations. We further outline our evaluation plan for the approach and provide preliminary evaluation results based on data processing agreements (DPAs) that must comply with the General Data Protection Regulation (GDPR). Our initial findings suggest that our approach yields substantial accuracy improvements and, at the same time, provides justification for compliance decisions.;Yes;;;No;No actual intermediate law representation besides the original text;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ICCAC.2015.24;;An Autonomic Legal-Rule Aware Cloud Service Broker;2015;Casalicchio, Emiliano;The ICT industry, and specifically critical sectors such as healthcare, transportation, energy and government require as mandatory the compliance of the ICT systems and services with legislation and regulation, as well as with standards. In the era of cloud computing, and particularly in a public cloud scenario, this law and regulation compliance management issue is exacerbated by the distributed nature of the system and by the limited control of the customer on the infrastructure/services. Also if the cloud industry is aware of this legislation/regulation compliance issue (e.g. the compliance program of Amazon, Google and Microsoft Azure), right now, there are no mechanism/architectures capable to check and to assure that the compliance is guaranteed during the whole life cycle of a cloud service, off-line and at run-time. In this paper we outline a reference architecture for the autonomic and legislation-aware cloud service broker and we propose a run-time linear programming based model that consider legal constraints and that perform service adaptation for the assurance of QoS and legal rule compliance.;Yes;;;Yes;;No;No;Yes;No;Custom;Yes;No;Manual;Not optimized;No;No (service compliance);Compliance;Software Development / Cloud;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ESPRE51200.2020.00007;;Towards Variability-Aware Legal-GRL Framework for Modeling Compliance Requirements;2020;"Sartoli, Sara; Ghanavati, Sepideh; Siami Namin, Akbar";The increasing adoption of cloud computing is making operating environments highly dynamic and changing. Once an operating environment condition (e.g., geographical location of data) changes, the compliance requirements might alsochange. To ensure that compliance requirements are continuouslymet, there is a need for frameworks that not only support modeling regulations, but also capture the potential environment variabilities and conditions in a systematic way. This paper introduces Variability-Aware Legal-GRL (Goal-oriented Requirements Language) framework for modeling compliance requirements in the presence of runtime changes. We extend the Goal-oriented Requirements Language (GRL) with new elements and model construction rules to model context-aware privacy policies for dynamic multi-jurisdictional domains as well as features for monitoring changes that trigger adaptation. We motivate and illustrate the proposed framework using Health Insurance Portability and Accountability Act (HIPAA) and Personal Health Information Protection Act (PHIPA) statements. The proposed modeling framework allows software engineers to automatically quantify and analyze satisfaction level of security and privacy related top level goals for multiple software design alternatives and thus, choose the best set of privacy measures.;Yes;;;Yes;;No;No;Yes;No;Legal-GRL, extension of GRL;Yes;From Hohfeldian model;Manual;Not optimized;No;Yes;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ACCESS.2024.3512434;;Human-in-the-Loop Learning With LLMs for Efficient RASE Tagging in Building Compliance Regulations;2024;"Al-Turki, Dhoyazan; Hettiarachchi, Hansi; Medhat Gaber, Mohamed; Abdelsamea, Mohammed M.; Basurra, Shadi; Iranmanesh, Sima; Saadany, Hadeel; Vakaj, Edlira";Automated compliance checking (ACC) in the Architecture, Engineering, and Construction (AEC) sector represents a pivotal task which is traditionally executed manually, demanding significant time and labor. This work investigates the automation of the Requirement, Applicability, Selection, and Exception (RASE) methodology for building regulatory compliance through the utilization of Large Language Models (LLMs) and active learning techniques. Specifically, we focus on the development and assessment of a system using the OpenAI GPT-4o model to transmute building regulation texts into structured YAML formats conducive to ACC processes. The study encompasses three experimental paradigms: few-shot learning, fine-tuning learning, and progressive active learning. Initial results from the few-shot learning experiment illustrate the model’s preliminary ability to interpret and process regulatory texts with limited examples. Fine-tuning enhances model performance by training it on a specialized dataset, thereby improving structural and textual accuracy. Progressive active learning, by iteratively incorporating expert feedback, further refines the accuracy of the model. The findings demonstrate substantial enhancements in both structural and semantic accuracies of the generated YAML files, underscoring the potential of integrating LLMs with active learning to streamline regulatory compliance automation. The methodologies and results presented here offer a comprehensive framework for advancing future research and practical applications in the domain of automated regulatory compliance.;Yes;;;Yes;;No;No;Yes;No;Building Compliance Rule Language (BCRL) - Markup with first order logic;No;To ACC (domain specific language);Automatic;Not optimized, but mentioned;No;No;Building design safety;Construction / Architecture;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/REW.2016.048;;Argumentation-Based Legal Requirements Engineering: The Role of Legal Interpretation in Requirements Acquisition;2016;"Muthuri, Robert; Boella, Guido; Hulstijn, Joris; Humphreys, Llio";The elicitation of legal requirements is more complex than the analysis of relevant legislation, subsidiary regulations or industrial standards. This paper aims to start bridging the efforts in legal informatics with those of legal requirements engineering towards effective legal requirements acquisition. The paper traces the steps involved in the interpretive process to illustrate how legal interpretation may affect the acquisition and specification of legal requirements for a given system. We apply informal logic to bridge the gap between the principles of interpretation in legal theory with the legal rules that determine compliance of business processes. We specifically apply argumentation schemes to characterize interpretive arguments which are then applied to business processes represented using value modelling. Other argumentation schemes are also applied to help generate the foregoing arguments and give structure to the interpretive process generally.;Yes;Might also be valuable for discussion;;No;Too focused on requirements elicitation, not LIR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE.2006.68;;Towards Regulatory Compliance: Extracting Rights and Obligations to Align Requirements with Regulations;2006;"Breaux, Travis D.; Vail, Matthew W.; Anton, Annie I.";In the United States, federal and state regulations prescribe stakeholder rights and obligations that must be satisfied by the requirements for software systems. These regulations are typically wrought with ambiguities, making the process of deriving system requirements ad hoc and error prone. In highly regulated domains such as healthcare, there is a need for more comprehensive standards that can be used to assure that system requirements conform to regulations. To address this need, we expound upon a process called semantic parameterization previously used to derive rights and obligations from privacy goals. In this work, we apply the process to the privacy rule from the U.S. Health Insurance Portability and Accountability Act (HIPAA). We present our methodology for extracting and prioritizing rights and obligations from regulations and show how semantic models can be used to clarify ambiguities through focused elicitation and to balance rights with obligations. The results of our analysis can aid requirements engineers, standards organizations, compliance officers, and stakeholders in assuring systems conform to policy and satisfy requirements;Yes;;;Yes;;No;No;Yes;No;"semantic models (patterns, Knowledge
Transformation Language)";No;No;mostly manual with tool support;Not optimized;No;No;Requirements Alignment;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ICMLCA63499.2024.10754395;;Adchat-TVQA: Innovative Application of LLMs-Based Text-Visual Question Answering Method in Advertising Legal Compliance Review;2024;"Gao, Ruiling; Hou, Yingqi; Tang, Weijie; Zhang, Jin; Hu, Yanbo; Huang, Haiyun; Tan, Wen'an; Li, Liping";Advertising legal compliance reviews have always been time-consuming and labor-intensive, and existing Large Language Models(LLMs) are far worse performing than senior industry experts. In this paper, we propose a novel LLMs-based text-visual question answering method called Adchat-TVQA for advertising legal compliance review. After reading an advertising image and the corresponding review question, it will first understand the content on the image through multimodal learning, then optimize the question with Zero-Shot Chain-of-Thought (CoT) prompting method based on predefined industry expert experience, and finally input the augmented question into the large language model for inquiry. The feasibility of this method is verified through system prototype implementation and end-to-end functional tests. In addition, we summarized the characteristics of advertising images and added image segmentation and text box transpose to the data processing process for system performance improvement. Performance testing of the text visual cognitive question task on the AIWIN2021 dataset shows that the method scores higher than Microsoft's LayoutLM, with an increasement of the score from 51.52% to 52.74%.;Yes;This is an expert support system / QA system so a bit out of the ordinary;;No;No actual representation of law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/SmartTechCon.2017.8358512;;Implementing interchange of legal data under information system using a subset by deriving on the form of akoma ntosa in context of right to information by encoding application and appeal;2017;"Kumar Singh, Manoj; Mishra, Anuranjan";Our law enforcing system called as Indian Legal System is lacking in terms of computerisation intelligent enough to enable law open for everybody. We are moving towards Digital India in all spheres of activity. In our country majority of people are not aware of the law of the land. AKOMA-NTOSO is an international technical standard for representing judiciary documents in addition to executive & legislative in a structured manner. We can call it XML vocabulary on law and it suggests also a convention of giving name for providing unique identifier to legal sources based on FRBR mode. There is no effort has been made to create standard representation of law in India. The subject matter of the paper goes into detail of creation of standard representation of parts of RTI Act 2005 for its implementation under a given circumstances. The process model of second appeal was undertaken. It was found that majority of RTI appeals at CIC are returned only for the reason that rule 8 and 9 of the RTI Act has not been fulfilled. The study captured the process of filing second appeal and created a schema of representation of various components and system prototype to check the compliance before accepting second appeal. The schema was created using subset of AKOMA-NTOSO schema, XML & HTML standard. The result shows that quality of services are improved by eighty percent(80%) and it has the potential to augment the way to create schema for entire RTI ACT. There are challenges associated with complexities in judicial system and quality of encoding of law on the basis of schema created and development of system to act accordingly. The study provided evidence that data on law can be interchanged among various system with semantic and technical interpretability.;Yes;More of a use case so not 100% sure;;Yes;;No;No;Yes;No;Akoma Ntoso;No;No;manual;not optimized;No;No;formalization;Indian appeal law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/CBI.2017.1;;The Conjoint Modeling of Value Networks and Regulations of Smart Grid Platforms: A Luxembourg Case Study;2017;"Razo-Zapata, Iván S.; Ma, Qin; Kaczmarek-Heß, Monika; de Kinderen, Sybren";The liberalization and digitalization of the energy sector have given rise to smart grid platforms, whereby energy and information flow in multiple directions and a diverse set of actors add value to the platform. To foster understanding of a smart grid value network, in terms of the involved actors and the value they exchange, conceptual value modeling techniques have been successfully used. However, value modeling is agnostic to the reasons behind a particular value network configuration. Thus, it is not able to capture an important aspect that determines the configuration of a smart grid value network, namely regulations. In this paper, we complement value modeling with the goal-driven modeling of regulations. As such, we take a first step towards showing compliance between value networks and the regulations behind it. We illustrate our approach with a scenario of producing and consuming green electricity in Luxembourg.;Yes;Not 100% I understood the paper;;Yes;;No;No;Yes;No;Goal Requirements Language (GRL);No;No;manual;GRL is supposed to be human understandable;Yes;No;Compliance;Electricity Market;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE.2013.6636760;;The regulatory world and the machine: Harmonizing legal requirements and the systems they affect;2013;Gordon, David G.;The past decade has seen a substantial increase in the issuance of privacy and security regulations governing personal information. Ensuring system and organizational compliance is both more important and more difficult than ever before, as the penalties have become more severe, and regulations more complex and nuanced. This also presents substantial difficulties for multi-national companies, as different states, countries, or regions do not adhere to a uniform standard, resulting in a mixed set of regulations for the systems they govern. In this work, I describe a framework to address this issue, referred to as requirements water marking, wherein requirements from different jurisdictions that govern the same system may be evaluated and reduced to a single standard of care, establishing a “high water mark” for regulatory compliance and reducing requirements complexity. The framework, which draws on work in requirements specification languages and requirements comparison, allows engineers and legal experts to systematically simplify compliance and determine both high and low standards of care, while maintaining traceability back to the original legal text. In addition, I investigate the proposed value of legal requirements models, demonstrating the relationship between proposed value of these models to organizational decision-making and the validity of the model.;Yes;;;No;Uses LIR (LRSL) but does not really focus on it;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/LISAT.2015.7160190;;Extending XACML to express and enforce laws and regulations privacy policies;2015;"Alshugran, Tariq; Dichter, Julius; Rusu, Amalia";Some software applications are developed to collect, store, and manage users' personal, medical, or financial information. In the United States, such applications are required to preserve users' privacy and to be compliant with the federal privacy laws and regulations. To formally guarantee compliance with federal regulations, it is necessary to express the privacy rules enforced by those regulations in a standard policy specification language. In this work we evaluate the eXtensible Access Control Model Language (XACML) as a formal specification language for privacy laws and regulations. Furthermore, we evaluate XACML features and attributes to extend it in order to enforce those privacy rules.;Yes;Use case, so maybe not;;Yes;;No;No;Yes;No;Xtensible Access Control Model Language (XACML);No;No;tool supported;Not optimized;Yes;No;Access Control;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE.2009.21;;Developing Production Rule Models to Aid in Acquiring Requirements from Legal Texts;2009;"Maxwell, Jeremy C.; Anton, Annie I.";Regulatory compliance is an important consideration for requirements engineering because recent regulations impose costly penalties for noncompliance. This paper details how developing production rule models can aid in acquiring software requirements from regulatory texts. Production rules enable requirements engineers to gain valuable domain knowledge of a particular legal text by providing the ability to receive precise answers to a specific query. In particular, a production rule model facilitates communication between requirements engineers and legal domain experts, supports and augments requirements elicitation, and resolves ambiguity. Prior work in this area has failed to detail a precise methodology for translating a legal text into production rules, and considered using production rule models for aiding requirements elicitation and validation. This paper introduces our production rule modeling methodology, and demonstrates this methodology using examples from a production rule model for four sections of the U.S. Heath Insurance Portability and Accountability Act (HIPAA).;Yes;;;Yes;;No;No;Yes;No;Prolog;Tracebility is given but not automatically;No;Manual;Not optimized;No (future work);No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ARES.2008.79;;Annotating Regulations Using Cerno: An Application to Italian Documents - Extended Abstract;2008;"Zeni, Nicola; Kiyavitskaya, Nadzeya; Cordy, James R.; Mich, Luisa; Mylopoulos, John";The increasing complexity of software systems and growing demand for regulations compliance require effective methods and tools to support requirements analysts activities. Internationalization of information systems due to both economics and Web based architectures call for the application of regulations written in different languages. Thus far existing approaches for extracting rights and obligations have concentrated on English documents. In this paper, we describe the results of the application of Cerno, a lightweight framework for semantic annotation, to legal documents written in Italian. In addition, we investigate critical issues for semantic annotation tools in a different cultural and environmental context. Results obtained, while preliminary, allow us to quantify the effort needed to port tools based on Cerno and give some insight on directions of future development of a multilingual system to support semantic annotation of regulations not only in different domains, but also written in different languages.;Yes;Extended Abstract?;;Yes;;No;No;Yes;No;First order predicate logic;No;Just from semi-formal rights or oblications to first-order predicate logic;;Not optimized;No;Yes;Compliance;multinational e-procurement;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2012.6347801;;Measurement-oriented comparison of multiple regulations with GRL;2012;"Rifaut, André; Ghanavati, Sepideh";In recent years, intentional models have been adapted to capture and analyze compliance needs and requirements. Furthermore, intentional models have been used to identify the impact of regulations on organizational goals by helping to elicit different alternatives about the business operations supported by compliant business processes and services. In other works, intentional models based on measurement-frameworks have provided well-structured models of regulations and compliance alternatives. This paper integrates Goal-Oriented Requirements Language (GRL)-based methodologies with measurement-based methodologies to improve support for comparing regulations sharing the same concerns via the (measurement) objectivity.;Yes;;;Yes;;No;No;Yes;No;"Goal Requirements Language (GRL); GRLaw extension: classification of requirements based on Hohfeldian";;No;manual;Not optimized;No;Yes;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ICDSP.2013.6622811;;Surveillance ontology for legal, ethical and privacy protection based on SKOS;2013;"Arguedas, Virginia Fernandez; Izquierdo, Ebroul; Chandramouli, Krishna";In a world filled with heightened vandalism and terrorist activities, video surveillance forms an integral part of any incident investigation. While aiming to provide safety and security for the citizens, CCTV cameras are exponentially deployed around metropolitan cities. However, the information thus collected and further processed should comply with the legal and ethical rules defined by the law. The primary ethical issue invoked by surveillance activities in general is that of privacy. In order to ensure that a surveillance system framework complies with the legal, ethical and privacy requirements of the law, in this paper we present a Surveillance Ontology extending the SKOS foundational ontology. The objective of this ontology is to translate the high-level linguistic rules into the information that can be processed and used to assess the compliance of the video analysis module with the rules defined.;Yes;;;No;Not enough focus on the actual LIR. Very surface level discussion of what it contians, but no on any reasining aspects or similar;No;No;Yes;Yes;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/IEEM45057.2020.9309666;;Digital Twin for Legal Requirements in Production and Logistics based on the Example of the Storage of Hazardous Substances;2020;"Perez, G. C.; Korth, B.";This paper aims to show a conceptual approach to audit and evaluate compliance with legal requirements in production and logistics using a digital twin. The adherence to compliance on an operative and strategic level is of particular importance since complex legal requirements are closely linked to many everyday production and logistics processes. Non-compliance can endanger employees and the environment as well as result in financial and reputational damage. Especially use cases with regard to handling and storing hazardous substances is characterized by a large number of different laws, administrative regulations, and safety requirements. In this context, it is particularly important to create a suitable database to comply with legal requirements and thus to provide managers and employees with appropriate instructions for action. We propose the concept of the digital twin for legal requirements in production and logistics and define relevant events to create a suitable database.;Yes;"Cool idea with application to ""real world""";;No;Too conceptual;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RCIS.2012.6240443;;Extracting security requirements from relevant laws and regulations;2012;"Jorshari, Fatemeh Zarrabi; Mouratidis, Haralambos; Islam, Shareeful";For software systems that process and manage sensitive information, compliance with laws has become not an option but a necessity. Analysing relevant laws and aligning them with the system requirements is necessary for attaining compliance issues. But analyzing laws within the context of software system requirements is a difficult task, mainly because the concepts used in legal texts are different compared to the concepts used in requirements engineering. This paper contributes to that direction. In particular it presents a process to model and analyse laws and regulations and to support the elicitation of security requirements based on the relevant legal and system context. Finally a case study is used to demonstrate the applicability of the proposed approach.;Yes;Only security though;;No;No direct formalization (as mentioned in the conclusion / future work);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE59067.2024.00012;;AI-Enabled Regulatory Change Analysis of Legal Requirements;2024;"Abualhaija, Sallam; Ceci, Marcello; Sannier, Nicolas; Bianculli, Domenico; Briand, Lionel C.; Zetzsche, Dirk; Bodellini, Marco";Statutory law is subject to change as legislation develops over time – new regulation can be introduced, while existing regulation can be amended, or repealed. From a requirements engineering (RE) perspective, such change must be dealt with to ensure the compliance of software systems at all times. Understanding the implications of regulatory change on compliance of software requirements requires navigating hundreds of legal provisions. Analyzing instances of regulatory change entirely manually is not only time-consuming, but also risky, since missing a change may result in non-compliant software which can in turn lead to hefty fines. In this paper, we propose MURCIA, an automated approach that leverages recent language models to assist human analysts in analyzing regulatory changes. To build MURCIA, we define a taxonomy that characterizes the regulatory changes at the textual level as well as the changes in the text's meaning and legal interpretation. We evaluate MURCIA on four regulations from the financial domain. Over our evaluation set, MURCIA can identify textual changes with F1 score of 90.5%, and it can provide, according to our taxonomy, the text meaning and legal interpretation with an F1 score of 90.8% and 83.7%, respectively.;Yes;(Careful, RE focus);;Yes;Not 100% sure, this is very change focused and not really reasoning focused with the LIR. LIR is more of a ephemeral goal in between, the actual goal being change detection;No;No;Yes;No;LLM;Yes;;tool supported;Yes, natural language;Yes;No;change detection;"Software Development; Finance";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RePa.2012.6359976;;Using the Goal-oriented pattern family framework for modelling outcome-based regulations;2012;"Behnam, Saeed Ahamdi; Amyot, Daniel; Mussbacher, Gunter; Braun, Edna; Cartwright, Nick; Saucier, Mario";Outcome-based regulations focus on measurable goals rather than on prescriptive ways of achieving these goals. As regulators start evolving regulations towards an outcome-based approach, it becomes important to reuse knowledge about existing problems and solutions, and patterns are known to be a means of increasing reusability. Regulatory parties can benefit from a pattern-based framework that (i) lays down a foundation for capturing knowledge about business goals and processes, (ii) provides methods for reusing this knowledge by extracting and customizing models for specific stakeholders, and (iii) enables evolution of the knowledge when new problems and solutions emerge. In this paper, we provide systematic steps for eliciting requirements leading to the creation of patterns and families and show the applicability of the Goal-oriented Pattern Family framework in this novel context. We improve the framework's infrastructure and include the concept of indicator in the framework in order to facilitate the reuse of compliance measurement approaches, in context.;Yes;I do not think I have fully understood this approach...;;No;This is not really law modelling, but more generally goal definition;No;No;Yes;No;;;;;Yes, ;Yes;;Compliance;Aviation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RE.2011.6051647;;A legal cross-references taxonomy for identifying conflicting software requirements;2011;"Maxwell, Jeremy C.; Antón, Annie I.; Swire, Peter";Companies must ensure their software complies with relevant laws and regulations to avoid the risk of costly penalties, lost reputation, and brand damage resulting from noncompliance. Laws and regulations contain internal cross-references to portions of the same legal text, as well as cross-references to external legal texts. These cross-references introduce ambiguities, exceptions, as well as other challenges to regulatory compliance. Requirements engineers need guidance as to how to address cross-references in order to comply with the requirements of the law. Herein, we analyze each external cross-reference within the U.S. Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule to determine whether a cross-reference either: introduces a conflicting requirement, a conflicting definition, and/or refines an existing requirement. Herein, we propose a legal cross-reference taxonomy to aid requirements engineers in classifying cross-references as they specify . Analyzing cross-references enables us to address conflicting requirements that may otherwise thwart legal compliance. We identify five sets of conflicting compliance requirements and recommend strategies for resolving these conflicts.;Yes;Difficult because about cross reference, but explicitly mentions compliance so kind of have to.;;No;Too requirement focused;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/BigData62323.2024.10826058;;Juris-Informatics: Law for AI and Law of AI;2024;"Satoh, Ken; Takeda, Hideaki; Goebel, Randy; Kano, Yoshinobu; Kim, Mi-Young; Rabelo, Juliano; Yoshioka, Masaharu";"This paper presents an outline of our research project developed at our research center for ""Juris-Informatics"". ""Juris-Informatics"" is a research field based on two main topics; ""Law by AI"" and ""Law of AI"". ""Law by Ai"" is a research field where we investigate a support tool by AI for legal activities such as legal reasoning and legal document processing. ""Law of AI"" is a research field where we conduct research on legal control of AI such as considering the legal responsibility of AI and legal compliance of AI.";Yes;;;Yes;;No;Yes;Yes;No;PROLEG (Not a typo, basically prolog);No;No;Manual;Not optimized;Yes;No;Explainable retrieval and entailment;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/WSCAR.2016.25;;Using XACML to Enhance Compliance with Privacy Regulations in Health Sector;2016;"Atiq, Areej Mohammad; Alsulaiman, Laith A.";Many corporate organizations use personal information (e.g. customers, citizens, and employees data) to perform their business mandates. However, a very huge amount of the processed information is considered private and many countries have issued laws to regulate how private information is collected, stored, manipulated or disclosed [1][2][3]. We propose the adoption and usage of XACML as a framework to map and specify all privacy provisions found in government regulations in order to enhance compliance. We have chosen health sector regulations in Saudi Arabia as a case study to demonstrate the appropriateness of XACML to map all privacy provisions.;Yes;;;Yes;;No;No;Yes;No;XACML;No;No;manual;Not optimized;No;No;Access Control;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2013.6671347;;Preserving traceability and encoding meaning in legal requirements extraction;2013;"Breaux, Travis D.; Gordon, David G.";Information system developers must ensure that their systems comply with government laws and regulations. To demonstrate compliance, developers can trace from statements in law to their system specifications while preserving how they identify and interpret ambiguity. In this paper, we present an application of the legal requirements specification language (LRSL) as a means to encode laws into a machine-readable specification. The encoding reduces ambiguity by making relations between requirements statements explicit. These relations include refinement, pre- and post-conditions, and exceptions that shape the environment in which the developer's system must operate and limiting the behavior of the system to a set of mandatory and discretionary actions. We illustrate the LRSL using a legal excerpt from Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule, section164.512(f) governing disclosures of protected health information to law enforcement in the United States.;Yes;;;Yes;;No;No;Yes;No;"semi-formal; legal requirements specification language (LRSL)";No;No;mostly automatic;optimized;No;No;tracability between processes and law;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ICEBE.2013.39;;RP-Match: A Framework for Automatic Mapping of Regulations with Organizational Processes;2013;"Sapkota, Krishna; Aldea, Arantza; Younas, Muhammad; Duce, David A.; Bañares-Alcántara, René";Mapping organizational processes with applicable regulatory guidelines is an important step in Regulatory Compliance Management. The Automation of the mapping process can help the overall compliance process. Though existing approaches compute mapping between different entities (e.g., ontology mapping, sentence similarity, semantic similarity and regulation-requirement mapping), the automation of the mapping process between regulation and processes has not been fully investigated yet. In this paper, we present RP-Match framework and propose a cascading-priority algorithm in order to compute similarity between regulation and processes. The framework also takes account of the structures of the regulation ontology and organizational process ontology for the similarity measures. The framework is tested using a Pharmaceutical industry case study. Results obtained show significant improvement in the mapping process.;Yes;"This is a bit ""late in the pipeline"" and is not really ""pure LKM"" but I think this should still be fine. And it is a good paper";;Yes;;No;No;Yes;Yes;"Custom ontology; entity relation tripples";Yes, purpose of paper is to make change reaction easier though it is more about creating a representation that allows tracability between law and requirements;No;semi-automatic (see Semantic-ART paper);Not optimized;No;Yes;tracability between processes and law;general;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/℡ERISE.2015.13;;Impact of Legal Interpretation in Business Process Compliance;2015;"Ghanavati, Sepideh; Hulstijn, Joris";Regulations are often written as open norms. Thus, the development of systems that support compliance involves interpretation. Often, compliance officers consider several alternative solutions. Comparing the feasibility and deciding which alternative to select are important tasks. In this paper, we aim to show how analyzing the impact of several interpretation can be supported by requirements engineering tools, in particular, by Legal-URN. Two cases are used to illustrate the importance of interpretation and how Legal-URN facilitates it.;Yes;Seems like too meta, but actually presents LEGAL-URN as an implementation;;Yes;;No;Yes;Yes;No;Legal-URN -> Hofeldian classes and GRL;No, not mentioned;Yes;Manual creation, automatic evaluation;Not optimized;Yes, minimal;Yes;demonstrating interpretations;"General; finance; privacy";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/COMPSAC.2018.10322;;LIoPY: A Legal Compliant Ontology to Preserve Privacy for the Internet of Things;2018;"Loukil, Faiza; Ghedira-Guegan, Chirine; Boukadi, Khouloud; Benharkat, Aicha Nabila";The Internet of Things (IoT) provides the opportunity to collect, process and analyze data. This opportunity helps to understand preferences and life patterns of individuals in order to offer them customized services. However, privacy has become a significant issue due to the personal nature of the knowledge derived from these data and the involved potential risks. Despite the increasing legislation pressure, few proposed solutions have dealt with the privacy requirements, such as consent and choice, purpose specification, and collection limitation. In this paper, we propose a privacy ontology in order to incorporate privacy legislation into privacy policies while considering several privacy requirements. Our proposed ontology aims both at making the smart devices more autonomous and able to infer data access rights and enforcing the privacy policy compliance at the execution level. We implemented and evaluated our privacy ontology based on a healthcare scenario.;Yes;;;Yes;;No;No;Yes;Yes;OWL extension;No;No;tool supported;Not optimized;No;No;Compliance;IOT, Privacy, Healthcare;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/MITP.2017.3051333;;Cognitive Compliance for Financial Regulations;2017;"Agarwal, Arvind; Ganesan, Balaji; Gupta, Ankush; Jain, Nitisha; Karanam, Hima P.; Kumar, Arun; Madaan, Nishtha; Munigala, Vitobha; Tamilselvam, Srikanth G.";Regulations are rules and directives published by authorities to safeguard consumer interest in an industry. Compliance with such regulations is getting increasingly hard due both to the complexity of these documents, which require experts to read, understand, and interpret them manually, and to the sheer volume of regulatory change. Many CFOs rate this as their top challenge. The authors' Cogpliance platform uses a cognitive approach to achieve regulatory compliance. Here, they describe key compliance-related tasks and demonstrate how Cogpliance helps compliance officers to handle those tasks effectively.;Yes;Kind of basic ngl and this paper seems like more of an advert than actually a research paper?;;No;Honestly, I do not feel like including this as the description of everything reads like a surface level advert. I am sure the actual technology and research is great, but this paper is not;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/CLEI64178.2024.10700326;;OntoPriv: Enhancing Understanding and Compliance in Privacy Legislation via Legal Ontologies;2024;"Suntaxi, Gabriela; Ojeda, Kelvin; Rodríguez, Franciso";Protecting personal data has become a critical concern in an increasingly digitized world. Consequently, governments have proposed regulations to protect the privacy of their citizens. Organizations that handle personal information must adhere to these regulations. However, achieving compliance with these regulations is not straightforward, and a structured approach is needed to interpret, implement, and maintain adherence to them, given their complexity. To overcome these challenges, we introduce OntoPriv, a legal ontology designed to facilitate compliance with data protection regulations. OntoPriv provides a structured representation of legal knowledge, enabling organizations to better understand regulatory requirements, identify relevant obligations, and establish adequate data protection practices. This article discusses the development, implementation, and evaluation of OntoPriv and explores its potential impact on enhancing compliance and promoting a culture of privacy and accountability within organizations.;Yes;;;Yes;;No;No;Yes;Yes;Base Ontology;No;No;Manual;Not optimized, but visualisations provided;Yes;Yes;Relation Retrieval;Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/BigData59044.2023.10386684;;Graph-Based Approach for European Law Classification;2023;"Russo, Raffaele; Giuseppe, Giuliano Di; Vanacore, Alessandro; Gatta, Valerio La; Ferraro, Antonino; Galli, Antonio; Postiglione, Marco; Moscato, Vincenzo";Deep learning, owing to its transformative influence across a myriad of sectors, has recently made its foray into the legal domain, instigated by the surge in digitization. Among the multitude of applications in this space, legal document classification emerges as a pivotal yet complex undertaking. Legal texts, characterized by unique domain-centric semantics and intricate linguistic patterns, necessitate precision-driven classification systems for numerous practical implications. This paper illuminates the challenges and opportunities in automating the classification of European Union (EU) legal documents, emphasizing the interrelationships among statutes and the hierarchical nature of legal references. In this context, we introduce a novel graph data modeling technique that adeptly marries content-centric indicators with the relational dynamics inherent among diverse legal documents. Central to our approach is a framework that melds text embeddings with graph neural networks for the classification of legal documents aligned with their subject-based directories. Empirical evaluations on the EU law dataset underline the efficacy of our model across varying granularities, from general thematic categories to intricate subtopics. This endeavor not only augments the comprehensibility and accessibility of EU jurisprudence but also holds significant implications across regulatory compliance, legal research, and policy formulation, underscoring the potential of deep learning in reshaping legal paradigms.;Yes;"Idk, they argue it is important for compliance but tbh, this is ""just"" documetn classification";;No;Going against my initial judgment, the classified classes are somewhat EU specific. This is really just classification if you ask me;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/EDOCW.2015.29;;A Methodology for Extracting Legal Norms from Regulatory Documents;2015;Hashmi, Mustafa;We present a methodology to extract legal norms from regulatory documents for their formalisation and later compliance checking. The need for the methodology is motivated from the shortcomings of existing approaches where the rule type and process aspects relevant to the rules are largely overlook. The methodology incorporates the well – known IF. THEN structure extended with the process aspect and rule type, and guides how to properly extract the conditions and logical structure of the legal rules for reasoning and modelling of obligations for compliance checking.;Yes;;;Yes;;No;No;Yes;No;Semi-formal, IF … THEN;Yes, they mention it in the final remarks that the representation can be used for that. I will take their word as I do not quite see it;No;semi-automated;IF … THEN relatively easy to understand;No;Yes;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/BigDataSecurityHPSCIDS52275.2021.00013;;A Semantically Rich Knowledge Graph to Automate HIPAA Regulations for Cloud Health IT Services;2021;"Kim, Dae-young; Joshi, Karuna P.";As healthcare organizations adopt cloud-based services to manage their patient data, compliance with the rules and policies of the Health Insurance Portability and Accountability Act (HIPAA) regulation becomes increasingly complex. At present, HIPAA rules are available only in large textual format and require significant human effort to implement in the Health IT systems. Moreover, every change in the regulation, like the recent relaxation in telehealth policy due to the COVID-19 pandemic, has to be manually implemented in the IT system. We have developed a semantically rich Knowledge graph, using Semantic Web technologies to represent HIPAA rules in a machine-processable format. This will significantly help in automatically reasoning of HIPAA policies. In this paper, we describe our design along with the results of our study of the current status of research on HIPAA ontology. We have validated our design against use cases defined by the US Department of Health and Human Services (HHS). This knowledge graph can be integrated with existing healthcare systems to provide automated compliance with HIPAA policies.;Yes;;;Yes;;No;No;Yes;No (but a KG);OWL extension;No;No;manual;Not optimized;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/SEAMS.2013.6595503;;Law and adaptivity in requirements engineering;2013;"Ingolfo, Silvia; Silva Souza, Vítor E.";The great impact that law has on the design of software systems has been widely recognized in past years. However, little attention has been paid to the challenge of coping with variability characterizing the legal domain (e.g., multiple ways to comply with a given law, frequent updates to regulations, different jurisdictions, etc.) on the design of software systems. This position paper advocates the use of adaptation mechanisms in order to support regulatory compliance for software systems. First we show an example of how Zanshin, a requirements-based adaptation framework, can be used to design a system that adapts to legal requirements to accommodate legal variability. Then we examine how legal texts can be analyzed as sources for parameters and indicators needed to support adaptation. As motivating running example we consider legal situations concerning the Google driverless car and its recent legalization in the highways of Nevada and soon also in California.;Yes;Requirements Engineering not really general compliance, but I think this is still applicable;;No;Position Paper, not really a suggestion for implementation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/CeDEM.2017.25;;Legal Ontology for Open Government Data Mashups;2017;"Mockus, Martynas; Palmirani, Monica";An important pillar of Linked Open Government Data is to be able to mix datasets by using common ontologies in order to infer new knowledge. The open government datasets to be mashed-up by developers may be subject to distinct licenses, legal notices, terms of use, and applicable law and regulations from multiple jurisdictions. Within this complex ecosystem there is a need to create semi-automatic tools supported by an ontology to help technical reusers of Public Sector Information to utilize datasets according to their intended purpose and in compliance with the legal obligations that govern the rights to reuse the data. Unfortunately, some researchers may avoid considering all the legal frameworks that apply in the domain of Open Government Data and limit their investigation to only the area of licenses. To enable wider, compliant utilisation of mashed-up open data, we have analysed the European Union (EU) legal framework of reuse of Public Sector Information (PSI), the EU Database Directive and copyright framework and other legal sources (e.g., licenses, legal notices, terms of use) that can apply to open government Datasets. From this deep analysis we now model several major concepts in an Ontology of Open Government Data Licenses Framework for a Mash-up Model (OGDL4M). There have been earlier ontologies for creative commons or open licenses, but they did not anticipate the other legal constraints that arise from Open Government regulations. The OGDL4M ontology will be used for qualifying datasets in order to improve the accuracy of their legal annotation. The Ontology also aims to connect each applicable legal rule to official legal texts in order to direct legal experts and reusers to primary sources. This paper aims to present the modules of the OGDL4M ontology in depth and to describe some preliminary evaluation.;Yes;example ontology;;Yes;;No;No;Yes;Yes;RDF, OWL, UML;No;Yes (to Akima Ntoso);manual;Not optimized;No (It seems from the evaulation section that they planned it, but never actually did it?);No;Ontology for modeling open government data knowledge graphs;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/BigData.2017.8258353;;Automated knowledge extraction from the federal acquisition regulations system (FARS);2017;"Saha, Srishty; Joshi, Karuna P.; Frank, Renee; Aebig, Michael; Lin, Jiayong";With increasing regulation of Big Data, it is becoming essential for organizations to ensure compliance with various data protection standards. The Federal Acquisition Regulations System (FARS) within the Code of Federal Regulations (CFR) includes facts and rules for individuals and organizations seeking to do business with the US Federal government. Parsing and gathering knowledge from such lengthy regulation documents is currently done manually and is time and human intensive. Hence, developing a cognitive assistant for automated analysis of such legal documents has become a necessity. We have developed semantically rich approach to automate the analysis of legal documents and have implemented a system to capture various facts and rules contributing towards building an efficient legal knowledge base that contains details of the relationships between various legal elements, semantically similar terminologies, deontic expressions and cross-referenced legal facts and rules. In this paper, we describe our framework along with the results of automating knowledge extraction from the FARS document (Title 48, CFR). Our approach can be used by Big Data Users to automate knowledge extraction from Large Legal documents.;Yes;;;Yes;;No;No;Yes;Yes;OWL, RDF;No;No;semi-automatic;Not optimized;Yes;No;Knowledge extraction;Business Dealings with the US government: Federal Acquisition Regulations System (FARS);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/REW.2016.045;;Establishing Reusable Requirements Derived from Laws and Regulations for Medical Device Development;2016;"Hauksdóttir, Dagný; Ritsing, Brian; Andersen, Jens Christian; Mortensen, Niels H.";For many industries a key activity in product development is to demonstrate legislative compliance by showing, explicitly, that all relevant requirements from regulatory documents have been identified and addressed. The analysis and interpretation of standards and regulations requires considerable skills and consumes significant effort in product development. Therefore initiating reuse from the analysis and elicitation of requirements from standards and regulations may provide promising potential for gaining efficiency in development and also for assuring sufficient quality of the work. In this paper, a method to manage requirements from standards, by establishing a reusable requirements catalogue, is suggested and a metamodel illustrating the information needed for tractability between derived requirements and legal texts, needed to facilitate reuse, is demonstrated. The paper presents a case study, where reusable requirements covering secondary packaging for medical injection devices were established, using a spreadsheet layout to capture and document the information presented in the metamodel.;Yes;Note, this is a basic Excel approach basically, technically it's fitting but also maybe a bit primitive in terms of general applicability;;No;An argumetn can be made for cunlusion but I do not see anything interesting added here, this is a) requirements focused with no focus on BPC b) not very formalized c) has no reasoning capabilities;;;;;;;;;;;;Compliance;Medical devices;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/S0004-3702(03)00102-4;https://www.sciencedirect.com/science/article/pii/S0004370203001024;A reduction-graph model of precedent in legal analysis;2003;Branting, L. Karl;Legal analysis is a task underlying many forms of legal problem solving. In the Anglo-American legal system, legal analysis is based in part on legal precedents, previously decided cases. This paper describes a reduction-graph model of legal precedents that accounts for a key characteristic of legal precedents: a precedent's relevance to subsequent cases is determined by the theory under which the precedent is decided. This paper identifies the implementation requirements for legal analysis using the reduction-graph model of legal precedents and describes GREBE, a program that satisfies these requirements.;Yes;Precedent, but not pure retrieval;;Yes;;Yes;Yes;No;No;"Reduction Graph, GREBE; Propositional Logic";Yes, not super explicitely mentioned, but it is evident from the approach itself.;No;manual;Yes (Template text output);Yes, only for the evaluation;No;CBR;General, example compensation law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.future.2016.11.025;https://www.sciencedirect.com/science/article/pii/S0167739X16306641;Research challenges in legal-rule and QoS-aware cloud service brokerage;2018;"Casalicchio, Emiliano; Cardellini, Valeria; Interino, Gianluca; Palmirani, Monica";The ICT industry and specifically critical sectors, such as healthcare, transportation, energy and government, require as mandatory the compliance of ICT systems and services with legislation and regulation, as well as with standards. In the era of cloud computing, this compliance management issue is exacerbated by the distributed nature of the system and by the limited control that customers have on the services. Today, the cloud industry is aware of this problem (as evidenced by the compliance program of many cloud service providers), and the research community is addressing the many facets of the legal-rule compliance checking and quality assurance problem. Cloud service brokerage plays an important role in legislation compliance and QoS management of cloud services. In this paper we discuss our experience in designing a legal-rule and QoS-aware cloud service broker, and we explore relate research issues. Specifically we provide three main contributions to the literature: first, we describe the detailed design architecture of the legal-rule and QoS-aware broker. Second, we discuss our design choices which rely on the state of the art solutions available in literature. We cover four main research areas: cloud broker service deployment, seamless cloud service migration, cloud service monitoring, and legal rule compliance checking. Finally, from the literature review in these research areas, we identify and discuss research challenges.;Yes;Does not present a single LIR but rather shows a framework of integrating LKM into a system;;No (Ask Marisol);This is not a single LIR, but rather a use case where many LIRs are combined;No;No;Yes;Yes (contains ontologies);LegalML, Akoma Ntoso, OWL, (BPMN);Yes;No;semi-automatic;Yes (Main representations not, but human interaction points);Yes, bu tonly implicitely as mentioned in the methodology;Yes;Compliance;Cloud;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/S0167-9236(00)00085-3;https://www.sciencedirect.com/science/article/pii/S0167923600000853;INCAS: a legal expert system for contract terms in electronic commerce;2000;"Tan, Yao-Hua; Thoen, Walter";Electronic commerce is doing business via electronic networks. Paper-based trade documents such as, for example, request for quotation, purchase order or invoice are replaced by electronic messages, in particular Electronic Data Interchange (EDI) messages. These electronic messages are not only transmitted much faster than paper-based documents, but they can also be processed automatically by computers. An example of this automated processing of electronic messages is electronic contracting and negotiation where the actual trade contract is on-line negotiated and concluded via an electronic network. We present the legal expert system INCAS that can provide on-line explanations about the use of Incoterms in trade contracts. Incoterms stipulate which party (buyer or seller) is responsible for arranging and paying transport of the goods, and arranging the documents necessary for this transport (e.g. export and import clearance documents, certification of origin, quality certificates etc.). INCAS is implemented in the programming language Prolog. We also explain how the defeasible reasoning capability of Prolog is essential for modelling the reasoning about the Incoterms.;Yes;Not 100% sure but mentions Prolog so must be good;;No;EX9;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.aei.2021.101288;https://www.sciencedirect.com/science/article/pii/S1474034621000422;Ontology and rule-based natural language processing approach for interpreting textual regulations on underground utility infrastructure;2021;"Xu, Xin; Cai, Hubo";The nation’s massive underground utility infrastructure must comply with a multitude of regulations. The regulatory compliance checking of underground utilities requires an objective and consistent interpretation of the regulations. However, utility regulations contain a variety of domain-specific terms and numerous spatial constraints regarding the location and clearance of underground utilities. It is challenging for the interpreters to understand both the domain and spatial semantics in utility regulations. To address the challenge, this paper adopts an ontology and rule-based Natural Language Processing (NLP) framework to automate the interpretation of utility regulations – the extraction of regulatory information and the subsequent transformation into logic clauses. Two new ontologies have been developed. The urban product ontology (UPO) is domain-specific to model domain concepts and capture domain semantics on top of heterogeneous terminologies in utility regulations. The spatial ontology (SO) consists of two layers of semantics – linguistic spatial expressions and formal spatial relations – for better understanding the spatial language in utility regulations. Pattern-matching rules defined on syntactic features (captured using common NLP techniques) and semantic features (captured using ontologies) were encoded for information extraction. The extracted information elements were then mapped to their semantic correspondences via ontologies and finally transformed into deontic logic (DL) clauses to achieve the semantic and logical formalization. The approach was tested on the spatial configuration-related requirements in utility accommodation policies. Results show it achieves a 98.2% precision and a 94.7% recall in information extraction, a 94.4% precision and a 90.1% recall in semantic formalization, and an 83% accuracy in logical formalization.;Yes;Not sure if compliance, check paper;;Yes;;No;No;Yes;No (uses ontology);Deaontic Logic;No;only internal;Automatic for rule extraction, manual for ontology construction -> count as automatic;Not optimized;No;No;Compliance;Underground utility infrastructure;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.is.2021.101966;https://www.sciencedirect.com/science/article/pii/S0306437921001563;Lynx: A knowledge-based AI service platform for content processing, enrichment and analysis for the legal domain;2022;"Schneider, Julián Moreno; Rehm, Georg; Montiel-Ponsoda, Elena; Rodríguez-Doncel, Víctor; Martín-Chozas, Patricia; Navas-Loro, María; Kaltenböck, Martin; Revenko, Artem; Karampatakis, Sotirios; Sageder, Christian; Gracia, Jorge; Maganza, Filippo; Kernerman, Ilan; Lonke, Dorielle; Lagzdins, Andis; Gil, Julia Bosque; Verhoeven, Pieter; Diaz, Elsa Gomez; Ballesteros, Pascual Boil";The EU-funded project Lynx focuses on the creation of a knowledge graph for the legal domain (Legal Knowledge Graph, LKG) and its use for the semantic processing, analysis and enrichment of documents from the legal domain. This article describes the use cases covered in the project, the entire developed platform and the semantic analysis services that operate on the documents.;Yes;;;Yes;;No;No;Yes;No (uses ontology);KG: OWL;Yes;Yes;Semi-automated;Visualisation;Yes;Yes;Compliance;EU law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.clsr.2023.105903;https://www.sciencedirect.com/science/article/pii/S0267364923001139;Enforcing legal information extraction through context-aware techniques: The ASKE approach;2024;"Castano, Silvana; Ferrara, Alfio; Furiosi, Emanuela; Montanelli, Stefano; Picascia, Sergio; Riva, Davide; Stefanetti, Carolina";To cope with the growing volume, complexity, and articulation of legal documents as well as to foster digital justice and digital law, increasing effort is being devoted to legal knowledge extraction and digital transformation processes. In this paper, we present the ASKE (Automated System for Knowledge Extraction) approach to legal knowledge extraction, based on a combination of context-aware embedding models and zero-shot learning techniques into a three-phase extraction cycle, which is executed a number of times (called generations) to progressively extract concepts representative of the different meanings of terminology used in legal documents chunks. A graph-based data structure called ASKE Conceptual Graph is initially populated through a data preparation step, and it is continuously enriched at each ASKE generation with results of document chunk classification, new extracted terminology, and newly derived concepts. A quantitative evaluation of ASKE knowledge extraction and document classification is provided by considering the EurLex dataset. Furthermore, we present the results of applying ASKE to a real case-study of Italian case law decisions with qualitative feedback from legal experts in the framework of an ongoing national research project.;Yes;Meaning representation;;Yes;Not 100% sure if I should keep;No;No;Yes;No;semi-formal, KG;No;No;Automatic;Future Work;Yes;No;Knowledge extraction;EU Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.aei.2020.101239;https://www.sciencedirect.com/science/article/pii/S1474034620302081;Semantic information alignment of BIMs to computer-interpretable regulations using ontologies and deep learning;2021;"Zhou, Peng; El-Gohary, Nora";A semantic information alignment method is proposed to align the representations used in building information models (BIMs) to the representations used in energy regulations. Compared to existing alignment efforts, which are either manual or semi-automated, the proposed method aims to automate the alignment process for supporting fully automated energy compliance checking. A first-level simple alignment method is proposed to align single design information instances to single regulatory concepts, in which (1) domain knowledge is used for interpreting the meaning of concepts to recognize candidate instances, and (2) deep learning is used for capturing the semantics behind the words to measure semantic similarity and select the matches. A final complex alignment method is proposed to recognize the instance groups belonging to a regulatory requirement, in which (1) supervised and unsupervised searching algorithms are used to identify the instance pairs, and (2) network modeling is used to group and link the instance pairs to the requirement. The proposed method showed 93.4% recall and 94.7% precision on the testing data.;Yes;Alignment, not representation?;;No;Alignment does not really fit my RQs, no BPC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.is.2019.101469;https://www.sciencedirect.com/science/article/pii/S0306437919305216;Design principles for the General Data Protection Regulation (GDPR): A formal concept analysis and its evaluation;2020;Tamburri, Damian A.;Data and software are nowadays one and the same: for this very reason, the European Union (EU) and other governments introduce frameworks for data protection — a key example being the General Data Protection Regulation (GDPR). However, GDPR compliance is not straightforward: its text is not written by software or information engineers but rather, by lawyers and policy-makers. As a design aid to information engineers aiming for GDPR compliance, as well as an aid to software users’ understanding of the regulation, this article offers a systematic synthesis and discussion of it, distilled by the mathematical analysis method known as Formal Concept Analysis (FCA). By its principles, GDPR is synthesised as a concept lattice, that is, a formal summary of the regulation, featuring 144372 records — its uses are manifold. For example, the lattice captures so-called attribute implications, the implicit logical relations across the regulation, and their intensity. These results can be used as drivers during systems and services (re-)design, development, operation, or information systems’ refactoring towards more GDPR consistency.;Yes;;;Yes;;No;No;Yes;No;lattice;No;No;Semi-automated;Yes;Not optimized;No;Compliance;"Software Development; Privacy";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.knosys.2021.107082;https://www.sciencedirect.com/science/article/pii/S0950705121003452;Towards an efficient rule-based framework for legal reasoning;2021;"Liu, Qing; Islam, Badiul; Governatori, Guido";A rule based knowledge system consists of three main components: a set of rules, facts to be fed to the reasoning corresponding to the data of a case, and an inference engine. In general, facts are stored in (relational) databases that represent knowledge in a first-order based formalism. However, legal knowledge uses defeasible deontic logic for knowledge representation due to its particular features that cannot be supported by first-order logic. In this work, we present a unified framework that supports efficient legal reasoning. In the framework, a novel inference engine is proposed in which the Semantic Rule Index can identify candidate rules with their corresponding semantic rules if any, and an inference controller is able to guide the executions of queries and reasoning. It can eliminate rules that cannot be fired to avoid unnecessary computations in early stages. The experiments demonstrated the effectiveness and efficiency of the proposed framework.;Yes;;;Yes;;No;No;Yes;No;Defeasible logic with deontic operators;No;No;Manual  (unspecified);Not optimized;No;Yes;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/0167-739X(95)00003-B;https://www.sciencedirect.com/science/article/pii/0167739X9500003B;Contributions of FGCS technology to applications in legal reasoning;1995;Sergot, Marek;The Japanese Fifth Generation Computer Systems (FGCS) Project identified legal reasoning as one of the benchmark applications designed to demonstrate its newly developed technology. This paper reviews the FGCS work on legal reasoning, with the aim of assessing (1) its contribution to the field of automated legal reasoning, and (2) its contribution to the wider aims of the FGCS project, which may be summarised as the development of new technologies intended to open up important new classes of applications. A secondary aim of the paper is to provide a summary of some of the main strands of research that have been carried out in the field of Artificial Intelligence and law in recent years.;Yes;Not 100% sure, have to read paper;;Yes;;No;No;Yes;No;Predicate logic;No;No;Manual  (unspecified);Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.artint.2020.103348;https://www.sciencedirect.com/science/article/pii/S0004370219301110;Designing normative theories for ethical and legal reasoning: LogiKEy framework, methodology, and tool support;2020;"Benzmüller, Christoph; Parent, Xavier; Torre, Leendert van der";A framework and methodology—termed LogiKEy—for the design and engineering of ethical reasoners, normative theories and deontic logics is presented. The overall motivation is the development of suitable means for the control and governance of intelligent autonomous systems. LogiKEy's unifying formal framework is based on semantical embeddings of deontic logics, logic combinations and ethico-legal domain theories in expressive classic higher-order logic (HOL). This meta-logical approach enables the provision of powerful tool support in LogiKEy: off-the-shelf theorem provers and model finders for HOL are assisting the LogiKEy designer of ethical intelligent agents to flexibly experiment with underlying logics and their combinations, with ethico-legal domain theories, and with concrete examples—all at the same time. Continuous improvements of these off-the-shelf provers, without further ado, leverage the reasoning performance in LogiKEy. Case studies, in which the LogiKEy framework and methodology has been applied and tested, give evidence that HOL's undecidability often does not hinder efficient experimentation.;Yes;;;Yes;Not 100% sure , a tiny bit too meta maybe;Yes;No;Yes;No;HOL covers deontic logic, modal logic;No;Yes, for example propositional to first order logic, but more generally deontic logic to the internal Higher order logic;Manual;Includes UI;No;No;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.compag.2018.05.007;https://www.sciencedirect.com/science/article/pii/S0168169918303260;Machine learning for automatic rule classification of agricultural regulations: A case study in Spain;2018;"Espejo-Garcia, Borja; Martinez-Guanter, Jorge; Pérez-Ruiz, Manuel; Lopez-Pellicer, Francisco J.; Zarazaga-Soria, F. Javier";Currently, pest management practices require modern equipment and the use of complex information, such as regulations and guidelines. The complexity of regulations is the root cause of the emergence of automated solutions for compliance assessment by translating regulations into sets of machine-processable rules that can be run by specialized modules of farm management information systems (FMIS). However, the manual translation of rules is prohibitively costly, and therefore, this translation should be carried out with the support of artificial intelligence techniques. In this paper, we use the official Spanish phytosanitary products registry to empirically evaluate the performance of four popular machine learning algorithms in the task of correctly classifying pesticide regulations as prohibitions or obligations. Moreover, we also evaluate how to improve the performance of the algorithms in the preprocessing of the texts with natural language processing techniques. Finally, due to the specific characteristics of the texts found in pesticide regulations, resampling techniques are also evaluated. Experiments show that the combination of the machine learning algorithm Logic regression, the natural language technique part-of-speech tagging and the resampling technique Tomek links is the best performing approach, with an F1 score of 68.8%, a precision of 84.46% and a recall of 60%. The experimental results are promising, and they show that this approach can be applied to develop a computer-aided tool for transforming textual pesticide regulations into machine-processable rules. To the best of our knowledge, this is the first study that evaluates the use of artificial intelligence methods for the automatic translation of agricultural regulations into machine-processable representations.;Yes;;;No ;just classification of prohibition vs obligation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/0167-9236(94)90029-9;https://www.sciencedirect.com/science/article/pii/0167923694900299;Defeasible reasoning in law;1994;"Dewitz, Sandra K.; Ryu, Young; Lee, Ronald M.";"Numerous legal scholars have asserted that legal reasoning is largely a deductive process in which legal rules are applied to the facts of a case in order to derive a conclusion. Though some might contest this assertion, it seems that what we know as law is largely a system of rules. However, these rules are not immutable and fully consistent; in many cases, multiple rules can be applied to the facts of a case, the conclusion derived from one rule conflicting with and potentially defeating that derived from another rule. In this paper, we discuss legal reasoning as defeasible reasoning and present a prototype of a computer-based legal reasoning system to illustrate the advantages of our approach. Defeasible reasoning is an appropriate foundation for the development of legal support systems because it not only can support the non-monotonicity of legal rules but also can resolve many of the conflicts that arise in applying these rules.";Yes;;;Yes;;No;Yes;Yes;No;Defeasible logic, d-Prolog;Not No;Yes;Manual;Yes, IF … THEN;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.is.2021.101842;https://www.sciencedirect.com/science/article/pii/S0306437921000788;A knowledge-centered framework for exploration and retrieval of legal documents;2022;"Castano, Silvana; Falduti, Mattia; Ferrara, Alfio; Montanelli, Stefano";Automated legal knowledge extraction systems are strongly demanded, to support annotation of legal documents as well as knowledge extraction from them, to provide useful and relevant suggestions to legal actors (e.g., judges, lawyers) for managing incoming new cases. In this paper, we propose CRIKE (CRIme Knowledge Extraction), a knowledge-based framework conceived to support legal knowledge extraction from a collection of legal documents, based on a reference legal ontology called LATO (Legal Abstract Term Ontology). We first introduce LATO-KM, the knowledge model of LATO where legal knowledge featuring documents in the collection is properly formalized as conceptual knowledge, in form of legal concepts and relationships, and terminological knowledge, in form of term-sets associated with legal concepts. Then, we present the bootstrapping cycle of CRIKE that aims to progressively enrich the terminological knowledge layer of LATO by extracting new terms from legal documents to be used for enriching the term-set associated with a corresponding legal concept. Finally, to evaluate the results obtained through CRIKE, we discuss experimental results on a real dataset of 180,000 court decisions of the State of Illinois taken from the Caselaw Access Project (CAP).;Yes;;;Yes;;No;No;Yes;Yes;Semi-formal, KG;Yes;No;Semi-automatic;Not optimized;Yes;No;Knowledge extraction;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.procs.2017.08.109;https://www.sciencedirect.com/science/article/pii/S1877050917314643;Towards a Legal Rule-Based System Grounded on the Integration of Criminal Domain Ontology and Rules;2017;"Ghosh, Mirna El; Naja, Hala; Abdulrab, Habib; Khalil, Mohamad";This research aims to define an integrated strategy for modelling legal norms in the criminal domain for supporting the legal reasoning. For this purpose, OWL-DL criminal domain ontology is captured from legal texts, using a middle-out approach, and legal rules are then formalized based on the ontology. The goal is to construct a legal rule-based decision support system for the Lebanese criminal domain, grounded on the integration of the criminal domain ontology and set of logic rules which are defined using the expressive ability of SWRL rule language.;Yes;;;Yes;only obligations;No;No;Yes;No;First order logic;No;No;tool supported;Not optimized;Yes;No;Reasoning, Decision support;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.knosys.2022.109046;https://www.sciencedirect.com/science/article/pii/S0950705122005123;Learning heterogeneous graph embedding for Chinese legal document similarity;2022;"Bi, Sheng; Ali, Zafar; Wang, Meng; Wu, Tianxing; Qi, Guilin";Measuring the similarity between legal documents to find prior documents from a massive collection that are similar to a current document is an essential component in legal assistant systems. This type of system can automatically link related legal documents to ensure that the same situations are treated identically in judicial practice. Most existing methodologies propose text- and citation-based methods to calculate the similarity between legal documents. However, those methods have difficulty capturing the semantics of many legal entities and giving more accurate similarity. The main reason is the lack of legal domain knowledge and citation relations between legal documents. We introduce practical, generic heterogeneous graph representation learning based on a legal heterogeneous knowledge graph to address these challenges. Specifically, we construct a heterogeneous knowledge graph containing legal entities and documents and develop a graph-based embedding model called L-HetGRL. A legal entity can simply be simply a legal-related encyclopedia entry that contains legal-domain knowledge utilized to enhance document representation. L-HetGRL incorporates learning legal document information and external legal domain knowledge in a unified manner by jointly considering heterogeneous content. In addition, we designed a legal case-aware semantic alignment module that effectively combines legal entities and their semantics in documents, thus improving the representation of entities. We conducted comprehensive experiments, including similar case matching and charge prediction, to evaluate the performance of our L-HetGRL on two real-world datasets. As a result, the experimental evaluations demonstrate that L-HetGRL outperforms other competitive baselines. In addition, we present a series of suggestions for document representation in the legal domain, which provide valuable guidelines for follow-up studies.;Yes;;;No;Retrieval focused;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/S0743-1066(96)00141-0;https://www.sciencedirect.com/science/article/pii/S0743106696001410;Representing actions: Laws, observations and hypotheses;1997;"Baral, Chitta; Gelfond, Michael; Provetti, Alessandro";We propose a modificationL 1 of the action description languageA. The languageL 1 allows representation of hypothetical situations and hypothetical occurrence of actions (as inA) as well as representation of actual occurrences of actions and observations of the truth values of fluents in actual situations. The corresponding entailment relation formalizes various types of common-sense reasoning about actions and their effects not modeled by previous approaches. As an application of L1 we also present an architecture for intelligent agents capable of observing, planning and acting in a changing environment based on the entailment relation of L1 and use logic programming approximation of this entailment to implement a planning module for this architecture. We prove the soundness of our implementation and give a sufficient condition for its completeness.;Yes;;;No;No focus on the legal domain;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.aei.2024.102735;https://www.sciencedirect.com/science/article/pii/S1474034624003835;Intermediate representations to improve the semantic parsing of building regulations;2024;"Fuchs, Stefan; Dimyadi, Johannes; Witbrock, Michael; Amor, Robert";Recent developments show that large transformer-based language models have the capability to generate coherent text and source code in response to user prompts. This capability can be used in the construction domain to interpret building regulations and convert them into a formal representation usable for automated compliance checking. While base-size models can already be taught to perform semantic parsing with decent quality, this paper shows how Intermediate Representations (IRs) can be used to improve the semantic parsing quality. With reversible IRs, the training time was reduced to almost a quarter of the initial duration, and through adding a hierarchical parsing step, improvements of up to 6.6% on F1 scores were reached. Furthermore, intermediate representations provide a novel and interpretable method towards a human-in-the-loop approach for translating building regulations into a formal representation.;Yes;;;Yes;Will focus on the end result of creating LegalLM not the actual research on creating LegalLM efficiently :D;No;No;Yes;No;LegalRuleML;No;Yes;Semi-automated;Not optimized;No;No;Compliance;Building regulations;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/0743-1066(94)90041-8;https://www.sciencedirect.com/science/article/pii/0743106694900418;Hierarchical representation of legal knowledge with metaprogramming in logic;1994;"Barklund, Jonas; Hamfelt, Andreas";We present an application of metaprogramming in logic that, unlike most metaprogramming applications, is not primarily concerned with controlling the execution of logic programs. Metalevel computation is used to define theories from schemata that were either given explicitly or obtained by abstraction from other theories. Our main application is a representation of legal knowledge in a metalogic programming language. We argue that legal knowledge is multilayered and therefore a single level representation language lacks the needed expressiveness. We show that legal rules can be partitioned into primary, secondary, tertiary, quaternary, and higher level rules. Our classification enables us to define a multilevel model of legal knowledge and a one-to-one correspondence with levels of metaprogramming in logic. We show that this framework has a potential for capturing important legal interpretation principles such as analogia legis, lex specialis legi generali derogat, etc. We have a running example from commercial law that utilizes rules up to the tertiary level, emphasizing analogia legis. The example is expressed in a multilevel metalogic programming language that provides a naming convention and employs reflection between levels.;Yes;;;Yes;This is interesting for focusing more on a meta level of rules, i.e. representing rules about rules. This reminds me of tempaltes;No;No;Yes;No;Alloy: Prolog with meta reasoning extension;No;No;Manual;Not optimized;No;No;Meta reasoning about rules;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.clsr.2024.106073;https://www.sciencedirect.com/science/article/pii/S0267364924001390;Bayesian deep learning: An enhanced AI framework for legal reasoning alignment;2024;"Zhang, Chuyue; Meng, Yuchen";"The integration of artificial intelligence into the field of law has penetrated the underlying logic of legal operations. Currently, legal AI systems face difficulties in representing legal knowledge, exhibit insufficient legal reasoning capabilities, have poor explainability, and are inefficient in handling causal inference and uncertainty. In legal practice, various legal reasoning methods (deductive reasoning, inductive reasoning, abductive reasoning, etc.) are often intertwined and used comprehensively. However, the reasoning modes employed by current legal AI systems are inadequate. Identifying AI models that are more suitable for legal reasoning is crucial for advancing the development of legal AI systems. Distinguished from the current high-profile large language models, we believe that Bayesian reasoning is highly compatible with legal reasoning, as it can perferm abductive reasoning, excel at causal inference, and admits the ""defeasibility"" of reasoning conclusions, which is consistent with the cognitive development pattern of legal professionals from apriori to posteriori. AI models based on Bayesian methods can also become the main technological support for legal AI systems. Bayesian neural networks have advantages in uncertainty modeling, avoiding overfitting, and explainability. Legal AI systems based on Bayesian deep learning frameworks can combine the advantages of deep learning and probabilistic graphical models, facilitating the exchange and supplementation of information between perception tasks and reasoning tasks. In this paper, we take perpetrator prediction systems and legal judegment prediction systems as examples to discuss the construction and basic operation modes of the Bayesian deep learning framework. Bayesian deep learning can enhance reasoning ability, improve the explainability of models, and make the reasoning process more transparent and visualizable. Furthermore, Bayesian deep learning framework is well-suited for human-machine collaborative tasks, enabling the complementary strengths of humans and machines.";Yes;DL approach always cool;;No;Not really focused on LIR, rather on the implications of deep learning and statistical methods as a whole. Mybe for discussion though;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.artint.2023.103861;https://www.sciencedirect.com/science/article/pii/S0004370223000073;Explainable AI tools for legal reasoning about cases: A study on the European Court of Human Rights;2023;"Collenette, Joe; Atkinson, Katie; Bench-Capon, Trevor";In this paper we report on a significant research project undertaken to design, implement and evaluate explainable decision-support tools for deciding legal cases. We provide a model of a legal domain, Article 6 of the European Convention on Human Rights, constructed using a methodology from the field of computational models of argument. We describe how the formal model has been developed, extended and transformed into practical tools, which were then used in evaluation exercises to determine the effectiveness and usability of the tools. The underpinning AI techniques used yield a level of explanation that is firmly grounded in legal reasoning and is also digestible by the target end users, as demonstrated through our evaluation activities. The results of our experimental evaluation show that on the first pass, our tool achieved an accuracy rate of 97% in matching the actual decisions of the cases and the user studies conducted gave highly encouraging results with respect to usability. As such, our project demonstrates how trustworthy AI tools can be built for a real world legal domain where critical needs of the end users are accounted for.;Yes;;;Yes;;Yes;Yes;No;No;ADF;Yes;No;manual;GUI;Yes;No;Legal argument;Human Rights;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/S0004-3702(03)00108-5;https://www.sciencedirect.com/science/article/pii/S0004370203001085;A model of legal reasoning with cases incorporating theories and values;2003;"Bench-Capon, Trevor; Sartor, Giovanni";Reasoning with cases has been a primary focus of those working in AI and law who have attempted to model legal reasoning. In this paper we put forward a formal model of reasoning with cases which captures many of the insights from that previous work. We begin by stating our view of reasoning with cases as a process of constructing, evaluating and applying a theory. Central to our model is a view of the relationship between cases, rules based on cases, and the social values which justify those rules. Having given our view of these relationships, we present our formal model of them, and explain how theories can be constructed, compared and evaluated. We then show how previous work can be described in terms of our model, and discuss extensions to the basic model to accommodate particular features of previous work. We conclude by identifying some directions for future work.;Yes;Common Law;;Yes;;Yes;Yes;No;No;Formal, custom formalization;No, but discussed;No;manual;Not optimized;No;No;Legal argument;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.compag.2019.03.027;https://www.sciencedirect.com/science/article/pii/S0168169918311402;End-to-end sequence labeling via deep learning for automatic extraction of agricultural regulations;2019;"Espejo-Garcia, Borja; Lopez-Pellicer, Francisco J.; Lacasta, Javier; Moreno, Ramón Piedrafita; Zarazaga-Soria, F. Javier";In the European Union, production standards in the form of legal regulations play an important role in farming. Because of the increasing amount of regulations, it is desirable to transform human-oriented regulations into a set of computer-oriented rules to provide decision support through the Farm Management Information System. To obtain the logical structure of rules, automatically labeling their meaningful information is necessary. In this work, we evaluate the performance of 8 different state-of-the-art deep learning architectures to develop an end-to-end sequence labeler for phytosanitary regulations. This sequence labeler extracts different meaningful information items to determine which pesticides can be applied to a crop, the place of the treatment, when it can be applied, and the maximum number of applications. The architectures evaluated do not require feature engineering and, hence, they are applicable to the agricultural regulations of different countries. The best system is a neural network that uses character embeddings, Bidirectional Long short-term memory and Softmax. It achieves a performance of 88.3% F1 score.;Yes;;;No;"Will disregard as ""only"" sequence labelling";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.cose.2008.08.001;https://www.sciencedirect.com/science/article/pii/S0167404808000679;A distributed requirements management framework for legal compliance and accountability;2009;"Breaux, Travis D.; Antón, Annie I.; Spafford, Eugene H.";Increasingly, new regulations are governing organizations and their information systems. Individuals responsible for ensuring legal compliance and accountability currently lack sufficient guidance and support to manage their legal obligations within relevant information systems. While software controls provide assurances that business processes adhere to specific requirements, such as those derived from government regulations, there is little support to manage these requirements and their relationships to various policies and regulations. We propose a requirements management framework that enables executives, business managers, software developers and auditors to distribute legal obligations across business units and/or personnel with different roles and technical capabilities. This framework improves accountability by integrating traceability throughout the policy and requirements lifecycle. We illustrate the framework within the context of a concrete healthcare scenario in which obligations incurred from the Health Insurance Portability and Accountability Act (HIPAA) are delegated and refined into software requirements. Additionally, we show how auditing mechanisms can be integrated into the framework and how auditors can certify that specific chains of delegation and refinement decisions comply with government regulations.;Yes;;;No;the obligations are not modelled themselves, there is just a model presented for the tracability / a meta model;No;No;Yes;No;;Yes;No;manual;Not optimized;No;Yes;Demonstrating compliance, tracability (not actually compliance itself in a way);Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.cose.2022.102697;https://www.sciencedirect.com/science/article/pii/S0167404822000955;Assessing frameworks for eliciting privacy & security requirements from laws and regulations;2022;Olukoya, Oluwafemi;The processing of personal data has become a prominent concern for stakeholders when selecting software or service providers to serve their needs. Different laws and legislation have been introduced to standardize and strengthen data protection policies across different countries to protect such data. Therefore, businesses and organizations responsible for managing personal data are obligated to implement the privacy and security requirements established by these laws and legislation. Different methods and tools have been provided for eliciting requirements for legally compliant software based on the relevant data protection laws and legislation. However, little has been done in assessing these methodologies on regulations outside the EU and the US. This paper aims to assess these methodologies on other information security laws and regulations beyond the General Data Protection Regulation (GDPR) and Health Insurance Portability and Accountability Act (HIPAA) by eliciting security requirements explicitly focusing on the Nigerian data protection regulation. To investigate the applicability of these methodologies, we use the extracted privacy and security requirements with information communication protocols in verifying compliance in procedural practices of products and services in the financial technology sector. The analysis reports on the completeness, consistency, and utility of the frameworks. Finally, foundational research directions for interoperable standards for eliciting software requirements from legal texts are proposed.;Yes;Not too sure;;No;EX1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/0950-7051(89)90007-5;https://www.sciencedirect.com/science/article/pii/0950705189900075;Generating legal arguments;1989;"Tyree, Alan L.; Greenleaf, Graham; Mobray, Andrew";Legal reasoning in the Common Law system has elements of reasoning by analogy, of reasoning from example, and certain characteristics which are unique. A legal expert system must provide a sophisticated level of justification for its advice, for the justification is the system's most important product. A legal expert system and its associated report generating system is described here.;Yes;Case law, careful, smeels of litigation;;Yes;;Yes;Yes;No;No;frames;Discussed but rather a limitation;No;Manual;No;Yes;No;Legal argument;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.32604/cmc.2022.024190;https://www.sciencedirect.com/science/article/pii/S1546221822010906;Regulation Relatedness Map Creation Method with Latent Semantic Analysis;2022;"Huyut, Mehmet Murat; Kocaoğlu, Batuhan; Meram, Ünzile";"Regulatory authorities create a lot of legislation that must be followed. These create complex compliance requirements and time-consuming processes to find regulatory non-compliance. While the regulations establish rules in the relevant areas, recommendations and best practices for compliance are not generally mentioned. Best practices are often used to find a solution to this problem. There are numerous governance, management, and security frameworks in Information Technology (IT) area to guide businesses to run their processes at a much more mature level. Best practice maps can used to map another best practice, and users can adapt themselves by the help of this relation maps. These maps are created generally by an expert judgment or top-down relationship analysis. These methods are subjective and easily creates inconsistencies. In order to have an objective and statistical relationships map, we propose a Latent Semantic Analysis (LSA) based modal to generate a specific relatedness correlation map. We created a relatedness map of a banking regulation to a best practice. We analyzed 224 statements of this regulation in relation to Control Objectives for Information Technologies (Cobit) 2019's 1202 activities. Furthermore, we support our LSA results with MCDM analysis methods; Fuzzy Analytics Hierarchy Process (FAHP) to prioritize our criteria and, WASPAS (Weighted Aggregated Sum Product Assessment Method) to compare similarity results of regulation and Cobit activity pairs. Instead of the subjective methods for mapping best practices and regulations, this study suggests creating relatedness maps supported by the objectivity of LSA.";Yes;Relatednes smight help, but not sure;EX5;No;relatedness of documents;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/j.procs.2015.09.230;https://www.sciencedirect.com/science/article/pii/S1877050915030756;A Cloud Service Broker with Legal-Rule Compliance Checking and Quality Assurance Capabilities;2015;"Casalicchio, Emiliano; Palmirani, Monica";The ICT industry, and specifically critical sectors such as healthcare, transportation, energy and government require as mandatory the compliance of the ICT systems and services with legislation and regulation, as well as with standards. In the era of cloud computing, and particularly in a public cloud scenario, this compliance management issue is exacerbated by the distributed nature of the system and by the limited control of the customer on the infrastructure/services. Also if the cloud industry is aware of this legislation/regulation compliance issue (e.g. the compliance program of Amazon, Google and Microsoft Azure), right now, there are nor reference architectures neither mechanisms capable to check and to assure, off-line and at run-time, that the compliance is guaranteed during the whole life cycle of a cloud service. Cloud service brokerage can play an important role in law/regulation compliance management of cloud services. In this paper we propose a broker-based solution for the management of law/regulation compliance. In the specific first we define a reference architecture for a legislation-aware cloud service broker, and second we propose an autonomic manager that integrate the MAPE-K control loop with the LegEx framework for the management of the legal compliance checking lifecycle.;Yes;A bit too use casey, but still valid;;No;Duplicate (though in different publication: 10.1109/ICCAC.2015.24);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
SD;https://doi.org/10.1016/S1571-0661(04)80899-5;https://www.sciencedirect.com/science/article/pii/S1571066104808995;CTML:: a context transport mark-up language for formalization and verification of legal, medical, bureaucratic and safety procedures and protocols;2001;Tonfoni, Graziella;"CPP-TRS [2] stands for Communicative Positioning Program - Text Representation Systems and is a visual language based upon a consistent set of dynamic visuals, which may be used in combination to represent qualitative reasoning about the nature of information packaged in textual format. A subset of CPP-TRS visuals, indicating those categories which create communicative context, precisely textual signs and textual symbols, have been recently isolated and converted into functions and commands of a mark-up language for documentation annotation. The newly derived special purpose language is called CTML, which means Context Transport Markup Language, [4] and the main objective to be achieved is accurate incorporation of contextual features into documentation. Communicative function carried by signs, together with communicative intention carried by symbols and communicative turn-taking carried by turn-taking symbols create context, which may be easily incorporated within each single instruction, that has been produced in textual format. Instructions displayed according to a set of categories selected as the most relevant ones will provide users with those interpretive clues which are needed to support accurate and effective understanding of each instructional sequence. Strategic information, such as legal, medical, bureaucratic text and safety protocols are, if designed and packaged according to the CTML standard [5] may be easily and effectively stored, retrieved, accessed, distributed and updated; therefore significantly enhancing power and speed in the search process as well.";Yes;;;No;This is not really representation of law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3594536.3595129;https://doi.org/10.1145/3594536.3595129;A Formal Framework for Combining Legal Reasoning Methods;2023;"Prakken, Henry; Sartor, Giovanni";This paper proposes a novel argumentation-based approach to combine legal-reasoning methods that each solve a subproblem of an overall legal problem. The methods can be of any nature (for instance, logical, case-based or probabilistic), as long as their input-output behaviour can be described at the metalevel with deductive or defeasible rules. The model is formulated in the ASPIC+ framework, to profit from its metatheory and explanation methods, and to allow for disagreement about how to solve a subproblem. The model is not meant to be directly implementable but to serve as a semantics for architectures and implementations.;Yes;;;Yes?;The model is not meant to be directly implementable but to serve as a semantics for architectures and implementations. :/;Yes;Yes;Yes;No;meta on top of any deductive or defeasible rules (ASPIC+ framework);No;Less conversion, more communication and integration;Manual, actually not creted at all;Not optimized;Yes, the authors are from the law faculty;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3689299.3689319;https://doi.org/10.1145/3689299.3689319;Lawyer GPT: A Legal Large Language Model with Enhanced Domain Knowledge and Reasoning Capabilities;2024;"Yao, Shunyu; Ke, Qingqing; Wang, Qiwei; Li, Kangtong; Hu, Jie";The emergence of large language models has brought about revolutionary changes in the field of natural language processing and has shown extraordinary potential in general tasks and various specific domain tasks, especially in the legal field. However, there are still many factors that constrain the application of large language models in the legal field, with the main problems being the lack of domain knowledge and the ability to apply knowledge to solve problems. Therefore, we propose Lawyer GPT, a legal large model that incorporates domain knowledge by using an external knowledge retrieval module to combine an external knowledge base and possesses legal reasoning capabilities. We have collected a large amount of legal domain data and combined it with general domain data, using GPT-4 Turbo to build a high-quality legal dataset. To make Lawyer GPT's legal reasoning capabilities more reliable, we have performed supervised fine-tuning on this dataset, providing it with a good ability to apply domain knowledge to solve problems and enabling it to independently handle various legal professional issues. In addition, we have constructed a legal knowledge base and used retrieval enhancement techniques to provide Lawyer GPT with tools to retrieve external domain knowledge, thereby improving the factual and rationality of the generated content. Experimental results show that Lawyer GPT has demonstrated good performance in both subjective and objective legal domain tests, showing a strong ability to handle legal issues.;Yes;;;No;Important for main part of paper! Not important here, as RAG with basic text retrieval;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2593770.2593780;https://doi.org/10.1145/2593770.2593780;Legal goal-oriented requirement language (legal GRL) for modeling regulations;2014;"Ghanavati, Sepideh; Amyot, Daniel; Rifaut, André";Every year, governments introduce new or revised regulations that are imposing new types of requirements on software development. Analyzing and modeling these legal requirements is time consuming, challenging and cumbersome for software and requirements engineers. Having regulation models can help understand regulations and converge toward better compliance levels for software and systems. This paper introduces a systematic method to extract legal requirements from regulations by mapping the latter to the Legal Profile for Goal-oriented Requirements Language (GRL) (Legal GRL). This profile provides a conceptual meta-model for the anatomy of regulations and maps its elements to standard GRL with specialized annotations and links, with analysis techniques that exploit this additional information. The paper also illustrates examples of Legal GRL models for The Privacy and Electronic Communications Regulations. Existing tool support (jUCMNav) is also extended to support Legal GRL modeling.;Yes;;;Yes;;No;No;Yes;No;semi-forma, Legal GRL;No;Only internally from Hohfeldian Models to Legal GRL;manual;Not optimized;No;Yes;compliance;EU law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3594536.3595175;https://doi.org/10.1145/3594536.3595175;Deontic Ambiguities in Legal Reasoning;2023;"Governatori, Guido; Rotolo, Antonino";"What happens if the way in which we handle a genuine deontic conflict —i.e., a deontic ambiguity— matters regarding the application of other norms that are not directly affected by that conflict? We argue that the law requires sometimes propagating the ambiguity to other norms and sometimes confining it to some norms only. We explore this issue and model different reasoning patterns. The problem is addressed in a new variant of Defeasible Deontic Logic. The contribution of this paper is threefold: (a) we extend the treatment of ambiguity blocking and propagation to Defeasible Deontic Logic; (b) we discuss reasoning patterns in the law, especially in criminal law, where we need to deal with both ambiguity blocking and ambiguity propagation in the same legal system and logic; (c) we devise an annotated variant of Defeasible Deontic Logic where we distinguish literals that must be obtained through an ambiguity-blocking mechanism from those that are derived using an ambiguity-propagating mechanism.";Yes;Might not be relevant as more of a general deontic discussion, check if paper contains reference to compliance, etc.;;Yes;I wonder if an argument can be made, that conflicting arguments are not relevant for compliance. I do not know how exactly, but non-compliance is given when either a prohibited action is taken or an obligation is not fulfilled. If one subsumption creates an obligation an another indicates that the obligation is not needed, the end result should be that the obligation should be fulfilled. Prohohbitions and obligations might conflict though;No;Yes;Yes;No;Defeasible deontic logic;No, note that the explicit encodings about change of law cannot really be counted as considering changes in law;No;manual;not optimized;No;No;Reasoning;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3689492.3690050;https://doi.org/10.1145/3689492.3690050;Software Engineering Methods for AI-Driven Deductive Legal Reasoning;2024;Padhye, Rohan;The recent proliferation of generative artificial intelligence (AI) technologies such as pre-trained large language models (LLMs) has opened up new frontiers in computational law. An exciting area of development is the use of AI to automate the deductive rule-based reasoning inherent in statutory and contract law. This paper argues that such automated deductive legal reasoning can now be viewed from the lens of software engineering, treating LLMs as interpreters of natural-language programs with natural-language inputs. We show how it is possible to apply principled software engineering techniques to enhance AI-driven legal reasoning of complex statutes and to unlock new applications in automated meta-reasoning such as mutation-guided example generation and metamorphic property-based testing.;Yes;Will need to check framing in paper;;No;Not really LIR. A case against RAG, but relevant to the main paper.;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3535511.3535555;https://doi.org/10.1145/3535511.3535555;An Information System for Law Integrating Ontological Bases with a Legal Reasoner Chatbot;2022;"Monteiro, Lucas Henrique de Assis; Rodrigues, Cleyton Mário de Oliveira; Sousa, Aêda Monalliza Cunha de";Context: The Semantic Web aims to assign meanings to resources available on the internet so that humans and computers can understand them. It can be used in the most diverse contexts, facilitating the development of systems where expert knowledge is formalized through logical-mathematical resources, mitigating potential inconsistencies, and promoting more human-friendly interaction services. Problem: The existence of semantic anomalies (use of rhetorical language, polysemy and inaccuracies) in the Brazilian Legal Domain enables the use of Semantic Web standards and technologies to mitigate these problems. Solution: This work deals with the development of an Information System that uses resources from the Semantic Web for the formal representation and the realization of legal inferences about Crimes Against Property. SI Theory: The Behavioral Decision Theory was approached, mainly in the incorporation of real patterns of decision making. Method: Bibliographic and documentary research methods were used to list the main concepts related to the Criminal Types investigated. The research is prescriptive and has a quali-quantitative approach. Summary of Results: A prototype system is presented, integrating ontologies of Brazilian Law with a chatbot that enables interaction with users in natural language, as well as performing reasoning tasks based on the knowledge formalized in these ontologies. Contributions and Impact in the IS area: The research will contribute to the automation of decision-making processes involving crimes against property, serving as an aid for professionals or law students and for legal simulations by ordinary people. Furthermore, it will serve as a reference for the development of other information systems with similar objectives in other contexts.;Yes;;;No;EX2;;;;;;;;;Heavily optimized;;;;Criminal Law, Property Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1109/SEH.2019.00012;https://doi.org/10.1109/SEH.2019.00012;Towards enhanced accountability in complying with healthcare regulations;2019;"Anish, Preethu Rose; Joshi, Vivek; Sainani, Abhishek; Ghaisas, Smita";The healthcare ecosystem is highly complex. It is composed of multiple stakeholders with intersecting interests. The healthcare regulations such as Health Insurance Portability and Accountability Act, much like the systems they protect, are complex and often difficult to interpret. Regulations contain obligations that must be fulfilled by healthcare systems that form the backbone of modern healthcare. In this paper, we present a model for extracting and deconstructing obligations. The Obligation Model allows for capturing the essence of obligations in terms of their attributes such as Responsible entity, Trigger, Action, Deadline and Reference. We augment the extracted obligations with auxiliary information present in regulation documents and provide an ownership based rendering of the deconstructed obligation in an HTML format. This helps in establishing an explicit ownership of obligations and contributes towards enhancing accountability of stakeholders towards fulfilling the obligations. The rendering will be useful for building compliant healthcare systems by making the legal text more comprehensible for system designers.;Yes;Not 100% sure, basically lgm for business process management, but very specific use case;;Yes;No idea what my first roun reasoning is on about here. This is totally fine;No;No;Yes;No;semi-formal: different criteria extracted;No;No;Automatic;Yes (HTML);Yes;No;Accountability, tracability;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3183428.3183433;https://doi.org/10.1145/3183428.3183433;Resolving ambiguities in regulations: towards achieving the kohlbergian stage of principled morality;2018;"Ghaisas, Smita; Sainani, Abhishek; Anish, Preethu Rose";According to Kohlberg, the final stage of morality is characterized by viewing laws as a means to an end by upholding values such as human dignity and fairness as guiding principles for complying with the essence of the law. Given that purpose of compliance is indeed wellbeing of citizens, software systems should, by design, incorporate these values so that laws are followed in spirit. How can we build software systems that incorporate these values? We present our work on disambiguating Health Insurance Portability and Accountability Act (HIPAA) so as to reduce the potential incidents of breach, thereby upholding of the aforesaid guiding principles of morality. We have employed deep learning based approaches to emulate the human process of disambiguation by integrating information from multiple sources, summarizing it, and augmenting the regulatory text with the additional information. This augmented regulatory text can be used by policy makers and software engineers to achieve compliance in spirit.;Yes;Bit confused what compliance in spirit is, but sure;;No;not enough LIR for me here;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3664476.3670878;https://doi.org/10.1145/3664476.3670878;A Risk Assessment and Legal Compliance Framework for Supporting Personal Data Sharing with Privacy Preservation for Scientific Research;2024;"Baloukas, Christos; Papadopoulos, Lazaros; Demestichas, Kostas; Weissenfeld, Axel; Schlarb, Sven; Aramburu, Mikel; Redó, David; García, Jorge; Gaines, Seán; Marquenie, Thomas; Eren, Ezgi; Erdogan Peter, Irmak";In order to perform cutting-edge research like AI model training, a large amount of data needs to be accessed. However, data providers are often reluctant to share their data with researchers as these might contain personal data and thereby sharing may introduce serious risks with significant personal, institutional or societal impacts. Apart from the need to control these risks, data providers must also comply with regulations like GDPR, which creates an additional overhead that makes data sharing even less appealing to data providers. Technologies like anonymization can play a critical role when sharing data that may contain personal information by offering privacy preservation measures like face or license plate anonymization. Therefore, we propose a framework to support data sharing of personal data for research by integrating anonymization, risk assessment and automatic licence agreement generation. The framework offers a practical and efficient solution for organisations seeking to enhance data-sharing practices without compromising information security.;Yes;Very specific use case;;No;This has no real representation of law?;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3594536.3595133;https://doi.org/10.1145/3594536.3595133;Multi-agent logic for reasoning about duties and powers in private law;2023;"Xu, Tianwen; Ju, Fengkui";Duties and powers are two fundamental notions in private law. In this work, we provide our conception of duties and powers and present a logic for reasoning about them. We treat duties as agents' obligations towards others to perform actions. We think that powers are agents' legal abilities, conferred by law, to change legal positions between agents. How to exercise powers is also specified by law. Many factors, including the exercise of powers, fulfillment of duties, violation of duties, and factual changes in the world, can change duties. The ontic level of the logic is a multi-agent dynamic logic, where agents have abilities to change atomic facts. At its normative level, agents have duties towards others to change atomic facts, and have powers to change duties by changing atomic facts. When agents behave, the ontic and normative aspects of the world change accordingly. The implications of the formalization are studied extensively.;Yes;ICP;;Yes;For future reference: ontic -> something in the real world, i.e., not deontic. This is to intelligent for me;No;No;Yes;No;Formal, custom formalization, missing Hofenfeldian permissions;No;No;manual (Unspecified);No;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3492547.3492661;https://doi.org/10.1145/3492547.3492661;Development of a web-resources testing system for compliance with GDPR regulation;2021;"Amanzholova, Saule; Akhmetova, Darya; Sagymbekova, Azhar";In this paper, we describe the development of a system for checking websites for compliance with the European standard on personal data processing - GDPR. The relevance of this problem is dictated by the entry into force of the General Data Protection Regulation, also known as the GDPR standard, as well as the obligation to comply with by all companies that process personal data and any other sensitive information of EU residents, regardless of the location of such a company. For a detailed study of this topic, statistical data was collected on the reaction of global companies in various spheres of life to the introduction of the GDPR personal data processing regulation, the impact of this standard on their future work and the measures taken by these companies. In addition, we examined existing Internet portals with similar processing parameters for websites. This article describes an implementation of a web application that validates a customer's site for compliance with the standard and issues a practical report with recommendations and notes in accordance with the list of fixes to the standard. We used tools and platforms such as Python, NodeJS, React.;Yes;;;No;Not sure how this passed initial screening, this is a very specific use case with no law representation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3462757.3466075;https://doi.org/10.1145/3462757.3466075;On semantics-based minimal revision for legal reasoning;2021;"Fungwacharakorn, Wachara; Tsushima, Kanae; Satoh, Ken";When literal interpretation of statutes leads to counterintuitive consequences, judges, especially in high courts, may identify counterintuitive consequences and revise interpretation of statutes. Researchers have studied revisions for computational legal representation. Generally, studies on revision usually consider minimal revision to reflect limitation of judges' legislative power. However, those studies tend to minimize the number of operations used for changing rules rather than minimize the changes of semantics (the set of conclusions obtained from the program), which vary among cases. In this paper, we consider minimizing the changes of semantics of a rule-base written in a normal logic program. We consider that each possible fact-base (the representation of a case) has its corresponding semantics and corresponding dominant rule-base, which is a set of Horn clauses obtained from the subset of rule-base that is specific to the considered fact-base. Hence, we present a new sub type of semantics-based minimal revision called a dominant-based minimal revision. Furthermore, we present one guidance to obtain one dominant-based minimal revision by using legal debugging and Closed World Specification. We also compare the dominant-based minimal revision with the syntax-based minimal revision in Theory Distance Metric. As the syntax-based minimal revision minimizes the number of operations used for changing rules, the comparison shows that the syntax-based minimal revision may cause extra semantics changes compared to the dominant-based minimal revision, especially when the rule-base contains multiple rules for the same consequence. We discuss that such extra semantics changes can be considered as unintentional changes caused by the syntax-based minimal revision. Hence, legal reasoning systems can check with the user such extra semantics changes to confirm the user intention of changes.;Yes;;;Yes;;No;No;Yes;No;Prolog;Yes, main focus;No;manual;No;No;No;Managing change, reducing semantic change;eGeneral;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/3351736.3351788;"Model-driven regulatory compliance: a case study of ""know your customer"" regulations";2015;"Sunkle, Sagar; Kholkar, Deepali; Kulkarni, Vinay";Modern enterprises face an unprecedented regulatory regime. Industry governance, risk, and compliance (GRC) solutions are document-oriented and expert-driven. Formal compliance checking techniques in contrast attempt to provide ways for rigorous modeling and analysis of regulatory compliance but miss out on holistic GRC perspective due to missing integration between diverse set of (semi-) formal models. We show that streamlining regulatory compliance using multiple purposive models of various aspects of regulations, it is possible to leverage both the rigor of formal techniques and the holistic enterprise GRC perspective. Our contributions are twofold. First, we present a model-driven architecture based on a conceptual model of integrated GRC that is capable of addressing key challenges of regulatory compliance. Second, using Know Your Customer regulations in Indian context as a case study, we demonstrate the utility of this architecture. Initial results with KYC regulations are promising and point to further work in model-driven regulatory compliance.;Yes;;;Yes;Note on this, we focus on step 2 for our analysis as it is the one dedicated to LIR;No;No;Yes;No;DR-Prolog (Defeasible Reasoning);Yes, major focus;No;semi-automated;Not optimized;No;Yes;Change management, operational alignment;Banking;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3644523.3644567;https://doi.org/10.1145/3644523.3644567;A Graph Matching Model Based on Cohesive Hypergraph Convolutional Network for Knowledge Graphs of Financial-field Regulatory Documents;2024;"Wang, Xiaoguo; Shi, Jiachen; Chen, Chao; Cui, Jianwen";Based on the actual demand of conducting banking business compliantly for intelligent retrieval of financial-field regulatory documents (FRDs), in view of the features of containing non-pairwise semantic information, high knowledge cohesion within segments and low knowledge coupling between segments in FRDs, in this paper, the hypergraph structure is adopted, and a model based on HGNN that can effectively classify graphs in this field is constructed to implement graph classification, called Cohesive Hypergraph Convolutional Network (CHCN) model. According to existing knowledge graphs of FRDs, a graph matching model in this field based on CHCN, BERT and other models is constructed to effectively solve the problem of graph matching, called Graph Matching model for Knowledge graph of Financial-field regulatory documents (FK-GM) model. The results of the experiments show that compared with other baseline models, CHCN model outperforms in F1, Precision and Recall in the graph classification task on public datasets and a dataset of banking regulatory documents, which verifies the effectiveness of FK-GM, the graph matching model proposed in this paper.;Yes;Retrieval, but for compliance;;No;Just retrieval;;;;;;;;;;;;;Finance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3277570.3277590;https://doi.org/10.1145/3277570.3277590;An Ontology Capturing the Interdependence of the General Data Protection Regulation (GDPR) and Information Security;2018;"Geko, Melisa; Tjoa, Simon";High returns for processing personal data and low penalties for privacy violations led to the circumstance that protection of privacy was often not considered a priority. To counter this habit and to harmonize data protection laws throughout the European Union, the EU-Commission has adopted the General Data Protection Regulation (GDPR), clarifying data subject rights and ensuring an appropriate level of privacy protection.Through high penalties for non-compliance (i.e. up to 2% - 4% of the annual worldwide turnover), GDPR was able to put high pressure on organizations to comply with the requirements. However, studies have shown that organizations are often overwhelmed by the actual requirements.In this paper, we therefore aim to support organization to understand this complex topic by providing an ontology-based data protection knowledge base, which highlights the interdependency of GDPR and information security.;Yes;Little focus on processes;;No;Discription of ontology to vague;No;No;Yes;Yes;;No (snapshot);No;unformal;;No;;;Privacy, EU Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2514601.2514605;https://doi.org/10.1145/2514601.2514605;Managing legal interpretation in regulatory compliance;2013;"Boella, Guido; Janssen, Marijn; Hulstijn, Joris; Humphreys, Llio; van der Torre, Leendert";Maintaining regulatory compliance is an increasing area of concern for business. Legal Knowledge Management systems that combine repositories of legislation with legal ontologies can support the work of in-house compliance managers. But there are challenges to overcome, of interpreting legal knowledge and mapping that knowledge onto business processes, and developing systems that can adequately handle the complexity with clarity and ease. In this paper we extend the Legal Knowledge Management system Eunomos to deal with alternative interpretations of norms connecting it with Business Process Management systems. Moreover, we propose a workflow involving the different roles in a company, which takes legal interpretation into account in mapping norms and processes, using Eunomos as a support.;Yes;;;No;EX5, no actual (formal) representation of law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3319619.3322038;https://doi.org/10.1145/3319619.3322038;On the use of context sensitive grammars in grammatical evolution for legal non-compliance detection;2019;"Im, Carl; Hemberg, Erik";We extend the context-free grammar mapping method in the Grammatical Evolution search heuristic. Grammatical Evolution guarantees the generation of transparent and syntactically correct sentences(phenotypes), but not necessarily semantically correct or feasible ones. Generating syntactically valid phenotypes with postprocessing to filter out semantically invalid ones suffers from some issues, e.g. introduction of bias toward short phenotypes and loss in search efficiency. These issues become significant in legal application domains. We first demonstrate that applying Grammatical Evolution with a context free grammar to legal non-compliance detection problems might not be a tenable solution. Then we demonstrate how the addition of context sensitivity improves both the search efficiency and achieves a greater diversity in the case of the iBoB problem regarding legal non-compliance.;Yes;;;No;No representation of law and a bit too short to get much infromation from;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;;A Regulation Enforcement Solution for Multi-agent Reinforcement Learning;2019;"Sun, Fan-Yun; Chang, Yen-Yu; Wu, Yueh-Hua; Lin, Shou-De";Human behaviors are regularized by a variety of norms or regulations, either to maintain orders or to enhance social welfare. However, if artificially intelligent (AI) agents make decisions on behalf of human beings, it is possible that an AI agent can opt to disobey the regulations (being defective) for self-interests. In this paper, we aim to answer the following question: In a decentralized environment (no centralized authority can control agents), given that not all agents are compliant to regulations at first, can we develop a mechanism such that it is in the self-interest of non-compliant agents to comply after all. We first introduce the problem as Regulation Enforcement and formulate it using reinforcement learning and game theory. Then we propose our solution based on the key idea that although we could not alter how defective agents choose to behave, we can, however, leverage the aggregated power of compliant agents to boycott the defective ones. We conducted simulated experiments on two scenarios: Replenishing Resource Management Dilemma and Diminishing Reward Shaping Enforcement, using deep multi-agent reinforcement learning algorithms. We further use empirical game-theoretic analysis to show that the method alters the resulting empirical payoff matrices in a way that promotes compliance (making mutual compliant a Nash Equilibrium).;Yes;This honestly does not seem like a good fit, but this brings some nice variance into the paper selection. Adding some GT to compliance is cool, but will have to check inclusion/exlusion criteria;;No;EX5;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3494193.3494260;https://doi.org/10.1145/3494193.3494260;Internet of Healthcare: Opportunities and Legal Challenges in Internet of Things-Enabled Telehealth Ecosystems;2022;Rak, Richard;The COVID-19 public health crisis has accelerated the transformation of health systems to become more closely tied to citizens/patients and increasingly dependent on the provision and use of telehealth services. Internet of Things (IoT)-enabled telehealth systems (deployed in conjunction with AI systems) could facilitate the smart transformation of healthcare from a merely reactive system to a data-driven and person-centred system that provides remote health diagnosis, monitoring and treatment services, integrated real-time response solutions, as well as prospective insights. However, the realisation of these health-related benefits requires the processing of vast amounts of data concerning health. These operations and the use of new enabling technologies raises significant legal concerns and questions the applicability of existing/proposed legal concepts. For this reason, the research analyses the adequateness of EU privacy, data protection, data governance, AI governance and other regulatory rules in IoT-enabled (and AI-augmented) telehealth systems. In addition, the research aims to identify technical and organisational measures (best practices), which could facilitate the implementation of normative principles in these information systems in an effective manner.;Yes;Next Round, but probably actually not a good fit;EX6, EX7;No;EX5;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3322640.3326695;https://doi.org/10.1145/3322640.3326695;Reasoning with Legal Cases: Analogy or Rule Application?;2019;"Atkinson, Katie; Bench-Capon, Trevor";Modelling reasoning with precedents has been a central concern of AI and Law since its inception. A recent paper has provided a discussion (in jurisprudential terms) of whether such reasoning is best seen as rule application or analogy. We review some of the prominent AI and Law approaches and find that over the years there has been a move away from analogy to rule application. Even in those approaches which do use analogy, however, the analogies handled concern only analogies between cases represented as sets of factors, and do not consider analogies between the elements of the fact situations peculiar to particular cases. In actual practice, however, analogies are used to determine which factors are relevant in a case, and which party is favoured by particular aspects of the case situation. Such analogies relate not to factors, but to real-world elements of the case and are hard to make and critique without a comprehensive common sense ontology. Thus while we may be able to construct specific ontologies to model past examples of such analogical reasoning, which can be useful for simulation and teaching, the ability to perform analogical reasoning on novel situations is, and is likely to remain, infeasible. This conclusion suggests that there will always be limits to our ability to construct systems able to handle new cases presenting novel situations.;Yes;Case focuesed but not just retrival, but actual reasoning;;No;EX5, position piece;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3086512.3086526;https://doi.org/10.1145/3086512.3086526;Compliance patterns: harnessing value modeling and legal interpretation to manage regulatory conversations;2017;"Muthuri, Robert; Boella, Guido; Hulstijn, Joris; Capecchi, Sara; Humphreys, Llio";"Companies must be able to demonstrate that their way of doing business is compliant with relevant rules and regulations. However, the law often has open texture; it is generic and needs to be interpreted before it can be applied in a specific case. Entrepreneurs generally lack the expertise to engage in the regulatory conversations that make up this interpretation process. In particular for the application domain of technological startups, this leads to legal risks. This research seeks to develop a robust module for legal interpretation. We apply informal logic to bridge the gap between the principles of interpretation in legal theory with the legal rules that determine compliance of business processes. Accordingly, interpretive arguments characterized by argument schemes are applied to business models represented by value modeling (VDML). The specific outcome of the argumentation process (if any) is then summarized into a compliance pattern, in a context-problem-solution format. A case study from copyright law, about an internet television company, shows that the approach is able to express the legal arguments of the case, but is also understandable for the target audience.";Yes;ICP?;;No;Not ICP, heavy focus on argumentation, less on the actual representation I am really not sure about this one as there is not really much LIR at all. Mabye relevant for reasoning in LLM though;Yes;Yes;Yes;No;Semi-Formal, EARS Framework (Easy Approach to Requirements Syntax);Yes;No;tool supported;Optimized;No;Yes;Compliance;Copyright law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3078861.3078879;https://doi.org/10.1145/3078861.3078879;Security Analysis and Legal Compliance Checking for the Design of Privacy-friendly Information Systems;2017;"Guarda, Paolo; Ranise, Silvio; Siswantoro, Hari";Nowadays, most of business practices involve personal data-processing of customers and employees. This is strictly regulated by legislation to protect the rights of the data subject. Enforcing regulation into enterprise information system is a non-trivial task that requires an interdisciplinary approach. This paper presents a declarative framework to support the specification of information system designs, purpose-aware access control policies, and the legal requirements derived from the European Data Protection Directive. This allows for compliance checking via a reduction to policy refinement that is supported by available automated tools. We briefly discuss the results of the compliance analysis with a prototype tool on a simple but realistic scenario about the processing of personal data to produce salary slips of employees in an Italian organization.;Yes;;;Yes;;No;No;Yes;No;First Order Logic, Attribute Based Access Control (template access control policies);No;No (Will not count template to ABAC) ;manual;No;No;Yes (More or less as future work);Access Control;Privacy, EU Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/2031678.2031684;Commitments with regulations: reasoning about safety and control in REGULA;2011;"Marengo, Elisa; Baldoni, Matteo; Baroglio, Cristina; Chopra, Amit K.; Patti, Viviana; Singh, Munindar P.";"Commitments provide a flexible means for specifying the business relationships among autonomous and heterogeneous agents, and lead to a natural way of enacting such relationships. However, current formalizations of commitments incorporate conditions expressed as propositions, but disregard (1) temporal regulations and (2) an agent's control over such regulations. Thus, they cannot handle realistic application scenarios where time and control are often central because of domain conventions or other requirements.We propose a new formalization of commitments that builds on an existing representation of events in which we can naturally express temporal regulations as well as what an agent can control, including indirectly as based on the commitments and capabilities of other agents. Our formalization supports a notion of commitment safety. A benefit of our consolidated approach is that by incorporating these considerations into commitments we enable agents to reason about and flexibly enact the regulations.The main contributions of this paper include (1) a formal semantics of commitments that accommodates temporal regulations; (2) a formal semantics of the notions of innate and social control; and (3) a formalization of when a temporal commitment is safe for its debtor. We evaluate our contributions using an extensive case study.";Yes;Framing as commitments, but I think yes;;No;Not law based (as far as I can tell);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3594536.3595137;https://doi.org/10.1145/3594536.3595137;ANGELIC II: An Improved Methodology for Representing Legal Domain Knowledge;2023;"Atkinson, Katie; Bench-Capon, Trevor";The purpose of this paper is to provide a definitive, up-to-date account of a methodology has that been proven successful for representing and reasoning about legal domains. The ANGELIC (ADF for kNowledGe Encapsulation of Legal Information for Cases) methodology was originally developed to exploit then recent developments in knowledge representation techniques that lend themselves well to capturing factor-based reasoning about legal cases. The methodology is situated firmly within the tradition of research in AI and Law that aims to build systems that are knowledge rich in terms of the domain expertise that is emulated within the systems. When the methodology was first introduced, it was demonstrated on academic examples, but it was subsequently used in and evaluated on a variety of real world domains for external clients. This set of evaluation exercises yielded a variety of learning points as the methodology was applied to different legal domains with their own particular features. These learning points, and the extensions to the methodology that follow from them, urge a consolidation exercise to provide an updated version of the methodology that reflects how it has matured over time. This paper represents a milestone in the development of the methodology in that it presents the ANGELIC II Domain Model, along with a description of its constituent parts, and demonstrates its application through a case study in a key evaluation domain.;Yes;case, but reasoning;;Yes;Not 100% sure;Yes;Yes;No;No;ANGELIC II (Abstract Dialectical Framework);No;Yes (Implementation in Programming Langages);manual;Slightly optimized (see 7.1);Yes;No;Argumentation;US Trade Secrets;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3322640.3326717;https://doi.org/10.1145/3322640.3326717;User-Friendly Open-Source Case-Based Legal Reasoning;2019;Morris, Jason;The access to justice crisis is one that cannot be effectively solved without the automation of legal services. The automation of legal services cannot be efficiently done without efficiently automating legal reasoning. Legal case-based reasoning (CBR) provides a method of obtaining explainable and strong predictions for legal issues that lawyers would typically predict on the basis of analogy to prior decided cases. Automating explainable predictions with regard to these sorts of legal issues is difficult without resort to CBR.Wider adoption of CBR in the legal realm therefore has the potential to increase the scope of legal services that can be automated. Despite this potential, as of early 2018 there were no open-source or commercially-available tools for building legal case-based reasoning systems. This paper describes an open-source tool named docassemble-openlcbr[5] designed for ease of use by legal professionals in implementing CBR in the development of automated legal services.;Yes;caseut reasoning;;No;Just use case, no description of methodology;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2746090.2746100;https://doi.org/10.1145/2746090.2746100;Deontic defeasible reasoning in legal interpretation: two options for modelling interpretive arguments;2015;"Rotolo, Antonino; Governatori, Guido; Sartor, Giovanni";This paper offers a new logical machinery for reasoning about interpretive canons. We identify some options for modelling reasoning about interpretations and show that interpretative argumentation has a distinctive structure where the claim that a legal text ought or may be interpreted in a certain way can be supported or attacked by arguments, whose conflicts may have to be assessed according to further arguments.;Yes;;;Yes;;Yes;No;Yes;No;Defeasible Logic, Deaontic Logic;No;No;Manual;No;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/2821464.2821473;Impact of legal interpretation on business process compliance;2015;"Ghanavati, Sepideh; Hulstijn, Joris";Regulations are often written as open norms. Thus, the development of systems that support compliance involves interpretation. Often, compliance officers consider several alternative solutions. Comparing the feasibility and deciding which alternative to select are important tasks. In this paper, we aim to show how analyzing the impact of several interpretation can be supported by requirements engineering tools, in particular, by Legal-URN. Two cases are used to illustrate the importance of interpretation and how Legal-URN facilitates it.;Yes;;;Yes;;No;No;Yes;No;Semi-Formal, Legal-URN;Yes;Yes (Export to IDM DOORS?);Manual;Visualisation;Yes;Yes;Compliance;"Privacy (EU); Finance";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/1367832.1367842;Relating taxonomies with regulations;2008;"Cheng, Chin Pang; Pan, Jiayi; Lau, Gloria T.; Law, Kincho H.; Jones, Albert";Increasingly, taxonomies are being developed for a wide variety of industrial domains and specific applications within those domains. These industry or application specific taxonomies attempt to represent the vocabularies commonly used by the practitioners. These formal representations have the potential to automate information retrieval, facilitate interoperability and improve decision making. Decisions made must comply with existing government regulations and codes of practices, which are not always known to the industry practitioners. Although regulations and codes are now in digital forms and are often available online, it remains difficult to search for relevant regulatory information that are applicable to particular decisions. As industry practitioners, unlike legal practitioners, are familiar with one or more industry-specific taxonomies but not necessarily regulatory organization systems, it would be desirable to relate regulations with existing industry-specific taxonomies.The mapping from a single taxonomy to a single regulation is a trivial keyword matching task. In this paper, we examine techniques to map a single taxonomy to multiple regulations, as well as to map multiple taxonomies to a single regulation. Those techniques include cosine similarity, Jaccard coefficient and market-basket analysis. These techniques provide a metric that measures the similarity between concepts from different taxonomies. Preliminary evaluations of the three metrics are performed using examples from the building industry. These examples illustrate the potential regulatory benefits from the mapping between various taxonomies and regulations.;Yes;Retrieval, but not just precedant;;No;Not really the type of representation I am looking for, too specific, not for compliance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2018358.2018378;https://doi.org/10.1145/2018358.2018378;Modelling temporal legal rules;2011;"Palmirani, Monica; Governatori, Guido; Contissa, Giuseppe";Legal reasoning involves multiple temporal dimensions but the existing state of the art of legal representation languages does not allow us to easily combine expressiveness, performance and legal reasoning requirements. Moreover we also aim at the combination of legal temporal reasoning with the defeasible logic approach, maintaining a computable complexity. The contribution of this work is to extend LKIF-rules with temporal dimensions and defeasible tools, extending our previous work [17].;Yes;;;Yes;;No;No;Yes;No;Legal Knowledge Interchange Format (LKIF) Extension (with temporal dimension);No (They explicitely model changes in the applicability of norms, but only retorspectively, not online);No (Not mentioned, but LKIF itself is fairly flexible);Manual;No;Yes (The authors themselves);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1146598.1146730;https://doi.org/10.1145/1146598.1146730;A distributed information management framework (REGNET) for environmental laws and regulations;2006;Law, Kincho H.;The complexity, diversity, and volume of Federal and State regulations (as well as supplementary and supportive documents) are detrimental to businesses and hinder public understanding of government. The objective of REGNET project is to develop information infrastructure and tools for regulatory information management and to facilitate compliance assistance. As a pilot research application, the REGNET project focuses on environmental regulations. The experimental scope of this project focuses on Code of Federal Regulations (CFR) Title 40: Protection of the Environment and California Code of Regulations (CCR) Title 22: Social Security. Implementation examples include regulations and selected supplementary documents, covering hazardous waste, drinking water and the management of used oil. Furthermore, tools have been tested with additional environmental regulations from other States and regulations from other domain areas, such as CFR Title 21 on Food and Drugs, and different regulations related to accessibility from the US and UK.;Yes;;;No;Research proposal;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2896982.2896985;https://doi.org/10.1145/2896982.2896985;Model management for regulatory compliance: a position paper;2016;"Kokaly, Sahar; Salay, Rick; Sabetzadeh, Mehrdad; Chechik, Marsha; Maibaum, Tom";Software has come to mediate many of the activities in life, including financial service platforms, social networks and vehicle control. As a result, governing bodies have responded to this trend by creating standards and regulations to address issues such as safety and privacy. In this context, the compliance of software development to standards and regulations has emerged as a key issue. For software development organizations, compliance is a complex and costly goal to achieve. They may have to comply with multiple standards due to multiple jurisdictions or to address different aspects of the software and these may overlap and conflict with each other. The evolution of standards must be tracked and changes assessed. Evidence for claims of compliance must be collected and managed. Finally, maintaining families of related software products (product lines) further multiplies the effort. In this paper, we propose to exploit the connection between the field of model management and the problem of compliance management and explore how to use model management techniques to address software compliance management issues.;Yes;Not sure fi I understand this?;;No;Position paper;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1321631.1321701;https://doi.org/10.1145/1321631.1321701;Extracting rights and obligations from regulations: toward a tool-supported process;2007;"Kiyavitskaya, Nadzeya; Zeni, Nicola; Breaux, Travis D.; Antón, Annie I.; Cordy, James R.; Mich, Luisa; Mylopoulos, John";"Security, privacy and governance are increasingly the focus of government regulations in the U.S., Europe and elsewhere. This trendhas created a ""regulation compliance problem"", whereby companiesand developers are required to ensure that their software complies with relevant regulations, either through design or reengineering. We previously proposed a methodology for extracting stakeholder requirements, called rights and obligations, from regulations. In this paper, we examine the challenges of developing tool support for this process. We apply the Cerno framework for textual semantic annotation to propose a tool for semi-automatic semantic annotation of concepts that constitute sources of requirements";Yes;;;Yes;;No;No;Yes;No;"Semi-Formal; Annotations";No;No;Automatic (After domain rules are established);Yes (Natural language with annotations);No;No;Understanding;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1047788.1047820;https://doi.org/10.1145/1047788.1047820;Logic-based regulation compliance-assistance;2003;"Kerrigan, Shawn; Law, Kincho H.";This paper focuses on the creation of a first order predicate calculus based regulation compliance-assistance system built upon an XML framework. Two areas of research that support the development of the compliance assistance system are discussed. The first is a document repository containing federal and state regulations and supplemental documents. The second is an XML framework for representing regulations and associated metadata. The prototype effort for the regulation assistance system has been focused on environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management. The objective of this research is to develop a formal infrastructure for regulatory information management and compliance assistance.;Yes;;;Yes;;No;No;Yes;No;First order logic (Embedded in XML);No;No (Yes into their logic solving software, but not really between formats);Manual (Referring to the logic, the XML is built automatically);Yes (UI, Natural language representation);Yes;No (But this is very much implied here….);Compliance;Environment;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3086512.3086535;https://doi.org/10.1145/3086512.3086535;Semantic types for computational legal reasoning: propositional connectives and sentence roles in the veterans' claims dataset;2017;"Walker, Vern R.; Han, Ji Hae; Ni, Xiang; Yoseda, Kaneyasu";This paper announces the creation and public availability of a dataset of annotated decisions adjudicating claims by military veterans for disability compensation in the United States. This is intended to initiate a collaborative, transparent approach to semantic analysis for argument mining from legal documents. The dataset is being used in the LUIMA argument-mining project. We address two major sub-tasks for making legal reasoning computable. First, we report the semantic types of propositional connective we use to extract information about legal rules from sentences in statutes, regulations, and appellate court decisions, and to represent those rules as integrated systems. Second, we report the semantic types of sentence role we use to extract and represent the fact-finding reasoning found in adjudicatory decisions, with the goal of identifying successful and unsuccessful patterns of evidentiary argument. For each type system, we provide explanations and examples. Thus, we hope to stimulate a shared effort to create diverse datasets in law, to empirically evolve optimal sets of semantic types for argument mining, and to refine protocols for accurately applying those types to texts.;Yes;Dataset but with interesting data;;Yes;Focus on conjunction elements;No;Yes;Yes;No;Semi-Formal framework, formalisation for deduction left open but considered;No;No;manual;Not optimized;Yes (authors);No;Reasoning;Veterans Disability Claim;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/1124191.1124268;A distributed information management framework (REGNET) for environmental laws and regulations;2004;"Law, Kincho H.; Wiederhold, Gio; Leckie, Jim; Thompson, Barton; Kerrigan, Shawn; Lau, Gloria T.; Labiosa, Bill; Heenan, Charles; Wang, Haoyi; Zhou, Liang; Trivedi, Pooja; Peng, Jun";There has been a push by the executive office that government agencies put more emphasis on compliance assistance in lieu of enforcement to encourage companies to comply with regulations. It is well recognized that the complexity, diversity, and volume of Federal and State regulations are detrimental to businesses and also hinder public understanding of government. In addition to the regulations, supplementary and supportive documents (such as preambles, interpretation guides) are also an important part of regulatory information. The objective of REGNET project is to develop a formal information infrastructure for regulatory information management and to facilitate compliance assistance. The experimental scope of this project covers Code of Federal Regulations (CFR) Title 40: Protection of the Environment. Implementation examples focus on the regulations and selected supplementary documents, covering hazardous waste, drinking water and the management of used oil.;Yes;;;No;Not technically a duplicate, but just a research proposal for the 2006 paper that was already included;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3136014.3136018;https://doi.org/10.1145/3136014.3136018;A domain-specific controlled English language for automated regulatory compliance (industrial paper);2017;"Roychoudhury, Suman; Sunkle, Sagar; Kholkar, Deepali; Kulkarni, Vinay";Modern enterprises operate in an unprecedented regulatory environment where increasing regulation and heavy penalties on non-compliance have placed regulatory compliance among the topmost concerns of enterprises worldwide. Previous research in the field of compliance has established that the manual specification of the regulations used by GRC frameworks not only fails to ensure their proper coverage but also negatively affects the turnaround time both in proving and maintaining the compliance. Our key contribution in this paper is an implementation of a controlled natural English like (domain-specific) language that can be used by domain experts to specify regulations for automated compliance checking. We demonstrate this language using examples from industry regulations in banking and financial services domain.;Yes;;;Yes;"10/10 paper. We focus on the LIR part, not the actual compliance part ""the
primary challenge in this case is the inability of domain
experts to contribute in creating a formal rule base""";No;No;Yes;No;Structured English (SE) ;No;Yes, important part, SE is translated for DR-Prolog or Drool;Semi-automated (NLP techniques);Optimized;Yes (Assumed from author affiliations);Yes;Compliance;Banking;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2695664.2695740;https://doi.org/10.1145/2695664.2695740;An ontological approach for simulating legal action in the Brazilian penal code;2015;"de O. Rodrigues, Cleyton Mário; de Azevedo, Ryan Ribeiro; de Freitas, Frederico Luiz Gonçalves; da Silva, Eunice Palmeira; da Silva Barros, Patrícia Vieira";The applicability of Artificial Intelligence for the Legal Domain has several and non-depleted lines of research. Since Colonization, the use of ambiguity in drafting the Brazilian Legal Documents was a palliative to solve cases involving economic, political and social interests between local authorities with the European Court. Further, when conflicts between norms emerge, only time, specificity and superiority criteria are not enough to break the tie, a second degree level governing what criteria should be used in different situations need to be addressed as well. In face of these tangle legal documents, this research project aims to present the OntoCrime and OntoLegalTask: ontological representations through which one can formalize the Brazilian Penal Law to check norm violation and automate legal reasoning. Finally, an experiment with the drinking-drive law is presented.;Yes;;;Yes;EX Litigation?;No;No;Yes;Yes;Description Logic;"Yes (""easily expanded"")";Yes;Manual;Not optimized;No;No;Litigation;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2482767.2482798;https://doi.org/10.1145/2482767.2482798;RTS - an integrated analytic solution for managing regulation changes and their impact on business compliance;2013;"Pasetto, Davide; Franke, Hubertus; Qian, Weihong; Guo, Zhili; Guo, Honglei; Duan, Dongxu; Ni, Yuan; Pan, Yingxin; Bao, Shenghua; Cao, Feng; Su, Zhong";Governance, Risk Management and Compliance are key success factors for corporations. Every company worldwide must ensure a proper compliance level with current and future laws and regulations, but managing the dynamic nature of the regulatory environment is a challenge, for both small and medium business as well as large corporations. Specifically the challenge is knowing and interpreting which regulations impact a particular business. Governments and standard bodies keep producing new, revised legislation, and businesses today rely on employees and consultants for tracking and understanding impact on their operations.This paper introduces a novel prototype solution that addresses these concerns through the use of advanced text analytics. In particular the system is able to discover sources of regulatory content on the world wide web, track the changes to these regulations, extract metadata and semantic information and use these to provide a semantically guided comparison of regulation versions. Moreover, by leveraging the IBM DeepQA architecture, the solution is able to cross reference business objectives with the regulatory database and provide insights about the impact of new and revised laws on a company's business.;Yes;;;Yes?;Not sure. I do not feel like this has great LIR;No;No;Yes;Yes;Semi-Formal, Typographical;Yes;No;Automatic;No;No;No;Tracking Changes;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3452021.3458816;https://doi.org/10.1145/3452021.3458816;Privacy: From Database Reconstruction to Legal Theorems;2021;Nissim, Kobbi;"There are significant gaps between legal and technical thinking around data privacy. Technical standards are described using mathematical language whereas legal standards are not rigorous from a mathematical point of view and often resort to concepts which they only partially define. As a result, arguments about the adequacy of technical privacy measures for satisfying legal privacy often lack rigor, and their conclusions are uncertain. The uncertainty is exacerbated by a litany of successful privacy attacks on privacy measures thought to meet legal expectations but then shown to fall short of doing so. As computer systems manipulating individual privacy-sensitive data become integrated in almost every aspect of society, and as such systems increasingly make decisions of legal significance, the need to bridge the diverging, and sometimes conflicting legal and technical approaches becomes urgent. We formulate and prove formal claims – ""legal theorems” – addressing legal questions such as whether the use of technological measures satisfies the requirements of a legal privacy standard. In particular, we analyze the notion of singling out from the GDPR and whether technologies such as k-anonymity and differential privacy prevent singling out. Our long-term goal is to develop concepts which are on one hand technical, so they can be integrated in the design of computer systems, and can be used in legal reasoning and for policymaking on the other hand.";Yes;Not 100% convinced, technically this is legal knowledge managment to make sure DBs are compliant, but somehow this seems a bit too mathematical?;;No;This is a formalization of a single aspect of a single regulation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1276318.1276340;https://doi.org/10.1145/1276318.1276340;Constructing arguments with a computational model of an argumentation scheme for legal rules: interpreting legal rules as reasoning policies;2007;Gordon, Thomas F.;A knowledge representation language for defeasible legal rules is defined, whose semantics is purely procedural, based on Walton's theory of argumentation and Loui's break with the relational tradition in 'Process and Policy'. Legal rules are interpreted as reasoning policies, by mapping them in the semantics to argumentation schemes. The reasoning process is regulated by argumentation protocols. Reasoning with legal rules is viewed as applying schemes for arguments from rules to construct arguments to be put forward in dialogues.;Yes;;;Yes;;Yes;No;Yes;No;defeasible logic;No;No;Manual;No;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2018358.2018391;https://doi.org/10.1145/2018358.2018391;Can temporal representation and reasoning make a difference in automated legal reasoning? lessons from an AI-based ethical reasoner;2011;"McLaren, Bruce M.; Ashley, Kevin D.";"Given a renewed interest in the field of AI and Law in more complex factual representations of legal cases in terms of narratives, techniques for representing and reasoning about temporal orderings of facts will become increasingly important. The SIROCCO (&lt;u&gt;S&lt;/u&gt;ystem for &lt;u&gt;I&lt;/u&gt;ntelligent &lt;u&gt;R&lt;/u&gt;etrieval of &lt;u&gt;O&lt;/u&gt;perationalized &lt;u&gt;C&lt;/u&gt;ases and &lt;u&gt;CO&lt;/u&gt;des) program employed a representation for the temporal ordering of events in ethics cases in a way that informed determinations of whether and how ethical norms were violated and if the problem and other cases were normatively analogous at a deeper level. At the same time, the program supported ordinary case enterers in translating the facts of textually described cases into a machine-processable representation. This paper presents these previously unpublished aspects of the work including a report of an empirical evaluation of the contribution of the temporal representation to the program's success in retrieving relevant norms and cases. Although the results were negative, a consideration of the reasons why is illuminating. While SIROCCO dealt with engineering ethics cases, it is clear that similar temporal considerations apply in legal cases and that the approach is likely to be useful in legal narrative representations.";Yes;;;Yes;This is a bit case retrieval focused;No;Yes;No;No;Extended Ethics Transcription Language (EETL) ;No;Minimal, to Allen's Temporal Relations;tool supported;Operators optimized for human understandability;No;No;Structural case mapping;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3479604;https://doi.org/10.1145/3479604;Dr.Aid: Supporting Data-governance Rule Compliance for Decentralized Collaboration in an Automated Way;2021-10;"Zhao, Rui; Atkinson, Malcolm; Papapanagiotou, Petros; Magnoni, Federica; Fleuriot, Jacques";Collaboration across institutional boundaries is widespread and increasing today. It depends on federations sharing data that often have governance rules or external regulations restricting their use. However, the handling of data governance rules (aka. data-use policies) remains manual, time-consuming and error-prone, limiting the rate at which collaborations can form and respond to challenges and opportunities, inhibiting citizen science and reducing data providers' trust in compliance. Using an automated system to facilitate compliance handling reduces substantially the time needed for such non-mission work, thereby accelerating collaboration and improving productivity. We present a framework, Dr.Aid, that helps individuals, organisations and federations comply with data rules, using automation to track which rules are applicable as data is passed between processes and as derived data is generated. It encodes data-governance rules using a formal language and performs reasoning on multi-input-multi-output data-flow graphs in decentralised contexts. We test its power and utility by working with users performing cyclone tracking and earthquake modelling to support mitigation and emergency response. We query standard provenance traces to detach Dr.Aid from details of the tools and systems they are using, as these inevitably vary across members of a federation and through time. We evaluate the model in three aspects by encoding real-life data-use policies from diverse fields, showing its capability for real-world usage and its advantages compared with traditional frameworks. We argue that this approach will lead to more agile, more productive and more trustworthy collaborations and show that the approach can be adopted incrementally. This, in-turn, will allow more appropriate data policies to emerge opening up new forms of collaboration.;Yes;Might have to check again, this is not really relevant to businesses I think;;Yes;Not a heavy focus on law, but rather data use policies;No;No;Yes;No;GOLOG, situation calculus (extension of FOL);No;No (only internal);Manual;Not optimized;No;No;Compliance;Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3452021.3458310;https://doi.org/10.1145/3452021.3458310;Model-theoretic Characterizations of Rule-based Ontologies;2021;"Console, Marco; Kolaitis, Phokion G.; Pieris, Andreas";An ontology specifies an abstract model of a domain of interest via a formal language that is typically based on logic. Although description logics are popular formalisms for modeling ontologies, tuple-generating dependencies (tgds), originally introduced as a unifying framework for database integrity constraints, and later on used in data exchange and integration, are also well suited for modeling ontologies that are intended for data-intensive tasks. The reason is that, unlike description logics, tgds can easily handle higher-arity relations that naturally occur in relational databases. In recent years, there has been an extensive study of tgd-ontologies and of their applications to several different data-intensive tasks. However, the fundamental question of whether the expressive power of tgd-ontologies can be characterized in terms of model-theoretic properties remains largely unexplored. We establish several characterizations of tgd-ontologies, including characterizations of ontologies specified by such central classes of tgds as full, linear, guarded, and frontier-guarded tgds. Our characterizations use the well-known notions of critical instance and direct product, as well as a novel locality property for tgd-ontologies. We further use this locality property to decide whether an ontology expressed by frontier-guarded (respectively, guarded) tgds can be expressed by tgds in the weaker class of guarded (respectively, linear) tgds, and effectively construct such an equivalent ontology if one exists.;Yes;No new representation? Technically has to be excluded I think;;No;Not law focused;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/956750.956845;https://doi.org/10.1145/956750.956845;Similarity analysis on government regulations;2003;"Lau, Gloria T.; Law, Kincho H.; Wiederhold, Gio";Government regulations are semi-structured text documents that are often voluminous, heavily cross-referenced between provisions and even ambiguous. Multiple sources of regulations lead to difficulties in both understanding and complying with all applicable codes. In this work, we propose a framework for regulation management and similarity analysis. An online repository for legal documents is created with the help of text mining tool, and users can access regulatory documents either through the natural hierarchy of provisions or from a taxonomy generated by knowledge engineers based on concepts. Our similarity analysis core identifies relevant provisions and brings them to the user's attention, and this is performed by utilizing both the hierarchical and referential structures of regulations to provide a better comparison between provisions. Preliminary results show that our system reveals hidden similarities that are not apparent between provisions based on node content comparisons.;Yes;Similarity for regulations and so, not just case law;;No;Similarity not realy compliance;;;;;;;;;;;;;Accesbility;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3047273.3047341;https://doi.org/10.1145/3047273.3047341;Regulatory Requirements Compliance in e-Government System Development: an Ontology Framework;2017;"Hasan, M. Mahmudul; Aganostopoulos, Dimosthenis; Loucopoulos, Pericles; Nikolaidou, Mara";Electronic government (e-Government) is increasingly gaining attention by the government and researcher to shape the public sector into digital society through enacting several e-Government system development policies and regulations. Hence, the compliance of regulatory requirement from these policies and regulations become an important accountability in e-Government project development where the concepts of regulatory requirements compliance is still scattered in the e-Government domain. This paper presents an ontology framework that describes the formal and explicit specification of the concepts of regulatory requirements compliance and their relations in e-Government system development. The ontology engineering technique 101 and Systematic Literature Review (SLR) were used in the process of developing the ontology framework of e-Government regulatory requirements compliance (eGovRRC). The e-Government system analyst can use this framework as a reference model to understand and conceptualize the interlinked set of clearly defined concepts of regulatory requirements compliance in e-Government system development projects.;Yes;;;Yes;;No;No;Yes;Yes;Informal (Future work if formalization using RDF/ OWL);Yes;No;Manual;Optimized;No;No;Compliance;e-Government;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2993318.2993329;https://doi.org/10.1145/2993318.2993329;Automating Financial Regulatory Compliance Using Ontology+Rules and Sunflower;2016;"Ford, Reginald; Denker, Grit; Elenius, Daniel; Moore, Wesley; Abi-Lahoud, Elie";Compliance departments in the international finance industry are struggling to use traditional methods to keep up with the demands of new and more stringent regulatory and policy requirements. One initiative supported by many institutions is definition of a common Financial Industry Business Ontology (FIBO). We regard a common ontology as an important step, but in order to support real-world uses cases, the ontology needs to be augmented, and further supplemented by rules that encode the meaning of regulations and policies. We use Sunflower, which is built on top of the Flora-2 knowledge representation languages and reasoner, to add automation to the compliance lifecycle. Sunflower is domain-agnostic, and financial regulatory compliance is one of its many application areas.;Yes;Just one specific ontology, but probably fitting;;Yes;;No;No;Yes;Yes;Flora-2 reasoning engine (includes defeasibility);Yes;Yes, mentions exports to other storage formats from Sunflower;Manual;Slightly optimized;Yes;Yes;Compliance;Finance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3209281.3209319;https://doi.org/10.1145/3209281.3209319;Regulatory supervision with computational audit in international supply chains;2018;"Wang, Yuxin; Hulstijn, Joris; Tan, Yao-hua";Nowadays, as international trade with cross-border logistics increases, the administrative burden of regulatory authorities has been dramatically raised. In order to reduce repetitive and redundant supervisory controls and promote automatic administration procedures, electronic data interchange (EDI)1 and other forms of information sharing are introduced and implemented. Compliance monitoring ensures data quality for information exchange and audit purpose. However, failure to be compliant with various regulations is still a general phenomenon globally among stakeholders in supply chains, leading to more problems such as delay of goods delivery, missing inventory, and security issues. To address these problems, traditional physical auditing methods are widely used but turned out to be time-consuming and costly, especially when multiple stakeholders are involved. Since there is limited empirical research on compliance monitoring for regulatory supervision in international supply chains, we propose a compliance monitoring framework that can be applied with data sharing and analytics. The framework implementation is validated by an extensive case study on customs supervision in the Netherlands using process mining techniques. Practically, both public and private sectors will benefit from our descriptive and prescriptive analytics for audit purposes. Theoretically, our control strategies developed at the operational level facilitates mitigation of risks at root causes.;Yes;;;No;"This is not really general representation of law, but just saying: We have this process model, make it law compliant and now continue. Idk, basically the process model just ""magically apears"" and there is little dicussion of how it is created";No;No;Yes;No;Petri Net, BPMN;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2514601.2514604;https://doi.org/10.1145/2514601.2514604;Argument schemes for reasoning with legal cases using values;2013;"Bench-Capon, Trevor; Prakken, Henry; Wyner, Adam; Atkinson, Katie";"Argument schemes can provide a means of explicitly describing reasoning methods in a form that lends itself to computation. The reasoning required to distinguish cases in the manner of CATO has been previously captured as a set of argument schemes. Here we present argument schemes that encapsulate another way of reasoning with cases: using preferences between social values revealed in past decisions to decide cases which have no exact matching precedents when the cases are described in terms of factors. We provide a set of schemes, with variations to capture different ways of comparing sets and varying degrees of promotion of values; we formalise these schemes; and we illustrate them with some examples.";Yes;Case law;;Yes;;Yes;Yes;No;No;Abstract argument framework, defeasible first order logic (ASPIC+);No, mentioned but not really integrated?;No;Manual;Sligthly optimized (Symbolic vs black box);No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2018358.2018368;https://doi.org/10.1145/2018358.2018368;Temporal accommodation of legal argumentation;2011;"Riveret, Régis; Rotolo, Antonino; Contissa, Giuseppe; Sartor, Giovanni; Vasconcelos, Wamberto";This paper proposes to integrate an argumentation framework with techniques from Temporal Constraint Satisfaction. Temporal constraints are thus embedded into legal argumentation to account for temporal aspects of legal reasoning. Through the accommodation of temporal constraints, the validity of arguments and of their conclusions is made relative to the time-points when the applied norms are alive, according to the adopted temporal perspective. A fixed-point semantics and an associated dialogue game are given.;Yes;legal argument;;Yes;Proof vs argument is well layed out here;Yes;No;Yes;No;defeasible logic;Yes, explicitely modelled;No;Manual;Not optimized;Yes (authors);No;Temporal reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2018358.2018359;https://doi.org/10.1145/2018358.2018359;Towards formalising argumentation about legal cases;2011;"Wyner, Adam Z.; Bench-Capon, Trevor J. M.; Atkinson, Katie M.";In this paper we offer an account of reasoning with legal cases in terms of argumentation schemes. These schemes, and undercutting attacks associated with them, are expressed as defeasible rules of inference that will lend themselves to formalisation within the AS-PIC+ framework. We begin by modelling the style of reasoning with cases developed by Aleven and Ashley in the CATO project, which describes cases using factors, and then extend the account to accommodate the dimensions used in Rissland and Ashley's earlier HYPO project. Some additional scope for argumentation is then identified and formalised.;Yes;argumentation;;Yes;;Yes;Yes;No;No;Abstract argument framework, defeasible first order logic (ASPIC+);No;No;Manual;No;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2018358.2018360;https://doi.org/10.1145/2018358.2018360;Legal shifts in the process of proof;2011;"Bex, Floris; Verheij, Bart";In this paper, we continue our research on a hybrid narrative-argumentative approach to evidential reasoning in the law by showing the interaction between factual reasoning and legal reasoning. We therefore emphasize the role of legal story schemes (as opposed to factual story schemes that formed the heart of our previous proposal). Legal story schemes steer what needs to be proven, but are also selected on the basis of what can be proven. They provide a coherent, holistic legal perspective on a criminal case that steers investigation and decision making. We present an extension of our previously proposed hybrid theory of reasoning with evidence, by making the connection with reasoning towards legal consequences. We discuss the phenomenon of legal shifts that shows that the step from evidence to (proven) facts cannot be isolated from the step from proven facts to legal consequences. We show how legal shifts can be modelled in terms of legal story schemes. Our model is illustrated by a discussion of the Dutch Wamel murder case.;Yes;Perfect in terms of change managment;;Yes;I think I did not fully grasp this paper… Maybe check again;Yes (evidential reasoning);Yes;No;No;Horn-clauses with only defeasible implication (Not sure how to call this);No;No;Manual (Not specified);Not optimized;No;No;Proof;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1568234.1568250;https://doi.org/10.1145/1568234.1568250;Legal reasoning with argumentation schemes;2009;"Gordon, Thomas F.; Walton, Douglas";Legal reasoning typically requires a variety of argumentation schemes to be used together. A legal case may raise issues requiring argument from precedent cases, rules, policy goals, moral principles, jurisprudential doctrine, social values and evidence. We present an extensible software architecture which allows diverse computational models of argumentation schemes to be used together in an integrated way to construct and search for arguments. The architecture has been implemented in Carneades, a software library for building argumentation tools. The architecture is illustrated with models of schemes for argument from ontologies, rules, cases and testimonial evidence and compared to blackboard systems for hybrid reasoning.;Yes;Case Law;;Yes;Not sure, this seems to have a bit of the wrong focus. Rething this;Yes;Yes;Yes;No;Description Logic, OWL (?);No;No;Manual (Not specified);Not optimized;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1109/WIIAT.2008.168;https://doi.org/10.1109/WIIAT.2008.168;Obligations with Deadlines and Maintained Interdictions in Privacy Regulation Frameworks;2008;"Piolle, Guillaume; Demazeau, Yves";We aim at providing artificial agents with logical tools to reason specifically on privacy-related regulations, in order to comply with them. In order to express these regulations, we propose a deontic and temporal logic based on predicates dealing with personal data management. Using an example, we show the need for specific operators to express obligations with deadlines and maintained interdictions. We define a set of eight specific requirements for such operators, we evaluate the existing proposals with respect to these requirements and we adapt our own ones, to better suit to our formalism.;Yes;Not 100% sure;;Yes;;No;No;Yes;No;Deontic logic with temporal aspects;No;No;Manual;Not optimized;No;No;Compliance;Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.159010;https://doi.org/10.1145/158976.159010;A logic for legal hierarchies;1993;Schobbens, Pierre-Yves;The theory of non-monotonic reasoning has interesting applications for the formalization and automated use of legal concepts, specially:In this paper, we use a logic [37, 38], that ranks contradictory formulae using two new paraconsistent variants of conjunction: “but” and “on the other hand”. Its algebraic proof theory is presented.;Yes;;;Yes;;No;No;Yes;No;FOL with defeaters;No;No;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3030024.3038261;https://doi.org/10.1145/3030024.3038261;Visual Exploration of Unstructured Regulatory Documents;2017;"Madaan, Nishtha; Karanam, Hima; Gupta, Ankush; Jain, Nitisha; Kumar, Arun; Tamilselvam, Srikanth";Governmental authorities publish rules and directives that govern the operations of an industry. These documents, called regulations, are meant to safeguard the interests of consumers. With increasing number, size and complexity of such documents, companies face an uphill task to comply with them. We present a cognitive system, called Cogpliance, for exploring and understanding regulatory documents with the goal of assisting compliance officers in attaining regulatory compliance. Cogpliance automatically reads natural language regulatory documents, extracts key concepts and presents an interactive information exploration user interface for answering compliance officers queries.;Yes;"Good example for no reasoning, but ""only"" displaying";;No;Sure, put this in the discussion, but no need to unclude, only visualisation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1568234.1568245;https://doi.org/10.1145/1568234.1568245;Segmentation of legal documents;2009;Loza Mencía, Eneldo;An overwhelming number of legal documents is available in digital form. However, most of the texts are usually only provided in a semi-structured form, i.e. the documents are structured only implicitly using text formatting and alignment. In this form the documents are perfectly understandable by a human, but not by a machine. This is an obstacle towards advanced intelligent legal information retrieval and knowledge systems. The reason for this lack of structured knowledge is that the conversion of texts in conventional form into a structured, machine-readable form, a process called segmentation, is frequently done manually and is therefore very expensive.We introduce a trainable system based on state-of-the-art Information Extraction techniques for the automatic segmentation of legal documents. Our system makes special use of the implicitly given structure in the source digital file as well as of the explicit knowledge about the target structure. Our evaluation on the French IPR Law demonstrates that the system is able to learn an effective segmenter given only a few manually processed training documents. In some cases, even only one seen example is sufficient in order to correctly process the remaining documents.;Yes;;;No;Purely structural analysis;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1052220.1052279;https://doi.org/10.1145/1052220.1052279;An e-government information architecture for regulation analysis and compliance assistance;2004;"Lau, Gloria T.; Kerrigan, Shawn; Law, Kincho H.; Wiederhold, Gio";The complexity and diversity of government regulations make understanding the regulations a non-trivial task. One of the issues is the existence of multiple sources of regulations and interpretive guides. In this work, we propose an information infrastructure for regulation analysis, which includes a document repository and tools for compliance assistance and similarity analysis. A regulatory repository is developed based on an XML format, and important features, such as concepts and measurements, are extracted using handcrafted rules and a text mining tool. Our framework provides compliance assistance using a reasoning tool based on First Order Predicate Calculus logic, where users are alerted of detected conflicts or otherwise compliance with the regulation. A relatedness analysis is performed by comparing the extracted features as well as structural and referential information from regulations. Examples of an electronic-rulemaking scenario and a compliance checking procedure are shown to demonstrate current capabilities of the prototype system.;Yes;ICP?;;Yes;Same technology as in https://dl.acm.org/doi/pdf/10.1145/1047788.1047820;No;No;Yes;No;First order logic (Embedded in XML);No;No;tool supported;Yes (Natural language);No (Knowledge engineer is not further specified);No;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2494603.2480302;https://doi.org/10.1145/2494603.2480302;Verification of interactive software for medical devices: PCA infusion pumps and FDA regulation as an example;2013;"Masci, Paolo; Ayoub, Anaheed; Curzon, Paul; Harrison, Michael D.; Lee, Insup; Thimbleby, Harold";Medical device regulators such as the US Food and Drug Administration (FDA) aim to make sure that medical devices are reasonably safe before entering the market. To expedite the approval process and make it more uniform and rigorous, regulators are considering the development of reference models that encapsulate safety requirements against which software incorporated in to medical devices must be verified. Safety, insofar as it relates to interactive systems and its regulation, is generally a neglected topic, particularly in the context of medical systems. An example is presented here that illustrates how the interactive behaviour of a commercial Patient Controlled Analgesia (PCA) infusion pump can be verified against a reference model. Infusion pumps are medical devices used in healthcare to deliver drugs to patients, and PCA pumps are particular infusion pump devices that are often used to provide pain relief to patients on demand. The reference model encapsulates the Generic PCA safety requirements provided by the FDA, and the verification is performed using a refinement approach. The contribution of this work is that it demonstrates a concise and semantically unambiguous approach to representing what a regulator's requirements for a particular interactive device might be, in this case focusing on user-interface requirements. It provides an inspectable and repeatable process for demonstrating that the requirements are satisfied. It has the potential to replace the considerable documentation produced at the moment by a succinct document that can be subjected to careful and systematic analysis.;Yes;I think, not 100% sure;;Yes;;No;No;Yes;No;Predicate logic (Note, Higher-order logic seems to only be used to model ;No;No;Manual;No;No;No;Safety;Medical devices, Software;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/10.5555/1124191.1124309;A software infrastructure for government regulation analysis and compliance assistance;2004;"Lau, Gloria T.; Kerrigan, Shawn; Wang, Haoyi; Law, Kincho H.; Wiederhold, Gio";Government regulations are voluminous, heavily cross-referenced and often ambiguous. To cope with the complexity and diversity of regulations, we developed a formal information infrastructure for regulation management, analysis and compliance assistance. In this system demonstration, several aspects of the project are shown - a regulatory document repository, a regulation assistance system and an e-rulemaking analysis prototype. Together, our system aids in understanding and compliance of government regulations and related documents. In order to develop a prototype system, we focus on accessibility and environmental regulations. The compliance assistance system is illustrated in the domain of used oil management, while the e-rulemaking analysis is performed on accessible public rights-of-way rules.;Yes;;;No;This basially has no content;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/10.5555/1065226.1065328;ITR/IM+SII: a distributed information management framework (REGNET) for environmental laws and regulations;2005;Law, Kincho H.;The complexity, diversity, and volume of Federal and State regulations (as well as supplementary and supportive documents) are detrimental to businesses and hinder public understanding of government. The objective of REGNET project is to develop information infrastructure and tools for regulatory information management and to facilitate compliance assistance. As a pilot research application, the REGNET project focuses on environmental regulations. The basic research tasks include: (1) textual parsing and storage, (2) semi-structured, indexed storage, (3) means to resolve semantic ambiguities, (4) cross-referencing appropriate for automated retrieval and analysis of relevant documents, and (5) on-line compliance checking of governmental regulations. The experimental scope of this project focuses on Code of Federal Regulations (CFR) Title 40: Protection of the Environment and California Code of Regulations (CCR) Title 22: Social Security. Implementation examples include regulations and selected supplementary documents, covering hazardous waste, drinking water and the management of used oil.;Yes;;;No;Basically a duplicate of the other law papers, but this one seems to be more automated? Ask Marisol what to do with this;No;No;Yes;No;;;;semi-automatic;;;;Compliance;Environment;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/10.5555/1124191.1124255;An information infrastructure for government regulation analysis and compliance assistance;2004;"Lau, Gloria T.; Kerrigan, Shawn; Wang, Haoyi; Law, Kincho H.; Wiederhold, Gio";"The complexity and diversity of government regulations make understanding the regulations a non-trivial task. One of the issues is the existence of multiple sources of regulations and interpretive guides; the latter are often independent of governing bodies. In this work, we describe a research prototype system that combines text mining and knowledge management techniques to help better manage, understand and analyze regulatory documents. This regulatory information infrastructure includes three integral parts: a document repository, a tool for similarity analysis and a compliance assistance system. This paper first presents the development of a legal corpus with multiple sources of regulatory documents consolidated into a unified format. A shallow parser is developed to consolidate different regulations into a unified XML format, which is well suited for handling semi-structured data such as legal documents. Important features, such as concepts, measurements, definitions and so on, are extracted and incorporated into the corpus by using handcrafted rules and text mining tools. A regulation compliance assistance system is introduced next, where First Order Predicate Calculus (FOPC) logic sentences are implemented to help users to perform compliance check in a question and answer session. Finally, a similarity analysis for regulations is developed, where Information Retrieval (IR) and structural matching techniques are used to identify related provisions among regulations.";Yes;;;No;This is the same paper for the 4th time basically. Will have to order probably and choose latest;No;No;Yes;No;First order logic embedded in XML;no;no;manual;Yes (readable natural language with logic metadata);No;No;Compliance;Environment;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1047788.1047833;https://doi.org/10.1145/1047788.1047833;Modelling legal reasoning in a mathematical environment through model theoretic semantics;2003;"Brasil, Samuel Meira; Garcia, Berilhes Borges";We introduce a mathematical model of legal reasoning using an underlying conditional logic semantics, to allow its tractability in some special cases. The main idea is to capture the entailment of legal consequences through a model of 0-1 programming. For such task, first we model legal reasoning with Lehmann's Lexicographic semantics and then we translate it to an instance of weighted MAXSAT problem, in order to compute the logical consequences of legal reasoning. Hence, combinatorial optimization algorithms can be used to yield the legal consequences of defeasible reasoning over legal conditional knowledge bases.;Yes;;;Yes;;No;Yes;Yes;No;SAT, defeasibie logic (Horn clauses);No;Yes (defeasible logic to SAT?);manual;No;Yes (authors, FDV Faculdades de Vitoria seems to be a legal faculty);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2046660.2046678;https://doi.org/10.1145/2046660.2046678;Managing multi-jurisdictional requirements in the cloud: towards a computational legal landscape;2011;"Gordon, David G.; Breaux, Travis D.";Although cloud services allow organizations to transfer the planning and setup to the service provider and thus reduce costs through reuse, these services raise new questions regarding the privacy and security of personal information stored in and transferred across systems in the cloud. Prior to cloud services, personal information was commonly stored within the owning or licensing company's locality where the company maintained its facilities. Cloud services, however, move data to remote, potentially unknown, locations maintained by third parties. The responsibility for data protection and integrity no longer remains exclusively with its owner or licensee, but with these third parties. Thus, both parties must identify and manage the many regulatory requirements that govern their services and products in this multi-jurisdictional environment. To simplify this problem, we are developing methods to extract and codify regulatory requirements from government laws. We apply previously validated metrics to measure gaps and overlaps between the codified regulations. Our findings include a semi-formalization of the legal landscape using operational constructs for high- and low-watermark practices, which correspond to high- and low standards of care, respectively. Business analysts and system developers can use these watermarks to reason about compliance trade-offs based on perceived businesses costs and risks. We discovered and validated these constructs using seven U.S. state data breach notification laws that govern transactions of financial and health information of residents of these seven states.;Yes;;;Yes;;No;No;Yes;No;"firt order logic; Requirements Specification Language (RSL)";No, mentioned, but not really expanded upon;Yes (To XML like formats, no logical translation);tool supported;Yes, Use of natural language connected by logic;Yes;No;Compliance;"Cloud; Multi-Jurisdiction";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2808797.2809368;https://doi.org/10.1145/2808797.2809368;Information Extraction of Regulatory Enforcement Actions: From Anti-Money Laundering Compliance to Countering Terrorism Finance;2015;"Plachouras, Vassilis; Leidner, Jochen L.";Financial fines imposed by regulatory bodies to penalize illegal activities and violations against regulations (cases of non-compliance) have recently become more common, and the sizes of fines have increased. This development coincides with the ongoing increase of complexity of regulatory rules. Huge fines have been imposed on banks for financial fraud and regulations have been made more stringent after 9/11 to curb funding of terrorist groups. Market players would also like to have available a database of fine events for a range of applications, such as to benchmark their competitors performance, or to use it as an early warning system for detecting shifts in regulators' enforcement behavior. To this end, we introduce the task of extracting fines from regulatory enforcement actions and we present a method to extract such fine event instances from timeline-like descriptions of regulatory investigation activities authored by legal professionals for a commercial product. We evaluate how well a rule-based method can extract information about fine events and we compare its performance to a machine-learning baseline. To the best of our knowledge, this work is the first one addressing this task.;Yes;A bit too specific, but generally acceptable;;No;this is just extraction of specific information, no real representation afterwards;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3462757.3466081;https://doi.org/10.1145/3462757.3466081;A combined rule-based and machine learning approach for automated GDPR compliance checking;2021;"Hamdani, Rajaa El; Mustapha, Majd; Amariles, David Restrepo; Troussel, Aurore; Meeùs, Sébastien; Krasnashchok, Katsiaryna";The General Data Protection Regulation (GDPR) requires data controllers to implement end-to-end compliance. Controllers must therefore ensure that the terms agreed with the data subject and their own obligations under GDPR are respected in the data flows from data subject to controllers, processors and sub processors (i.e. data supply chain). This paper seeks to contribute to bridge both ends of compliance checking through a two-pronged study. First, we conceptualize a framework to implement a document-centric approach to compliance checking in the data supply chain. Second, we develop specific methods to automate compliance checking of privacy policies. We test a two-modules system, where the first module relies on NLP to extract data practices from privacy policies. The second module encodes GDPR rules to check the presence of mandatory information. The results show that the text-to-text approach outperforms local classifiers and enables the extraction of both coarse-grained and fine-grained information with only one model. We implement full evaluation of our system on a dataset of 30 privacy policies annotated by legal experts. We conclude that this approach could be generalized to other documents in the data supply as a means to improve end-to-end compliance.;Yes;;;Yes;Focus only on section 5 as the others seem to have no LIR;No;No;Yes;No;JsonLogic, Subset of First order Logic?;No;No;Manual;No (JsonLogic);Yes;No (Privacy Policies);Compliance;Privacy (EU);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/323706.323799;https://doi.org/10.1145/323706.323799;Developing computational models of discretion to build legal knowledge based systems;1999;"Kerner, Yaakov HaCohen; Schild, Uri; Zeleznikow, John";Few legal knowledge based systems have been constructed which provide numerical advice. None have been built in discretionary domains. Our research, directed towards the domains of sentencing and family law property division has lead to the development of three distinct forms of judicial discretion.To model these different discretionary domains we use diverse artificial intelligence tools including case-based reasoning and knowledge discovery from databases. We carry out a detailed comparison of two discretionary legal knowledge based systems. Judge's Apprentice is a case-based reasoner which recommends ranges of sentences for convicted Israeli rapists and robbers. SplitUp uses Knowledge Discovery from Databases to learn what percentage of marital property the partners to a divorce in Australia will receive. The systems are compared with regard to reasoning, explanation, evaluation and coping with conflicting cases.;Yes;Not sure, might be very heavy on the case base;;No;A bit too case based without much modeling of law. This is technically very similar to ADF so you could argue for inclusion but I do not see the added value here;Yes;Yes;No;No;Weighted Trees;;;;No;Yes;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://link.springer.com/chapter/10.1007/978-3-642-24606-7_5;Establishing regulatory compliance for software requirements;2011;"Ingolfo, Silvia; Siena, Alberto; Mylopoulos, John";A software system complies with a regulation if its operation is consistent with the regulation under all circumstances. The importance of regulatory compliance for software systems has been growing, as regulations are increasingly impacting both the functional and nonfunctional requirements of legacy and new systems. HIPAA and SOX are recent examples of laws with broad impact on software systems, as attested by the billions of dollars spent in the US alone on compliance. In this paper we propose a framework for establishing regulatory compliance for a given set of software requirements. The framework assumes as inputs models of the requirements (expressed in i*) and the regulations (expressed in Nòmos). In addition, we adopt and integrate with i* and Nòmos a modeling technique for capturing arguments and establishing their acceptability. Given these, the framework proposes a systematic process for revising the requirements, and arguing through a discussion among stakeholders that the revisions make the requirements compliant. Our proposed framework is illustrated through a case study involving fragments of the HIPAA regulation.;Yes;;;Yes;Focus is much more on the requirements modelling, not the regulation modelling;Yes;No;Yes;No;Nòmos (Goal driven);No;No;"manual (not specified, ""Regulations as input in Nòmos as a given)";No;No;No (only in related work);Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2065003.2065021;https://doi.org/10.1145/2065003.2065021;Towards semantic methodologies for automatic regulatory compliance support;2011;"Sapkota, Krishna; Aldea, Arantza; Duce, David A.; Younas, Muhammad; Bañares-Alcántara, René";Businesses and organizations must comply with requirements and expectations such as regulations, policies, mandates and guidelines to meet public standards and avoid hefty penalties. Checking compliance manually is a laborious, extensive and error-prone process. The problems in the process are, to some extent, alleviated by using computerized compliance management systems. However, these systems are experiencing challenges in coping with the frequent changes and updates in the regulations. This paper describes our research on the use of semantic web technologies to support compliance management. In particular, we propose a methodology, RegCMatic that supports the management of the compliance system. Its originality lies on automating the extraction of regulatory information from regulatory texts, and mapping regulations to organizational internal processes. Our proposed methodology is applied to the Pharmaceutical industry, where regulatory information is extracted from the Eudralex EU regulation and modeled using a semantic formalism.;Yes;;;Yes;;No;No;Yes;No (uses ontology);According to SemReg Ontology;No (Limitation);No;tool supported;No;No;No (But hinted at + related work);Compliance;Pharma;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2000799.2000802;https://doi.org/10.1145/2000799.2000802;Discovering Multidimensional Correlations among Regulatory Requirements to Understand Risk;2011-09;"Gandhi, R. A.; Lee, S. W.";Security breaches most often occur due to a cascading effect of failure among security constraints that collectively contribute to overall secure system behavior in a socio-technical environment. Therefore, during security certification activities, analysts must systematically take into account the nexus of causal chains that exist among security constraints imposed by regulatory requirements. Numerous regulatory requirements specified in natural language documents or listed in spreadsheets/databases do not facilitate such analysis. The work presented in this article outlines a stepwise methodology to discover and understand the multidimensional correlations among regulatory requirements for the purpose of understanding the potential for risk due to noncompliance during system operation. Our lattice algebraic computational model helps estimate the collective adequacy of diverse security constraints imposed by regulatory requirements and their interdependencies with each other in a bounded scenario of investigation. Abstractions and visual metaphors combine human intuition with metrics available from the methodology to improve the understanding of risk based on the level of compliance with regulatory requirements. In addition, a problem domain ontology that classifies and categorizes regulatory requirements from multiple dimensions of a socio-technical environment promotes a common understanding among stakeholders during certification and accreditation activities. A preliminary empirical investigation of our theoretical propositions has been conducted in the domain of The United States Department of Defense Information Technology Security Certification and Accreditation Process (DITSCAP). This work contributes a novel approach to understand the level of compliance with regulatory requirements in terms of the potential for risk during system operation.;Yes;Heavy focus on security, but also contains a section on modelling so at least have a proper look;;No;No real LIR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1047788.1047826;https://doi.org/10.1145/1047788.1047826;On original generation of structure in legal documents;2003;"Kimbrough, Steven O.; Lee, Thomas Y.; Padmanabhan, Balaji; Yang, Yinghui";This position paper advocates a vision in the development of automated legal reasoning and presents evidence supporting the plausibility of that vision. The paper observes that original creation of documents of legal import in either fully formal or semistructured form offers the prospect of greatly reducing the cost and expanding the scope of knowledge engineering for legal reasoning. This, it is claimed, is most likely to be achieved via formalization of various sublanguages of legal discourse. SeaSpeak is an example of such a sublanguage and it appears to be amenable to full formalization. Short of that, much can be done with partial formalization and semistructured documents. The paper presents a tabular format for message expression, motivated by a formal agent communication language.;Yes;;;No;How did this land in the second round?! This is a position paper on the generation of legal documetns???;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;;Establishing regulatory compliance for information system requirements: an experience report from the health care domain;2010;"Siena, Alberto; Armellin, Giampaolo; Mameli, Gianluca; Mylopoulos, John; Perini, Anna; Susi, Angelo";Adherence to laws and regulations imposes important constraints on organizations, for legacy and new systems, both for their design and operation. Nòmos is a framework that supports the development of compliant software systems. In this paper, we report on the application of Nòmos in an industrial project, to provide model-based evidence that a set of requirements for a healthcare information system are compliant with a specific law. Compliance is treated as a collection of assigned responsibilities to social and system actors. The design of compliance pays special attention to auditability, i.e., making sure that design-time compliance is actually being adhered to.;Yes;Very use casey, but I feel like there is still a lot to learn;;Yes;What is with the first round comment???;No;No;Yes;No;Nòmos;No;No;Manual;No;Yes;No;Compliance;Health care;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2971603.2971629;https://doi.org/10.1145/2971603.2971629;"Ontology-based model of law retrieval system for R&amp;D projects";2016;"Kim, Wooju; Lee, Youna; Kim, Donghe; Won, Minjae; Jung, HaeMin";"Research and development projects have close relationship with laws. In some cases, new technologies resulted from R&amp;D projects can't be used because some statutes restrict them. The reason of this problem is that researchers don't know exactly which laws can affect their R&amp;D projects. To solve the issue, we suggest a model for law retrieval system that can be used by researchers of R&amp;D projects to find related statutes. Input of this model is a query document that describes the main contents of a project. By using ontology, legal terms are extracted from the document and statutes defining them are retrieved as a set of related laws. After this searching process, statutes are provided to researchers with their ranks, which are assigned using relevance scores we developed. By using this model, we can make a system for researchers to search a list of statutes that may affect R&amp;D projects, and finally, they can adjust their project's direction by checking the list, preventing their works from being useless.";Yes;Law retreival (not case retrieval);;No;Too retrieval focused, little more;No;No;Yes;Yes;;;;;;;;Retrieval;R&D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.159001;https://doi.org/10.1145/158976.159001;A simple computational model for nonmonotonic and adversarial legal reasoning;1993;Sartor, Giovanni;In many commonsense contexts only incoherent and conflicting information is available. In such contexts reasonable conclusions must be derived from inconsistent sets of premises. This is especially the case in legal reasoning: legal norms can be issued by different authorities, in different times, to reach incompatible socio-political objectives, and the meaning of those norms can be semantically indeterminate.Logic deduction alone is insufficient to derive justified conclusions out of inconsistent legal premises, since in the most popular logical systems (such as classical or intuitionistic logic) everything can be deduced from any contradiction. Nevertheless, much research now underway shows that formal methods can be developed for reasoning with conflicting information. The possibility of obtaining justified conclusions from an inconsistent set of premises increases when an ordering is defined over that set, since the ordering of the premises can be translated into an ordering of the competing arguments. This fact is particularly relevant for legal reasoning, since lawyers effectively solve normative conflicts by using ordering relations.In the following page, a model for reasoning with ordered defaults, interpreted as unidirectional inference rules, is proposed: a language for representing (possibly) contradictory rules is introduced, a notion of argument is defined, and types of arguments are distinguished. A simple interpreter in Prolog able to develop those arguments is also illustrated. Finally, the significance of the proposed model (and, more generally, of the acceptance of inconsistency) for the formal analysis of legal systems is discussed.;Yes;;;Yes;;Yes;No;Yes;No;Defeasible Horn Clauses;No;No;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1276318.1276355;https://doi.org/10.1145/1276318.1276355;Representational complexity in law;2007;"Surden, Harry; Genesereth, Michael; Logu, Bret";Computationally represented laws should accurately model their real-world counterparts in rules-based legal compliance systems. Legal theoretical considerations, however, often complicate the task of faithful representation. One approach to this problem has been to create sophisticated models capable of representing rules of arbitrary legal complexity. An alternative approach, which we advocate in this paper, is to focus on a subset of individual legal rules which are more amenable to simplified computational representation from a legal theoretical perspective. We propose a measure of such a tendency that we term the representational complexity of a legal rule. Our approach involves a systematic examination of particular legal rules along all of the relevant dimensions of legal theoretical complexity identified by the legal scholarship. In this way, we suggest that is possible to identify discrete legal rules which are likely to be, from a legal theoretical standpoint, amenable to simpler computational representation.;Yes;;;No;To meta, just an opinion piece;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2846012.2846022;https://doi.org/10.1145/2846012.2846022;A Workflow-Based Solution for the Law Study Process Management;2015;"Cherouana, Amina; Aouine, Amina; Mahdaoui, Latifa";In the context of e-government engineering, legal requirements capture is arguably the most important phase in order to ensure the compliance of public e-services with the rigorous legal basis characterizing public institutions. This step is a strongly cooperative process that brings into interaction three roles with different skills and prerequisites. This paper proposes a workflow-based solution providing a cooperative space for these involved roles and an execution environment of the instances of the law study process. In addition, it also allows the assessment and the validation of the resulting legal requirements through a law meta-model.;Yes;Eh, basically this is more about organizational structures than CS in the classical sense from my point of view;;No;Too much focus on the workflow, law only represented via meta-models;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/323706.323798;https://doi.org/10.1145/323706.323798;A demonstration of a legal reasoning system based on teleological analogies;1999;"Kakuta, Tokuyasu; Haraguchi, Makoto";In this article, we demonstrate our analogical legal reasoning system based on a teleological approach to interpret laws, using an actual example. By this demonstration, we show the validity of our approach. The example is based on a real legal problem and consists of an actual case, the actual decision on the case by the Japanese Supreme Court and two major doctrines on the case in Japan. The problem and the doctrines are also analyzed from the viewpoint of GDA (Goal-Dependent Abstraction) framework in this article. We further show that our system using GDA can provide helpful information to evaluate and revise interpretations of legal rules.;Yes;;;Yes;;No;No;Yes;No;order-sorted horn clauses (+ Terminological KB, basically hierarchical relations);No;No;Manual;Not optimized;Yes (authors);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1047788.1047824;https://doi.org/10.1145/1047788.1047824;Using configuration technology as the core of a legal decision support system;2003;"van der Meer, Erik R.; Henriksen, Ioanna Stavrinidou; Andersen, Henrik Reif";This paper is concerned with the development of a logical model of a given legal act and the realization of a web-based decision support system on the basis of this model. The system is implemented using a configuration engine, which provides full propositional reasoning in polynomial time (after an off-line compilation step), and a good web-coupling infrastructure. To the best of our knowledge it is the first decision support system that is based on such an engine. Further issues that are addressed are the main problems that were encountered during the modeling of the act and the techniques that have been used to overcome them, as well as a number of user interface issues that are of crucial importance if such a system is to be accepted by its users.;Yes;;;Yes;Shows limits of propositionsl logic;No;No;Yes;No;Propositional Logic, Binary Decision Diagrams + Turing Complete Languge (JS);Yes (Though tbh not sophisticated);No, only internal from PML to Binary Decision Diagrams;Manual;Optimized;Yes (in evaluation);No;Reasoning;Pension;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.159013;https://doi.org/10.1145/158976.159013;Identification of implicit legal requirements with legal abstract knowledge;1993;"Sakurai, Seiichiro; Yoshino, Hajime";In order to acquire legal rules from legal texts, legal requirements and legal effects must be identified. However, some of legal requirements are expressed implicitly. Such implicit legal requirements can be found by lawyers when they understand legal texts. In this paper, to mechanize legal knowledge acquisition process, a lawyer's understanding process of legal texts is analyzed. The lawyer's understanding process can be viewed as an abductive reasoning process, since the lawyer can introduce implicit legal requirements which have not appeared in legal texts. This paper models such a reasoning process when lawyers understand legal texts. Based on the analysis of lawyer's understanding process, a knowledge acquisition support system is proposed.;Yes;;;Yes;;No;No;Yes;No;(Higher Order) Horn Clauses;No;No (only to other types of CPF);Manual;Optimized (The argument is that Horn Clauses can easily be understood by lawyers which I would personally doubt);No (Not explicitely stated, but hinted at);No;Knowledge deduction;UN sale of goods;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2462410.2462423;https://doi.org/10.1145/2462410.2462423;Privacy promises that can be kept: a policy analysis method with application to the HIPAA privacy rule;2013;"Chowdhury, Omar; Gampe, Andreas; Niu, Jianwei; von Ronne, Jeffery; Bennatt, Jared; Datta, Anupam; Jia, Limin; Winsborough, William H.";Organizations collect personal information from individuals to carry out their business functions. Federal privacy regulations, such as the Health Insurance Portability and Accountability Act (HIPAA), mandate how this collected information can be shared by the organizations. It is thus incumbent upon the organizations to have means to check compliance with the applicable regulations. Prior work by Barth et. al. introduces two notions of compliance, weak compliance (WC) and strong compliance (SC). WC ensures that present requirements of the policy can be met whereas SC also ensures obligations can be met. An action is compliant with a privacy policy if it is both weakly and strongly compliant. However, their definitions of compliance are restricted to only propositional linear temporal logic (pLTL), which cannot feasibly specify HIPAA. To this end, we present a policy specification language based on a restricted subset of first order temporal logic (FOTL) which can capture the privacy requirements of HIPAA. We then formally specify WC and SC for policies of our form. We prove that checking WC is feasible whereas checking SC is undecidable. We then formally specify the property WC entails SC, denoted by Δ, which requires that each weakly compliant action is also strongly compliant. To check whether an action is compliant with such a policy, it is sufficient to only check whether the action is weakly compliant with that policy. We also prove that when a policy ℘ has the Δ-property, the present requirements of the policy reduce to the safety requirements imposed by ℘. We then develop a sound, semi-automated technique for checking whether practical policies have the Δ-property. We finally use HIPAA as a case study to demonstrate the efficacy of our policy analysis technique.;Yes;Bit use casey but generally topical;;Yes;;No;No;Yes;No;(restricted) first-order linear temporal logic;No;Yes, from their subset of FOTL to a superset;tool supported;Not optimized;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2463728.2463764;https://doi.org/10.1145/2463728.2463764;REGNET: regulatory information management, compliance and analysis;2012;"Law, Kincho H.; Lau, Gloria";This paper describes a research effort that aims to develop information infrastructure and tools to facilitate access, compliance and analysis of government regulations. It is well recognized that the complexity, diversity, and volume of government regulations are detrimental to business and hinder public understanding of government. The burden of complying with regulations can fall disproportionately on small businesses since these businesses may not have the expertise or resources to keep track of the regulations and the requirements. The situation can potentially be improved by developing appropriate tools that can help facilitate the regulatory and compliance process. To illustrate, this paper discusses the applications of information technology for selected services related to regulations, such as compliance assistance, comparison of regulation from diverse sources, and e-rulemaking.;Yes;;;Yes?;Regnet again :D;No;No;Yes;No;first order logic;No (mentioned but not elaborated);No;tool supported;Optimized (UI, Natural Language);Yes;No;Compliance;Environment;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1806799.1806825;https://doi.org/10.1145/1806799.1806825;A machine learning approach for tracing regulatory codes to product specific requirements;2010;"Cleland-Huang, Jane; Czauderna, Adam; Gibiec, Marek; Emenecker, John";"Regulatory standards, designed to protect the safety, security, and privacy of the public, govern numerous areas of software intensive systems. Project personnel must therefore demonstrate that an as-built system meets all relevant regulatory codes. Current methods for demonstrating compliance rely either on after-the-fact audits, which can lead to significant refactoring when regulations are not met, or else require analysts to construct and use traceability matrices to demonstrate compliance. Manual tracing can be prohibitively time-consuming; however automated trace retrieval methods are not very effective due to the vocabulary mismatches that often occur between regulatory codes and product level requirements. This paper introduces and evaluates two machine-learning methods, designed to improve the quality of traces generated between regulatory codes and product level requirements. The first approach uses manually created traceability matrices to train a trace classifier, while the second approach uses web-mining techniques to reconstruct the original trace query. The techniques were evaluated against security regulations from the USA government's Health Insurance Privacy and Portability Act (HIPAA) traced against ten healthcare related requirements specifications. Results demonstrated improvements for the subset of HIPAA regulations that exhibited high fan-out behavior across the requirements datasets.";Yes;Keep in for now but not sure if I want to keep, this is about matching regulations to requirements. Probably good to show the broadness of the review but not 100% ideal paper;;No;See First round reason;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1920320.1920325;https://doi.org/10.1145/1920320.1920325;ENDORSE: a legal technical framework for privacy preserving data management;2010;"Malone, Paul; McLaughlin, Mark; Leenes, Ronald; Ferronato, Pierfranco; Lockett, Nick; Guillen, Pedro Bueso; Heistracher, Thomas; Russello, Giovanni";The ENDORSE project is concerned with providing assurances for data protection for both data controllers and data subjects. The project will define a rules based language called PRDL (Privacy Rules Definition Language) which can be used to express legislative requirements, organizational privacy policy as well as user consent. ENDORSE will provide a rules engine to ensure that privacy policies expressed in this language are compliant with legislative requirements for the applicable jurisdictions. In addition a set of technology adapters will be developed which will provide transformations from PRDL to target access control and policy configuration instances, which in turn can be used by organizations to ensure that internal data handling practices are in turn compliant. In parallel to this effort a certification methodology will be developed to provide a means of generating a privacy seals. This paper describes an overview of the project, the motivation behind the initiative, its aims and objectives as well as an introduction to the approach taken and technologies foreseen to achieves these aims. The paper also provides a discussion of how the results of the project can be applied in different scenarios.;Yes;Privacy specific but should be fine;;No;This seems like a very detailed research proposal. The formalisations are not yet provided;;;;;(Privacy Rules Definition Language, describes as similar to RuleML, so could be basically anything;;Yes (future work, adapters);;;;;Compliant Data Managment;Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3474624.3477069;https://doi.org/10.1145/3474624.3477069;Developing an Inspection Checklist for the Adequacy Assessment of Software Systems to Quality Attributes of the Brazilian General Data Protection Law: An Initial Proposal;2021;"Mendes, João; Viana, Davi; Rivero, Luis";"The General Data Protection Law (LGPD) in Brazil was created with the goal of regulating how associations collect, transmit and store users’ personal data. Although it became applicable in 2020, several software development teams still don’t know what quality attributes are necessary for a system to comply with such law and to avoid legal and monetary penalties. Furthermore, there are still no checklists for verifying quality criteria related to the Brazilian LGPD. In this paper, an inspection checklist is proposed to evaluate software systems regarding their adherence to the Brazilian LGPD. We identified the attributes from papers describing the impact of the law in the development of Brazilian software systems; and from papers describing existing techniques and quality attributes for evaluating the adherence of software systems to laws from other countries. The final evaluation checklist contains a total of 52 attributes distributed in evaluation categories, such as: transparency, legal rights, security, contentment and responsibility. To assess the proposed checklist, we applied the checklist to evaluate a government web application. The initial results indicate that the current version of the checklist allows the identification of problems regarding the adherence of software systems to the Brazilian LGPD.";Yes;Not 100% sure bit specific but might work;;No;EX2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.159003;https://doi.org/10.1145/158976.159003;Legal knowledge acquisition using case-based reasoning and model inference;1993;"Yamaguti, Takahira; Kurematsu, Masaki";Although Case-Based Reasoning comes out in order to solve knowledge acquisition bottleneck, a case structure acquisition bottleneck has emerged, superseding it. Because we cannot decide an appropriate case structure in advance, a framework for CBR should be able to improve a case structure dynamically, collecting and analyzing cases. Here is discussed a new framework for knowledge acquisition using CBR and model inference. Model Inference tries to obtain new descriptors(predicates) with interaction of a domain expert, regarding the predicate as the slots that compose a case structure, with an eye to the function of theoretical term generation. The framework has two features: (1) CBR obtains a more suitable group of slots (a case structure) incrementally through cooperation with model inference, and (2) model inference with theoretical term capability discovers the rules which deal with a given task better. Furthermore, we evaluate the feasibility of the framework by implementing it to deal with law interpretation and certify two features with the framework.;Yes;Case based;;Yes;;No;Yes;Yes;No;Horn clauses (as anb end result);No;No (Only from cases to the horn clauses);semi-automated;Optimized (slightly);No;No;Knowledge Acquisition;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/323706.323709;https://doi.org/10.1145/323706.323709;Toward adding knowledge to learning algorithms for indexing legal cases;1999;"Brüninghaus, Stefanie; Ashley, Kevin D.";Case-based reasoning systems have shown great promise for legal argumentation, but their development and wider availability are still slowed by the cost of manually representing cases. In this paper, we present our recent progress toward automatically indexing legal opinion texts for a CBR system. Our system SMILE uses a classification-based approach to find abstract fact situations in legal texts. To reduce the complexity inherent in legal texts, we take the individual sentences from a marked-up collection of case summaries as examples. We illustrate how integrating a legal thesaurus and linguistic information with a machine learning algorithm can help to overcome the difficulties created by legal language. The paper discusses results from a preliminary experiment with a decision tree learning algorithm. Experiments indicate that learning on the basis of sentences, rather than full documents, is effective. They also confirm that adding a legal thesaurus to the learning algorithm leads to improved performance for some, but not all, indexing concepts.;Yes;legal case;;No;"Indexing legal cases could be interesting, but this is a ""toward"" paper so will be strict here";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.158990;https://doi.org/10.1145/158976.158990;Towards a legal analogical reasoning system: knowledge representation and reasoning methods;1993;"Yoshino, Hajime; Haraguchi, Makoto; Sakurai, Seiichiro; Kagayama, Sigeru";Analogy has many important functions in the domain of law. Since the number of legal rules is restricted and their content is often incomplete, it is necessary at times for a lawyer to opt for an analogical application of a legal rule to a given case in order to decide the case properly. He may apply the rule, though it may not have originally been deemed related to such an event, on the basis of some similarity between the event of the case and the requirement of the relevant legal rule. This type of reasoning is called legal analogy. This paper analyzes an actual case of legal analogy in the field of Japanese civil law in order to clarify the reasoning methods used in analogy, as well as knowledge to justify the analogy. Finally it will be shown how the knowledge is utilized in a symbolic reasoning system both in terms of inverse and standard resolution.;Yes;;;Yes;;Yes;No;Yes;No;Horn Clauses;No;No;Manual;Not optimized;Yes (author);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/277339.277344;https://doi.org/10.1145/277339.277344;An application of rule-based and case-based reasoning within a single legal knowledge-based system;1997-09;"Pal, Kamalendu; Campbell, John A.";A knowledge-based system, Advisory Support for Home Settlement in Divorce (ASHSD), which gives advice on different aspects of matrimonial-home-settlement in English divorce law is described. The system employs two reasoning methods, rule-based reasoning (RBR) and case-based reasoning (CBR) in an integrated framework. It automates the estimation of the relative suitability of these reasoning methods for any given new case. This relative suitability is judged by matching the features of the selected best case and best rule against the new case. Standard methods of numerical taxonomy are used to determine which of the matches is best, and therefore whether a new case is better solved by calling on rules that express the usual legal knowledge in the area or by referring to a past case that has a interpretation of an ambiguous situation which rules fail to underpin.;Yes;not 100% sure;;Yes;;No;Yes;Yes;No;"IF... THEN for statues; semi-formal collection of facts for cases";No;No;Manual;Not optimized;Yes;No;Legal decision support;Home Settlement in Divorce;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2254129.2254162;https://doi.org/10.1145/2254129.2254162;Towards law-aware semantic cloud policies with exceptions for data integration and protection;2012;"Hu, Yuh-Jong; Wu, Win-Nan; Cheng, Di-Rong";The main issues related to cloud computing implementation are security, privacy, and law-awareness. We consider data protection with law-awareness as the major concern for cloud service providers (CSPs) and their customers. Therefore, we provide Law-as-a-Service (LaaS) for CSPs on our law-aware semantic cloud policy infrastructure. The semantic legal policies in compliance with the laws are enforced automatically at the super-peer to enable LaaS. This allows CSPs to deploy their cloud resources and services without worrying about law violations. Afterward, users could query data from the law-aware super-peer within a super-peer domain. Each query is also compliant with the laws. Policies are shown as a combination of OWL-DL ontologies and stratified Datalog rules with negation for a policy's exceptions handling through defeasible (or non-monotonic) reasoning. Finally, the proof-of-concepts prototype systems have been implemented for an H1N1 pandemic investigation scenario in the semantic cloud to justify our approach.;Yes;Does not hit the naul on the head, but yes, contains LKM;;Yes;Start 6.1;No;No;Yes;No;"Description Logic (DL)based ontologies; Datalog";Yes;No;Manual;Not optimized;No;No;Compliance of policies;Privacy, Cloud computing;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/1123196.1123283;Regulatory information management and compliance assistance;2003;"Kerrigan, Shawn; Heenan, Charles; Wang, Haoyi; Law, Kincho H.; Wiederhold, Gio";The REGNET Project aims to develop a formal information infrastructure for regulatory information management and compliance assistance. This paper discusses three components of current research and development efforts. The first is a document repository containing federal and state regulations and supplemental documents. This repository includes a suite of concept hierarchies that enable users to browse documents according to the terms they contain. The second is an XML framework for representing regulations and associated metadata. The XML framework enables the augmentation of regulation text with tools and information that will help users understand and comply with the regulation. The third component is the creation of a compliance assistance system built upon the XML framework. The compliance assistance system and the document repository can serve as a backend for the development of application-specific compliance guidance systems. The prototype effort for the document repository has been focused on environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management.;Yes;;;No;How many regnet papers are there??? Will exclude this one because it focuses on the document repo;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2064713.2064727;https://doi.org/10.1145/2064713.2064727;Semantic-ART: a framework for semantic annotation of regulatory text;2011;"Sapkota, Krishna; Aldea, Arantza; Duce, David A.; Younas, Muhammad; Bañares-Alcántara, René";Converting regulatory texts to machine interpretable models can enhance the automation of compliance management (CM) processes. The process poses serious research challenges as the information to be extracted from the regulatory texts comes from different regulatory bodies and is in different formats. In this paper, we present the main problems that we have faced in this area and how we have tackled them. Our proposed framework, Semantic-ART, considers the use of semantic annotation (SA) techniques to extract the regulations automatically.;Yes;;;Yes;;No;No;Yes;No, uses;KB according to SemReg ;No;No (just file formats);Semi-automatic;Not optimized;No;Yes;Compliance;Pharma;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/2663546.2663572;Law and adaptivity in requirements engineering;2013;"Ingolfo, Silvia; Souza, Vítor E. Silva";The great impact that law has on the design of software systems has been widely recognized in past years. However, little attention has been paid to the challenge of coping with variability characterizing the legal domain (e.g., multiple ways to comply with a given law, frequent updates to regulations, different jurisdictions, etc.) on the design of software systems. This position paper advocates the use of adaptation mechanisms in order to support regulatory compliance for software systems. First we show an example of how Zanshin, a requirements-based adaptation framework, can be used to design a system that adapts to legal requirements to accommodate legal variability. Then we examine how legal texts can be analyzed as sources for parameters and indicators needed to support adaptation. As motivating running example we consider legal situations concerning the Google driverless car and its recent legalization in the highways of Nevada and soon also in California.;Yes;Difficult as basically just for requirements engineering, but nonetheless interesting lkm;;No;"Position paper; Although technically this seems to contain more info than many papers I have included";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1882992.1883092;https://doi.org/10.1145/1882992.1883092;The production rule framework: developing a canonical set of software requirements for compliance with law;2010;"Maxwell, Jeremy C.; Antón, Annie I.";The cost of noncompliance, as well as lost reputation and brand damage resulting from noncompliance, makes legal compliance critical in software systems. In this paper, we present a production rule framework that software engineers can to specify compliance requirements for software. A component of our framework is the production rule modeling methodology, which we have introduced in previous work [12, 14]. We apply the framework to check iTrust, an open source electronic medical records system, for compliance with the Health Insurance Portability and Accountability Act (HIPAA) Security Rule. We model the Security Rule using production rules and employ the model to analyze the iTrust requirements for legal compliance. Using the framework, we were able to identify 13 functional and 5 non-functional requirements that were previously overlooked using an agile driven software engineering approach. These new requirements are critical for compliance with the Security Rule.;Yes;Difficult as basically just for requirements engineering, honestly this one is a bit on edge, I think I would kick it;;Yes;;No;No;Yes;No;Prolog;No;No;Manual;Yes, UI;No;Yes;Compliance;"Privacy (Medicine); Software Development";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.158989;https://doi.org/10.1145/158976.158989;The use of meta-rules in rule based legal computer systems;1993;"Schild, Uri J.; Herzog, Shai";Rule-Based Systems in the legal domain are often obtained by formalizing legislation. We consider the addition of meta-knowledge in the form of meta-rules to such a system. Such an approach has many advantages both for control and for dealing with the intrinsic vagueness of legal rules. Legal computer systems of different kinds have been proposed and built over the years. In this paper we shall present a legal reasoning system which uses concepts discussed in this paper. The system consists of a knowledge base, obtained by formalizing legislation, and uses a meta-rules mechanism for deduction and legal reasoning.;Yes;ICP, meta knowledge;;Yes;;No;No;Yes;No;"Prolog: Horn Based Rules; Higher level rules (rules on rules) ";No;No;"Manual; With automatic inference of new rules";Not optimized;No;No;Meta reasoning about rules;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/74014.74034;https://doi.org/10.1145/74014.74034;Legal reasoning - a jurisprudential description;1989;Wahlgren, P.;This paper provides a description of a legal reasoning process. The presentation originates from a research project combining Law and Artificial Intelligence (AI) and contains theoretical results from system-developing activities that have been carried out in cooperation with the Swedish Court Administration and a major Swedish employer's association. The research project, and several parallel projects at the Swedish Law and Informatics Research Institute (IRI), is being documented in the series IRI-reports.Related work, especially focusing on computerized formalization of legal norms and legal decision processes from a jurisprudential perspective is carried out at The Norwegian Research Center for Computers and Law, but contributions have also been made by many others1 and legal reasoning has been investigated from somewhat different perspectives2.;Yes;;;No;Too high level;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/74014.74029;https://doi.org/10.1145/74014.74029;Representing and reusing explanations of legal precedents;1989;Branting, L. K.;Precedent-based legal reasoning depends on accurate assessment of relevant similarities between new cases and existing precedents. Determining the relevant similarities between a new case and a precedent with respect to a legal category requires knowing the explanation of the precedent's membership in the category. GREBE is a system that uses both general legal rules and specific explanations of precedents to evaluate legal predicates in new cases. GREBE assesses the similarity of a new case to a precedent of a legal category by attempting to find a pattern of relations in the new case that corresponds to the facts of the precedent responsible for its category membership. Missing relations in the new case are inferred by reusing other explanations from past cases.;Yes;Precendent Law;;;This paper barely explains anything?;Yes;Yes;No;No;"semantic networks; Some unspecified common sense rules?";No;No;Manual;Not op;Yes;No;Legal argumentation;Workers Compensation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/pdf/10.5555/1123196.1123254;Generating original structure in regulatory documents;2003;"Kimbrough, Steven O.; Lee, Thomas Y.; Padmanabhan, Balaji; Yang, Yinghui";"As technology and society continue to evolve, the size of the corpus of government policies and procedures continues to more than keep pace. The U.S. Federal Tax Code today consumes over 2.8 million words or 6000 pages. There are more than 20,000 cross-references both within the code itself and to external regulations. Navigating the sea of information is a daunting task for the IRS let alone a well-intentioned tax payer, or policy-maker seeking to eliminate redundancies, inconsistencies, or loopholes. While tools for tasks such as compliance checking or query answering have long held promise, automated reasoning, however intelligent, needs something to reason upon, a formalized knowledge base of some kind. In other domains people may be the primary targets of knowledge engineering; in the policy realm, much of the requisite knowledge resides in legal and regulatory documents.";Yes;TODO check if paper actually contains novel ideas;;No;"position paper, that reasoning is good :+1;";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3322640.3326729;https://doi.org/10.1145/3322640.3326729;MagnetDroid: security-oriented analysis for bridging privacy and law for Android applications;2019;"Uliana, Emanuele; Stathis, Kostas; Jago, Robert";MagnetDroid is a novel artificial intelligence framework that integrates a security ontology, a multi-agent organisation, and a logical reasoning procedure to help build a bridge between the worlds of Android application analysis and law, with respect to privacy. Our contribution helps identify violations of the law by Android applications, as well as predict legal consequences. The resulting implementation of MagnetDroid can be useful to privacy-concerned users in order to acknowledge problems with the privacy of the applications they use, to application developers/publishers to help them identify which problems to fix, and to lawyers in order to provide an additional level of interpretation for any court when considering the privacy of Android applications.;Yes;Not 100% sure, this is law representation but maybe not applicable for BPC;;Yes;Starting with 4.1;No;No;Yes;No;Prolog;No;No;Manual;No;Yes (author);No;Compliance;"Data Protection; Android";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.158980;https://doi.org/10.1145/158976.158980;Monological reason-based logic: a low level integration of rule-based reasoning and case-based reasoning;1993;Hage, Jaap;This paper contains an informal introduction to a theory about legal reasoning (reason-based logic) that takes the notion of a reason to be central. Arguing for a conclusion comes down to first collecting the reasons that plead for and against the conclusion, and second weighing them. The paper describes how we can establish the presence of a reason and how we can argue whether the reasons for or the reasons against the conclusion prevail. It also addresses the topic of meta-level reasoning about the use of rules in concrete cases. It is shown how both rule-based reasoning and case-based reasoning are naturally incorporated in the theory of reason-based logic.;Yes;Contains both case and rule based reasoning;;Yes;Shows how case and rule based logic can be unified;No;Yes;Yes;No;"Prolog, (""domain specific"" language Monological Reason-Based Logic, but implemented using Horn Clauses in Prolog)";No;No;Manual;No;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.159008;https://doi.org/10.1145/158976.159008;KICS: a knowledge-intensive case-based reasoning system for statutory building regulations and case histories;1993;"Yang, Soon-Ae; Robertson, Dave; Lee, John";"There have been several knowledge-based systems for statutory building regulations during the last decade, such as Fenves et al's systems using the SASE model, Stone and Wilcox's system using a rule-based approach, and Waard's system using Cornick et al;'s model-based approach. However, they take into account only one side of building regulations, considering them only in the context of design systems and ignoring the existence of case histories. Building regulations are also part of a legal system and have characteristics of law. In this paper, we propose a Knowledge-Intensive Case-based reasoning System which can be used for the retrieval and maintenance of building regulations and case histories. First, we propose a unified knowledge representation scheme for both statutory building regulations and case histories. Second, we describe the retrieval of regulations information, which uses the notion of implied similarity as well as structural mapping. Finally, we describe knowledge acquisition from case histories, which is guided by knowledge gained from statutory regulations and case histories.";Yes;Contains both case and rule based reasoning;;Yes;;No;Yes;Yes;Yes;Prolog like subset of FOL (Guessing from the examples….);Yes (mentioned, but is done manually);No;Manual;No;No;No;Compliance;Building regulations;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2746090.2746111;https://doi.org/10.1145/2746090.2746111;Evaluating the use of abstract dialectical frameworks to represent case law;2015;"Al-Abdulkarim, Latifa; Atkinson, Katie; Bench-Capon, Trevor";Abstract Dialetical Frameworks (ADFs) are a recent development in computational argumentation which are, it has been suggested, a fruitful way of implementing theories of case law expressed in terms of factors. In this paper we evaluate this proposal, by representing the CATO analysis using ADFs. We evaluate the ease of implementation, the efficacy of the resulting program, ease of refinement of the program, transparency of the reasoning, relation to formal argumentation techniques, and transferability across domains.;Yes;Case law but at least argumentative reasoning;;Yes;;Yes;Yes;No;No;ADF (Prolog);No;Yes, From CATO, To Prolog;Manual;No;No;No;Reasoning;Trade Secrets;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/158976.158997;https://doi.org/10.1145/158976.158997;Beyond knowledge representation: commercial uses for legal knowledge bases;1993;"Dayal, Surendra; Harmer, Michael; Johnson, Peter; Mead, David";At the 1991 Conference, SoftLaw presented a paper dealing with issue which arise in the modelling of legislation as English sentences and rules which a computer can process. Using the techniques outlined in that article, knowledge bases may be constructed to model areas of the law, especially those concerned with public administration. This paper illustrates the incorporation of such knowledge bases into a large scale application. This type of application may be used to drive the business of any organisation which primarily administers a large body of rules (legislative or otherwise).Firstly, the paper gives a background description of the role played by ASSESS, a large scale application whose processing is based around legal knowledge bases.Secondly, the system architecture of ASSESS is examined, focusing on: (i) the overall architecture of the application, and why that architecture was adopted, (ii) the structure of the knowledge based component of the application, and the reasons for that structure.;Yes;;;No;To systems focused, not implementation focused enough, does not mention how the legal rules are encoded;;;;;;;;;Yes, UI;Yes;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1082473.1082576;https://doi.org/10.1145/1082473.1082576;Knowledge and social laws;2005;"van der Hoek, Wiebe; Roberts, Mark; Wooldridge, Michael";In this paper we combine existing work in the area of social laws with a framework for reasoning about knowledge in multi-agent systems. The unifying framework in which this is done is based on Alternating-time Temporal Logic (ATL), to which semantics we add epistemic accessibility relations (to deal with the knowledge), actions (in order to naturally talk about allowed and forbidden actions) and updates (to model the effect of the implementation of the constraint in a social law). Apart from a constraint, a social law has an objective: in our formalism, such objectives may refer to the knowledge that agents possess or do not possess. The result is a framework in which we can, for example, express that a desirable property (objective) of a social law is that one agent has the ability to bring about a certain type of knowledge in another agent, or that if one agent knows something, then it should behave in a certain way. We illustrate our approach with a case study, and we use model checking to demonstrate that properties of social laws with respect to this case study.;Yes;Agent view;;No;Social Laws are not laws….;No;No;No;No;Alternating Temporal Epistemic Logic (ATEL);No;Manual;;Not Optimized;No;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3086512.3086533;https://doi.org/10.1145/3086512.3086533;Formalizing arguments, rules and cases;2017;Verheij, Bart;"Legal argument is typically backed by two kinds of sources: cases and rules. In much AI &amp; Law research, the formalization of arguments, rules and cases has been investigated. In this paper, the tight formal connections between the three are developed further, in an attempt to show that cases can provide the logical basis for establishing which rules and arguments hold in a domain. We use the recently proposed formalism of case models, that has been applied previously to evidential reasoning and ethical systems design. In the present paper, we discuss with respect to case-based modeling how the analogy and distinction between cases can be modeled, and how arguments can be grounded in cases. With respect to rule-based modeling, we discuss conditionality, generality and chaining. With respect to argument-based modeling, we discuss rebutting, undercutting and undermining attack. We evaluate the approach by developing a case model of the rule-based arguments and attacks in Dutch tort law. In this way, we illustrate how statutory, rule-based law from the civil law tradition can be formalized in terms of cases.";Yes;mixture of rules and cases, might have to check paper as focus seems to lie on cases;;Yes;"""This and related work has shown that the formal and computational relations between arguments, rules and cases are close""";Yes;Yes;Yes;No;Propositional Logic;No;No;Manual;No;No;No;Reasoning;tort law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2746090.2746120;https://doi.org/10.1145/2746090.2746120;RuleOMS: a rule-based online management system;2015;"Islam, Mohammad Badiul; Governatori, Guido";We propose an architecture for a rule-based online management systems (RuleOMS). Typically, many domain areas face the problem that stakeholders maintain databases of their business core information and they have to take decisions or create reports according to guidelines, policies or regulations. To address this issue we propose the integration of databases, in particular relational databases, with a logic reasoner and rule engine. We argue that defeasible logic is an appropriate formalism to model rules, in particular when the rules are meant to model regulations. The resulting RuleOMS provides an efficient and flexible solution to the problem at hand using defeasible inference. A case study of an online child care management system is used to illustrate the proposed architecture.;Yes;No obvious from the abstract, but this also contains legal representation;;Yes;;No;No;Yes;No;Defeasible Logic;No;Yes, From realational database to part to DL;Manual;No, they argue JSON is easy for humans to read, which is not a lie, but I do not want to count that;No;Yes;Compliance;Child Care Management System;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;;https://dl.acm.org/doi/10.5555/2484920.2485116;Law enforcement in norm-governed learning agents;2013;"Riveret, Régis; Contissa, Giuseppe; Rotolo, Antonino; Pitt, Jeremy V.";We study law enforcement mechanisms within a population of norm-governed learning agents. We show that a traditional analysis based on expected utility can be misleading, because learning agents tend to comply even though their surveillance is stopped. This has significant implications for the design of self-organising institutions with endogenous resources, where the cost of monitoring and norm enforcement has to be taken into consideration.;Yes;Cars, but also kind of relevant as it does show a type of compliance. Not BPC though;;No;This is not really about representing law and reasoning with it, but ist influence on agents;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1568234.1568248;https://doi.org/10.1145/1568234.1568248;Case law in extended argumentation frameworks;2009;"Bench-Capon, Trevor; Modgil, Sanjay";In this paper we discuss how recent developments in argumentation frameworks, most notably Extended Argumentation Frameworks, can inform the representation of a body of case law using abstract argumentation techniques. This builds on previous work which has first used abstract Argumentation Frameworks, and then Value based Argumentation Frameworks for this purpose.Extended Argumentation Frameworks augment Argumentation Frameworks to not only allow arguments to be attacked, but also attacks to be attacked. This allows argumentation based reasoning about information normally assumed to be metalevel to the object level domain of argumentation, including argumentation over preferences, values and the audience based ranking of values promoted by arguments. The Extended Argumentation Frameworks can then be rewritten as standard Argumentation Frameworks, so that cases, and values and their rankings relevant to the cases, can be reasoned about using standard dialogue games for Argumentation Frameworks. In this way precedents can be represented as collections of arguments and dialogues using these arguments. Now, when confronted with a new case, these dialogues may be used to identify ways of deploying the arguments in the new case so as to reach a favourable position.;Yes;Argumentation, though I am starting to doubt not including argumentation is a great idea;;Yes;;Yes;Yes;No;No;(Extended) Argumentation Framework;No;Yes, Value based argumentation frameworks (VAF) to argumentation frameworks (AF);Manual;No toptimized;No;No;Reasoning;Animal Ownership (cases);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1594139.1594151;https://doi.org/10.1145/1594139.1594151;Law-aware access control for international financial environments;2009;"Stieghahn, Michael; Engel, Thomas";Financial institutions are restricted by legislation and have to ensure that mobile access to data is legal in a defined context. However, today's access control solutions work but cannot decide whether an access is legal. Especially when an access from different countries is required different legislations have to be taken into account. In this paper, we address the problem of a law-compliant access in international financial environments. We present an extension to context-aware access control systems so that they incorporate legal constraints. To this end, we introduce different facets of context information, their interrelations, and describe their necessity for a law-aware access control. Finally, by using an international banking application scenario, we demonstrate how a system that follows our approach can decide about access.;Yes;;;Yes;;No;No;Yes;No;RBAC variation, with context (temporal, locational);Yes;No;Manual;No;No;No;Access Control;Finance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/2018358.2018376;https://doi.org/10.1145/2018358.2018376;The systematization of law in terms of the validity;2011;Yoshino, Hajime;In legal praxis, it is important to decide what legal relations exist in a legal problem-event on the one hand and to decide what legal rules are applicable to decide it in terms of the validation by contract through constitution or convention on the other hand. These dimensions are strongly related with each other. This paper clarifies the logical structure of a legal system to decide the above two dimension in unified reasoning in terms of the validity of legal sentences. It provides a logical model of reasoning the validity of legal sentences for a unified legal reasoning system, in which legal relations according to the time progress of legal problem-events are decided and at the same time the applicability of relevant legal rules to decide them is decided. We demonstrate the legitimacy and efficiency of this model by applying it to concrete examples and showing how legal meta-sentences and legal meta-inference work in this model.;Yes;;;Yes;;No;No;Yes;No;First order logic (Compound Predicate Formula);No (just on a meta leval, meta rule that new law have precedent over old ones);No;Manual;No;No;No;Reasoning;Contract law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1165485.1165517;https://doi.org/10.1145/1165485.1165517;Computational law;2005;"Love, Nathaniel; Genesereth, Michael";Computational law is an approach to automated legal reasoning focusing on semantically rich laws, regulations, contract terms, and business rules in the context of electronically-mediated actions. Current computational tools for electronic commerce fall short of the demands of business, organizations, and individuals conducting complex transactions over the web. However, the growth of semantic data in the world of electronic commerce and online transactions, coupled with grounded rulesets that explicitly reference that data, provides a setting where applying automated reasoning to law can yield fruitful results, reducing inefficiencies, enabling transactions and empowering individuals with knowledge of how laws affect their behavior.;Yes;;;No;EX1 it seems. Does not suggest anything new;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3168821;https://doi.org/10.1145/3168821;Synthesizing an instruction selection rule library from semantic specifications;2018;"Buchwald, Sebastian; Fried, Andreas; Hack, Sebastian";Instruction selection is the part of a compiler that transforms intermediate representation (IR) code into machine code. Instruction selectors build on a library of hundreds if not thousands of rules. Creating and maintaining these rules is a tedious and error-prone manual process. In this paper, we present a fully automatic approach to create provably correct rule libraries from formal specifications of the instruction set architecture and the compiler IR. We use a hybrid approach that combines enumerative techniques with template-based counterexample-guided inductive synthesis (CEGIS). Thereby, we overcome several shortcomings of existing approaches, which were not able to handle complex instructions in a reasonable amount of time. In particular, we efficiently model memory operations. Our tool synthesized a large part of the integer arithmetic rules for the x86 architecture within a few days where existing techniques could not deliver a substantial rule library within weeks. Using the rule library, we generate a prototype instruction selector that produces code on par with a manually-tuned instruction selector. Furthermore, using 63012 test cases generated from the rule library, we identified 29498 rules that both Clang and GCC miss.;Yes;;;No;This is not law related?;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/383535.383542;https://doi.org/10.1145/383535.383542;Dynamic arguments in a case law domain;2001;"Henderson, John; Bench-Capon, Trevor";In this paper we describe an approach to reasoning with cases which takes into account the view that case law evolves through a series of decisions. This is in contrast to approaches which take as a starting point a set of decided cases, with no account taken of the order in which they were decided. The model of legal reasoning we follow is based on Levi's account which shows how decided cases often need to be reinterpreted in the light of subsequent decisions, so that features of cases wax and wane in importance. Our aim is to reproduce the arguments that could have been used in a given case, rather than to apply a retrospective understanding of the law to them. A second novel feature is that we use a general purpose ontology to describe the cases, rather than one developed specifically to model the pertinent cases. The paper describes a prototype implementation, and uses an example to illustrate how our approach works. After this case by case description we make some remarks on the insights gained, and draw some conclusions.;Yes;Case Law;;Yes;;Yes;Yes;No;No (uses a common sense ontology);Predicate logic;Yes;No;No;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1877714.1877723;https://doi.org/10.1145/1877714.1877723;MWeb: A principled framework for modular web rule bases and its semantics;2011-01;"Analyti, Anastasia; Antoniou, Grigoris; Damasio, Carlos Viegas";We present a principled framework for modular Web rule bases, called MWeb. According to this framework, each predicate defined in a rule base is characterized by its defining reasoning mode, scope, and exporting rule base list. Each predicate used in a rule base is characterized by its requesting reasoning mode and importing rule base list. For legal MWeb modular rule bases S, the MWebAS and MWebWFS semantics of each rule base s ∈ S with respect to S are defined model-theoretically. These semantics extend the answer set semantics (AS) and the well-founded semantics with explicit negation (WFSX) on ELPs, respectively, keeping all of their semantical and computational characteristics. Our framework supports: (1) local semantics and different points of view, (2) local closed-world and open-world assumptions, (3) scoped negation-as-failure, (4) restricted propagation of local inconsistencies, and (5) monotonicity of reasoning, for fully shared predicates.;Yes;A bit general but ok;;Yes;;Yes;No;Yes;No;Predicate Logic Horn clauses with custom semantics;No (Although one could argue I think that the modular rule base extension could somewhat be used to model change, but not frames that way);Yes, to extended logic programs (ELPs);Manual;Not optimized;No;No;Interpretation?;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/383535.383537;https://doi.org/10.1145/383535.383537;Theory based explanation of case law domains: 38;2001;"Bench-Capon, Trevor; Sartor, Giovanni";In this paper we put forward a formal description of theories which can be used to record understanding of, and explain decisions in, case law domains. We believe that reasoning with cases involves all of theory construction, use and evaluation, and that awareness of the theory which provides a context for case based arguments is essential to understanding such arguments. Moreover, our account of these theories includes a systematic link between factors and values, which we believe is necessary to explain why some arguments prove to be more persuasive than others. We begin by formalising the various elements that the theories contain, and then provide a set of theory constructors which allow theories to built up from the background of decided cases. We show how such theories can be used to explain decisions on particular cases. We discuss how theories can be compared and evaluated. We then show how the argument moves of HYPO and CATO can be understood in terms of our framework. We conclude with a brief discussion of an implementation of the framework, and a summary of the major features of our approach.;Yes;Meta, case law;;Yes;;Yes;Yes;No;No;Hightly formalized reducable to Prolog;No;No;Manual;Not optimized;Yes (authors);No;Reasoning;Animal Ownership (cases);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/3208788.3208802;https://doi.org/10.1145/3208788.3208802;Interchange of criminal rules between CLRL and LKIF;2018;"Wang, Xing; Sun, Yixin; Tang, Xiaoliang; Chen, Ji; Jin, Jiuxiang";There is much fuzzy and non-monotonic knowledge in the Semantic Web Criminal Law Area. In recent years, the problem of fuzzy rules interchange has become one of the most important problems in the Semantic Web. Aiming at the problem of heterogeneous fuzzy rule interchange in the Semantic Web, which is based on the proposed Semantic Web Criminal Law Rule Language (CLRL), and based on the rules and norms of XML. We construct the rule mapping between the CLRL and Legal Knowledge Interchange Format (LKIF), and propose a heterogeneous fuzzy criminal law rules interchange architecture (CRIAXS), which supports the bidirectional rule interchange between legal rules. We also analyze the problem of information loss caused by the different language expression ability in the process of legal knowledge interchange, and put forward to the solution. Based on the above description, the prototype system CRIAXS which is based on the JavaScript language has been achieved on the HBuilder platform. We also verify the correctness and stability of the system through multiple conversion examples. The results show that the architecture and the implemented system which laysa solid foundation for the rule-based reasoning, has a good solution to the communication problem between heterogeneous systems, and it has a wide range of application prospects.;Yes;Not 100% sure, seems focused on litigation/criminal law, but also kontains reference to transformation to legal knowledge interchange format, thus very interesting;;Yes;;No;No;Yes;No;LKIF and CLRL, fuzzy, non-monotonic logic combined with propositional logic;No;Yes, from and to legal knowledge interchange format and Criminal Law Rule Language;Automated;Not optimized;No;No;Representation Conversion;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/1882992.1883093;https://doi.org/10.1145/1882992.1883093;A comprehensive privacy-aware authorization framework founded on HIPAA privacy rules;2010;"AL Faresi, Ahmed; Wijesekera, Duminda; Moidu, Khaled";Health care entities publish privacy polices that are aligned with government regulations such as Health Insurance Portability and Accountability Act (HIPPA) and promise to use and disclose health data according to the stated policies. However actual practices may deliberately or unintentionally violate these policies. To ensure enforcement of such policies and ultimately HIPAA compliancy there is a need to develop an enforcement mechanism. In this paper we extend our work on IT-enforceable policies, submitted to the International Journal of Medical Informatics. The submitted work involved a detailed analysis of HIPPA privacy rules to extract object related conditions needed to make a disclosure decision. In this paper we extend this work to propose machine enforceable policies that embody HIPAA privacy disclosure rules and a health care entity access control rules. We also propose a comprehensive access/privacy control architecture that enforces the proposed polices. The architectural model is designed to allow for a dynamic configuration of policies without reconfiguring the architecture responsible for enforcement. Both the proposed policies and the architecture allow for multiple stakeholders to adjust the privacy preferences to manage the disclosure of data by adjusting the designated parameters in their respective policies. The objective of this study is to provide a comprehensive model for privacy protection, access and logging of PHI, that is HIPAA compliant.;Yes;Bit specific to HIPPA privacy, but valid nonetheless;;Yes;;No;No;Yes;No;"Formal, simple patterns, for example (Role, (Healthcare-ops(Purpose),
User-conditions, Obligation))";Yes (Decouple privacy and access control policies);No;Manual;Not optimized;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1109/WI-IAT.2013.171;https://doi.org/10.1109/WI-IAT.2013.171;Automatic Information Extraction from Texts with Inference and Linguistic Knowledge Acquisition Rules;2013;"Araujo, Denis A. de; Rigo, Sandro J.; Muller, Carolina; Chishman, Rove";In this paper we present a novel methodology for automatic information extraction from natural language texts, based on the integration of linguistic rules, multiple ontologies and inference resources, integrated with an abstraction layer for linguistic annotation and data representation. The methodology allows ontology population with instances of events. The main contribution presented is related to the exploration of the flexibility of linguistic rules and domain knowledge representation, through their manipulation and integration by a reasoning system. The results from the case study indicate that the proposed approach is effective for the legal domain.;Yes;Perfect, honeslty been a while since I've had a positive match;;No;No focus on LIR after extraction;;;;No, uses;;;;Automatic;;;;information extraction;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/41735.41743;https://doi.org/10.1145/41735.41743;A case-based system for trade secrets law;1987;"Rissland, E. L.; Ashley, K. D.";In this paper, we give an overview of our case-based reasoning program, HYPO, which operates in the field of trade secret law. We discuss key ingredients of case-based reasoning, in general, and the correspondence of these to elements of HYPO. We conclude with an extended example of HYPO working through a hypothetical trade secrets case, patterned after an actual case.;Yes;Careful, have to be consistent here. This is case based, but with reasoning?;;Yes;This is the paper that introduces HYPO :o;Yes;Yes;No;No;Semi-formal, frames with dimension encoded;No;No;Manual;Not optimized;No;No;Argumentation;Trade Secrets;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ACM;10.1145/570186.570195;https://doi.org/10.1145/570186.570195;An asynchronous rule-based approach for business process automation using obligations;2002;"Abrahams, Alan; Eyers, David; Bacon, Jean";The Edee architecture provides a mechanism for explicitly and uniformly capturing business occurrences, and provisions of contracts, policies, and law. Edee is able to reason about the interactions of intra-, inter-, and extra-organizational policy, and execute business procedures informed by the combined legal effects of these diverse rules. We show through an example how Edee's asynchronous approach, namely to initiate actions only after consulting the database to determine active obligations, differs from the traditional synchronous approach in which procedural side-effects are initiated when clauses of rules are evaluated. The example show-cases both conflict detection and resolution in Edee. Edee's novel mechanism for business process automation is based on assessment of legal status and directives, and can be contrasted to the conventional task-dependency and process-synchronization approach employed in other workflow systems.;Yes;;;No;I cannot cleanly extract a nice LIR from this;No;No;Yes;No;;No;;;;;Yes;business process automation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/5689.5920;https://doi.org/10.1145/5689.5920;The British Nationality Act as a logic program;1986;"Marek Sergot; Marek Sergot; Fariba Sadri; Fariba Sadri; Robert Kowalski; Robert A. Kowalski; Frank Kriwaczek; F. Kriwaczek; Peter Hammond; Peter Hammond; Hans Cory; H. T. Cory";The formalization of legislation and the development of computer systems to assist with legal problem solving provide a rich domain for developing and testing artificial-intelligence technology.;Yes;;;Yes;;No;No;Yes;No;(definite) Horn Clauses, Prolog;Yes (They argue that they are close enough to the original text to allow for easy change);No;Manual;"Yes, apparently ""is easy for both naive users and experts to understand"" but at the same time it is just Prolog";Yes, minimally, the implementation was demonstrated to the drafters of the statute;No;legal problem solving;Tax Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/158976.158982;https://doi.org/10.1145/158976.158982;Representing teleological structure in case-based legal reasoning: the missing link;1993;"Donald H. Berman; Donald H. Berman; Carole D. Hafner; Carole D. Hafner";We argue that robust case-based models of legal knowledge that represent the way in which practicing professionals use legal decisions must contain a deeper domain model that represents the purposes behind the rules articulated in the cases. We propose a  model for representing the teleological components of legal decisions, and we suggest a method for utilizing this representation in a HYPO-like framework for case-based legal argument.;Yes;;;;;Yes;Yes;No;No;Semi-Formal, extend HYPO using teleological factor;No;No;Manual;Not optimized;No;No;Argumentation;Animal Ownership (cases);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://apps.dtic.mil/sti/pdfs/ADA250559.pdf;Modeling Legal Argument: Reasoning with Cases and Hypotheticals;1991;"Kevin D. Ashley; Kevin D. Ashley";"This dissertation is about adversarial, case-based reasoning and the HYPO program that performs adversarial reasoning with cases and hypotheticals in the legal domain. The dissertation identifies and describes basic case-based operations, an adversarial, case-based reasoning process, a schematic structure for case-based arguments, the kinds of counter-examples that arise and the knowledge sources necessary to support adversarial, case-based reasoning. The HYPO program embodies the methodology. It comprises: (1) a structured Case Knowledge Base (""CKB"") of actual legal cases; (2) an indexing scheme (""dimensions"") for retrieval of relevant cases from the CKB; (3) methods for analyzing problem situations and retrieving relevant cases; (4) methods for interpreting and assessing the relevancy of past cases by ""positioning"" the problem situation with respect to relevant existing cases in the CKB as seen from the viewpoint of the problem at hand and finding the most-on-point cases; (5) methods for comparing/contrasting cases (e.g., citing, distinguishing, finding counter-examples); (6) methods for posing hypotheticals that test the sensitivity of the problem situation to changes, particularly with regard to potentially adverse effects of new damaging facts coming to light and existing favorable ones being discredited; (7) methods for generating ""3-ply"" argument outlines to play out realistic legal arguments citing cases in a manner familiar to attorneys; and (8) methods for explaining alternative decisions of the problem situation by posing hypotheticals, comparing arguments and summarizing the precedents. HYPO's performance compares favorably to that of judges and attorneys in actual legal cases. The law is an excellent domain to study case-based reasoning since by its very nature it: (1) espouses a doctrine of precedent in which prior cases are the primary tools for justifying legal conclusions; and (2) employs precedential reasoning to make up for the lack of strong domain models with which to reason deductively about problem situations. The law is also a paradigm for adversarial case-based reasoning; there are ""no right answers"", only arguments pitting interpretations of cases and facts against each other. The dissertation addresses issues of central concern to Artificial Intelligence including: relevance and credit assignment, indexing and inference control, argumentation, analogical reasoning and explanation.";Yes;dissertation;;No;dissertation which basically mostly just covers HYPO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-94-015-9010-5_5;https://doi.org/10.1007/978-94-015-9010-5_5;Modelling Reasoning with Precedents in a Formal Dialogue Game;1998;"Henry Prakken; Henry Prakken; Giovanni Sartor; Giovanni Sartor";This paper analyses legal reasoning with precedents in the setting of a formally defined dialogue game. After giving a legal-theoretical account of judicial reasoning with precedents, a formal method is proposed for representing precedents and it is discussed how such representations can be used in a formally defined dialectical protocol for dispute. The basic ideas are to represent cases as argument structures (including pro and con arguments, and the arguments for adjudicating their conflicts) and to define certain case-based reasoning moves as strategies for introducing information into a dispute. In particular, analogizing and distinguishing are conceived as elementary theory construction moves, which produce new information on the basis of an existing stock of cases. The approach also offers the possibility of using portions of precedents and of expressing criteria for determining the outcome of precedent-based disputes.;Yes;;;Yes;;Yes;Yes;No;No;Formal, defeasible logic;Yes (2.2.3);No;Manual;Not optimized;Yes (authors);No;Argumentation;Tax Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/bf00118496;https://doi.org/10.1007/bf00118496;A dialectical model of assessing conflicting arguments in legal reasoning;1996;"Henry Prakken; Henry Prakken; Giovanni Sartor; Giovanni Sartor";Inspired by legal reasoning, this paper presents a formal framework for assessing conflicting arguments. Its use is illustrated with applications to realistic legal examples, and the potential for implementation is discussed. The framework has the form of a logical system for defeasible argumentation. Its language, which is of a logic-programming-like nature, has both weak and explicit negation, and conflicts between arguments are decided with the help of priorities on the rules. An important feature of the system is that these priorities are not fixed, but are themselves defeasibly derived as conclusions within the system. Thus debates on the choice between conflicting arguments can also be modelled. The proof theory of the system is stated in dialectical style, where a proof takes the form of a dialogue between a proponent and an opponent of an argument. An argument is shown to be justified if the proponent can make the opponent run out of moves in whatever way the opponent attacks. Despite this dialectical form, the system reflects a `declarative', or `relational' approach to modelling legal argument. A basic assumption of this paper is that this approach complements two other lines of research in AI and Law, investigations of precedent-based reasoning and the development of `procedural', or `dialectical' models of legal argument.;Yes;;;Yes;;Yes;Yes;No;No;"Formal, defeasible logic; extended logic programming";;No;Manual;Not optimized;No;No;Conflict resolution;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/74014.74031;https://doi.org/10.1145/74014.74031;Representing the structure of a legal argument;1989;"Cathy Marshall; Catherine C. Marshall";"The investigation described in this paper is part of a larger project to characterize and develop computational tools to help people formulate, record, and present arguments and rationale in diverse domains such as law, policy, and design where argumentation and decision-making are fundamental processes. To build such tools, it is necessary first to design a uniform representation for the structure of arguments; law has provided us with a good starting point for understanding this structure. Since arguments are important legal artifacts, law maintains a recorded institutional memory of them in forms such as casebooks, databases, and courtroom transcripts. This analysis is primarily concerned with the arguments that occur in two excerpts from Supreme Court oral argument transcripts; it is directed toward developing a system of semi-formal representations of the structure of these arguments in hypertext. A system of representations of argument structure, coupled with an understanding of the argumentation process, can be used to form the basis for tools for authoring, fault-detection, and other activities associated with formulating and presenting rationale.";Yes;;;No;This is more about the visual representation of arguments. Would not really see this as part of my RQs;Yes;Yes;No;No;Formal;;No;Manual;Yes, UI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/j.artint.2007.04.010;https://doi.org/10.1016/j.artint.2007.04.010;The Carneades model of argument and burden of proof;2007;"Thomas F. Gordon; Thomas F. Gordon; Henry Prakken; Henry Prakken; Douglas Walton; Douglas Walton";We present a formal, mathematical model of argument structure and evaluation, taking seriously the procedural and dialogical aspects of argumentation. The model applies proof standards to determine the acceptability of statements on an issue-by-issue basis. The model uses different types of premises (ordinary premises, assumptions and exceptions) and information about the dialectical status of statements (stated, questioned, accepted or rejected) to allow the burden of proof to be allocated to the proponent or the respondent, as appropriate, for each premise separately. Our approach allows the burden of proof for a premise to be assigned to a different party than the one who has the burden of proving the conclusion of the argument, and also to change the burden of proof or applicable proof standard as the dialogue progresses from stage to stage. Useful for modeling legal dialogues, the burden of production and burden of persuasion can be handled separately, with a different responsible party and applicable proof standard for each. Carneades enables critical questions of argumentation schemes to be modeled as additional premises, using premise types to capture the varying effect on the burden of proof of different kinds of questions.;Yes;;;Yes;;Yes;Yes;No;No;Formal, argumentation graphs;No;No;Manual;Yes, graph visualisation;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-006-9003-3;https://doi.org/10.1007/s10506-006-9003-3;Legal case-based reasoning as practical reasoning;2005;"Katie Atkinson; Katie Atkinson; Trevor Bench‐Capon; Trevor J. M. Bench-Capon";In this paper we apply a general account of practical reasoning to arguing about legal cases. In particular, we provide a reconstruction of the reasoning of the majority and dissenting opinions for a particular well-known case from property law. This is done through the use of Belief-Desire-Intention (BDI) agents to replicate the contrasting views involved in the actual decision. This reconstruction suggests that the reasoning involved can be separated into three distinct levels: factual and normative levels and a level connecting the two, with conclusions at one level forming premises at the next. We begin by summarising our general approach, which uses instantiations of an argumentation scheme to provide presumptive justifications for actions, and critical questions to identify arguments which attack these justifications. These arguments and attacks are organised into argumentation frameworks to identify the status of individual arguments. We then discuss the levels of reasoning that occur in this reconstruction and the properties and significance of each of these levels. We illustrate the different levels with short examples and also include a discussion of the role of precedents within these levels of reasoning.;Yes;;;No;Always hurts to remove one of Atkinsons papers but this does not focus too much on the law representation aspects;Yes;Yes;No;No;;No;No;Manual;Not optimized;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1093/logcom/ext010;https://pure.rug.nl/ws/portalfiles/portal/98237371/A_formalisation_of_argumentation_schemes_for_legal_case_based_reasoning_in_ASPIC_.pdf;A formalization of argumentation schemes for legal case-based reasoning in ASPIC+;2015;"Henry Prakken; Henry Prakken; Adam Wyner; Adam Wyner; Trevor Bench‐Capon; Trevor J. M. Bench-Capon; Katie Atkinson; Katie Atkinson";In this article we offer a formal account of reasoning with legal cases in terms of argumentation schemes. These schemes, and undercutting attacks associated with them, are formalized as defeasible rules of inference within the ASPIC+ framework. We begin by modelling the style of reasoning with cases developed by Aleven and Ashley in the CATO project, which describes cases using factors, and then extend the account to accommodate the dimensions used in Rissland and Ashley's earlier HYPO project. Some additional scope for argumentation is then identified and formalized.;Yes;;;Yes;;Yes;Yes;No;No;ASPIC+, Dun's abstract argumentation framwork + first-order logic with defesaibility;No;No;Manual;Not optimized;Yes (author);No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://scholar.google.com/scholar?q=Carneades%20and%20Abstract%20Dialectical%20Frameworks:%20A%20Reconstruction;Carneades and Abstract Dialectical Frameworks: A Reconstruction;2010;"Gerhard Brewka; Gerhard Brewka; Thomas F. Gordon; Thomas F. Gordon";Carneades is a rather general framework for argumentation. Unlike many other approaches, Carneades captures a number of aspects, like proof burdens, proof standards etc., which are of central importance, in particular in legal argumentation. In this paper we show how Carneades argument evaluation structures can be reconstructed as abstract dialectical frameworks (ADFs), a recently proposed generalization of Dung argumentation frameworks (AFs). This not only provides at least an indirect link between Carneades and AFs, it also allows us to handle arbitrary argument cycles, thus lifting a restriction of Carneades. At the same time it provides strong evidence for the usefulness of ADFs as analytical/semantical tools in argumentation.;Yes;;;No;Cannot find copy of paper;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1023/a:1019589831118;https://doi.org/10.1023/a:1019589831118;Teleological arguments and theory-based dialectics;2002;"Giovanni Sartor; Giovanni Sartor";This paper proposes to model legal reasoning asdialectical theory-constructiondirected by teleology. Precedents are viewed asevidence to be explained throughtheories. So, given a background of factors andvalues, the parties in a case canbuild their theories by using a set of operators,which are called theory constructors.The objective of each party is to provide theoriesthat both explain the evidence (theprecedents) and support the decision wished by thatparty. This leads to theory-basedargumentation, i.e., a dialectical exchange ofcompeting theories, which support opposedoutcomes by explaining the same evidence and appealingto the same values. The winneris the party that can reply with a more coherent theoryto all theories of its adversary.;Yes;;;Yes;;Yes;Yes;No;No;Formal;Yes, by allowing conflicting decisions using temporal modeling;No;Manual;Not optimized;No;No;Argumentation;Animal Ownership (pierson);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://www.csc.liv.ac.uk/~tbc/publications/jurixAS.pdf;Argument Schemes for Legal Case-based Reasoning;2007;"Adam Wyner; Adam Wyner; Trevor Bench‐Capon; Trevor J. M. Bench-Capon";In this paper we use the notion of argument schemes to analyse some leading approaches to case-based reasoning in Law. We identify a set of argument schemes that can express the argument provided by such systems and draw attention to some important differences between the various approaches.;Yes;;;Yes;;Yes;Yes;No;No;Formal argumentation frameworks;No;No;Manual;Not optimized;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-87877-3_13;https://doi.org/10.1007/978-3-540-87877-3_13;Automating the Extraction of Rights and Obligations for Regulatory Compliance;2008;"Nadzeya Kiyavitskaya; Nadzeya Kiyavitskaya; Nicola Zeni; Nicola Zeni; Travis D. Breaux; Travis D. Breaux; Annie I. Antón; Annie I. Antón; James R. Cordy; James R. Cordy; Luisa Mich; Luisa Mich; John Mylopoulos; John Mylopoulos";"Government regulations are increasingly affecting the security, privacy and governance of information systems in the United States, Europe and elsewhere. Consequently, companies and software developers are required to ensure that their software systems comply with relevant regulations, either through design or re-engineering. We previously proposed a methodology for extracting stakeholder requirements, called rights and obligations, from regulations. In this paper, we examine the challenges to developing tool support for this methodology using the Cerno framework for textual semantic annotation. We present the results from two empirical evaluations of a tool called ""Gaius T."" that is implemented using the Cerno framework and that extracts a conceptual model from regulatory texts. The evaluation, carried out on the U.S. HIPAA Privacy Rule and the Italian accessibility law, measures the quality of the produced models and the tool's effectiveness in reducing the human effort to derive requirements from regulations.";Yes;;;Yes;;No;No;Yes;No;"Semantic Markup, of actors, policies, ...; no logic";No;No (Future Work);tool supported;Optimized by nature: Natural Language;Yes (expoert involved in parsing HIPPA);No;Compliance;"Privacy (In Healthcare); Accessability";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1023/b:arti.0000046007.11806.9a;https://doi.org/10.1023/b:arti.0000046007.11806.9a;Towards a formal account of reasoning about evidence: argumentation schemes and generalisations;2003;"Floris Bex; Floris Bex; Henry Prakken; Henry Prakken; Chris Reed; Chris Reed; Douglas Walton; Douglas Walton";This paper studies the modelling of legal reasoning about evidence within general theories of defeasible reasoning and argumentation. In particular, Wigmore's method for charting evidence and its use by modern legal evidence scholars is studied in order to give a formal underpinning in terms of logics for defeasible argumentation. Two notions turn out to be crucial, viz. argumentation schemes and empirical generalisations.;Yes;;;No;Wrong framing, not really representation of law, but about evidence framing (which is part of law, but this is a bit too litigation heavy);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1080/19462160903564592;https://doi.org/10.1080/19462160903564592;An abstract framework for argumentation with structured arguments;2010;"Henry Prakken; Henry Prakken";An abstract framework for structured arguments is presented, which instantiates Dung's (‘On the Acceptability of Arguments and its Fundamental Role in Nonmonotonic Reasoning, Logic Programming, and n-Person Games’, Artificial Intelligence, 77, 321–357) abstract argumentation frameworks. Arguments are defined as inference trees formed by applying two kinds of inference rules: strict and defeasible rules. This naturally leads to three ways of attacking an argument: attacking a premise, attacking a conclusion and attacking an inference. To resolve such attacks, preferences may be used, which leads to three corresponding kinds of defeat: undermining, rebutting and undercutting defeats. The nature of the inference rules, the structure of the logical language on which they operate and the origin of the preferences are, apart from some basic assumptions, left unspecified. The resulting framework integrates work of Pollock, Vreeswijk and others on the structure of arguments and the nature of defeat and extends it...;Yes;;;Yes;;Yes;Yes;No;No;Formal, Abstract Argumentation Framework;No;No;Manual;Not optimized;Yes (author);No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s00766-013-0181-8;https://doi.org/10.1007/s00766-013-0181-8;GaiusT: supporting the extraction of rights and obligations for regulatory compliance;2015;"Nicola Zeni; Nicola Zeni; Nadzeya Kiyavitskaya; Nadzeya Kiyavitskaya; Luisa Mich; Luisa Mich; James R. Cordy; James R. Cordy; John Mylopoulos; John Mylopoulos";Ensuring compliance of software systems with government regulations, policies, and laws is a complex problem. Generally speaking, solutions to the problem first identify rights and obligations defined in the law and then treat these as requirements for the system under design. This work examines the challenge of developing tool support for extracting such requirements from legal documents. To address this challenge, we have developed a tool called GaiusT. The tool is founded on a framework for textual semantic annotation. It semiautomatically generates elements of requirements models, including actors, rights, and obligations. We present the complexities of annotating prescriptive text, the architecture of GaiusT, and the process by which annotation is accomplished. We also present experimental results from two case studies to illustrate the application of the tool and its effectiveness relative to manual efforts. The first case study is based on the US Health Insurance Portability and Accountability Act, while the second analyzes the Italian accessibility law for information technology instruments.;Yes;;;Yes;Ist Gaius again, maybe this time with more than future work :p;No;No;Yes;Yes;"Semantic Markup, of actors, policies, ...; no logic";No;No (Only file formats);Automatic (after syntactic indicators have been added, authors call it semi-automatic, but will go with automatic);Yes, UI;Yes (discussion);No;Compliance;"Privacy (In Healthcare); Accessability";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1023/a:1008308627745;https://doi.org/10.1023/a:1008308627745;A method for the computational modelling of dialectical argument with dialogue games;2000;"Trevor Bench‐Capon; Trevor J. M. Bench-Capon; T. Geldard; T. Geldard; Paul Leng; P. H. Leng";In this paper we describe a method for the specification of computationalmodels of argument using dialogue games. The method, which consists ofsupplying a set of semantic definitions for the performatives making upthe game, together with a state transition diagram, is described in full.Its use is illustrated by some examples of varying complexity, includingtwo complete specifications of particular dialogue games, Mackenzie's DC,and the authors' own TDG. The latter is also illustrated by a fully workedexample illustrating all the features of the game.;Yes;Dialogue game;;No;This is more about modelling the court than the underlying law. Of course this argument could be made for A(D)Fs but this is more pronounced;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1080/19462166.2012.661766;https://doi.org/10.1080/19462166.2012.661766;Relating Carneades with abstract argumentation via the ASPIC + framework for structured argumentation;2012;"Bas van Gijzel; Bas van Gijzel; Henry Prakken; Henry Prakken";Carneades is a recently proposed formalism for structured argumentation with varying proof standards, inspired by legal reasoning, but more generally applicable. Its distinctive feature is that each statement can be given its own proof standard, which is claimed to allow a more natural account of reasoning under burden of proof than existing formalisms for structured argumentation, in which proof standards are defined globally. In this article, the two formalisms are formally related by translating Carneades into the ASPIC+ framework for structured argumentation. Since ASPIC+ is defined to generate Dung-style abstract argumentation frameworks, this in effect translates Carneades graphs into abstract argumentation frameworks. For this translation, we prove a formal correspondence and show that certain rationality postulates hold. It is furthermore proved that Carneades always induces a unique Dung extension, which is the same in all of Dung's semantics, allowing us to generalise Carneades to cycle-containi...;Yes;;;No;Focus on Carneades which seems to be more about proof burden which we do not really care for;;;;;"ASPIC+; ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/re.2014.6912249;https://doi.org/10.1109/re.2014.6912249;Goal-oriented compliance with multiple regulations;2014;"Sepideh Ghanavati; Sepideh Ghanavati; André Rifaut; André Rifaut; Éric Dubois; Eric Dubois; Daniel Amyot; Daniel Amyot";Most systems and business processes in organizations need to comply with more than one law or regulation. Different regulations can partially overlap (e.g., one can be more detailed than the other) or even conflict with each other. In addition, one regulation can permit an action whereas the same action in another regulation might be mandatory or forbidden. In each of these cases, an organization needs to take different strategies. This paper presents an approach to handle different situations when comparing and attempting to comply with multiple regulations as part of a goal-oriented modeling framework named LEGAL-URN. This framework helps organizations find suitable trade-offs and priorities when complying with multiple regulations while at the same time trying to meet their own business objectives. The approach is illustrated with a case study involving a Canadian health care organization that must comply with four laws related to privacy, quality of care, freedom of information, and care consent.;Yes;;;Yes;;No;No;Yes;No;Legal-URN;Yes (tracability links);No (only internal from Hohfeldian representation to Legal-GRL);Manual (semi-automation as future work);Not optimized;No;Yes;Compliance with multiple regulations;Privacy (In Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/222092.222225;https://doi.org/10.1145/222092.222225;DiaLaw: a dialogical framework for modeling legal reasoning;1995;"A.R. Lodder; Arno R. Lodder; Aimée Herczog; Aimée Herczog";"Article Free Access Share on DiaLaw: a dialogical framework for modeling legal reasoning Authors: Arno R. Lodder University of Limburg, Faculty of law, P.O. Box 616; 6200 MD Maastricht; The Netherlands University of Limburg, Faculty of law, P.O. Box 616; 6200 MD Maastricht; The NetherlandsView Profile , Aimée Herczog University of Nijmegen, Faculty of Mathematics, P.O. Box 9010, 6500 GL Nijmegen, The Netherlands University of Nijmegen, Faculty of Mathematics, P.O. Box 9010, 6500 GL Nijmegen, The NetherlandsView Profile Authors Info & Claims ICAIL '95: Proceedings of the 5th international conference on Artificial intelligence and lawMay 1995 Pages 146–155https://doi.org/10.1145/222092.222225Published:24 May 1995Publication History 13citation271DownloadsMetricsTotal Citations13Total Downloads271Last 12 Months25Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF";Yes;;;No;This is not enough about representing law and more about what someone can do in a dialoge game at a given moment / what formal steps there are;Yes;Yes;No;No;Formal (adaptation of Reason Based Logic);No;No;Manual;Not optimized;Yes (aithors);No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2018358.2018369;https://doi.org/10.1145/2018358.2018369;Semantic models for policy deliberation;2011;"Katie Atkinson; Katie Atkinson; Trevor Bench‐Capon; Trevor J. M. Bench-Capon; D. Cartwright; Dan Cartwright; Adam Wyner; Adam Wyner";Semantic models have received little attention in recent years, much of their role having been taken over by developments in ontologies. Ontologies, however, are static, and so have only a limited role in reasoning about domains in which change matters. In this paper, we focus on the domain of policy deliberation, where policy decisions are designed to change things to realise particular social values. We explore how a particular kind of state transition system can be constructed to serve as a semantic model to support reasoning about alternative policy decisions. The policy making process includes stages that support the construction of a model, which can then be exploited in reasoning. The reasoning itself will be driven by a particular argumentation scheme for practical reasoning, and the ways in which arguments based on this scheme can be attacked and evaluated. The evaluation provides alternative policy positions. The semantics underpin a current web-based implementation, designed to solicit structured feedback on policy proposals.;Yes;Really cool, unique;;No;This is more about creating policy and arguing about potential policy than really representing normative / deontic policies;Yes;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/edoc.2011.23;https://doi.org/10.1109/edoc.2011.23;CoReL: Policy-Based and Model-Driven Regulatory Compliance Management;2011;"Marwane El Kharbili; Marwane El Kharbili; Qin Ma; Qin Ma; Pierre Kelsen; Pierre Kelsen; Elke Pulvermueller; Elke Pulvermueller";Regulatory compliance management is now widely recognized as one of the main challenges still to be efficiently dealt with in information systems. In the discipline of business process management in particular, compliance is considered as an important driver of the efficiency, reliability and market value of companies. It consists of ensuring that enterprise systems behave according to some guidance provided in the form of regulations. This paper gives a definition of the research problem of regulatory compliance. We show why we expect a formal policy-based and model-driven approach to provide significant advantages in allowing enterprises to flexibly manage decision-making related to regulatory compliance. For this purpose, we contribute CoReL, a domain-specific modeling language for representing compliance requirements that has a graphical concrete syntax. Informal semantics of CoReL are introduced and its use is illustrated on an example. CoReL allows to leverage business process compliance modeling and checking, enhancing it with regard to, among other dimensions, user-friendliness, genericity, and traceability.;Yes;;;Yes;I hope I did not misunderstand the goals here as this seems to rather model business policies than legal regulations, but they state that legal regulation modelling is one of the goals;Yes;No;Yes;No;"Formal but flexible; Predicate Logic";Yes (Decouple compliance requirements and business model);Yes, into formal logic;Manual;Yes, UI;No;Yes;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/222092.222142;https://doi.org/10.1145/222092.222142;PLAID: proactive legal assistance;1995;"Trevor Bench‐Capon; Trevor J. M. Bench-Capon; Geof Staniford; Geof Staniford";Article PLAID: proactive legal assistance Share on Authors: T. J. M. Bench-Capon Department of Computer Science, The University of Liverpool, Liverpool, England Department of Computer Science, The University of Liverpool, Liverpool, EnglandView Profile , G. Staniford Department of Computer Science, The University of Liverpool, Liverpool, England Department of Computer Science, The University of Liverpool, Liverpool, EnglandView Profile Authors Info & Claims ICAIL '95: Proceedings of the 5th international conference on Artificial intelligence and lawMay 1995 Pages 81–88https://doi.org/10.1145/222092.222142Published:24 May 1995 15citation212DownloadsMetricsTotal Citations15Total Downloads212Last 12 Months2Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access;Yes;Wow, this is really really cool, 1995 paper that provides a kind of chat bot;;Yes;;No;Yes;Yes;No;Horn Clauses (Prolog);No;Yes, into natural language;Manual;Yes, chat bot;No;No;Question Answering;General (Poor Law is fictional);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1047788.1047834;https://doi.org/10.1145/1047788.1047834;Induction of defeasible logic theories in the legal domain;2003;"Benjamin Johnston; Benjamin Johnston; Guido Governatori; Guido Governatori";Defeasible Logic is a promising representation for legal knowledge that appears to overcome many of the deficiencies of previous approaches to representing legal knowledge. Unfortunately, an immediate application of technology to the challenges of generating theories in the legal domain is an expensive and computationally intractable problem. So, in light of the potential benefits, we seek to find a practical algorithm that uses heuristics to discover an approximate solution. As an outcome of this work, we have developed an algorithm that integrates defeasible logic into a decision support system by automatically deriving its knowledge from databases of precedents. Experiments with the new algorithm are very promising -- delivering results comparable to and exceeding other approaches.;Yes;;;Yes;;No;No;Yes;No;Defeasible First Order Logic;No;No, only from the formalised precedants, which we do not count as conversion for the sake of this statistics, but generally yes;Automated (from already formalised cases);Optimized (Minimally with natural language annotations);No;No;Reasoning;Criminal Law, Financial, Welfare;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-009-9078-8;https://doi.org/10.1007/s10506-009-9078-8;PADUA: a protocol for argumentation dialogue using association rules;2009;"Maya Wardeh; Maya Wardeh; Trevor Bench‐Capon; Trevor J. M. Bench-Capon; Frans Coenen; Frans Coenen";We describe PADUA, a protocol designed to support two agents debating a classification by offering arguments based on association rules mined from individual datasets. We motivate the style of argumentation supported by PADUA, and describe the protocol. We discuss the strategies and tactics that can be employed by agents participating in a PADUA dialogue. PADUA is applied to a typical problem in the classification of routine claims for a hypothetical welfare benefit. We particularly address the problems that arise from the extensive number of misclassified examples typically found in such domains, where the high error rate is a widely recognised problem. We give examples of the use of PADUA in this domain, and explore in particular the effect of intermediate predicates. We have also done a large scale evaluation designed to test the effectiveness of using PADUA to detect misclassified examples, and to provide a comparison with other classification systems.;Yes;;;Yes;;No;Yes;No;No;"Dialogue; Data encoded using if..then / premise -> conclusion";Yes (rules are derived directly from the decision dataset, so it would just be appended);No;Automated;Not optimized;No;No;Reasoning;Welfare;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/re.2005.12;https://doi.org/10.1109/re.2005.12;Analyzing goal semantics for rights, permissions, and obligations;2005;"Travis D. Breaux; Travis D. Breaux; Annie I. Antón; Annie I. Antón";"Software requirements, rights, permissions, obligations, and operations of policy enforcing systems are often misaligned. Our goal is to develop tools and techniques that help requirements engineers and policy makers bring policies and system requirements into better alignment. Goals from requirements engineering are useful for distilling natural language policy statements into structured descriptions of these interactions; however, they are limited in that they are not easy to compare with one another despite sharing common semantic features. In this paper, we describe a process called semantic parameterization that we use to derive semantic models from goals mined from privacy policy documents. We present example semantic models that enable comparing policy statements and present a template method for generating natural language policy statements (and ultimately requirements) from unique semantic models. The semantic models are described by a context-free grammar called KTL that has been validated within the context of the most frequently expressed goals in over 100 Internet privacy policy documents. KTL is supported by a policy analysis tool that supports queries and policy statement generation.";Yes;;;No;Privacy Policies, not laws;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/41735.41762;https://doi.org/10.1145/41735.41762;Esplex: A rule and conceptual model for representing statutes;1987;"Carlo Biagioli; Carlo Biagioli; C. Biagioli; Philip Mariani; Paola Mariani; P. Mariani; Daniela Tiscornia; D. Tiscornia; Daniela Tiscornia";The characteristics of the ESPLEX system which may be defined as a “rule and conceptual based model” are illustrated, together with the possibilities for its utilization, its similarities with other existing projects, and the requisites of the knowledge representation language.  The methodology and the theoretical propositions that have led to the definition of the representation language are therefore explained. The characteristics of the system which manages the knowledge base are also described and a brief comment is made regarding future development.;Yes;;;Yes;;No;No;Yes;No;"Horn clauses; Prolog";No;No;Manual;Not optimized;Yes (authors);No;Reasoning; agricultural tenancie;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/j.jal.2007.06.010;https://doi.org/10.1016/j.jal.2007.06.010;Intermediaries and intervenients in normative systems;2008;"Lars Lindahl; Lars Lindahl; Jan Odelstad; Jan Odelstad";Many concepts in legal texts are “intermediaries”, in the sense that they serve as links between statements of legal grounds, on one hand, and of legal consequences, on the other. In our paper, an  ...;Yes;;;Yes;;No;No;Yes;No;Boolean Algebra;No;No;Manual;Not optimized;Yes (authors);No;Identification of intermediates;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://intranet.csc.liv.ac.uk/~tbc/publications/v16_JURIX2013_.pdf;Argumentation schemes for reasoning about factors with dimensions;2013;"Katie Atkinson; Katie Atkinson; Trevor Bench‐Capon; Trevor J. M. Bench-Capon; Henry Prakken; Henry Prakken; Adam Wyner; Adam Wyner";In previous work we presented argumentation schemes to capture the CATO and value based theory construction approaches to reasoning with legal cases with factors. We formalised the schemes with ASPIC+, a formal representation of instantiated argumentation. In ASPIC+ the premises of a scheme may either be a factor provided in a knowledge base or established using a further argumentation scheme. Thus far we have taken the factors associated with cases to be given in the knowledge base. While this is adequate for expressing factor based reasoning, we can further investigate the justifications for the relationship between factors and facts or evidence. In this paper we examine how dimensions as used in the HYPO system can provide grounds on which to argue about which factors should apply to a case. By making this element of the reasoning explicit and subject to argument, we advance our overall account of reasoning with legal cases and make it more robust.;Yes;;;Yes;;Yes;Yes;No;No;ASPIC+;No;No;Manual;Not optimized;Yes (authors);No;Argumentation;Animal Ownership (pierson);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=ca9f91677321bb4e891b13ee0ff35586268da7c6;Integrating Dialectical and Accrual Modes of Argumentation;2010;"Sanjay Modgil; Sanjay Modgil; Trevor Bench‐Capon; Trevor J. M. Bench-Capon";This paper argues that accrual should be modelled in terms of reasoning about the application of preferences to sets of arguments, and shows how such reasoning can be formalised within metalevel argumentation frameworks. These frameworks adopt the same machinery and level of abstraction as Dung's argumentation framework. We thus provide a dialectical argumentation semantics that integrates accrual, and illustrate our approach by instantiating our framework with the arguments and attacks defined by an object level formalism that accommodates reasoning about priorities over sets of rules.;Yes;;;No;Not law specific enough (though note that the authors have published many times in the field of AI&Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-37422-7_11;https://doi.org/10.1007/978-3-642-37422-7_11;Regulatory requirements traceability and analysis using semi-formal specifications;2013;"Travis D. Breaux; Travis D. Breaux; David G. Gordon; David G. Gordon";Information systems are increasingly distributed and pervasive, enabling organizations to deliver remote services and share personal information, worldwide. However, developers face significant challenges in managing the many laws that govern their systems in this multi-jurisdictional environment. In this paper, we report on a computational requirements document expressible using a legal requirements specification language (LRSL). The purpose is to make legal requirements open and available to policy makers, business analysts and software developers, alike. We show how requirements engineers can codify policy and law using the LRSL and design, debug, analyze, trace, and visualize relationships among regulatory requirements. The LRSL provides new constructs for expressing distributed constraints, making regulatory specification patterns visually salient, and enabling metrics to quantitatively measure different styles for writing legal and policy documents. We discovered and validated the LRSL using thirteen U.S. state data breach notification laws.;Yes;;;Yes;;No;No;Yes;No;"Legal Requirements Specification Language; Semi formal semantic markup";No;No (Only file formats);tool supported;Optimized;Yes;No;tracability ;Data breach notification law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-75183-0_12;https://doi.org/10.1007/978-3-540-75183-0_12;Modeling control objectives for business process compliance;2007;"Shazia Sadiq; Shazia Sadiq; Guido Governatori; Guido Governatori; Kioumars Namiri; Kioumars Namiri";Business process design is primarily driven by process improvementobjectives. However, the role of control objectives stemming from regulationsand standards is becoming increasingly important for businesses in light ofrecent events that led to some of the largest scandals in corporate history. Asorganizations strive to meet compliance agendas, there is an evident need toprovide systematic approaches that assist in the understanding of the interplaybetween (often conflicting) business and control objectives during businessprocess design. In this paper, our objective is twofold. We will firstly present aresearch agenda in the space of business process compliance, identifying majortechnical and organizational challenges. We then tackle a part of the overallproblem space, which deals with the effective modeling of control objectivesand subsequently their propagation onto business process models. Controlobjective modeling is proposed through a specialized modal logic based onnormative systems theory, and the visualization of control objectives onbusiness process models is achieved procedurally. The proposed approach isdemonstrated in the context of a purchase-to-pay scenario.;Yes;;;Yes?;Eh, yes law modelled but only in the wider field of normative requiremetns;No;No;Yes;No;"Formal Contract Language (FCL); Deontic operators, atomic propositions, reparation chains";No (They talk about it, but do not really do anything with it as far as I can tell);Yes, to RuleML;Manual;Yes, UI, visuallisation;No;Yes;Compliance;General (Purchase to Pay Scenario is more of a business case, not law);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://www.researchgate.net/profile/Collin-Lynch/publication/220809949_A_Process_Model_of_Legal_Argument_with_Hypotheticals/links/0fcfd50fa48bbe6e38000000/A-Process-Model-of-Legal-Argument-with-Hypotheticals.pdf;A Process Model of Legal Argument with Hypotheticals;2008;"Kevin D. Ashley; Kevin D. Ashley; Collin F. Lynch; Collin Lynch; Niels Pinkwart; Niels Pinkwart; Vincent Aleven; Vincent Aleven";"This paper presents a process model of arguing with hypotheticals and uses it to explain examples of oral arguments before the U.S. Supreme Court that are like those employed in Socratic law teaching. The process model has been partially implemented in the LARGO (Legal ARgument Graph Observer) intelligent tutoring system. The program supports students in diagramming oral argument examples; its feedback on students' diagrammatic reconstructions of the examples enforces the expectations of the process model. The paper presents empirical evidence that features of the argument diagrams made with LARGO are correlated with independent measures of argumentation ability. The examples and empirical results support the model's explanatory and diagnostic utility.";Yes;;;No;More of a descriptive meta model on argument so a bit to far removed from RQs;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://research.vu.nl/ws/portalfiles/portal/232296898/DiaLaw1999LAPS.pdf;DiaLaw: On Legal Justification and Dialogical Models of Argumentation;1999;"A.R. Lodder; Arno R. Lodder";Preface. 1. Introduction. 2. From law to DiaLaw. 3. DiaLaw. Framework and general rules. 4. DiaLaw. Special rules for communication. 5. DiaLaw in action. 6. Dialogical models of argumentation. 7. What is an argument? Properties of procedural models of argumentation. 8. In conclusion. Appendix- Prolog code of DiaLaw. References. Index of names. Index of subjects.;Yes;Had this already?;;No, EX1, book;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://ufal.mff.cuni.cz/~hladka/INTLIB/LOAIT07-Proceedings.pdf#page=43;The LKIF core ontology of basic legal concepts;2007;"Rinke Hoekstra; Rinke Hoekstra; Joost Breuker; Joost Breuker; Marcello Di Bello; M. di Bello; Alexander Boer; Alexander Boer";In this paper we describe a legal core ontology that is part of a generic architecture for legal knowledge systems, which will enable the interchange of knowledge between existing legal knowledge systems. This Legal Knowledge Interchange Format, is under development in the Estrella project and has two main roles: 1) the translation of legal knowledge bases written in different representation formats and formalisms and 2) a knowledge representation formalism that is part of a larger architecture for developing legal knowledge systems. A legal (core) ontology can play an important role in the translation of existing legal knowledge bases to other representation formats, in particular into LKIF as the basis for articulate knowledge serving. We describe the methodology underlying the LKIF core ontology, introduce the concepts it defines, and discuss its use in the formalisation of an EU directive.;Yes;;;Yes;;No;No;Yes;Yes;OWL-DL + SWRL;No;No;Manual;Not optimized;Yes;No;Ontology for general purpose;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/0020-7373(91)90013-w;https://doi.org/10.1016/0020-7373(91)90013-w;CABARET: rule interpretation in a hybrid architecture;1991;"Edwina L. Rissland; Edwina L. Rissland; David B. Skalak; David B. Skalak";;Yes;"""Rules often have unspoken qualifications and exceptions""…";;Yes;;Yes;Yes;No;No;Predicate Logic;No, mentioned but not really integrated?;No;Manual;Not optimized;No;No;Reasoning;Tax Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-012-9125-8;https://doi.org/10.1007/s10506-012-9125-8;A factor-based definition of precedential constraint;2012;"John F. Horty; John F. Horty; Trevor Bench‐Capon; Trevor J. M. Bench-Capon";This paper describes one way in which a precise reason model of precedent could be developed, based on the general idea that courts are constrained to reach a decision that is consistent with the assessment of the balance of reasons made in relevant earlier decisions. The account provided here has the additional advantage of showing how this reason model can be reconciled with the traditional idea that precedential constraint involves rules, as long as these rules are taken to be defeasible. The account presented is firmly based on a body of work that has emerged in AI and Law. This work is discussed, and there is a particular discussion of approaches based on theory construction, and how that work relates to the model described in this paper.;Yes;common law;;Yes;;Yes;Yes;No;No;Formal;"Yes (""just add new case"" though a bit more grounded in theory)";No;Manual;Not optimized;No;No;Reasoning;Trade Secrets;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/323706.323713;https://doi.org/10.1145/323706.323713;Some observations on modelling case based reasoning with formal argument models;1999;"Trevor Bench‐Capon; Trevor J. M. Bench-Capon";In this paper I shall explore the modelling of case based reasoning using a formal model of argument, taking the approach of Prakken and Sartor as my starting point. I first consider their method of representing cases, and describe how — if we restrict ourselves to independent boolean factors — we can fruitfully model the domain as a partial order on rules. I then consider the issues relating to quantifiable factors, as used in HYPO, and factor hierarchies, as used in CATO. The former presents some difficulties for modelling as a partial order, and, coupled with the latter, forces us to recognise two different kinds of reasoning used in concept application which have different implications for representing the domain. I then present some conclusions arising from the discussion.;Yes;;;Yes;;Yes;Yes;No;No;boolean factors imply decision;"Yes, by graph analysis to break up circular ""conflicts""";No;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/41735.41750;https://doi.org/10.1145/41735.41750;A Prolog model of the income tax act of Canada;1987;"David M. Sherman; D. M. Sherman";The use of computers in Canadian tax planning has until now been concentrated on numerical analysis. The computer is indeed an excellent tool for calculating tax effects where the legal results of transactions are known. However, I maintain that it can be equally useful as a tool for analysing transactions to determine what those legal results are. The complexities of the Canadian tax system are such that a given transaction could have unintended tax results, where the facts resulting from the transaction fit the words of a rule which may have been designed for, and is perceived as applying to, different circumstances altogether.  In this paper I consider the structure and form of the Income Tax Act and show how it is well-designed for computerization. I then review the primary design considerations for a computer-based tax planning system. Finally, I describe the implementation of a partial tax analysis system which I have programmed in Prolog, and review its deficiencies and the extensions which would be required to make it a useful planning tool for tax practitioners.  NOTE: this paper is a greatly condensed version of a Master of Laws (LL.M.) thesis, “Blueprint for a Computer-Based Model of the Income Tax Act of Canada”, York University, September 1986. Important detail, references and examples have been omitted due to lack of space. Interested readers are invited to contact the author for a copy of the thesis.;Yes;Eh, tax planning;;Yes;;No;No;Yes;No;"Horn clauses; Prolog";Yes (Prolog is close to natural language, thus rules can be substituted);No;Manual;Not optimized (Usual Prolog understandability);Yes (author);No;Reasoning;Tax Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1080/13600834.1993.9965668;https://pyrobots.csc.liv.ac.uk/~tbc/publications/orton.pdf;Argument‐based explanation of the British nationality act as a logic program;1993;"Trevor Bench‐Capon; Trevor J. M. Bench-Capon; Frans Coenen; Frans Coenen; Paul A. Orton; Paul Orton";Abstract Explanations are a significant component of any knowledge‐based system in the legal domain. We have previously proposed a method by which explanations can be improved by making use of annotations on program clauses as to the role of the clause, and organising the explanation according to an argument schema based on that of Stephen Toulmin. In this paper we describe an application of this approach to a part of the British Nationality Act. This serves to illustrate both the practicality of making the required annotations on a legal logic program, and the gains in terms of explanation that can be achieved.;Yes;;;Yes;;No (Despite Title, not the kind of argumentation I mean);No;Yes;No;"Horn clauses; Prolog";No;No;Manual;Not optimized;No;No;Reasoning;Citizenship;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/158976.158991;https://doi.org/10.1145/158976.158991;BankXX: a program to generate argument through case-base search;1993;"Edwina L. Rissland; Edwina L. Rissland; David B. Skalak; David B. Skalak; Menahem Friedman; M. Timur Friedman";"In this paper we describe a system, called BankXX, which generates arguments by performing a heuristic best-first search of a highly interconnected network of legal knowledge. The legal knowledge includes cases represented from a variety of points of view—cases as collections of facts, cases as dimensionally-analyzed fact situations, cases as bundles of citations, and cases as prototypical factual scripts—as well as legal theories represented in terms of domain factors. BankXX performs its search for useful information using one of three evaluation functions encoded at different levels of abstraction: the domain level, an “argument-piece” level, and the overall argument level. Evaluation at the domain level uses easily accessible information about the nodes,  such  as their type; evaluation at the argument-piece level uses information about generally useful components of case-based argument, such as best cases and supporting legal theories; evaluation at the overall-argument level uses factors, called argument dimensions, which address the overall substance and quality of an argument, such as the centrality of its supporting cases or the success record of its best theory. BankXX is instantiated in the area of personal bankruptcy governed by Chapter 13 of the U.S. Bankruptcy Code, which permits a debtor to be discharged from debts through completion of a court-approved payment plan. In particular, our system addresses the requirement that such Chapter 13 plans be “proposed in good faith.”";Yes;;;Yes;;Yes;Yes;No (though statues are involved in this approach);No;Continuous factors for cases;No;No;Manual;Not optimized;No;No;Reasoning;Bankruptcy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/relaw.2012.6347798;https://doi.org/10.1109/relaw.2012.6347798;Extracting meaningful entities from regulatory text: Towards automating regulatory compliance;2012;"Krishna Sapkota; Krishna Sapkota; Arantza Aldea; Arantza Aldea; Muhammad Younas; Muhammad Younas; David A. Duce; David A. Duce; René Bañares‐Alcántara; René Bañares-Alcántara";Extracting essential meaning from the regulatory text helps in the automation of the Compliance Management (CM) process. CM is a process where organizations assure that the processes are run according to requirements and expectations. However, extraction of meaningful text from regulatory guidelines comes with many research challenges such as dealing with different document-format, implicit document-structure, textual ambiguity and complexity. In this paper, the extended version of the Semantic-ART framework is described, which focuses on tackling the challenges of document-structure identification and regulatory-entity extraction. An initial result has shown an inspirational result as compared to the previous version of the framework.;Yes;;;Yes;;No;No;Yes;No;Semantic Markup of entities;No;No;Automatic;Optimized by nature: Markup in natural language;No;Yes;Semantic extraction;Pharma;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/s0004-3702(03)00105-x;https://doi.org/10.1016/s0004-3702(03)00105-x;Using background knowledge in case-based legal reasoning: a computational model and an intelligent learning environment;2003;"Vincent Aleven; Vincent Aleven";;Yes;;;Yes;This is the CATO paper, so although this is more about education I fell, I still want to include it;Yes;Yes;No;No;"Factors to decision; factor hierarchy to include normative knowledge";No;No;Manual;Yes (for education);Yes;No;Education;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/383535.383544;https://doi.org/10.1145/383535.383544;Automatic text representation, classification and labeling in European law;2001;"Erich Schweighofer; Erich Schweighofer; Andreas Rauber; Andreas Rauber; Michael Dittenbach; Michael Dittenbach";The huge text archives and retrieval systems of legal information have not achieved yet the representation in the well-known subject-oriented structure of legal commentaries. Content-based classification and text analysis remains a high priority research topic. In the joint KONTERM, SOM and LabelSOM projects, learning techniques of neural networks are used to achieve similar high compression rates of classification and analysis like in manual legal indexing. The produced maps of legal text corpora cluster related documents in units that are described with automatically selected descriptors. Extensive tests with text corpora in European case law have shown the feasibility of this approach. Classification and labeling proved very helpful for legal research. The Growing Hierarchical Self-Organizing Map represents very interesting generalities and specialties of legal text corpora. The segmentation into document parts improved very much the quality of labeling. The next challenge would be a change from tf × idf vector representation to a modified vector representation taking into account thesauri or ontologies considering learned properties of legal text corpora.;Yes;Retrieval;;No;This is a bit subjective, but this represents documents as a whole and this I would say is not really applicable to compliance.;;;;;;;;;;Yes (author, Computers and Law);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/41735.41761;https://doi.org/10.1145/41735.41761;Oblog-2: A hybrid knowledge representation system for defeasible reasoning;1987;"Thomas F. Gordon; T. F. Gordon";Oblog-2 is a hybrid knowledge representation system comparable to Krypton and KL-TWO. It combines a terminological reasoner with a Prolog-like inference mechanism. The terminological component supports the description of type and attribute taxonomies. Entities are instances of a set of types. Procedures for determining the values of attributes are Horn clause rules indexed by type. The known types of an entity determine its set of applicable rules, which changes as our knowledge about the types of the entity is refined, supporting a form of defeasible reasoning. Oblog-2 has been designed for modeling legal domains. Laws can be represented as general rules with exceptions, a technique traditionally used in the law, together with burden of proof rules, for reaching decisions when less than perfect information is available.;Yes;;;Yes;;No;No;Yes;No;Hierarchy and Horn clauses (leading to defeasible reasoning);No;No;Manual;Not optimized;Yes (authors);No;Reasoning;Contract Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/323706.323717;https://doi.org/10.1145/323706.323717;Checking regulation consistency by using SOL-resolution;1999;"Laurence Cholvy; Laurence Cholvy";This paper addresses the problem of regulation consistency checking. Regulations are sets of rules which express what is obligatory, permitted, forbidden and under which conditions. We first define a first order language to model regulations. Then we introduce a definition of regulation consistency. We show that checking the consistency of a regulation comes to generate some particular consequences of some first order formulas. Then, we show that we can apply Inoue's inference rule, SOL-resolution, which is complete for generating, from some clauses, their consequences which satisfy a given condition.;Yes;;;Yes;;No;No;Yes;No;First order logic, Standard Deaontic Logic;No;Yes, from Standard Deaontic Logic to first order logic;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-008-9070-8;https://doi.org/10.1007/s10506-008-9070-8;An ontology in OWL for legal case-based reasoning;2008;"Adam Wyner; Adam Wyner";The paper gives ontologies in the Web Ontology Language (OWL) for Legal Case-based Reasoning (LCBR) systems, giving explicit, formal, and general specifications of a conceptualisation LCBR. Ontologies for different systems allows comparison and contrast between them. OWL Ontologies are standardised, machine-readable formats that support automated processing with Semantic Web applications. Intermediate concepts, concepts between base-level concepts and higher level concepts, are central in LCBR. The main issues and their relevance to ontological reasoning and to LCBR are discussed. Two LCBR systems (AS-CATO, which is based on CATO, and IBP) are analysed in terms of basic and intermediate concepts. Central components of the OWL ontologies for these systems are presented, pointing out differences and similarities. The main novelty of the paper is the ontological analysis and representation in OWL of LCBR systems. The paper also emphasises the important issues concerning the representation and reasoning of intermediate concepts.;Yes;;;Yes;;No;Yes;No;Yes;OWL-DL;No;No;Manual;Optimized, UI, shared ;No;No;Ontology Creation;Trade Secrets;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1165485.1165506;https://doi.org/10.1145/1165485.1165506;Automatic semantics extraction in law documents;2005;"Carlo Biagioli; C. Biagioli; Carlo Biagioli; C. Biagioli; Enrico Francesconi; Enrico Francesconi; Andrea Passerini; Andrea Passerini; Simonetta Montemagni; Simonetta Montemagni; Claudia Soria; Claudia Soria";Normative texts can be viewed as composed by formal partitions (articles, paragraphs, etc.) or by semantic units containing fragments of a regulation (provisions). Provisions can be described according to a metadata scheme which consists of provision types and their arguments. This semantic annotation of a normative text can make the retrieval of norms easier. The detection and description of the provisions according to the established metadata scheme is an analytic intellectual activity aiming at classifying portions of a normative text into provision types and to extract their arguments. Automatic facilities supporting this intellectual activity are desirable. Particularly, in this paper, two modules able to qualify fragments of a normative text in terms of provision types and to extract their arguments are presented.;Yes;;;Yes;;No;No;Yes;No;Semantic Markup;No;No;Automatic (after dataset is created);Optimized, Natural language with markup;Yes;No;Markup?;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1080/11663081.1997.10510900;https://webspace.science.uu.nl/~prakk101/pubs/DefArgJANCL97.pdf;Argument-based extended logic programming with defeasible priorities;1997;"Henry Prakken; Henry Prakken; Giovanni Sartor; Giovanni Sartor";ABSTRACT Inspired by legal reasoning, this paper presents a semantics and proof theory of a system for defeasible argumentation. Arguments are expressed in a logic-programming language with both weak and strong negation, conflicts between arguments are decided with the help of priorities on the rules. An important feature of the system is that these priorities are not fixed, but are themselves defeasibly derived as conclusions within the system. Thus debates on the choice between conflicting arguments can also be modelled. The semantics of the system is given with a fixpoint definition, while its proof theory is stated in dialectical style, where a proof takes the form of a dialogue between a proponent and an opponent of an argument: an argument is shown to be justified if the proponent can make the opponent run out of moves in whatever way the opponent attacks.;Yes;;;Yes;;Yes;No;Yes;No;Defeasible Logic;No;No;manual;Not optimized;Yes (authors);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/bf00118493;https://doi.org/10.1007/bf00118493;A theory of legal reasoning and a logic to match;1996;"Jaap Hage; Jaap Hage";This paper describes a model of legal reasoning and a logic for reasoning with rules, principles and goals that is especially suited to this model of legal reasoning. The paper consists of three parts. The first part describes a model of legal reasoning based on a two-layered view of the law. The first layer consists of principles and goals that express fundamental ideas of a legal system. The second layer contains legal rules which in a sense summarise the outcome of the interaction of the principles and goals for a number of case types. Both principles, goals and rules can be used in legal arguments, but their logical roles are different. One characteristic of the model of legal reasoning described in the first part of the paper is that it takes these logical differences into account. Another characteristic is that it pays serious attention to the phenomena of reasoning about the validity and acceptance of rules, respectively principles and goals, and about the application of legal rules, and the implications of these arguments for the use of rules, principles and goals in deriving legal conclusions for concrete cases. The second part of the paper first describes a logic (Reason-Based Logic) that is especially suited to deal with legal arguments as described in terms of the previously discussed model. The facilities of the logic are illustrated by means of examples that correspond to the several aspects of the model. The third part of the paper deals with a number of logico-philosophical reflections on Reason-Based Logic. The occasion is also used to compare these presuppositions with theories of defeasible reasoning based on the comparison of arguments.;Yes;;;Yes;;No;No;Yes;No;Reason-Based Logic, Basically First Order Logic;No;Yes, to and from PS-logic;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1023/b:arti.0000046008.49443.36;https://doi.org/10.1023/b:arti.0000046008.49443.36;Dialectical argumentation with argumentation schemes: an approach to legal logic;2003;"Bart Verheij; Bart Verheij";This paper describes an approach to legal logic based on the formal analysis of argumentation schemes. Argumentation schemes - a notion borrowed from the field of argumentation theory - are a kind of generalized rules of inference, in the sense that they express that given certain premises a particular conclusion can be drawn. However, argumentation schemes need not concern strict, abstract, necessarily valid patterns of reasoning, but can be defeasible, concrete and contingently valid, i.e., valid in certain contexts or under certain circumstances. A method is presented to analyze argumentation schemes and it is shown how argumentation schemes can be embedded in a formal model of dialectical argumentation. The approach also provides insight into the role of critical questions.;Yes;;;Yes;;No;No (they argues it is a combination, but this is not about precedent matching in the classical CBR way);Yes;No;DEFLOG, Basically defesabile horn clauses, with defeaters;No;No;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-00328-8_2;https://www.researchgate.net/publication/221586192_Detecting_Regulatory_Compliance_for_Business_Process_Models_through_Semantic_Annotations;Detecting Regulatory Compliance for Business Process Models through Semantic Annotations;2008;"Guido Governatori; Guido Governatori; Jörg Hoffmann; Jörg Hoffmann; Shazia Sadiq; Shazia Sadiq; Ingo Weber; Ingo Weber";A given business process may face a large number of regulatory obligations the process may or comply with. Providing tools and techniques to evaluate the compliance degree of a given process is a key objective in emerging business process platforms. We propose a diagnostic framework to assess the compliance gaps present in a given process. Checking whether a process is compliant with the rules involves enumerating all reachable states and is hence, in general, a hard search problem. The approach taken here allows to provide useful diagnostic information in polynomial time based on two underlying techniques. A conceptually faithful representation for regulatory obligations is firstly provided by a formal rule language based on a non-monotonic deontic logic of violations. Secondly, processes are formalized through semantic annotations that allow a logical state space to be created. The intersection of the two allows us to devise an efficient method to detect compliance gaps.;Yes;;;Yes;Section 2.1;No;No;Yes;No;"Formal Contract Language (FCL); Deontic operators, atomic propositions, reparation chains";No, limitation;No;Manual;Not optimized;No;Yes;Compliance;Money Laundering;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/222092.222245;https://doi.org/10.1145/222092.222245;Better language, better thought, better communication: the A-Hohfeld language for legal analysis;1995;"Layman E. Allen; Layman E. Allen; Charles S. Saxon; Charles S. Saxon";A-HOHFELD is a representational language used in MINT (Multiple INTerpretation) Interpretation-Assistance (expert) systems for precisely expressing alternative structural interpretations of sets of legal rules. It draws heavily upon the timlamental legal conceptions formulated by Wesley N. HoMeld at the dawn of the Twentieth Century. In the current version of AHOHFELD the original conceptions have been modified and extended in seeking to define a language sufficiently robust to express all LEGAL RELATIONS and all changes in legal states of affairs. Hohfeld emphasized the use of fundamental legal conceptions in the analysis of judicial reasoning, elsewhere we have shown the use of A-HOHFELD for the analysis of sets of statutory rules, and here we illustrate its use in thinking about legal doctrine. This use of A-HOHFELD is offered as a possible example of where fluency in a more precise and complete language might have facilitated an earlier recognition of remedial alternatives that have apparently only recently been appearing in legal literature and judicial decisions. To the extent that AHOHFELD so strengthens legal analysis, it farther exemplifies how work on problems of artificial intelligence in computer science tiuittidly feeds back to law and illustrates how precision in language contributes to thought as well as communication.;Yes;;;Yes;;No;No;Yes;No;A-HOHFELD, formalisation of Hohfelds categorisations, Semi-Formal, If … Then;"Yes, ""robust to all changes in legal states of affairs"" (as is the base model)";No;Manual;Not optimized;No;Yes;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1142/s0218843012400023;https://www.researchgate.net/publication/229078195_Using_Patterns_for_the_Analysis_and_Resolution_of_Compliance_Violations;Using patterns for the analysis and resolution of compliance violations;2012;"Amal Elgammal; Amal Elgammal; Oktay Türetken; Oktay Turetken; Willem‐Jan van den Heuvel; Willem-Jan van den Heuvel";Today's enterprises demand a high degree of compliance of business processes to meet laws and regulations, such as Sarbanes-Oxley and Basel II. Compliance should be enforced during all phases of business process lifecycle, from the phases of analysis and design to deployment, monitoring and evaluation. In this paper, a taxonomy of compliance constraints for business processes is introduced based on the notion of compliance patterns. Patterns facilitate the formal specification of compliance constraints that enable their verification and analysis against business process models. This taxonomy serves as the backbone of the root-cause analysis, which is conducted to reason about and eventually to resolve design-time compliance violations, by providing appropriate guidelines as remedies to alleviate design-time compliance deviations. We have developed and integrated a set of tools to observe and evaluate the applicability of our approach, and experiment with it in case studies.;Yes;;;No;No real modelling of law, rather just the business side of things;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/re.2013.6636714;https://doi.org/10.1109/re.2013.6636714;Assessing regulatory change through legal requirements coverage modeling;2013;"David G. Gordon; David G. Gordon; Travis D. Breaux; Travis D. Breaux";"Developing global markets offer companies new opportunities to manufacture and sell information technology (IT) products in ways unforeseen by current laws and regulations. This innovation leads to changing requirements due to changes in product features, laws, or the locality where the product is sold or manufactured. To help developers rationalize these changes, we introduce a preliminary framework and method that can be used by requirements engineers and their legal teams to identify relevant legal requirements and trace changes in requirements coverage. The framework includes a method to translate IT regulations into a legal requirements coverage model used to make coverage assertions about existing or planned IT systems. We evaluated the framework in a case study using three IT laws: California's Confidentiality of Medical Records Act, the U.S. Health Information Portability and Accountability Act (HIPAA) and amendments from the Health Information Technology for Economic and Clinical Health (HITECH) Act, and the India 2011 Information Technology Rules. Further, we demonstrate the framework using three scenarios: new product features are proposed; product-related services are outsourced abroad; and regulations change to address changes in the market.";Yes;;;Yes;Interesting points about possible changes: change of regulation, move to new jurisdisction, product change;No;No;Yes;No;Legal Requirements Specification Language (LRSL);Yes (one of 3 major contributions in the paper is dealing whith changed legislation);No;Manual;Not optimized;Yes;No;Change management;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-319-12206-9_35;https://doi.org/10.1007/978-3-319-12206-9_35;Compliance with Multiple Regulations;2014;"Sepideh Ghanavati; Sepideh Ghanavati; Llio Humphreys; Llio Humphreys; Guido Boella; Guido Boella; Guido Boella; Guido Boella; Luigi Di; Luigi Di Caro; Livio Robaldo; Livio Robaldo; Leendert van der Torre; Leendert van der Torre";With an increase in regulations, it is challenging for organizations to identify relevant regulations and ensure that their business processes comply with legal provisions. Multiple regulations cover the same domain and can interact with, complement or contradict each other. To overcome these challenges, a systematic approach is required. This paper proposes a thorough approach integrating the Eunomos knowledge and document management system with Legal-URN framework, a Requirements Engineering based framework for business process compliance).;Yes;;;Yes;Will use as proxy for Ref [2] in this paper. Could argue that this paper focuses on the wrong part of Eunomos;No;No;Yes;No;Legal-GRL;Yes, fully automatic from crawling to conflict detection;No;Automatic;Not optimized;No;No;Compliance;Privacy (in Healthcare);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1017/s1352325211000036;http://www.horty.umiacs.io/articles/2008-rrp.pdf;RULES AND REASONS IN THE THEORY OF PRECEDENT;2011;"John F. Horty; John F. Horty";"The doctrine of precedent, as it has evolved within the common law, has at its heart a form of reasoning—broadly speaking, a logic—according to which the decisions of earlier courts in particular cases somehow generalize to constrain the decisions of later courts facing different cases, while still allowing these later courts a degree of freedom in responding to fresh circumstances. Although the techniques for arguing on the basis of precedent are taught early on in law schools, mastered with relative ease, and applied on a daily basis by legal practitioners, it has proved to be considerably more difficult to arrive at a theoretical understanding of the doctrine itself—a clear articulation of the underlying logic. My purpose in this paper is to describe a new framework within which we can begin to address this problem. I concentrate on two of the most fundamental questions in the theory of precedent. First, how is it, exactly, that precedent cases constrain future decisions—what is the mechanism of constraint? And second, how is a balance then achieved between the constraints of precedent and the freedoms allowed to later courts for developing the law? The view I present will be contrasted with three other views, or models, of precedential constraint appearing in the literature. The first is the rule model. A precedent case normally contains, not only a description of the facts of the case along with a decision on the basis of those facts, but also some particular rule through which that decision was reached. According to the rule model, it is this rule that carries the precedential constraint. Constraint by precedent just is constraint by rules; a precedent case constrains the decision of a later court when the rule contained in that precedent applies to the fact situation confronting the later court.";Yes;;;Yes;;No, specifically not just case-based reasoning ~ argumentation, but modeling the base logic;Yes;No;No;Formal description as factors, rules and outcomes. No typical modelling as FOL or similar;Yes, conceptual model of law changes with new cases ;No;Manual;Not optimized;No;No;Extracting logic from cases;Trade Secrets;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-016-9179-0;https://doi.org/10.1007/s10506-016-9179-0;An argumentation framework for contested cases of statutory interpretation;2016;"Douglas Walton; Douglas Walton; Giovanni Sartor; Giovanni Sartor; Fabrizio Macagno; Fabrizio Macagno";This paper proposes an argumentation-based procedure for legal interpretation, by reinterpreting the traditional canons of textual interpretation in terms of argumentation schemes, which are then classified, formalized, and represented through argument visualization and evaluation tools. The problem of statutory interpretation is framed as one of weighing contested interpretations as pro and con arguments. The paper builds an interpretation procedure by formulating a set of argumentation schemes that can be used to comparatively evaluate the types of arguments used in cases of contested statutory interpretation in law. A simplified version of the Carneades Argumentation System is applied in a case analysis showing how the procedure works. A logical model for statutory interpretation is finally presented, covering pro-tanto and all-things-considered interpretive conclusions.;Yes;;;Yes;Very interesting as it integrates case knowledge into statutes;Yes;Yes;Yes;No;ASCPIC+ (I do not think the statuetes are represented formally);No;No;Manual;Not optimiezd;Yes (author);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://repository.lib.ncsu.edu/server/api/core/bitstreams/ae01e979-e2e8-40ab-a043-d386fccd18c0/content;Reasoning About Legal Text Evolution for Regulatory Compliance in Software Systems;2013;"Jeremy C. Maxwell; Jeremy C. Maxwell";;Yes;RQ3;;Yes;TODO read more carefully, just skimmed very through very surface level;No;No;Yes;No;Formal, set of rule patterns;Yes (main focus);No;Manual;Not optimiezd;Yes (In acknowledgments);No;Change managment, compliance;Privacy in Medicine;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://www.researchgate.net/profile/Annie-Anton/publication/265072742_A_Refined_Production_Rule_Model_for_Aiding_in_Regulatory_Compliance/links/545f8d470cf295b56161c5fd/A-Refined-Production-Rule-Model-for-Aiding-in-Regulatory-Compliance.pdf;A refined production rule model for aiding in regulatory compliance;2010;"Jeremy C. Maxwell; Jeremy C. Maxwell; Annie I. Antón; Ana I. Anton";Software engineers are being asked to develop software for increasingly regulated environments. When systems are not dependably compliant, companies must pay the high cost of non-compliance, including the cost of lost reputation and brand damage. Regulations represent the minimum level of security and dependability with which systems must comply. We develop a methodology for creating production rule models to aid developers in specifying legally compliant software requirements. By querying production rule models, software engineers can gain valuable knowledge of the legal text. They can perform an initial compliance analysis and obtain preliminary compliance requirements that can be further refined in consultation with a lawyer. We model the law using the legal concepts of rights, obligations, privileges, no-rights, powers, liabilities, immunities, and disabilities. Herein, we develop heuristics for specifying production rules that model legal texts. We refined our methodology within the context of a case study in which we model the Privacy Rule, Part E, of the Health Insurance Portability and Accountability Act (HIPAA).;Yes;;;Yes;;No;No;Yes;No (used minimal structural ontology);Production Rules, Prolog;No (mentioned but not elaborated);No;Manual;Not optimiezd;No;No;Compliance;Privacy in Medicine;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-41924-9_5;https://doi.org/10.1007/978-3-642-41924-9_5;Automated Reasoning for Regulatory Compliance;2013;"Alberto Siena; Alberto Siena; Silvia Ingolfo; Silvia Ingolfo; Anna Perini; Anna Perini; Angelo Susi; Angelo Susi; John Mylopoulos; John Mylopoulos";Regulatory compliance is gaining attention from information systems engineers who must design systems that at the same time satisfy stakeholder requirements and comply with applicable laws. In our previous work, we have introduced a conceptual modelling language called Nomos 2 that aids requirements engineers analyze law to identify alternative ways for compliance. This paper presents an implemented reasoning tool that supports analysis of law models. The technical contributions of the paper include the formalization of reasoning mechanisms, their implementation in the NRTool, as well as an elaborated evaluation framework intended to determine whether the tool is scalable with respect to problem size, complexity as well as search space. The results of our experiments with the tool suggest that this conceptual modelling approach scales to real life regulatory compliance problems.;Yes;;;Yes;;No;No;Yes;No;Datalog, Nòmos 2, formal as atnecedents, consequents and situations;No;Yes (internal, but interesting) Nòmos to datalog;Manual;Not optimiezd;No;No (only in related work);Cinokuabce;No;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://d1wqtxts1xzle7.cloudfront.net/74402573/Lexical_Semantics_and_Expert_Legal_Knowl20211108-7324-1g80ji1.pdf?1738447697=&response-content-disposition=inline%3B+filename%3DLexical_semantics_and_expert_legal_knowl.pdf&Expires=1745920055&Signature=Kf4DAHl-n4MmWycACl1j47yuvDRr7WHcTr3OVyOT4gmJVayMwJizGC0ljfZ-CYqBny2yJoS3KipVuutCPbmfX5ZlzGRqQULhzmLLKCgAp8KgLTxZZPHYpH8xm-RA50Lrg6am7iObqqkgzDo6e6aKjMb50PXEb7rQvJvB7mxWCherX~q46lUrc5pPSDqfKZCNgDZ5rQacTJYhdXMX1NwRaDYz3b-Hyi3dAfoPZrbYWHDRSJeNpjt~eh2Z0YUbgxfChS1xcO~~uP5L5MZkKLCwaJmtoVTz-l8sfB88zISPMcnn4es3jmWf0iJiCBHx--WlSffydcch67pKD-by2jJJcg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA;Lexical Semantics and Expert Legal Knowledge towards the Identification of Legal Case Factors;2010;"Adam Wyner; Adam Wyner; Wim Peters; Wim Peters";Legal case factors are textually represented facts which are represented in reported legal case decisions. Precedent decisions contribute to the decision of a case under consideration. As textually represented facts, factors linguistically encode semantic properties and relationships among the entities which can be leveraged to identify and extract the legal case factors from decisions. We integrate legal and linguistic resources in a text analysis tool with which we annotate textual passages. Using annotations tailored to legal case factors, the legal researcher can rapidly zero in on textual spans which represent specific combinations of factors, participants, and semantic properties which bear on who played what role with respect to a factor. The research reports progress on the development of a tool.;Yes;;;Yes;;No;Yes;No;No;Semi-Formal factors;No (Usual case argument, but extraction focus so not mentioned);No;Semi-automatic (though I would nearly argue automatic from my personal classification;Yes, UI;No;No;Case factor extraction;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://cdn.aaai.org/AAAI/1980/AAAI80-077.pdf;Rule-based models of legal expertise;1980;"D. A. Waterman; D. A. Waterman; Mark A. Peterson; Mark A. Peterson";This paper describes a rule-based legal decisonmaking system (LDS) that embodies the skills and knowledge of an expert in product liability law. The system is being used to study the effect of changes in legal doctrine on settlement strategies and practices. LDS is implemented in ROSIE, a rule-oriented language designed to facilitate the development of large expert systems. The ROSIE language is briefly described and our approach to modeling legal expertise using a prototype version of LDS is presented.;Yes;;;Yes;No I did not spend 10 minutes looking at a ROSIE tutorial just to realize it was a different ROSIE programming language;No;Yes;No;No;"Semi-Formal in ROSIE language; IF…THEN…";Yes? Basically just reapply procedure?;No;Manual;Yes, UI;No;No;Reasoning;Liability;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://dl.gi.de/server/api/core/bitstreams/f6face2a-3b56-4872-86de-2f71121507ab/content;A Semantic Framework for Compliance Management in Business Process Management.;2009;"Marwane El Kharbili; Marwane El Kharbili; Elke Pulvermüller; Elke Pulvermüller";;Yes;Baiscally just some BPMN modelling :/;;No;Seems promessing, but the exact modelling of the policy is not really specified, but rather left open to implementation (in future work);No;No;Yes;Yes;;;;;;No;Yes;Compliance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=59fb6cd116ff084a96ebbf988f605ad737f0e4d2;Rule based business process compliance;2012;"Guido Governatori; Guido Governatori; Sidney Shek; Sidney Shek";In this paper we report on the development and evaluation of a business process compliance checker, based on the compliance-by-design methodology proposed by Governatori and Sadiq [9]. For a screencast see http://www.youtube.com/watch?v=gFmDQJNai_4;Yes;FLC, https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=59fb6cd116ff084a96ebbf988f605ad737f0e4d2;;Yes;;No;No;Yes;No;Formal Contract Language;No, mentioned but not expanded upon;No;Manual;Not optimized;Yes (implied, domain experts, maybe not quite lawyers);Yes;Compliance;Telecommunication;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-319-12206-9_22;https://doi.org/10.1007/978-3-319-12206-9_22;Nòmos 3: Legal Compliance of Roles and Requirements;2014;"Silvia Ingolfo; Silvia Ingolfo; Ivan Jureta; Ivan Jureta; Alberto Siena; Alberto Siena; Anna Perini; Anna Perini; Angelo Susi; Angelo Susi";The problem of regulatory compliance for a software system consists of ensuring through a systematic, tool-supported process that the system complies with all elements of a relevant law. To deal with the problem, we build a model of the law and contrast it with a model of the requirements of the system. In earlier work, we proposed a modelling language for law (Nomos 2) along with a reasoning mechanism that answers questions about compliance. In this paper we extend Nomos 2 to include the concepts of role and requirement so that we can reason about compliance in specific domains. Also, Nomos 3 represents the distribution of responsibilities to roles, distinguishing social from legal roles. Nomos 3 models allow us to reason about compliance of requirements and roles with the norms that constitute a law. A small case study is used to illustrate the elements of Nomos 3 and the kinds of reasoning it supports.;Yes;Perfect;;Yes;;No;No;Yes;No;Propositional Logic (Taken from other Nòmos 3 paper (https://ieeexplore.ieee.org/document/6912273));No;No (Work in Progress);Manual;Not optimized;No;No;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-319-19069-3_12;https://doi.org/10.1007/978-3-319-19069-3_12;Handling Regulatory Goal Model Families as Software Product Lines;2015;"Anthony Palmieri; Anthony Palmieri; Anthony Palmieri; Philippe Collet; Philippe Collet; Daniel Amyot; Daniel Amyot";Goal models can capture the essence of legal and regulation statements and many of their relationships, enabling compliance analysis. However, current goal modeling approaches do not scale well when handling large regulations with many variable parts that depend on different aspects of regulated organizations. In this paper, we propose a tool-supported approach that integrates the Goal-oriented Requirement Language and feature modeling to handle regulatory goal model families. We show how they can be organized as a Software Product Line (SPL), ensuring the consistency of the SPL as a whole, and providing an adapted derivation process associated to a feature model configuration. The proposed approach is also evaluated on large generated SPLs with results suggesting its capability to address scalability concerns.;Yes;;;Yes;;No;No;Yes;No;"Software Product Line; Formal";No;Yes, to SAT for automatic compliance checking;Manual;Yes, graphical language;No;Yes;Compliance;Aviation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://www.researchgate.net/profile/Guido-Governatori/publication/265815818_A_formal_study_on_legal_compliance_and_interpretation/links/54add3ef0cf2828b29fcb5c3/A-formal-study-on-legal-compliance-and-interpretation.pdf;A formal study on legal compliance and interpretation;2010;"Guido Boella; Guido Boella; Guido Governatori; Guido Governatori; Antonino Rotolo; Antonino Rotolo; Leendert van der Torre; Leendert van der Torre";This paper proposes a logical framework to capture the norm change power and the limitations of the judicial system in revising the set of constitutive rules defining the concepts on which the applicability of norms is based. In particular, we reconstruct the legal arguments leading to an extensive or restrictive interpretation of norms.;Yes;;;Yes;;No;No;Yes;No;Defeasible logic with deontic operators;Yes modelled;No;Manual;Not optimized;No;No;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://itc.scix.net/pdfs/w78-1992-110.content.pdf;An expertext system for building standards;1992;"Casson A; Stone D";The paper describes work on a current collaborative research project involving UK Universities and the Scottish Office's Building Directorate. Previous work by the Directorate had identified limitations in a conventional expert systems approach to the development and management of building Standards information. Work in the current project seeks to overcome these limitations by combining representational paradigms. In particular, a system is being designed and implemented which is based on and seeks to extend the concept of Headed Record Expertext (Diaper 90) in which formalised information can be attached, where appropriate, to nodes in a hypertext version of the Standards. The systemalso handles navigation rules and provides intelligent guidance for the reader through the hyperdocument. The underlying node/arc representational structure is also intended to support the capture of argumentation material generated during the development, maintenance and use ofStandardsinformation.;Yes;;;No;Focus on legislation creation not application;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-20116-5_6;https://doi.org/10.1007/978-3-642-20116-5_6;Checking Regulatory Compliance of Business Processes and Information Systems;2009;"Motoshi Saeki; Motoshi Saeki; Motoshi Saeki; Motoshi Saeki; Haruhiko Kaiya; Haruhiko Kaiya; Satoshi Hattori; Satoshi Hattori";In these years, many laws and regulations are being enacted to prevent business processes (BPs) and information systems (ISs) from their malicious users. As a result, it is significant for organizations to ensure that their BPs and ISs comply with these regulations. This paper proposes a technique to apply a formal technique to ensure the regulatory compliance of BP or IS descriptions written in use case models. We translate the use case models of the behavior of BPs and ISs into finite state transition machines. Regulations are represented with computational tree logic (CTL) and their satisfiability are automatically verified using a model checker SMV. The modality of regulations can be specified with temporal operators based on branching time semantics of the CTL in our technique.;Yes;;;No;This sucks. This is a really good paper. But I cannot access it;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://www.informatik.uni-leipzig.de/~brewka/papers/KR10dialectical.pdf;Abstract dialectical frameworks;2010;"Gerhard Brewka; Gerhard Brewka; Stefan Woltran; Stefan Woltran";In this paper we introduce dialectical frameworks, a powerful generalization of Dung-style argumentation frameworks where each node comes with an associated acceptance condition. This allows us to model different types of dependencies, e.g. support and attack, as well as different types of nodes within a single framework. We show that Dung's standard semantics can be generalized to dialectical frameworks, in case of stable and preferred semantics to a slightly restricted class which we call bipolar frameworks. We show how acceptance conditions can be conveniently represented using weights respectively priorities on the links and demonstrate how some of the legal proof standards can be modeled based on this idea.;Yes;https://www.informatik.uni-leipzig.de/~brewka/papers/KR10dialectical.pdf;;No;Too meta, does not specify the formalisation that should be used;No;No;Yes;Yes;Not fixed, Ontology represented in different formats;"No, ""not …. clear how … ontolog[ies] could offer new contributions""";;;;No;;Core Ontologies;Traffic;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-32253-5_7;https://doi.org/10.1007/978-3-540-32253-5_7;A constructive framework for legal ontologies;2005;"Aldo Gangemi; Aldo Gangemi; Maria-Teresa Sagri; Maria-Teresa Sagri; Daniela Tiscornia; Daniela Tiscornia";The increasing development of legal ontologies seems to offer interesting solutions to legal knowledge formalization, which in past experiences lead to a limited exploitation of legal expert systems for practical use. The paper describes how a constructive approach to ontology can provide useful components to create newly designed legal decision support systems either as local or Web-based semantic services. We describe the relation of our research to AI&Law and legal philosophy, the components of our Core Legal Ontology, the JurWordNet semantic lexicon, and some examples of use of legal ontologies for both norm conformity and compatibility. Our legal ontologies are based on DOLCE+, an extension of the DOLCE foundational ontology developed in the WonderWeb and Metokis EU projects.;Yes;;;Yes;ADF paper :D;Yes;Yes;No;No;ADF;No;Yes, most interestingly, a normal logic program;Manual;Not optimized;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/3-540-61313-7_80;https://doi.org/10.1007/3-540-61313-7_80;Labelling Ideality and Subideality;1996;"Guido Governatori; Guido Governatori";"In this paper we suggest ways in which logic and law may usefully relate; and we present an analytic proof system dealing with the Jones Porn's deontic logic of Ideality and Subideality, which offers some suggestions about how to embed legal systems in label formalism.";Yes;;;Yes;;No;No;Yes;No;Formal, Deontic Logic;No;No;Manual (Proofs are automatic);Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://scholar.google.com/scholar?q=A%20software%20infrastructure%20for%20regulatory%20information%20management%20and%20compliance%20assistance;A software infrastructure for regulatory information management and compliance assistance;2003;"Shawn Kerrigan; Shawn Kerrigan; Charles Heenan; Charles Heenan; Kincho H. Law; Kincho H. Law";The Regnet Project aims to develop a formal information infrastructure for regulatory information management and compliance assistance. This paper discusses three basic milestones of current research and development efforts. The first is the creation of a document repository containing federal and state regulations and supplemental documents. This repository includes a suite of concept hierarchies that enable users to browse documents according to the terms they contain. The second is an XML framework for representing regulations and associated metadata. The XML framework enables the augmentation of regulation text with tools and information that will help users understand and comply with the regulation. The third milestone is the creation of a compliance assistance system built upon the XML framework. The prototype effort for the document repository has been focused on environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management.;Yes;Not sure, dissertation, but probably. Also more about retrieval;;No;Will mark this as a semantic duplicate as the system is present in some of the earlier papers by Kerrigan included in this SLR;No;No;Yes;No;XML Markup with Embedded Logic;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://scholar.google.com/scholar?q=A%20conceptually%20rich%20model%20of%20business%20process%20compliance;A conceptually rich model of business process compliance;2010;"Guido Governatori; Guido Governatori; Antonino Rotolo; Antonino Rotolo";In this paper we extend the preliminary work developed elsewhere and investigate how to characterise many aspects of the compliance problem in business process modeling. We first define a formal and conceptually rich language able to represent, and reason about, chains of reparational obligations of various types. Second, we devise a mechanism for normalising a system of legal norms. Third, we specify a suitable language for business process modeling able to automate and optimise business procedures and to embed normative constraints. Fourth, we develop an algorithm for compliance checking and discuss some computational issues regarding the possibility of checking compliance runtime or of enforcing it at design time.;Yes;I think this is a duplicate???;;Yes;;No;No;Yes;No;"Process Compliance Language; Defeasible deontic logic";No;No;Manual;Not optimized;Yes (author);Yes;Compliance;Finance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-85569-9_2;https://doi.org/10.1007/978-3-540-85569-9_2;MetaLex XML and the Legal Knowledge Interchange Format;2008;"Alexander Boer; Alexander Boer; Radboud Winkels; Radboud Winkels; Fabio Vitali; Fabio Vitali";Electronic government invariably involves XML and electronic law: legislation is as essential to public administration as the ball is to a ball game. This paper gives an overview of two XML standard proposals dealing with two complementary aspects of electronic legislation --- the documents themselves as a carrier, and an institutional reality they represent --- in a coherent way: MetaLex XML and the Legal Knowledge Interchange format (LKIF). MetaLex XML is well on its way to becoming formal and de facto standard for legislation in XML. LKIF is yet to be submitted as a proposed standard. LKIF includes some interesting innovations from an AI & Law perspective.;Yes;;;Yes?;Not sure, this is a kind of meta paper on MetaLex + LKIF, not sure if it adds too much;No;No;Yes;No;"Semi-Formal: MetaLex, LKIF; XML standards, no formal logic";No, Future Work;Yes, both formats meant as base line interchange;Manual;Not optimized;Yes (Discussions with Estrella consortium);No;Representation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-32253-5_9;https://doi.org/10.1007/978-3-540-32253-5_9;Building legal ontologies with METHONTOLOGY and WebODE;2005;"Óscar Corcho; Oscar Corcho; Mariano Fernández-López; Mariano Fernández-López; Asuncíon Gómez-Pérez; Asunción Gómez-Pérez; Angel López-Cima; Angel López-Cima";This paper presents how to build an ontology in the legal domain following the ontology development methodology METHONTOLOGY and using the ontology engineering workbench WebODE. Both of them have been widely used to develop ontologies in many other domains. The ontology used to illustrate this paper has been extracted from an existing class taxonomy proposed by Breuker, and adapted to the Spanish legal domain.;Yes;Maybe too descriptive of the process;;No;Methondology (though it has some basic LIR);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-89982-2_67;https://doi.org/10.1007/978-3-540-89982-2_67;ASPARTIX: Implementing Argumentation Frameworks Using Answer-Set Programming;2008;"Uwe Egly; Uwe Egly; Sarah Alice Gaggl; Sarah Alice Gaggl; Stefan Woltran; Stefan Woltran";The system ASPARTIX is a tool for computing acceptable extensions for a broad range of formalizations of Dung's argumentation framework and generalizations thereof. ASPARTIX relies on a fixed disjunctive datalog program which takes an instance of an argumentation framework as input, and uses the answer-set solver DLV for computing the type of extension specified by the user.;Yes;;;No;This is a solver tool not really the representation focus itsefl;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-16524-5_9;https://doi.org/10.1007/978-3-642-16524-5_9;Multi-layer markup and ontological structures in Akoma Ntoso;2009;"Gioele Barabucci; Gioele Barabucci; Luca Cervone; Luca Cervone; Monica Palmirani; Monica Palmirani; Silvio Peroni; Silvio Peroni; Fabio Vitali; Fabio Vitali";The XML documents that represent legal resources contain information and legal knowledge that belong to many distinct conceptual layers. This paper shows how the Akoma Ntoso standard keeps these layers well separated while providing ontological structures on top of them. Additionally, this paper illustrates how Akoma Ntoso allows multiple interpretations, provided by different agents, over the same set of texts and concepts and how current semantic technologies can use these interpretations to reason on the underlying legal texts.;Yes;;;Yes;Not the introducing paper of Akoma Ntoso, but good reference;No;No;Yes;No;Akoma Ntoso;No, mentioned can relate for example amendments, but as there is no meta semantic layer that is really being changed I will say no;Yes, into semantic formats;Manual (despite some parts being automatable);Yes, XML with text;Yes (Akoma Ntoso at least, acknowledgments seem to heavily indicate it);No;Representation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/11779568_108;https://doi.org/10.1007/11779568_108;TERMINAE method and integration process for legal ontology building;2006;"Sylvie Desprès; Sylvie Desprès; Sylvie Szulman; Sylvie Szulman";This paper describes the contruction method of a legal application ontology. This method is based on the merging of micro-ontologies built from European community directives. The terminae construction method from texts enhanced by an alignment process with a core legal ontology is used for building micro-ontologies. A merging process allows constructing the legal ontology.;Yes;;;No;Ontology construction focus;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-31570-1_2;https://doi.org/10.1007/978-3-642-31570-1_2;Visualizing normative systems: an abstract approach;2012;"Silvano Colombo Tosatto; Silvano Colombo Tosatto; Guido Boella; Guido Boella; Leendert van der Torre; Leendert van der Torre; Serena Villata; Serena Villata";Abstract normative systems allow to reason with norms even when their content is not detailed. In this paper, we propose a our preliminary results to visualize abstract normative systems, in such a way that we are able to reason with institutional facts, obligations and permissions. Moreover, we detect meaningful patterns emerging from the proposed visualization, and we show how these patterns can be used to define commonly used reusable solutions.;Yes;;;;;No;No;Yes;No;Visualisation of deaontic logic;No;No;Manual;Yes, graphical language;No;No;Visualisation;Housing;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1023/a:1008289826410;https://doi.org/10.1023/a:1008289826410;On the logical foundations of compound predicate formulae for legal knowledge representation;1997;"Hideaki Yoshino; Hajime Yoshino";In order to represent legal knowledge adequately, it is vital to create a formal device that can freely construct an individual concept directly from a predicate expression. For this purpose, a Compound Predicate Formula (CPF) is formulated for use in legal expert systems. In this paper, we willattempt to explain the nature of CPFs by rigorous logical foundation, i.e., establishing their syntax and semantics precisely through the use of appropriate examples. We note the advantages of our system over other such systems and discuss the significance of CPFs with regard to the formalization of legal reasonings using examples from the United Nations Convention for the International Sale of Goods.;Yes;;;Yes;;No;No;Yes;No;Compound predicate formulas (basically just horn clauses);No;No;Manual;Not optimized;No;No;;Commerce;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/3-540-57234-1_49;https://doi.org/10.1007/3-540-57234-1_49;Legal Expert System KONTERM - Automatic Representation of Document Structure and Contents;1993;"Erich Schweighofer; Erich Schweighofer; Werner Winiwarter; Werner Winiwarter";Our legal expert system KONTERM contains a selective thesaurus and a knowledge base for the automatic representation of the structure and the contents of the document. The thesaurus takes into account the necessary degree of formalism of legal language and therefore overcomes the untidiness of natural language and represents automatically the expert knowledge of a lawyer about legal terminology. The required selectivity of the individual descriptors is achieved by distinguishing between precise legal terms and words with fuzzy meanings as well as by detecting hidden word senses. This thesaurus, together with the expert rules for structuring the document, provides the user with an analytical document representation. In addition to that, hypertext links will be supplemented in order to offer the lawyer a convenient tool for efficient information retrieval.;Yes;;;No;Too retrieval focused, little more;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-16524-5_5;https://doi.org/10.1007/978-3-642-16524-5_5;Model regularity of legal language in active modifications;2009;"Monica Palmirani; Monica Palmirani; Raffaella Brighi; Raffaella Brighi";One of the main emerging challenges in legal documentation is to capture the meaning and the semantics of normative content using NLP techniques, and to isolate the relevant part of the linguistic speech. The last five years have seen an explosion in XML schemas and DTDs whose focus in modelling legal resources their focus was on structure. Now that the basic elements of textual descriptiveness are well formalized, we can use this knowledge to proceed with content. This paper presents a detailed methodology for classifying modificatory provisions in depth and providing all the necessary information for semiautomatically managing the consolidation process. The methodology is based on an empirical legal analysis of about 29,000 Italian acts, where we bring out regularities in the language associated with some modifications, and where we define patterns of proprieties for each type of modificatory provision. The list of verbs and the frames inferred through this empirical legal analysis have been used by the NLP group at the University of Turin to refine a syntactical NLP parser for isolating and representing the sentences as syntactic trees, and the pattern will be used by the light semantic interpreter module to indentify the parameters of modificatory provisions.;Yes;"Also for discussion; Fig. 1 really nice";;Yes;;No;No;Yes;No;Mixed. Structure via XML, Ontologies for semantic logic, predicate logic;Yes, focus. ;No (just internal);tool supported;Not optimized;Yes (data creation);No;Change managment, compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-85569-9_7;https://doi.org/10.1007/978-3-540-85569-9_7;Supporting the Construction of Spanish Legal Ontologies with Text2Onto;2008;"Johanna Völker; Johanna Völker; Sergi Fernández; Sergi Fernandez Langa; York Sure; York Sure";The IST project SEKT (Semantically Enabled Knowledge Technologies) aims at developing semantic technologies by integrating knowledge management, text mining, and human language technology. Tools and methodologies implemented in the SEKT project are employed and optimized in three case studies, one of them being concerned with intelligent integrated decision support for legal professionals. The main goal of this case study is to offer decision support to newly appointed judges in Spain by means of iFAQ, an intelligent Frequently Asked Questions system based on a complex ontology of the legal domain. Building this ontology is a tedious and time-consuming task requiring profound knowledge of legal documents and language. Therefore, any kind of automatic support can significantly increase the efficiency of the knowledge acquisition process. In this paper we present Text2Onto, an open-source tool for ontology learning, and our experiments with legal case study data. The previously existing English version of Text2Onto has been adapted to support the linguistic analysis of Spanish texts, including language-specific algorithms for the extraction of ontological concepts, instances and relations. Text2Onto greatly facilitated the automatic generation of the initial version of the Spanish legal ontology from a given collection of Spanish documents. In further iterative steps which included a mixture of learning and manual effort the ontology has been refined and applied to the real-world case study.;Yes;;;No;Too ontology construcion heavy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/11536406_13;https://doi.org/10.1007/11536406_13;Reasoning with textual cases;2005;"Stefanie Brüninghaus; Stefanie Brüninghaus; Kevin D. Ashley; Kevin D. Ashley";This paper presents methods that support automatically finding abstract indexing concepts in textual cases and demonstrates how these cases can be used in an interpretive CBR system to carry out case-based argumentation and prediction from text cases. We implemented and evaluated these methods in SMILE+IBP, which predicts the outcome of legal cases given a textual summary. Our approach uses classification-based methods for assigning indices. In our experiments, we compare different methods for representing text cases, and also consider multiple learning algorithms. The evaluation shows that a text representation that combines some background knowledge and NLP combined with a nearest neighbor algorithm leads to the best performance for our TCBR task.;Yes;;;No;Cool, reasoning on factors as per usual, but extraction directly from text, not really relevant to LIR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e3a1c091825c2e33e832df6c5f2c44a638ddb54a;Epistemology and ontology in core ontologies: FOLaw and LRI-Core, two core ontologies for law;2004;"J.A.P.J. Breukers; J.A.P.J. Breukers; Rinke Hoekstra; Rinke Hoekstra";"For more than a decade constructing ontologies for legal domains, we, at the Leibniz Center for Law, felt really the need to develop a core ontology for law that would enable us to re-use the common denominator of the various legal domains. In this paper we present two core ontologies for law. The first one was the result of a PhD thesis by [Valente, 1995], called FOLaw. FOLaw speci- fies functional dependencies between types of knowledge involved in legal reasoning. Despite the fact that FOLaw was the starting point for a number of ontologies and legal reasoning systems in various (European) projects, it is rather an epistemological framework than a (core) ontology. We are not the only ones who easily confound epistemology with ontology. In the paper we present some examples and discuss whether this epistemological promiscuity in (core) ontology development is a serious problem. It is to some extent, as it limits the scope of re-use (if not leading to confusion). Therefore, we started about four years ago the development of a 'real' core-ontology for law based upon notions of common sense. The reason for a common-sense foundation is that domain independent concepts of law - the common denominator - are still tainted with a strong common-sense flavor. Moreover, domains of law refer to social activities which are generally governed by common-sense notions. This core ontology, called LRI-Core, consists of five major portions ('worlds'): physical, mental and abstract classes; roles and occurrences.";Yes;;;Yes?;Interesting distinction between epistimologies and ontologies. Use for definition of ontology I think;No;No;Yes;Yes;Unspecified but formal;No;No;Manual;Not optimized;Yes (authors);No;Ontological Representation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-24908-2_30;https://doi.org/10.1007/978-3-642-24908-2_30;LegalRuleML: XML-based rules and norms;2011;"Monica Palmirani; Monica Palmirani; Guido Governatori; Guido Governatori; Antonino Rotolo; Antonino Rotolo; Said Tabet; Said Tabet; Harold Boley; Harold Boley; Adrian Paschke; Adrian Paschke";Legal texts are the foundational resource where to discover rules and norms that feed into different concrete (often XML-based) Web applications. Legislative documents provide general norms and specific procedural rules for eGovernment and eCommerce environments, while contracts specify the conditions of services and business rules (e.g. service level agreements for cloud computing), and judgments provide information about the legal argumentation and interpretation of norms to concrete case-law. Such legal knowledge is an important source that should be detected, properly modeled and expressively represented in order to capture all the domain particularities. This paper provides an extension of RuleML called LegalRuleML for fostering the characteristics of legal knowledge and to permit its full usage in legal reasoning and in the business rule domain. LegalRuleML encourages the effective exchange and sharing of such semantic information between legal documents, business rules, and software applications.;Yes;;;Yes;;No;No;Yes;No;Specified via XML-schemas, extension of RuleML;Yes, (append rules, add temporal reasoning);No;Manual;Not optimized;No;Yes;Information interchange;Copyright, Contracts;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-38709-8_20;https://doi.org/10.1007/978-3-642-38709-8_20;Diagnostic information for compliance checking of temporal compliance requirements;2013;"Elham Ramezani Taghiabadi; Elham Ramezani Taghiabadi; Dirk Fahland; Dirk Fahland; Boudewijn F. van Dongen; Boudewijn F. van Dongen; Wil M. P. van der Aalst; Wil M. P. van der Aalst";Compliance checking is gaining importance as today's organizations need to show that operational processes are executed in a controlled manner while satisfying predefined (legal) requirements or service level agreements. Deviations may be costly and expose an organization to severe risks. Compliance checking is of growing importance for the business process management and auditing communities. This paper presents an approach for checking compliance of observed process executions recorded in an event log to temporal compliance requirements, which restrict when particular activities may or may not occur. We show how temporal compliance requirements discussed in literature can be unified and formalized using a generic temporal compliance rule. To check compliance with respect to a temporal rule, the event log describing the observed behavior is aligned with the rule. The alignment then shows which events occurred out of order and which events deviated by which amount of time from the prescribed behavior. This approach integrates with an existing approach for control-flow compliance checking, allowing for multi-perspective diagnostic information in case of compliance violations. We show the feasibility of our technique by checking temporal compliance rules of real life event logs.;Yes;Petri Nets? But focus not really on the regulation representation? More of a means to an end?;;No;Interesting because Petri Nets but no real focus on LIR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.3233/sw-140146;https://doi.org/10.3233/sw-140146;An OWL ontology library representing judicial interpretations;2016;"Marcello Ceci; Marcello Ceci; Marcello Ceci; Aldo Gangemi; Aldo Gangemi";The article introduces JudO, an OWL2 ontology library of legal knowledge that relies on the metadata contained in judicial documents. JudO represents the interpretations performed by a judge while conducting legal reasoning towards the adjudication of a case. To the aim of this application, judicial interpretation is intended in the restricted sense of the acts of judicial subsumption performed by the judge when he considers a material instance (token in Searle's terminology), and assigns it to an abstract category (type). The ontology library is based on a theoretical model and on some specific patterns that exploit some new features introduced by OWL2. JudO provides meaningful legal semantics, while retaining a strong connection to source documents (fragments of legal texts). The application task is to enable detection and modeling of jurisprudence-related information directly from the text, and to perform shallow reasoning on the resulting knowledge base. The ontology library is also supposed to support a defeasible rule set for legal argumentation on the groundings of judicial decisions.;Yes;;;Yes;Tim Berners Lee’s Semantic Web layer cake, adapted to the legal domain in [47].!!!;No;Yes;No;Yes;OWL2;No;No;Manual;Not optimized;Yes;No;Ontological Representation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-540-30470-8_75;https://doi.org/10.1007/978-3-540-30470-8_75;Cases and Dialectical Arguments – An Approach to Case-Based Reasoning;2004;"Bram Roth; Bram Roth; Bart Verheij; Bart Verheij";Case-based reasoning in the law is a reasoning strategy in which legal conclusions are supported by decisions made by judges. If the case at hand is analogous to a settled case, then by judicial authority one can argue that the settled case should be followed. Case-based reasoning is a topic where ontology meets logic since one’s conception of cases determines one’s conception of reasoning with cases. In the paper, it is shown how reasoning with cases can be modelled by comparing the corresponding dialectical arguments. A unique characteristic thereby is the explicit recognition that it is in principle contingent which case features are relevant for case comparison. This contigency gives rise to some typical reasoning patterns. The present work is compared to other existing approaches to reasoning by case comparison, and some work on legal ontologies is briefly discussed regarding the role attributed to cases.;Yes;;;Yes;;Yes;Yes;No;No;Semi-formal: Comparisons of factors;No;No;Manual;Not optimized;No;No;Case Comparison;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/11575863_104;https://doi.org/10.1007/11575863_104;Building e-laws ontology: new approach;2005;"Ahmad Kayed; Ahmad Kayed";Semantic Web provides tools for expressing information in a machine accessible form where agents (human or software) can understand it. Ontology is required to describe the semantics of concepts and properties used in web documents. Ontology is needed to describe products, services, processes and practices in any e-commerce application. Ontology plays an essential role in recognizing the meaning of the information in Web documents. This paper attempts to deploy these concepts in an e-law application. E-laws ontology has been built using existing resources. It has been shown that extracting concepts is less hard than building relationships among them. A new algorithm has been proposed to reduce the number of relationships, so the domain knowledge expert (i.e. lawyer) can refine these relationships.;Yes;;;No;Law ontologies are nice and all, but not really concrete representation of specific laws in this case. This is also more process focused;;;;Yes;;;;;;;;;E-Commerce;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-642-11355-0_7;https://doi.org/10.1007/978-3-642-11355-0_7;Ontology and time evolution of obligations and prohibitions using semantic web technology;2009;"Nicoletta Fornara; Nicoletta Fornara; Marco Colombetti; Marco Colombetti";The specification and monitoring of conditional obligations and prohibitions with starting points and deadlines is a crucial aspect in the design of open interaction systems. In this paper we regard such obligations and prohibitions as cases of social commitment, and propose to model them in OWL, the logical language recommended by the W3C for Semantic Web applications. In particular we propose an application-independent ontology of the notions of social commitment, temporal proposition, event, agent, role and norms that can be used in the specification of any open interaction system. We then delineate a hybrid solution that uses the OWL ontology, SWRL rules, and a Java program to dynamically monitor or simulate the temporal evolution of social commitments, due to the elapsing of time and to the actions performed by the agents interacting within the system.;Yes;;;No;Not law focused enough and I have problems fitting these types of ontology design papers into the SLR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.3233/978-1-58603-952-3-170;https://www.researchgate.net/publication/220809909_Automated_Legal_Assessment_in_OWL_2;Automated Legal Assessment in OWL 2;2008;"Saskia van de Ven; Saskia van de Ven; Joost Breuker; Joost Breuker; Rinke Hoekstra; Rinke Hoekstra; Lars Wortel; Lars Wortel";In this paper we describe HARNESS, a legal knowledge-based system that is developed in the context of ESTRELLA. This system is primarily aimed at the task of legal assessment, i.e. determining whether some case violates and/or complies with legal norms. We explain how the sound and complete reasoning provided by OWL-DL reasoners is exploited by a careful representation of norms, using examples from law on taxation of gifts. We describe a plugin for Protege 4 that enables easy experimentation for this system, powered by Pellet.;Yes;;;Yes;;No;No;Yes;Yes;OWL2 using deontic logic;No;No;tool supported;Not optimized;Yes (authors);No;Compliance (=Assessment);Taxation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/158976.158981;https://doi.org/10.1145/158976.158981;A reduction-graph model of ratio decidendi;1993;"L. Karl Branting; L. Karl Branting";This paper proposes a model of  ration decidendi  as a justification structure consisting of a series of reasoning steps, some of which relate abstract predicates to other abstract predicates and some of which relate abstract predicates to specific facts. This model satisfies four adequacy criteria for  ratio decidendi  identified from the jurisprudential literature. In particular, the model shows how the theory under which a case is decided controls its precedential effect. By contrast, a purely case-based model of  ratio  fails to account for the dependency of precedential effect on the theory of decision.;Yes;I think so, this is a bit of a specialized representation though and also argumentative and case based so might have to kick;;Yes;;No;Yes;No;No;Reduction Graphs;No (case argument);No;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1568234.1568241;https://doi.org/10.1145/1568234.1568241;NLP-based extraction of modificatory provisions semantics;2009;"Alessandro Mazzei; Alessandro Mazzei; Daniele Paolo Radicioni; Daniele P. Radicioni; Raffaella Brighi; Raffaella Brighi";"In this paper we illustrare a research based on NLP techniques aimed at automatically annotate modificatory provisions. We propose an approach which pairs deep syntactic parsing with rule-based shallow semantic analysis relying on a fine-grained taxonomy of modificatory provisions. The implemented system is evaluated on a large dataset hand-crafted by legal experts; the results are discussed and future directions of the research outlined.";Yes;;;Yes;;No;No;Yes;No;Semantic Markup;Yes, focus. Automatic;No;Semi-automatic;Yes, Markup;Yes (data creation);No;Change managment;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/relaw.2013.6671344;https://doi.org/10.1109/relaw.2013.6671344;Transforming regulations into performance models in the context of reasoning for outcome-based compliance;2013;"Rouzbahan Rashidi-Tabrizi; Rouzbahan Rashidi-Tabrizi; Gunter Mussbacher; Gunter Mussbacher; Daniel Amyot; Daniel Amyot";Recently, interest in performance modeling of out-come-based regulations has grown in the regulatory community. In this context, performance modeling refers to the measuring of important business aspects in a coordinated manner and the use of these measurements for improved decision making. Goal modeling techniques have shown to be beneficial when expressing and analyzing performance models. Since most regulations are still written in natural language, support for the transformation of regulatory text into performance models is needed. This allows regulators and regulated parties to keep working with familiar natural language regulations and to use goal models indirectly while avoiding a potentially significant learning curve for goal-modeling techniques. In this paper, we present such a tool-supported transformation to goal models expressed with the User Requirements Notation that enables reasoning about outcome-based regulations via widely available evaluation mechanism for goal models. The transformation is implemented in the jUCM-Nav goal modeling tool and illustrated with an example from the banking domain.;Yes;;;Yes;;No;No;Yes;No;User Requirements Notation -> GRL;No;No (just import from csv);tool supported;Yes, Input optimized for regulators, Spread Sheet;No;Yes;Compliance;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1165485.1165502;https://doi.org/10.1145/1165485.1165502;Additive consolidation for dialogue game;2005;"Yoshitaka Suzuki; Yoshitaka Suzuki; Satoshi Tojo; Satoshi Tojo";Our purpose is to propose postulates about operators which capture dynamic aspects on a legal argumentation, and to construct operators which satisfy the postulates and expand plaintiff and defendant's theories coherently. These ideas are the generalizations of Olsson's additive consolidation. Consolidation is studied in the field of belief revision, and makes an agent's epistemic state coherent. Therefore, our presentation will build a bridge between legal reasoning and belief revision.;Yes;;;No;Will disregard as though CBR is generally allowed this leans a bit too heavily into the epistomological aspects of it for my liking;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/41735.41753;https://doi.org/10.1145/41735.41753;Legal reasoning in 3-D;1987;"Marvin Belzer; M. Belzer";This article contains a theory of normative defeasible reasoning based on the modal deontic logic 3-D. The concept of “relative weight” between competing norms is defined, and 3-D is used to formalize two types of legal reasoning (“subsumptive” and “means/end”). A general overview is given of a PROLOG program, 3dpr, that implements the 3-D based theory of normative reasoning.;Yes;;;Yes;;No;No;Yes;No;"Defeasible Logic; solvable in Prolog";No;Yes to Prolog;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/re.2012.6345813;https://doi.org/10.1109/re.2012.6345813;Towards outcome-based regulatory compliance in aviation security;2012;"Rasha Tawhid; Rasha Tawhid; Edna Braun; Edna Braun; Nick Cartwright; Nick Cartwright; Mohammad Alhaj; Mohammad Alhaj; Gunter Mussbacher; Gunter Mussbacher; Azalia Shamsaei; Azalia Shamsaei; Daniel Amyot; Daniel Amyot; Saeed Ahmadi Behnam; Saeed Ahmadi Behnam; Gregory Richards; Greg Richards";Transport Canada is reviewing its Aviation Security regulations in a multi-year modernization process. As part of this review, consideration is given to transitioning regulations where appropriate from a prescriptive style to an outcome-based style. This raises new technical and cultural challenges related to how to measure compliance. This paper reports on a novel approach used to model regulations with the Goal-oriented Requirement Language, augmented with qualitative indicators. These models are used to guide the generation of questions for inspection activities, enable a flexible conversion of real-world data into goal satisfaction levels, and facilitate compliance analysis. A new propagation mechanism enables the evaluation of the compliance level of an organization. This outcome-based approach is expected to help get a more precise understanding of who complies with what, while highlighting opportunities for improving existing regulatory elements.;Yes;Aviation specific, but GRL generally applicable;;Yes;;No;No;Yes;No;URN -> GRL;No;No;Manual;Not optimized;Yes (teams involved in the review of regulations);No;Compliance;Aviation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2514601.2514638;https://doi.org/10.1145/2514601.2514638;Regorous: a business process compliance checker;2013;"Guido Governatori; Guido Governatori; Sidney Shek; Sidney Shek";We report on the development of Regorous, a business process compliance checker, based on the compliance-by-design methodology proposed by Governatori and Sadiq [8]. For a screencast see http://www.youtube.com/watch?v=gFmDQJNai_4r;Yes;FCL/PCL;;No;This is too surface level. Also I feel like there are typos here because FCL and PCL are not the same!?;;;;;"Process Compliance Language; Defeasible deontic logic";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2514601.2514619;https://doi.org/10.1145/2514601.2514619;Modeling teleological interpretation;2013;"Tomasz Żurek; Tomasz Zurek; Michał Araszkiewicz; Michał Araszkiewicz";The paper presents a model of teleological interpretation of statutory legal rules as well as an example of the genuine law case, which has been modeled with use of established methodology.;Yes;;;Yes;This slightly messed with my brain and is not 100% applicable to BPC I think. Basically the idea is to assume that implications rather provide instantiations of a broader unstated rule which is the actual rule that should be follwed. Interesting for discussion as it shows the limitations of many forms of legal reasoning based on dogmatic rule encoding;No;No;Yes;No;Formal, Horn Clauses with teleological interpretation, not really meant for general reasoning but to prove a point;No;No;Manual;Not optimized;No;No;Meta analysis (but they do present LIR even if it is not really for LIR purposes);General (Taxi but just one example case);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/0020-7373(91)90012-v;https://doi.org/10.1016/0020-7373(91)90012-v;Building explanations from rules and structured cases;1991;"L. Karl Branting; L. Karl Branting";;Yes;;;Yes;;No;Yes;Yes;No;Horn clauses, Prolog (statutes), frames (cases);No, mentioned though;No;Manual;Not optimized;Yes;No;Reasoning;Compensation Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-008-9072-6;https://doi.org/10.1007/s10506-008-9072-6;Integrated access to legal literature through automated semantic classification;2009;"Enrico Francesconi; Enrico Francesconi; Ginevra Peruginelli; G. Peruginelli; G. Peruginelli; Ginevra Peruginelli";Access to legal information and, in particular, to legal literature is examined for the creation of a search and retrieval system for Italian legal literature. The design and implementation of services such as integrated access to a wide range of resources are described, with a particular focus on the importance of exploiting metadata assigned to disparate legal material. The integration of structured repositories and Web documents is the main purpose of the system: it is constructed on the basis of a federation system with service provider functions, aiming at creating a centralized index of legal resources. The index is based on a uniform metadata view created for structured data by means of the OAI approach and for Web documents by a machine learning approach, which, in this paper, has been assessed as regards document classification. Semantic searching is a major requirement for legal literature users and a solution based on the exploitation of Dublin Core metadata, as well as the use of legal ontologies and related terms prepared for accessing indexed articles have been implemented.;Yes;Retrieval;;No;Retrieval focused;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/158976.158988;https://doi.org/10.1145/158976.158988;Legal interpretation in expert systems;1993;"Daniel Poulin; Daniel Poulin; Paul Bratley; Paul Bratley; Jacques Frémont; Jacques Frémont; Ejan Mackaay; Ejan Mackaay";"A legal expert system expresses as a set of formal rules the norms found in the provisions of a statute or regulation, in case law or other legal texts. The process of constructing the system involves interpreting these legal texts and recasting each of them into one or more formal legal rules. The primary sources of law or law-formulations, to use Susskind’s term [Susskind 87, 36-37, 124], must be transformed into law-statements—statements about what the content of the law is—and these in turn must be translated into a formal language as rules of inference which Susskind terms legal productions. These transformations take place outside the context of specific cases, that is without reference to concrete legal problems those rules are designed to solve. The construction of a legal expert system involves two conceptual steps: to identify the legal norms that a statute conveys and to express these norms as formal rules. Several strategies have been proposed for this transformation process. Some consist of a rather straightforward transposition of law texts into formal language at the expense of a substantial loss of meaning of the legal concepts involved; others call for a subtler and more complex legal analysis. In all cases, however, what is at stake is the interpretation of legal documents. The problem of interpreting legal documents is well known to lawyers. In legal usage, the term interpretation is employed when the meaning of a legal text, typically a statutory provision, has to be assessed in a concrete situation. In constructing expert systems, one must interpret legal documents ahead of such concrete applications. This interpretation can only be provisional. The best one can do in constructing the knowledge base is to foreclose as few as possible of the meanings for particular provisions one may ultimately want to consider in concrete situations. Conversely, when using the system in a particular situation, one may want to consider different interpretations and their";Yes;;;Yes;;No;No;Yes;No;"Semi-Formal logic, not specified, Multiple levels of ""implications""";Yes, can deal with it, though not automatically, just by adding more rules;No;Manual;Not optimized;Yes (authors(;No;Reasoning;Insurance;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/112646.112667;https://doi.org/10.1145/112646.112667;Norms and formalization;1991;"Henning Herrestad; Henning Herrestad";;Yes;Chisholm paradox is really cool :D;;No;Really cool meta analysis but technically I would call this EX1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/323706.323795;https://doi.org/10.1145/323706.323795;A collaborative legal information retrieval system using dynamic logic programming;1999;"Paulo Quaresma; Paulo Quaresma; Paulo Quaresma; Irene Pimenta Rodrigues; Irene Pimenta Rodrigues";We propose a framework for a collaborative legal information retrieval system based on dynamic logic programming. In order to be collaborative our system keeps the context of the interaction and tries to infer the user intentions. Each event is represented by logic programming facts which are used to dynamically update the previous user model. User intentions are inferred from this new model and are the basis of the interaction between the system and the legal texts knowledge base. As legal texts knowledge base we are using the documents from the Portuguese Attorney General (Procuradoria Geral da Republica). In this paper we will show some examples of the obtained collaborative behaviour.;Yes;No, having two logics, deontic and dynamic and shortening both to DL is not at all confusing;;Yes, bit short though;;No;No;Yes;No;Logic Programming (prepositional horn clauses);No;No;Manual;Not optimized;No;No;Retrieval;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/wi-iat.2014.64;https://doi.org/10.1109/wi-iat.2014.64;Learning of Legal Ontology Supporting the User Queries Satisfaction;2014;"Imen Bouaziz Mezghanni; Imen Bouaziz Mezghanni; Faı̈ez Gargouri; Faiez Gargouri; Faiez Gargouri";In recent years, the development of legal ontologies has increased significantly with the diversity of their applications known as complicated due to the complexity of their domain. In the preliminary part of this paper, we introduce the major steps in the learning process, then we present some works interested in Arabic ontology learning. The rest of the paper serves to propose our approach for ontology learning from Tunisian Legal Texts designed for legal information retrieval. The search process that we suggest exploits the user's profile and uses a query reformulation mechanism based on the learned ontology. The purpose of the system is to satisfy a user's specific retrieval requirement by finding the best response to his request.;Yes;;;Yes;information retrieval, but not just document ;No;No;Yes;No;Unspecified;No;No, just internal;tool supported;Not optimized;No;No;Retrieval;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2746090.2746096;https://doi.org/10.1145/2746090.2746096;Introducing LUIMA: an experiment in legal conceptual retrieval of vaccine injury decisions using a UIMA type system and tools;2015;"Matthias Grabmair; Matthias Grabmair; Kevin D. Ashley; Kevin D. Ashley; Ran Chen; Ran Chen; Preethi Sureshkumar; Preethi Sureshkumar; Chen Wang; Chen Wang; Eric Nyberg; Eric Nyberg; Vern R. Walker; Vern R. Walker";This paper presents first results from a proof of feasibility experiment in conceptual legal document retrieval in a particular domain (involving vaccine injury compensation). The conceptual markup of documents is done automatically using LUIMA, a law-specific semantic extraction toolbox based on the UIMA framework. The system consists of modules for automatic sub-sentence level annotation, machine learning based sentence annotation, basic retrieval using Apache Lucene and a machine learning based reranking of retrieved documents. In a leave-one-out experiment on a limited corpus, the resulting rankings scored higher for most tested queries than baseline rankings created using a commercial full-text legal information system.;Yes;eh, do not love this, just retrieval, but technically have to include;;No;Retrieval focused, though law is the domain, I see little law specific representation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1146598.1146662;https://doi.org/10.1145/1146598.1146662;Locating related regulations using a comparative analysis approach;2006;"Gloria T. Lau; Gloria T. Lau; Haoyi Wang; Haoyi Wang; Kincho H. Law; Kincho H. Law";The sheer volume and complexity of government regulations make any attempt to locate, understand and interpret the information a daunting task. Other factors, such as the scattered distribution of the regulations across many sources, different terminologies and cross referencing, further complicate the technical issues in developing a regulation information management system. This paper describes a comparative analysis approach and its potential application to assist locating relevant regulations from different sources. Examples from environmental regulations are employed to illustrate the proposed methodology and framework.;Yes;retrieval;;No;document retrieval;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1557914.1557944;https://doi.org/10.1145/1557914.1557944;Extracting semantic annotations from legal texts;2009;"Leonardo Lesmo; Leonardo Lesmo; Alessandro Mazzei; Alessandro Mazzei; Daniele Paolo Radicioni; Daniele P. Radicioni";This paper illustrates a system designed to automatically extract semantic annotations of the normative modifications present in legal texts. The work relies on a deep parsing approach. The problem of semantically annotating legal texts is cast to the problem of mapping parse trees to semantic frames representing such modifications. We report a preliminary experimentation along with the dataset employed, and discuss the results to point out future improvements.;Yes;"bit boring if you ask me, ""just"" markup and semantic tagging";;Yes;Duplicate? Seems very familiar?;No;No;Yes;No;Semantic Markup;"No, they talk about ""text consolidation"" in the introduction, but do not really seem to do anything with it";No;Automatic;Yes, marked up natural text;Yes;No;Retrieval;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/41735.41749;https://doi.org/10.1145/41735.41749;A connectionist approach to conceptual information retrieval;1987;"Richard K. Belew; Richard K. Belew";This report proposes that recent advances using low-level connectionist representations offer new possibilities to those interested in free text information retrieval (IR). The AIR system demonstrates that this representation suits the IR domain well, particularly the special problems attending the more sophisticated forms of conceptual retrieval required in legal applications. Also, the natural way in which connectionist representations allow  learning  means that AIR can avoid the high costs associated with manual indexing while providing comparable results. The paper begins by motivating the importance of legal information retrieval, from the perspectives of both the Law and artificial intelligence (AI). Our approach is then compared to traditional methods for IR, and to more recent work using higher-level  symbolic  representations from AL After a brief introduction to connectionist representations in general, the AIR system is presented. The paper closes with evidence that this system does, in fact, begin to support the use of those “open textured” concepts that make the Law both a very difficult and a very illuminating domain for AI research.;Yes;retrieval;;No;"""For us, working on the problem of LIB, this lack means that logicbased KRLs are unable to represent open texture concepts"". Btw, how come you start using AIR and then only explain what it means in a single footnote on pate 5??? Will not include as this is document retrieval";No;No;Yes;No;"Non-logical; Connectionist approach";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-012-9119-6;https://doi.org/10.1007/s10506-012-9119-6;A legal case OWL ontology with an instantiation of Popov v. Hayashi;2012;"Adam Wyner; Adam Wyner; Rinke Hoekstra; Rinke Hoekstra";The paper provides an OWL ontology for legal cases with an instantiation of the legal case Popov v. Hayashi. The ontology makes explicit the conceptual knowledge of the legal case domain, supports reasoning about the domain, and can be used to annotate the text of cases, which in turn can be used to populate the ontology. A populated ontology is a case base which can be used for information retrieval, information extraction, and case based reasoning. The ontology contains not only elements for indexing the case (e.g. the parties, jurisdiction, and date), but as well elements used to reason to a decision such as argument schemes and the components input to the schemes. We use the Protege ontology editor and knowledge acquisition system, current guidelines for ontology development, and tools for visual and linguistic presentation of the ontology.;Yes;;;Yes;;No;Yes;No;Yes;OWL 2;No;No (Yes to ACE, but not really a semantic translation);Manual;Not optimized;Yes (authors);No;Modelling;Property law (ownership);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2514601.2514610;https://doi.org/10.1145/2514601.2514610;Using event progression to enhance purposive argumentation in the value judgment formalism;2013;"Matthias Grabmair; Matthias Grabmair; Kevin D. Ashley; Kevin D. Ashley";This paper expands on the previously published value judgment formalism. The representation of situations is enhanced by introducing event progressions similar to actions in general AI planning. Using event progressions, situations can be assessed as to what facts they contain as well as what facts may ensue with some likelihood, thereby opening up a situation space. Purposive legal argumentation can be modeled using propositions and rules controlling the likelihoods of value-laden consequences. The paper expands the formalism to cover event progressions and illustrates the functionality using an example based on Young v. Hitchens.;Yes;Argument for parametric (common sense) vs normative knowledge;;Yes?;;Yes;Yes;No;No;Formal, argumentation graphs, temporal aspects, formally defined inference;Yes;No;Manual;Not optimized;Yes (authors);No;Modelling;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/222092.222098;https://doi.org/10.1145/222092.222098;Teleological reasoning in reason-based logic;1995;"Jaap Hage; Jaap Hage";;Yes;;;Yes;;No;No;Yes;No;Defeasible First Order Predicate Logic;Yes, rule replacment;No;Manual;Not optimized;Yes (aithors, I think metajuridica is law);No;Reasoning;General (small property law example;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/112646.112661;https://doi.org/10.1145/112646.112661;Indian central civil service pension rules: a case study in logic programming applied to regulations;1991;"Marek Sergot; Marek Sergot; Anand Kamble; A. S. Kamble; K. K. Bajaj; K. K. Bajaj";Logic programming has been applied to a variety of examples in law and rules and regulations of different kinds. The best known examples are the representations of the British Nationality Act 1981 [Sergot et al. 1986] and United Kingdom social security legislation [Bench-Capon et al. 1987] constructed at Imperial College, London. The paper [Sergot 1988] and the survey [Sergot 1990] contain references to other applications. Essentially, these applications construct a legal analysis program by representing some fragment of legislation in logic and then executing the representatio~ either as a stand-alone program or as a compment of some bigger system.;Yes;Yay, more prolog;;Yes;;No;No;Yes;No;Prolog (no further specification);No;No;Manual;Not optimized;No;No;Reasoning;Pension;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/ictai.2010.95;https://doi.org/10.1109/ictai.2010.95;An Environment for the Joint Management of Written Policies and Business Rules;2010;"François Lévy; François Lévy; Abdooulaye Guissé; Abdoulaye Guissé; Adeline Nazarenko; Adeline Nazarenko; Nouha Omrane; Nouha Omrane; Sylvie Szulman; Sylvie Szulman";The contemporary world produces huge bodies of policies and regulations, while the underlying procedures tend to be automated in decision systems, which are designed to define, deploy, execute, monitor and maintain the various rules to which an organization or enterprise has to comply. It is important that the written documentation is integrated into such decision systems in order to refer to the texts to explain decisions, to update the systems when the policy evolves or, conversely, to amend the source documents if some of the rules happen to be inconsistent. The problem is that the complexity of information to be searched for is not reachable by an automated processing, but that their volume prohibits a manual one. Arguing that the integration of policies in decision systems can be better achieved through a semantic annotation than by the full parsing of the source documentation, this paper presents a technical environment that enables the building and exploitation of such semantic annotations.;Yes;bit boring, mostly retrieval, some anotations;;No;indexing / retrieval;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/112646.112648;https://doi.org/10.1145/112646.112648;Incorporating procedural context into a model of case-based legal reasoning;1991;"Donald H. Berman; Donald H. Berman; Carole D. Hafner; Carole D. Hafner";In this paper we analyze the procedural considerations that affect the use of legal casesas precedents and propose a model of procedural knowledge that can be combined with substantive legal reasoning models to produce a more robust theory of case-based legal reasoning in common law jurisdictions. Our model addresses one component of procedural knowledge the distinction between questions of fact and questions of law. We categorize 32 different procedural scenarios into 10 basic types of legal results. We then propose rules for determining the precedential value of these result types. Finally we suggest a method for incorporating procedural distinctions into case-based reasoning systems.;Yes;Not sure, technically general case based reasoning but heavy focus on litigation;;No;I see no added value here as the procedural representation is technically LIR, but with such a heavy focus on the actual happenings of the court that it tends to be EX8;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1080/13600834.1994.9965701;https://www.ai.rug.nl/~verheij/publications/pdf/lcai94.pdf;Reason-Based Logic: a Logic for Reasoning with Rules and Reasons;1994;"Jaap Hage; Jaap Hage; Bart Verheij; Bart Verheij";Abstract The main claim of this paper is that reasoning with rules, especially rules of law, is different from reasoning with statements that are true or false. This difference is, amongst others, reflected in the defeasibility of arguments in which rules play a role. Reason‐based logic is a logic that has special facilities for dealing with rules and with reasons based on rules. In particular it allows arguments in which conclusions are derived by ‘weighing’ the reasons that plead for and against them. In this article we illustrate some characteristics of reasoning with rules, and show how reason‐based logic deals with these characteristics. The article is concluded with some general considerations concerning reason‐based logic and a comparison with some other logics for defeasible reasoning.;Yes;;;Yes;;No;No;Yes;No;Defeasible First Order Predicate Logic;No (note different RBL paper allows rule replacment);No;Manual;Not optimized;Yes (aithors, I think metajuridica is law);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/158976.158977;https://doi.org/10.1145/158976.158977;A logical framework for modelling legal argument;1993;"Henry Prakken; Henry Prakken";"This paper investigates the relevance of the logical study of argumentation systems for AI-and-law research, in particular for modelling the adversarial aspect of legal reasoning. It does so in applying the argumentation framework of Prakken (1993a/b) to the legal domain. Three elements of the framework are particularly illustrated: firstly, its generality, in that it leaves room for any standard for comparing pairs of arguments; secondly, its ability to model the combined use of these standards; and finally, its relevance for modelling metalevel reasoning. These three features make the framework suitable as a logical framework for any theory of legal argument.";Yes;AF for legal?;;Yes;;Yes;Yes;Yes;No;Defeasible First Order Logic;No (just the usual temporal constraint things);No;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/261618.261621;https://doi.org/10.1145/261618.261621;Reasoning with precedents in a dialogue game;1997;"Henry Prakken; Henry Prakken; Giovanni Sartor; Giovanni Sartor";;Yes;;;No;Subjective problems of adding dialogue game approaches to SLR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2018358.2018372;https://doi.org/10.1145/2018358.2018372;Analogy, similarity and factors;2011;"Michał Araszkiewicz; Michał Araszkiewicz";Analogy has been considered in AI and law primarily in relation to reasoning from precedent cases rather than reasoning from statutes. Where a statutory provision does not apply to a case, the principle of e contrario, that if the case is not covered by the rule the negation of the conclusion can be taken as established, has typically been assumed to apply. There are, however, cases where analogy is an appropriate way to bring a case under a statutory rule. In this paper we discuss using analogy in reasoning with states, and where this should be avoided and e contrario followed. Our account will be based on the notion of factors as developed in AI and law case based reasoning.;Yes;idk, technically yes I guess;;Yes;;Yes;Yes;No;No;"Semi-Formal, Defeasible logic; factor representation of cases (sketch)";No;No;Manual;Not optimized;Yes (author, dep of legal theory);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1165485.1165509;https://doi.org/10.1145/1165485.1165509;Updating ontologies in the legal domain;2005;"Guiraude Lame; Guiraude Lame; Sylvie Desprès; Sylvie Després; Sylvie Desprès";This paper describes experimental research investigating automated techniques for creating legal ontologies from legislation and for merging existing ontologies with new ones when new laws are adopted. The first part of the paper describes how the ontologies are built, the second part how they are merged for updating the first one.Given a legal ontology, elaborated using certain methods and tools and dedicated to information retrieval, we explore the way to update it. We present important elements concerning the initial ontology: purposes, methods and tools. We describe the experimentation of the updating of a legal ontology.;Yes;Bit meta, but kind of relevant to RQs;;Yes;Bit too process focused tbh, but will keep as it is RQ relevant;No;No;Yes;Yes;Unspecified, XML;Yes;No;Semi-automated;Not optimized;Yes;No;Updating Ontologies;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2018358.2018383;https://doi.org/10.1145/2018358.2018383;An agent-based legal knowledge acquisition methodology for agile public administration;2011;"Alexander Boer; Alexander Boer; Tom van Engers; Tom M. van Engers";This paper proposes a knowledge elicitation method based on serious gaming for theory construction about the effects of the law on the behaviours of agents. These games provide input to simulations of business process and product design alternatives. For knowledge representation, we have combined agent role descriptions with a generic task framework. An important thesis of this paper is that, in the interest of quick and simple domain analysis, agent roles, not intelligent agents, should be the focal object of simulation of complex social organizations. At least if getting a grip on social complexity is the purpose of modeling.;Yes;;;No;Not really LIR. A case against RAG, but relevant to the main paper.;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/2611040.2611048;https://doi.org/10.1145/2611040.2611048;A Methodology based on Commonsense Knowledge and Ontologies for the Automatic Classification of Legal Cases;2014;"Nicola Capuano; Nicola Capuano; Carmen De Maio; Carmen De Maio; Saverio Salerno; Saverio Salerno; Daniele Toti; Daniele Toti";"We describe a methodology for the automatic classification of legal cases expressed in natural language, which relies on existing legal ontologies and a commonsense knowledge base. This methodology is founded on a process consisting of three phases: an enrichment of a given legal ontology by associating its terms with topics retrieved from the Wikipedia knowledge base; an extraction of relevant concepts from a given textual legal case; and a matching between the enriched ontological terms and the extracted concepts. Such a process has been successfully implemented in a corresponding tool that is part of a larger framework for self-litigation and legal support for the Italian law.";Yes;;;No;Not really compliance related;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/222092.222205;https://doi.org/10.1145/222092.222205;Information filtering: the computation of similarities in large corpora of legal texts;1995;"Erich Schweighofer; Erich Schweighofer; Werner Winiwarter; Werner Winiwarter; Dieter Merkl; Dieter Merkl";TraditiottaJ information retrieval systems do not satis& the lawyers’ demands because they provide only syntactic representation of legal data, The bottleneck for the creation of the more promising conceptual information retrieval systems is the time-consuming knowledge acquisition. The best solution is the representation of legal knowledge by simple linguistic tools, statistics and neural networks. In our prototype KONTERM we represent legal knowledge about concepts and documents by a knowledge base which is structured by statistical and connectionist methods. In fitture, this knowledge base will be used to filter legal knowledge from documents.;Yes;bit dated;;No;document retrieval;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/222092.222243;https://doi.org/10.1145/222092.222243;Obligations directed from bearers to counterparts;1995;"Henning Herrestad; Henning Herrestad; Christen Krogh; Christen Krogh";This articles provides a logical analysis of the concepts of directed obligation, prohibition and permission. These concepts are used to express normative relations between a bearer and a counterpart. They play a predominant role in Hohfeld’s analysis of rights. On our analysis, a directed obligation is defined as a conj unction of a statement expressing that a bearer ought to do a certain act and a statement expressing that it ought to be the case for the counterpart that the bearer does this act. A similar definition is offered of directed prohibition and permission. The proposed analysis is discussed in view of two competing theories of rights: the benefit theory and the claimant theory. The present proposal is found to be supported by the benefit theory. 1 The problem of how to represent directed obligations This paper contributes to the formal analysis of the concept of rights in the tradition from Hohfeld, Kanger and Lindahl. In a number of papers Allen and Saxon have defended the value of a formal representation of rights when making programs to aid the process of drafting or interpreting law (cf. [AS86], [AS93a], [AS93b]). (Concerning the relevance to automated tools for legal drafting, see also [H G93].) This supports the relevance of our paper to AI and Law. Furthermore, Jones and Sergot argues that certain complex systems are best analysed from a ‘normative perspective’, and suggests Lindahl’s analysis as a useful tool (cf. [JS93] ). In [Kro95] it is argued that a representation of normative relations discussed here may be useful to the design of multi–agent systems, as these systems have reached a level where full regimentation i= impossible and reliance will be based on the ability to make contracts between agents. This suggests the relevance of the present paper to mainstream AI as well. Permission to copy without fee all or part of this material is granted provided that the copies we not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee andlor specific permission.;Yes;;;No;a bit too focused on a specific problem not as much focused on law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/bf00118492;https://doi.org/10.1007/bf00118492;A model of argumentation and its application to legal reasoning;1996;"Kathleen P. Freeman; Kathleen Freeman; Kathleen Freeman; Arthur M. Farley; Arthur M. Farley";We present a computational model of dialectical argumentation that could serve as a basis for legal reasoning. The legal domain is an instance of a domain in which knowledge is incomplete, uncertain, and inconsistent. Argumentation is well suited for reasoning in such weak theory domains. We model argument both as information structure, i.e., argument units connecting claims with supporting data, and as dialectical process, i.e., an alternating series of moves by opposing sides. Our model includes burden of proof as a key element, indicating what level of support must be achieved by one side to win the argument. Burden of proof acts as move filter, turntaking mechanism, and termination criterion, eventually determining the winner of an argument. Our model has been implemented in a computer program. We demonstrate the model by considering program output for two examples previously discussed in the artificial intelligence and legal reasoning literature.;Yes;;;No;Dialectics skew to far in the direction of litigation for my taste;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1568234.1568263;https://doi.org/10.1145/1568234.1568263;Supporting of legal reasoning for cases which are not strictly regulated by law;2009;"Tomasz Żurek; Tomasz Zurek; Emil Kruk; Emil Kruk";Statute law legislators are usually not in a position to foresee each and every situation or event which may actually occur in real life. That is why lawyers in the course of their everyday practice very often struggle with interpreting the cases which are not expressly regulated in the law. The legal theory and practice has given rise to a wide array of methods to deal with this type of problems. The solutions described in this article have been implemented in the advisory system developed by the authors whose main goal is to provide automatic legal advice on the Agricultural Tax;Yes;"JBOSS; idk, but I do not see much novel research here. Good job, but not really applicable for my SLR?";;No;Interesting, but too narrow in scope to be relevant to the SLR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1061/(asce)0887-3801(2005)19:1(1);http://eil.stanford.edu/publications/shawn_kerrigan/CP-22476_Manuscript.pdf;Regulation-centric, logic-based compliance assistance framework;2005;"Shawn Kerrigan; Shawn Kerrigan; Kincho H. Law; Kincho H. Law";This paper describes the development of a logic based regulation compliance assistance system that builds upon an extensible markup language (XML) framework. First, a document repository containing federal regulations and supplemental documents, and an XML framework for representing regulations and associated metadata are briefly discussed. The prototype effort for the regulation assistance system focuses on federal environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management. The overall objective is to develop a formal infrastructure for regulatory information management and compliance assistance.;Yes;Regnet again;;Yes?;Too much regnet;No;No;Yes;No;first order logic;No (mentioned but not elaborated);No;tool supported;Optimized (UI, Natural Language);Yes;No;Compliance;Environment;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/j.eswa.2015.02.029;https://doi.org/10.1016/j.eswa.2015.02.029;A rule-based semantic approach for automated regulatory compliance in the construction sector;2015;"Thomas Beach; Thomas Beach; Yacine Rezgui; Yacine Rezgui; Haijiang Li; Haijiang Li; Tala Kasim; Tala Kasim";A rule-based semantic approach for compliance checking.An ontological framework for regulatory compliance checking.Extracting regulations from semantic analysis of textual documents.Semantic rules to deliver regulatory compliance checking based on instances of the proposed ontology.Semantic mapping of regulations to data file formats. A key concern for professionals in any industry is ensuring regulatory compliance. Regulations are often complex and require in depth technical knowledge of the domain in which they operate. The level of technical detail and complexity in regulations is a barrier to their automation due to extensive software development time and costs that are involved. In this paper we present a rule-based semantic approach formulated as a methodology to overcome these issues by allowing domain experts to specify their own regulatory compliance systems without the need for extensive software development. Our methodology is based on the key idea that three semantic contexts are needed to fully understand the regulations being automated: the semantics of the target domain, the specific semantics of regulations being considered, and the semantics of the data format that is to be checked for compliance. This approach allows domain experts to create and maintain their own regulatory compliance systems, within a semantic domain that is familiar to them. At the same time, our approach allows for the often diverse nature of semantics within a particular domain by decoupling the specific semantics of regulations from the semantics of the domain itself. This paper demonstrates how our methodology has been validated using a series of regulations automated by professionals within the construction domain. The regulations that have been developed are then in turn validated on real building data stored in an industry specific format (the IFCs). The adoption of this methodology has greatly advanced the process of automating these complex sets of construction regulations, allowing the full automation of the regulation scheme within 18months. We believe that these positive results show that, by adopting our methodology, the barriers to the building of regulatory compliance systems will be greatly lowered and the adoption of three semantic domains proposed by our methodology provides tangible benefits.;Yes;;;Yes;;No;No;Yes;Yes;Semantic Web Rule Language;Yes (updates via UI);No;Semi-automatic;Optmized UI;Yes (discussion);No;Compliance;Construction;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1023/a:1008359312576;https://doi.org/10.1023/a:1008359312576;Diagnosis and decision making in normative reasoning;1999;"Leendert van der Torre; Leendert W. Torre; Yao‐Hua Tan; Yao-Hua Tan";Diagnosis theory reasons about incomplete knowledge and only considers the past. It distinguishes between violations and non-violations. Qualitative decision theory reasons about decision variables and considers the future. It distinguishes between fulfilled goals and unfulfilled goals. In this paper we formalize normative diagnoses and decisions in the special purpose formalism DIO(DE)2 as well as in extensions of the preference-based deontic logic PDL. The DIagnostic and DEcision-theoretic framework for DEontic reasoning DIO(DE)2 formalizes reasoning about violations and fulfillments, and is used to characterize the distinction between normative diagnosis theory and (qualitative) decision theory. The extension of the preference-based deontic logic PDL shows how normative diagnostic and decision-theoretic reasoning -- i.e. reasoning about violations and fulfillments -- can be formalized as an extension of deontic reasoning.;Yes;;;Yes;Diagnosis vs decision theory as an interesting point;No;No;Yes;No;Deontic logic (DIO(DE)^2 or as PDL;No;Yes to Prohairetic Deontic Logic (PDL);Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1165485.1165490;https://doi.org/10.1145/1165485.1165490;Temporalised normative positions in defeasible logic;2005;"Guido Governatori; Guido Governatori; Antonino Rotolo; Antonino Rotolo; Giovanni Sartor; Giovanni Sartor";We propose a computationally oriented non-monotonic multi-modal logic arising from the combination of temporalised agency and temporalised normative positions. We argue about the defeasible nature of these notions and then we show how to represent and reason with them in the setting of Defeasible Logic.;Yes;;;Yes;;No;No;Yes;No;defeasible logic with temporal aspects;No;No;Manual;Not optimized;Yes (author);No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/222092.222265;https://doi.org/10.1145/222092.222265;ON-LINE: an architecture for modelling legal information;1995;"André Valente; Andre Valente; Joost Breuker; Joost Breuker";"This paper describes ON-LINE (ONtology-based Legal Information Environment), an architecture for a legal workbench which combines two major functions: legal information serving and legal analysis. Some of the main features of ON-LINE are: the integrated storage and representation of legal text and knowledge by using interconnected knowledge aud text repositories; a representation of legal knowledge based on a functional ontology of law; the emphssis on legal modelling as a central task in legal practice. ON-LINE comprises three main modules. The Legal Information Server is able to retrieve legal information baaed on either textnal or conceptual search. The Legal Information ModelZing Toolkit is a collection of integrated tools to transform legaJ text into legal knowledge. The Legal Analysis Environment contains reasoning tools to perform two of the central legal tasks: assessment and planning. The architecture is intended to be a basis for experimentation, and it is therefore highly extensible. ONLINE is partially implemented in Common Lisp and it is supported by the LOOM system.";Yes;;;Yes;;No;No;Yes;No;deontic functions (LISP);No;Yes, surface level description of external interchange format;Manual;Not optimized;No;No;Reasoning;Software Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/cisis.2008.146;https://doi.org/10.1109/cisis.2008.146;Building RDF Ontologies from Semi-Structured Legal Documents;2008;"Flora Amato; Flora Amato; Antonino Mazzeo; Antonino Mazzeo; Antonio Penta; Antonio Penta; Antonio Picariello; Antonio Picariello; A. Picariello";The increasing interest in the context of e-government requires intelligent techniques for legal information and knowledge management. In this paper we describe a system that, given a number of legal paper documents, automatically transforms them into suitable RDF statements, using several ontological and linguistic knowledge levels. Although we describe a general methodology for a number of application domains, our system is particularly suitable for the notary realm.;Yes;;;Yes;;No;No;Yes;Yes;RDF;;No;Automatic;Not optimized;Yes (evaluation);No;Ontology Creation;Notary;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1111/j.1467-9337.1994.tb00175.x;https://doi.org/10.1111/j.1467-9337.1994.tb00175.x;A Formal Model of Legal Argumentation;1994;"Giovanni Sartor; Giovanni Sartor";. The paper gives a formal reconstruction of some fundamental patterns of legal reasoning, intended to reconcile symbolic logic and argumentation theory. Legal norms are represented as unidirectional inference rules which can be combined into arguments. The value of each argument (its qualification as justified, defensible, or defeated) is determined by the importance of the rules it contains. Applicability arguments, intended to contest or support the applicability of norms, preference arguments, purporting to establish preference relations among norms, and interpretative arguments are also formalised. All those argument types are connected in a unitary model, which relates legal reasoning to the indeterminacy of legal systems, intended as the possibility to develop incompatible defensible arguments. The model is applied to permissive norms and normative hierarchies, and is implemented in a Prolog program.;Yes;more prolog, argumentation here is less of the classical arugmentation, but rather just reasoning;;Yes;Add non-monotonicity to list of terms;No;No;Yes;No;unidirectional inference rules;No;No (just to Prolog);Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1093/logcom/exp009;https://www.csc.liv.ac.uk/~tbc/publications/finalWynerBench-CaponJudicialContexts.pdf;Modelling Judicial Context in Argumentation Frameworks;2009;"Adam Wyner; Adam Wyner; Trevor Bench‐Capon; Trevor J. M. Bench-Capon";Much work using argumnentation frameworks treats arguments as entirely abstract, related by a uniform attack relation which always succeeds unless the attacker can itself be defeated. However, this does not seem adequate for legal argumentation. Some proposals have suggested regulating attack relations using preferences or values on arguments and which filter the attack relation, so that some attacks fail and so can be removed from the framework. This does not capture several important context related features of legal reasoning, such as how an audience can prefer or value an argument, yet be constrained by precedent or authority not to accept it. Nor does it explain how certain types of attack may not be allowed in a particular procedural context. For this reason, evaluation of the status of arguments within a given framework must be allowed to depend not only on the attack relations along with the preference or value of arguments, but also on the nature of the attacks and the context in which they are made. We present a means to represent these features, enabling us to account for a number of factors currently considered to be beyond the remit of formal argumentation frameworks. We give three examples of the use of approach: appealing a case, overruling a precedent, and rehearing of a case as a civil rather than criminal proceeding.;Yes;Cool estension on general AF;;Yes;;Yes;Yes;No;No;Formal, Argumentation Framework;No;No;Manual;Not optimized;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/s0004-3702(03)00107-3;https://doi.org/10.1016/s0004-3702(03)00107-3;Artificial argument assistants for defeasible argumentation;2003;"Bart Verheij; Bart Verheij";;Yes;;;Yes;;Yes;Yes;No;No;defesible logic, DEFLOG;No;No;Manual;Not optimized;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://scholar.google.com/scholar?q=Using%20NLP%20techniques%20to%20identify%20legal%20ontology%20components:%20concepts%20and%20relations;Using NLP techniques to identify legal ontology components: concepts and relations;2005;"Guiraude Lame; Guiraude Lame";A method to identify ontology components is presented in this article. The method relies on Natural Language Processing (NLP) techniques to extract concepts and relations among these concepts. This method is applied in the legal field to build an ontology dedicated to information retrieval. Legal texts on which the method is performed are carefully chosen as describing and conceptualizing the legal domain. We suggest that this method can help legal ontology designers and may be used while building ontologies dedicated to other tasks than information retrieval;Yes;I guess, but more focus on the process, not the representation;;Yes;;No;No;Yes;Yes;semi-formal, ontology;No;No;Semi automatic;Minimal, UI;No;No;Ontology construction;General (French Codes);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1143120.1143123;https://doi.org/10.1145/1143120.1143123;An empirical study of natural language parsing of privacy policy rules using the SPARCLE policy workbench;2006;"Carolyn Brodie; Carolyn Brodie; Clare-Marie﻿ Karat; Clare-Marie Karat; John Karat; John Karat";Today organizations do not have good ways of linking their written privacy policies with the implementation of those policies. To assist organizations in addressing this issue, our human-centered research has focused on understanding organizational privacy management needs, and, based on those needs, creating a usable and effective policy workbench called SPARCLE. SPARCLE will enable organizational users to enter policies in natural language, parse the policies to identify policy elements and then generate a machine readable (XML) version of the policy. In the future, SPARCLE will then enable mapping of policies to the organization's configuration and provide audit and compliance tools to ensure that the policy implementation operates as intended. In this paper, we present the strategies employed in the design and implementation of the natural language parsing capabilities that are part of the functional version of the SPARCLE authoring utility. We have created a set of grammars which execute on a shallow parser that are designed to identify the rule elements in privacy policy rules. We present empirical usability evaluation data from target organizational users of the SPARCLE system and highlight the parsing accuracy of the system with the organizations' privacy policies. The successful implementation of the parsing capabilities is an important step towards our goal of providing a usable and effective method for organizations to link the natural language version of privacy policies to their implementation, and subsequent verification through compliance auditing of the enforcement logs.;Yes;Not really legal policies, but pllicies nonetheless;;No;Ok, but focus on privacy policies and parsing techniques, less on actual LIR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://scholar.google.com/scholar?q=Using%20values%20and%20theories%20to%20resolve%20disagreement%20in%20law%201;Using values and theories to resolve disagreement in law 1;2000;"Trevor Bench‐Capon; Trevor J. M. Bench-Capon; Giovanni Sartor; Giovanni Sartor";In this paper we describe a novel approach to reasoning with cases and precedents. The approach is intended to address two main problems. First we find that current case based reasoning systems tend to offer relatively little support in determining the outcome of a case. They either present a list of cases which may inform, but cannot determine, the outcome, or else, as in HYPO and its successors ((1), (2), (3)), present arguments for both sides of a question leaving it the user to decide which is the more persuasive. What is lacking from these accounts is a notion of what it is that makes an argument persuasive. This is addressed in the context of AI and Law by Berman and Hafner in (4), and in law generally by Perelman (e.g. (5)). For Berman and Hafner an argument is made persuasive by supporting the purposes that the law is designed for, and for Perelman it is by advancing or protecting values that its audience subscribes to (on teleological argument, see also (6)). We believe these things to be effectively the same: the purpose of a law is typically to advance or promote some desired value, and the audience is the community subject to the law. Thus our first goal is to provide a model of case based reasoning in which we can use purposes and values to explain disagreements and their resolution. The second problem is the lack of the notion of context in many of the existing case based reasoning systems. A given case is decided in the context both of relevant past cases, which can supply precedents which will inform the decision, and in the context of future cases to which it will be relevant and possibly act as a precedent. A case is thus supposed to cohere with both past decisions and future decisions. This context is largely lost if we state the question as being whether one bundle of factors is more similar to the factors of a current case than another bundle, as in HYPO, or whether one rule is preferred to another, as in logical reconstructions of such systems, for example that of (7)). Recognition of context is vital if we are to understand accounts of legal reasoning (e.g. (8)) in which it is 1 This paper represents current on-going work investigating argument in case law. The ideas represent a;Yes;;;Yes;;Yes;Yes;No;No;Formal, factors;No;No;Manual;Not optimized;Yes (author);No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1165485.1165505;https://doi.org/10.1145/1165485.1165505;Constructing a semantic network for legal content;2005;"Radboud Winkels; Radboud Winkels; Alexander Boer; Alexander Boer; Emile de Maat; Emile de Maat; Tom van Engers; Tom M. van Engers; Matthijs Breebaart; Matthijs Breebaart; Henri Melger; Henri Melger";The Dutch Tax and Customs Administration (DTCA) is one of many organizations that deal with a multitude of electronic legal data, from various sources and in different formats. In this paper, we describe the results of a study aimed at better access to these sources by having a supplier and format independent knowledge store that describes the sources and their interrelations in a semantic network. Furthermore we developed parsers to automatically detect the identity of sources and typed references within the sources to other legal documents. These parsers can be used to fill and update the semantic network as new documents are added.;Yes;;;Yes;More of a proposal tbh, KB never built;No;No;Yes;Yes;OWL/RDF;Yes (automatic, very cool);No;Automatic (with manual fixes);Not optimized;Yes (authors);No;Knowledge Extraction;Tax;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.3233/978-1-61499-468-8-11;https://scholar.uwindsor.ca/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1032&context=crrarpub;Argumentation Schemes for Statutory Interpretation: A Logical Analysis;2014;"Giovanni Sartor; Giovanni Sartor; Douglas Walton; Douglas Walton; Fabrizio Macagno; Fabrizio Macagno; Antonino Rotolo; Antonino Rotolo";;Yes;Seems very similar to all the other papers proposing DF, have to read for understanding the USP;;No;Too meta, no actual formalism choosen;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://cgi.csc.liv.ac.uk/~katie/jurix14a.pdf;Abstract Dialectical Frameworks for Legal Reasoning.;2014;"Latifa Al-Abdulkarim; Latifa Al-Abdulkarim; Katie Atkinson; Katie Atkinson; Trevor Bench‐Capon; Trevor J. M. Bench-Capon";Dialectical Frameworks for Legal Reasoning Latifa AL-ABDULKARIM, Katie ATKINSON, Trevor BENCH-CAPON Department of Computer Science, The University of Liverpool, UK Abstract. In recent years a powerful generalisation of Dung’s abstract argumentation frameworks, Abstract Dialectical Frameworks (ADF), has been developed. ADFs generalise the abstract argumentation frameworks introduced by Dung by replacing Dung’s single acceptance condition (that all attackers be defeated) with acceptance conditions local to each particular node. Such local acceptance conditions allow structured argumentation to be straightforwardly incorporated. Related to ADFs are prioritised ADFs, which allow for reasons pro and con a node. In this paper we show how these structures provide an excellent framework for representing a leading approach to reasoning with legal cases. In recent years a powerful generalisation of Dung’s abstract argumentation frameworks, Abstract Dialectical Frameworks (ADF), has been developed. ADFs generalise the abstract argumentation frameworks introduced by Dung by replacing Dung’s single acceptance condition (that all attackers be defeated) with acceptance conditions local to each particular node. Such local acceptance conditions allow structured argumentation to be straightforwardly incorporated. Related to ADFs are prioritised ADFs, which allow for reasons pro and con a node. In this paper we show how these structures provide an excellent framework for representing a leading approach to reasoning with legal cases.;Yes;more angelic;;Yes;;Yes;Yes;No;Mo;ADFs with Horn clause implementation;No;No;Manual;Not optimized;No;No;Argumentation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://repository.lib.ncsu.edu/server/api/core/bitstreams/2f5b5248-ef8b-4cb2-a843-c973745ee185/content;Managing ambiguity and traceability in regulatory requirements: A tool-supported frame-based approach;2007;"Travis D. Breaux; Travis D. Breaux; Annie I. Antón; Ana I. Anton";;Yes;https://repository.lib.ncsu.edu/server/api/core/bitstreams/2f5b5248-ef8b-4cb2-a843-c973745ee185/content;;Yes;;No;No;Yes;No;Semi-Formal: Deontic Logic Frames, but not really symbolised for logic;No;No;tool supported (main markup is manual);Not optimized;No;No;Tracability;Privacy (In medicine);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=3e171f21ddb2f0ffb4bfcfb98b12bf4aba69ae11;An algorithm to generate compliance monitors from regulations;2006;"Travis D. Breaux; Travis D. Breaux; Annie I. Antón; Ana I. Anton";"Developing software systems in heavily regulated industries requires methods to ensure systems comply with regulations and law. An algorithm to generate finite state machines (FSM) from stakeholder rights and obligations for compliance monitoring is proposed. Rights and obligations define what people are permitted or required to do; these rights and obligations affect software requirements and design. The FSM allows stakeholders, software developers and compliance officers to trace events through the invocation of rights and obligations as preand postconditions. Compliance is monitored by instrumenting runtime systems to report these events and detect violations. Requirements and software engineers specify the rights and obligations, and our algorithm performs three supporting tasks: 1) identify ambiguities, 2) balance rights with obligations, and 3) generate finite state machines. Preliminary validation of the algorithm includes FSMs generated from U.S. healthcare regulations and tool support to parse these specifications and generate the FSMs.";Yes;https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=3e171f21ddb2f0ffb4bfcfb98b12bf4aba69ae11;;Yes;;No;No;Yes;No;Finite Statemachine;No;Yes, from formal semantic model;Semi-automated;Not optimized;No;No;Compliance;Privacy (In medicine);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/978-3-319-49004-5_48;https://doi.org/10.1007/978-3-319-49004-5_48;Semantic Business Process Regulatory Compliance Checking Using LegalRuleML;2016;"Guido Governatori; Guido Governatori; Mustafa Hashmi; Mustafa Hashmi; Ho-Pun Lam; Ho-Pun Lam; Serena Villata; Serena Villata; Monica Palmirani; Monica Palmirani";Legal documents are the source of norms, guidelines, and rules that often feed into different applications. In this perspective, to foster the need of development and deployment of different applications, it is important to have a sufficiently expressive conceptual framework such that various heterogeneous aspects of norms can be modeled and reasoned with. In this paper, we investigate how to exploit Semantic Web technologies and languages, such as LegalRuleML, to model a legal document. We show how the semantic annotations can be used to empower a business process regulatory compliance system and discuss the challenges of adapting a semantic approach to legal domain.;Yes;;;Yes;;No;No;Yes;No;LegalML;Yes;Yes, to PCL for reasoning;Manual;Not optimized;Yes (evaluation);Yes;Compliance;Telecommunication;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://scholar.google.com/scholar?q=Representation%20of%20case%20law%20for%20argumentative%20reasoning;Representation of case law for argumentative reasoning;2017;"LM Al Abdulkarim; LM Al-Abdulkarim; LM Al Abdulkarim; Latifa Al-Abdulkarim";"Modelling argumentation based on legal cases has been a central topic of AI and Law since its very beginnings. The current established view is that facts must be determined on the basis of evidence. Next, these facts must be used to ascribe legally significant predicates (factors and issues) to the case, on the basis of which the outcome can be established. This thesis aims to provide a method to encapsulate the knowledge of bodies of case law from various legal domains using a recent development in AI knowledge representation, Abstract Dialectical Frameworks (ADFs), as the central feature of the design method. Three legal domains in the US Courts are used throughout the thesis: The domain of the Automobile Exception to the Fourth Amendment, which has been freshly analysed in terms of factors in this thesis; the US Trade Secrets domain analysed from well-known legal case-based reasoning systems (CATO and IBP); and the Wild Animals domain analysed extensively in AI and Law. In this work, ADFs play a role akin to that of Entity-Relationship models in the design of database systems to design and implement programs intended to decide cases, described as sets of factors, according to a theory of a particular domain based on a set of precedent cases relating to that domain. The ADFs in this thesis are instantiated from different starting points: factor-based representation of oral dialogues and factor-based analysis of legal opinions. A legal dialogue representation model is defined for the US Supreme Court Oral Hearing dialogues. The role of these hearings is to identify the components that can form the basis of an argument that will resolve the case. Dialogue moves used by participants have been identified as the dialogue proceeds to assert and modify argument components in term of issues, factors and facts, and to produce what are called Argument Component Trees (ACTs) for each participant in the dialogue, showing how these components relate to one another. The resulting trees can be then merged and used as input to decide the accepted components using an ADF. The model is illustrated using two landmark case studies in the Automobile Exception domain: Carney v. California and US v. Chadwick. A legal justification model is defined to capture knowledge in a legal domain and to provide justification and transparency of legal decisions. First, a legal domain ADF is instantiated from the factor hierarchy of CATO and IBP, then the method is applied to the other two legal domains. In each domain, the cases are expressed in terms of factors organised into an ADF, from which an executable program can be implemented in a straightforward way by taking advantage of the closeness of the acceptance conditions of the ADF to components of an executable program. The proposed method is evaluated to test the ease of implementation, the efficacy of the resulting program, the ease of refinement, transparency of the reasoning and transferability across legal domains. This evaluation suggests ways of improving the decision by incorporating the case facts, and considering justification and reasoning using portions of precedents. The final result is ANGELIC (ADF for kNowledGe Encapsulation of Legal Information from Cases), a method for producing programs that decide the cases with a high degree of accuracy in multiple domains.";Yes;ADF, dissertation;;No;We have quite a few of the Liverpool papers alredy, this is somewhat of an EX1 over these papers. Will this remove as EX1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1016/j.datak.2018.04.009;https://doi.org/10.1016/j.datak.2018.04.009;NómosT: Building large models of law with a tool-supported process;2018;"Nicola Zeni; Nicola Zeni; Elias A. Seid; Elias A. Seid; Priscila Engiel; Priscila Engiel; John Mylopoulos; John Mylopoulos";;Yes;;;Yes;??? I am pretty sure it is Nòmos not Nómos?;No;No;Yes;No;Nòmos, deontic, propositional logic;No;No;semi-automatic;Yes, UI / HTML;No;No;Representation;Privacy / Data Protection;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.3233/aac-180039;https://doi.org/10.3233/aac-180039;Representing argumentation schemes with Constraint Handling Rules (CHR);2018;"Thomas F. Gordon; Thomas F. Gordon; Horst E. Friedrich; Horst Friedrich; Douglas Walton; Douglas Walton";;Yes;Argumentation, not sure if this should count?;;No;Not law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.15439/2018f79;https://annals-csis.org/Volume_15/drp/pdf/79.pdf;Modelling Legal Interpretation in Structured Argumentation Framework;2018;"Tomasz Żurek; Tomasz Zurek; Michał Araszkiewicz; Michał Araszkiewicz";The paper discusses the problem of formal modeling of the interpretation of statutory legal norms. The authors propose a comprehensive framework that allows the representation of the interpretation process. The authors' proposal is illustrated by a real-life example.;Yes;Argumentation;;Yes;;No;No;Yes;No;ASPIC+;No;No;Manual;Not optimized;Yes (author);No;Modelling Interpretation;Tax;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-010-9104-x;https://doi.org/10.1007/s10506-010-9104-x;Argumentation mining;2011;"Raquel Mochales; Raquel Mochales; Marie‐Francine Moens; Marie-Francine Moens";Argumentation mining aims to automatically detect, classify and structure argumentation in text. Therefore, argumentation mining is an important part of a complete argumentation analyisis, i.e. understanding the content of serial arguments, their linguistic structure, the relationship between the preceding and following arguments, recognizing the underlying conceptual beliefs, and understanding within the comprehensive coherence of the specific topic. We present different methods to aid argumentation mining, starting with plain argumentation detection and moving forward to a more structural analysis of the detected argumentation. Different state-of-the-art techniques on machine learning and context free grammars are applied to solve the challenges of argumentation mining. We also highlight fundamental questions found during our research and analyse different issues for future research on argumentation mining.;Yes;Argumentation;;No;Rather explanatory than normative;Yes;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/bf00118494;https://doi.org/10.1007/bf00118494;Abstract argumentation;1996;"Robert Kowalski; Robert A. Kowalski; Francesca Toni; Francesca Toni";In this paper we explore the thesis that the role of argumentation in practical reasoning in general and legal reasoning in particular is to justify the use of defeasible rules to derive a conclusion in preference to the use of other defeasible rules to derive a conflicting conclusion. The defeasibility of rules is expressed by means of non-provability claims as additional conditions of the rules. We outline an abstract approach to defeasible reasoning and argumentation which includes many existing formalisms, including default logic, extended logic programming, non-monotonic modal logic and auto-epistemic logic, as special cases. We show, in particular, that the `admissibility' semantics for all these formalisms has a natural argumentation-theoretic interpretation and proof procedure, which seem to correspond well with informal argumentation. In the admissibility semantics there is only one way for one argument to attack another, namely by undermining one of its non-provability claims. In this paper, we show how other kinds of attack between arguments, specifically how rebuttal and priority attacks, can be reduced to the undermining of non-provability claims.;Yes;;;Yes;;Yes;No;Yes;No;Formal, Defeasible Logic for demonstration;No;Yes, defeasible logic in the form of defeaters to additional conditions;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/models.2019.00-20;https://doi.org/10.1109/models.2019.00-20;Using Models to Enable Compliance Checking Against the GDPR: An Experience Report;2019;"Damiano Torre; Damiano Torre; Damiano Torre; Ghanem Soltana; Ghanem Soltana; Mehrdad Sabetzadeh; Mehrdad Sabetzadeh; Lionel C. Briand; Lionel C. Briand; Yuri Auffinger; Yuri Auffinger; Peter Goes; Peter Goes";The General Data Protection Regulation (GDPR) harmonizes data privacy laws and regulations across Europe. Through the GDPR, individuals are able to better control their personal data in the face of new technological developments. While the GDPR is highly advantageous to individuals, complying with it poses major challenges for organizations that control or process personal data. Since no automated solution with broad industrial applicability currently exists for GDPR compliance checking, organizations have no choice but to perform costly manual audits to ensure compliance. In this paper, we share our experience building a UML representation of the GDPR as a first step towards the development of future automated methods for assessing compliance with the GDPR. Given that a concrete implementation of the GDPR is affected by the national laws of the EU member states, GDPR's expanding body of case law and other contextual information, we propose a two-tiered representation of the GDPR: a generic tier and a specialized tier. The generic tier captures the concepts and principles of the GDPR that apply to all contexts, whereas the specialized tier describes a specific tailoring of the generic tier to a given context, including the contextual variations that may impact the interpretation and application of the GDPR. We further present the challenges we faced in our modeling endeavor, the lessons we learned from it, and future directions for research.;Yes;ICP? But bit boring :D;;Yes;;No;No;Yes;No;UML, Object Constraint Language;No, mentioned but only addressed in terms of tracability;No;Manual (Future work is automatic);Not optimized;Yes (authors);No;Compliance;Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/3322640.3326707;https://doi.org/10.1145/3322640.3326707;Automated reasoning in normative detachment structures with ideal conditions;2019;"Tomer Libal; Tomer Libal; Tomer Libal; Matteo Pascucci; Matteo Pascucci";In this article we introduce a logical structure for normative reasoning, called Normative Detachment Structure with Ideal Conditions, that can be used to represent the content of certain legal texts in a normalized way. The structure exploits the deductive properties of a system of bimodal logic able to distinguish between ideal and actual normative statements, as well as a novel formalization of conditional normative statements able to capture interesting cases of contrary-to-duty reasoning and to avoid deontic paradoxes. Furthermore, we illustrate how the theoretical framework proposed can be mechanized to get an automated procedure of query-answering on an example of legal text.;Yes;somewhat novel :D;;Yes;;No;No;Yes;No;Deaontic Logic, (Note, this expands on SDL and has some discussion on the nuances of DL);No;No;Manual;Not optimized;No;No;Reasoning / Question Answering;Commerce;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://link.springer.com/chapter/10.1007/978-3-030-44429-7_9;A Methodology for Implementing the Formal Legal-GRL Framework: A Research Preview;2020;"Amin Rabinia; Amin Rabinia; Sepideh Ghanavati; Sepideh Ghanavati; Sepideh Ghanavati; Sepideh Ghanavati; Llio Humphreys; Llio Humphreys; Torsten Hahmann; Torsten Hahmann; Torsten Hahmann";[Context and motivation] Legal provisions create a distinct set of requirements for businesses to be compliant with. Capturing legal requirements and managing regulatory compliance is a challenging task in system development. [Question/problem] Part of this task involves modeling legal requirements, which is not trivial for requirements engineers as non-experts in law. The resultant legal requirements models also tend to be very complex and hard to understand. [Principal ideas/results] To facilitate the modeling process, we propose a formal framework for modeling legal requirements. This framework includes a methodology that helps to resolve complexities of legal requirements models. [Contribution] In this paper, we outline this methodology and present a procedure that reduces modal and conditional complexities of legal models and facilitates automation of the modeling process.;Yes;;;Yes;Technical preview, but ok. This has got a very simple but cool thing were they model permissions as a disjunction of a prohibition and an obligation;No;No;Yes;No;Legal-GRL;No;No;Automatic;Not optimized;No;No, just in Lit Rev;Modelling, Reasoning;Privacy;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://www.researchgate.net/profile/Monica-Becue-Bertaut/publication/221466548_Statistical_Study_of_Judicial_Practices/links/0f31753b4070219bff000000/Statistical-Study-of-Judicial-Practices.pdf#page=195;A methodology to create legal ontologies in a logic programming information retrieval system;2005;"José Saias; José Saias; Paulo Quaresma; Paulo Quaresma; Paulo Quaresma";Legal web information retrieval systems need the capability to reason with the knowledge modeled by legal ontologies. Using this knowledge it is possible to represent and to make inferences about the semantic content of legal documents. In this paper a methodology for applying NLP techniques to automatically create a legal ontology is proposed. The ontology is defined in the OWL semantic web language and it is used in a logic programming framework, EVOLP+ISCO, to allow users to query the semantic content of the documents. ISCO allows an easy and efficient integration of declarative, object-oriented and constraint-based programming techniques with the capability to create connections with external databases. EVOLP is a dynamic logic programming framework allowing the definition of rules for actions and events. An application of the proposed methodology to the legal information retrieval system of the Portuguese Attorney General's Office is described.;Yes;OWL and Prolog;;Yes;;No;No;Yes;No;OWL;No;Yes to Prolog for evaluation;Automatic;Not optimized;No;No;Information Retrieval;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://orbilu.uni.lu/bitstream/10993/43561/1/SCSBD_RE20.pdf;Automated Recommendation of Templates for Legal Requirements;2020;"Amin Sleimi; Amin Sleimi; Marcello Ceci; Marcello Ceci; Mehrdad Sabetzadeh; Mehrdad Sabetzadeh; Lionel C. Briand; Lionel C. Briand; John Dann; John Dann";"[Context] In legal requirements elicitation, requirements analysts need to extract obligations from legal texts. However, legal texts often express obligations only indirectly, for example, by attributing a right to the counterpart. This phenomenon has already been described in the Requirements Engineering (RE) literature [1]. [Objectives] We investigate the use of requirements templates for the systematic elicitation of legal requirements. Our work is motivated by two observations: (1) The existing literature does not provide a harmonized view on the requirements templates that are useful for legal RE; (2) Despite the promising recent advancements in natural language processing (NLP), automated support for legal RE through the suggestion of requirements templates has not been achieved yet. Our objective is to take steps toward addressing these limitations. [Methods] We review and reconcile the legal requirement templates proposed in RE. Subsequently, we conduct a qualitative study to define NLP rules for template recommendation. [Results and Conclusions] Our contributions consist of (a) a harmonized list of requirements templates pertinent to legal RE, and (b) rules for the automatic recommendation of such templates. We evaluate our rules through a case study on 400 statements from two legal domains. The results indicate a recall and precision of 82,3% and 79,8%, respectively. We show that introducing some limited interaction with the analyst considerably improves accuracy. Specifically, our human-feedback strategy increases recall by 12% and precision by 10,8%, thus yielding an overall recall of 94,3% and overall precision of 90,6%.";Yes;"Not 100% sure. Might not be compliance relevant, ""only tempaltes""";;No;Not really LIR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1007/s10506-007-9050-4;https://doi.org/10.1007/s10506-007-9050-4;Formal models of coherence and legal epistemology;2007;"Amalia Amaya; Amalia Amaya";This paper argues that formal models of coherence are useful for constructing a legal epistemology. Two main formal approaches to coherence are examined: coherence-based models of belief revision and the theory of coherence as constraint satisfaction. It is shown that these approaches shed light on central aspects of a coherentist legal epistemology, such as the concept of coherence, the dynamics of coherentist justification in law, and the mechanisms whereby coherence may be built in the course of legal decision-making.;Yes;I still do not understand what coherence is;;No;"A bit too meta, more about general ideas, not about a proper ""coherent"" (haha) approach";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://scholar.google.com/scholar?q=Critical%20Questions%20to%20Argumentation%20Schemes%20in%20Statutory%20Interpretation.;Critical Questions to Argumentation Schemes in Statutory Interpretation.;2021;"Michał Araszkiewicz; Michal Araszkiewicz";;Yes;Argumentation;;No, For discussion;A bit too meta. It does not introduce WSM and I honestly did not understand all of the paper in the limited time frame, but this focuses on very specific parts of argument;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1002/int.20307;https://www.irit.fr/~Leila.Amgoud/art-NMR-UF-04.pdf;On bipolarity in argumentation frameworks;2008;"Leila Amgoud; Leïla Amgoud; Claudette Cayrol; Claudette Cayrol; M. C. Lagasquie-Schiex; Marie-Christine Lagasquie-Schiex; P. Livet; Pierre Livet";In this article, we propose a survey of the use of bipolarity in argumentation frameworks. On the one hand, the notion of bipolarity relies on the presence of two kinds of entities that have a diametrically opposed nature and that represent repellent forces (a positive entity and a negative entity). The notion exists in various domains (for example with the representation of preferences in artificial intelligence, or in cognitive psychology). On the other hand, argumentation process is a promising approach for reasoning, based on the construction and the comparison of arguments. It follows five steps: building the arguments, defining the interactions between these arguments, valuating the arguments, selecting the most acceptable arguments and, finally, drawing a conclusion. Using the nomenclature proposed by Dubois and Prade, this article shows on various applications, and with some formal definitions, that bipolarity appears in argumentation (in some cases if not always) and can be used in each step of this process under different forms. © 2008 Wiley Periodicals, Inc.;Yes;argumentation;;No;No law;Yes;;;No;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1093/jigpal/jzp075;https://www.researchgate.net/publication/220245232_Changing_legal_systems_Legal_abrogations_and_annulments_in_Defeasible_Logic;Changing legal systems: legal abrogations and annulments in Defeasible Logic;2010;"G. Governatori; A. Rotolo";"NA; NA";;;;Yes;;No;No;Yes;No;(temporal) defeasible logic;Yes (models abrogations and annulments);No;Manual;Not optimized;Yes (authors);No;Change managment;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/DEXA.2011.46;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6059841;Intuitionistic Description Logic and Legal Reasoning;2011;"E. H. Haeusler; V. d. Paiva; A. Rademaker";"DI PUC-Rio, Puerto Rico; NA; CMA FGV-Rio, Brazil";;;;Yes;This is getting very theoretical. I think in the discussion I can mention this rather as a limitation of classical logic;No;No;Yes;No;Intuitionistic Description Logic (Note self: intuitionistic: -A or A != True);No;No;Manual;Not optimized;No;No;Reasoning;Private;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/FSKD.2016.7603429;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603429;Representation of Chinese criminal law in the semantic web;2016;"X. Wang; Y. Sun; M. Ge; J. Chen";"Liaoning Technical University, Huludao, China; Liaoning Technical University, Huludao, China; Liaoning Technical University, Huludao, China; Liaoning Technical University, Huludao, China";;;;Yes;;No;No;Yes;No;LegalRuleML;No;Yes from SBVR's  Structured English to LegalRuleML;Manual;Not optimized;Yes (discussion);No;Reasoning;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ICTAI.2018.00055;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576053;Legal Reasoning in Answer Set Programming;2018;"T. Aravanis; K. Demiris; P. Peppas";"Department of Business Administration, University of Patras, Patras, Greece; Department of Business Administration, University of Patras, Patras, Greece; Department of Business Administration, University of Patras, Patras, Greece";;;;Yes;ASP seems to help with non-monotonic reasoning. I get the general idea, but am missing a proper coutner example…;No;No;Yes;No;Answer Set Programming (Note self, basically Prolog, closed-world assumption: false unless proven otherwise);No;No;Manual;Not optimized;No;No;Reasoning;General (Toy example domain);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2008.5;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4797468;Formal Modeling of Airport Security Regulations using the Focal Environment;2008;"D. Delahaye; J. . -F. Etienne; V. V. Donzeau-Gouge";"CEDRIC-CNAM, Paris, France; CEDRIC-CNAM, Paris, France; CEDRIC-CNAM, Paris, France";;;;Yes;;No;No;Yes;No;"FoCaL (Not the first Programming Language that comes up when googleing, but some other FOL like language); First Order Logic";No;No;Manual;Not optimized;No;No;Reasoning;Aviation;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2015.7330205;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7330205;Semantic web representations for reasoning about applicability and satisfiability of federal regulations for information security;2015;"S. Mandal; R. Gandhi; H. Siy";"University of Nebraska at Omaha, Omaha, USA; University of Nebraska at Omaha, Omaha, USA; University of Nebraska at Omaha, Omaha, USA";;use case;;Yes;;No;No;Yes;Yes;OWL+SWRL based formalization of Nòmos 2;No;"Yes (Nòmos concepts to OWL-DL SWRL; Nòmos to FOL (done by NRTool, not really part of paper)";Manual (Extraction of Nòmos Norms);Not optimized;No;No;Reasoning, Translation;Information Security;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/DEXA.2001.953089;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953089;Legal knowledge representation using the resource description framework (RDF);2001;M. P. Ebenhoch;NA;;;;Yes;;No;No;Yes;No;RDF;No;No (again just serialization/file format conversions);Manual;Not optimized;No;No;Representation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/REW.2017.51;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8054855;An Algebraic Approach for Analyzing of Legal Requirements;2017;"A. Letichevsky; O. Letychevskyi; V. Peschanenko; M. Poltorackij";"Glushkov Institute of Cybernetics of NAS of Ukraine, Kyiv, Ukraine; Glushkov Institute of Cybernetics of NAS of Ukraine, Kyiv, Ukraine; Kherson State University, Kherson, Ukraine; Kherson State University, Kherson, Ukraine";;;;Yes;;No;No;Yes;No;Formal, Algebraic Programming System (APS);No;No;Manual;Not optimized;"Yes (in the actual task ""specialist in jurisprudence)";No;Compliance;Tax;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/HICSS.1999.772631;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=772631;On the analysis of regulations using defeasible rules;1999;"G. Antoniou; D. Billington; M. J. Maher";"CIT, Griffith University, Nathan, QLD, Australia; CIT, Griffith University, Nathan, QLD, Australia; CIT, Griffith University, Nathan, QLD, Australia";;;;Yes;;No;No;Yes;No;Defeasible Logic;No;No;Manual;Not optimized;No;No;Reasoning;General (Toy Examples);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/CICTN64563.2025.10932494;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932494;Automating Legal Expertise: A Rule-Based Approach to Legal Reasoning Systems;2025;"B. Bhavishya; A. Shukla; M. Aggarwal";"Department of IT, KIET Group of Institutions Delhi NCR, Ghaziabad, India; Department of IT, KIET Group of Institutions Delhi NCR, Ghaziabad, India; Department of IT, KIET Group of Institutions Delhi NCR, Ghaziabad, India";;Just some prolog;;Yes;;No;"No (they argue this is case based, but this does not contain any discussion of factors or similar, but only ""simple"" implications from tpye to outcome)";Yes;No;Prolog (no further specification);No;No;Manual;Not optimized;No;No;Reasoning;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/IMCOM56909.2023.10035590;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035590;VNLES: A Reasoning-enable Legal Expert System using Ontology Modeling-based Method: A Case Study of Vietnam Criminal Code;2023;"Q. T. Dao; T. K. Dang; T. P. H. Nguyen; T. M. C. Le";"Ho Chi Minh City University of Technology, VNU-HCM, Vietnam; Ho Chi Minh City University of Food Industry, Vietnam; Ho Chi Minh City University of Law, Vietnam; Ho Chi Minh City University of Technology and Education, Vietnam";;;;Yes;;No;No;Yes;Yes;OWL-DL, SWRL;No;No;Manual;Not optimized;Yes (authors);No;Reasoning;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/GCAT59970.2023.10353499;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10353499;Data and Knowledge Engineering for Legal Precedents Using First-Order Predicate Logic;2023;"M. N. Alam; M. S. Kabir; A. Verma";"Faculty of Computing, Guru Kashi University, Talwandi Sabo, Bathinda, India; Department of Law, Raffles University, Neemrana, Rajasthan, India; Faculty of Juridical Sciences, Rama University, Uttar Pradesh, India";;;;Yes;;No;Yes (Precendents are used to derive Rules);No;No;First Order Predicate Logic;No (Limitation);No;Manual;Not optimized;Yes (authors);No;Reasoning;marriage law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ICICSE.2012.9;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239780;A Method of Legal Text Formalization;2012;"D. Lang; S. Huang; T. Lv";"Computer Science & Technology, Harbin Engineering University, Harbin, China; Computer Science & Technology, Harbin Engineering University, Harbin, China; Computer Science & Technology, Harbin Engineering University, Harbin, China";;;;Yes;;No;No;Yes;No;Computational Tree Logic (Temporal, Formal);No;No;Automatic;Not optimized;No;No;Modelling;Insurance Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/RELAW.2013.6671344;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671344;Transforming regulations into performance models in the context of reasoning for outcome-based compliance;2013;"R. Rashidi-Tabrizi; G. Mussbacher; D. Amyot";"School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, Canada; School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, Canada; School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, Canada";;;;No;Duplicate!;No;No;Yes;No;Goal-oriented Requirement Language (GRL);No;No;Manual;;;;;Banking;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/DEXA.1999.795283;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=795283;Towards the formalization of legal causal reasoning;1999;J. Lehmann;Faculty of Law, Department of Computer Science and Law, University of Amsterdam, Amsterdam, Netherlands;;;;No;More of a research proposal;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.23919/CISTI52073.2021.9476581;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476581;Automated Reasoning with Legal Ontologies: A Case Study on Brazilian Councilwoman Marielle Franco’s Murder;2021;"C. M. de Oliveira Rodrigues; F. Luis Gonçalves de Freitas; I. J. Varzinczak; J. Fausto Lorenzato de Oliveira";"PPGEC/Poli, UPE Multicampi, Garanhuns, PE, Brazil; Center of Informatics (CIn, UFPE), Recife, PE, Brazil; CRIL, Université d’Artois & CNRS, Lens, France; Polytechnic School of Pernambuco, UPE, Recife, PE, Brazil";;Description logic;;Yes;;No;No;Yes;No;Formal, Description Logic (SHIQ);No;No;Manual;Yes (UI);No;No;Reasoning;Criminal Law;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/64.21892;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=21892;A case-based approach to modeling legal expertise;1988;"K. D. Ashley; E. L. Rissland";"University of Massachusetts, USA; University of Massachusetts, USA";;Another hypo, not sure how much novel research this contains, but sure;;No;;No;Yes;No;No;HYPO (factor/dimensions);No;No;Manual;Not optimized;Yes (authors);No;Reasoning;Trade Secrets;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/69.506715;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506715;A deductive object-oriented database system for situated inference in law;1996;"S. Wong; S. Tojo";"Depautnzent of Radiology, University of California-San Francisco, San Francisco, CA, USA; Japan Advanced Institute of Science and Technology, Ishikawa, Japan";;;;Yes;;No;Yes;Yes;No;Formal, Situation Theory;No;Yes? From abstract formulization to QUIXOTE model;Manual;Not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/IRI.2004.1431514;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1431514;Fusing legal knowledge;2004;E. Gregoire;CRIL-CNRS Université d'Artois, Lens, France;;Maybe a bit to much on the reasoning and less on the law representation side, but probably valid;;Yes;;No;No;Yes;No;Formal, propositional knowledge (but details secondary, this is about fusing KBs);No;No;Manual;Not optimized;No;No;Merging Rules;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/CEC.2010.15;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708409;Ontology-Enabled Knowledge Management in Environmental Regulations and Incentive Policies: The ERIPAD System;2010;"S. -C. Oh; X. Zhao; S. R. Biller; K. Lee; H. -I. Jung; M. Sohn; H. Lee";"General Motors Research and Development Center, Warren, MI, USA; General Motors Research and Development Center, Warren, MI, USA; General Motors Research and Development Center, Warren, MI, USA; Sungkyunkwan University, Suwon, Gyeonggi, South Korea; Sungkyunkwan University, Suwon, Gyeonggi, South Korea; Sungkyunkwan University, Suwon, Gyeonggi, South Korea; Sungkyunkwan University, Suwon, Gyeonggi, South Korea";;;;Yes;;No;No;Yes;Yes;RDF (Some additional theory, i.e., ABox vs TBox, but that is generally it);No (mentioned in introduction, but not really expanded upon);No;Manual;Yes (UI);No;No;Managment, Retrieval;Environment;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/BigData50022.2020.9378107;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378107;SALKG: A Semantic Annotation System for Building a High-quality Legal Knowledge Graph;2020;"M. Tang; C. Su; H. Chen; J. Qu; J. Ding";"Nanjing Audit University,School of Information Engineering,Nanjing,P. R. China; Nanjing Audit University,School of Information Engineering,Nanjing,P. R. China; The University of North Texa,Department of Information Science,Denton,USA; Beihua University,College of Computer Science and Technology,Jilin,P. R. China; The University of North Texa,Department of Information Science,Denton,USA";;;;Yes;;No;No;Yes;No;RDF;No;No;Semi-automatic (cannot really go higher as the main annotation is completely manual);Yes (UI);No;No;Knowledge Base creation?;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/CAIA.1993.366619;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=366619;HELIC-II: As a legal argumentation support system;1993;"Y. Ohtake; K. Nitta; S. Maeda; M. Ono; H. Ohsaki; J. Yoneda";"ICOT, Minato, Tokyo, Japan; ICOT, Minato, Tokyo, Japan; ICOT, Minato, Tokyo, Japan; ICOT, Minato, Tokyo, Japan; JIPDEC, Minato, Tokyo, Japan; JIPDEC, Minato, Tokyo, Japan";;argumentation;;No;Too little detail on the formalisaation;No;Yes;Yes;No;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/MIS.2021.3052995;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328536;Fact Investigation and Proof Standards in Legal Argumentation;2021;M. O. Moguillansky;Universidad Nacional del Sur, Bahía Blanca, Argentina;;argumentation;;No;too argumentation focused, dialectic. EX8;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ICDH62654.2024.00032;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645807;Semantically Rich Approach to Automating Regulations of Medical Devices;2024;"S. Chattoraj; R. Walid; K. P. Joshi";"Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, USA; Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, USA; Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, USA";;;;Yes;;No;No;Yes;Yes;OWL/RDF;No;No;Manual;Not optimized;Yes (evaluation, assuming domain experts are law experts, could not find Andrea Iorga);No;Knowledge Base creation?;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/SoMeT.2013.6645652;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645652;A semantic web platform for legal knowledge in cloud;2013;"C. Gheorghiu; A. Panu; L. Alboaie";"Faculty of Computer Science, Alexandru Ioan Cuza University, Iasi, Romania; Faculty of Computer Science, Alexandru Ioan Cuza University, Iasi, Romania; Faculty of Computer Science, Alexandru Ioan Cuza University, Iasi, Romania";;;;Yes;;No;No;Yes;Yes;OWL/RDF;No, Odd one, never really mentioned but potential from what I see;No;Automatic;Not optimized;No;No;Transparency;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/AICT61888.2024.10740457;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10740457;Transforming Legal Documents into Knowledge Goldmines: Application on the Algerian Official Journal;2024;"H. S. Abdellah; M. M’hamed; S. Faouzi; O. Aymen; H. Fedoua; A. Mohamed Chakib; B. Takieddine";"Computer Science Department, Ecole Militaire Polytechnique, Algiers, Algeria; Computer Science Department, Ecole Militaire Polytechnique, Algiers, Algeria; Computer Science Department, Ecole Militaire Polytechnique, Algiers, Algeria; Computer Science Department, Ecole Militaire Polytechnique, Algiers, Algeria; Computer Science Department, Ecole Militaire Polytechnique, Algiers, Algeria; Computer Science Department, Ecole Militaire Polytechnique, Algiers, Algeria; Computer Science Department, Ecole Militaire Polytechnique, Algiers, Algeria";;Would consider this relatively basic, it is just an ontology construction, but fine;;No;This is rather descriptive of the algerian governments structure than really about normative texts;No;No;Yes;No;Bascially RDF triples;No, abrogations etc exist as relations, but nothing more;No;Manual;Not optimized;Yes (data extraction);No;Data Retrieval;Official Journal, i.e., structural?;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
IEEE;10.1109/ACCESS.2017.2745208;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8016577;An Ontological Chinese Legal Consultation System;2017;"N. Zhang; Y. -F. Pu; S. -Q. Yang; J. -L. Zhou; J. -K. Gao";"Library of Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; School of Law, Sichuan University, Chengdu, China; School of Computer Science, Chengdu University of Information Technology, Chengdu, China; School of Law, Southwestern University of Finance and Economics, Chengdu, China";;Retrieval, but no just case retrieval;;Yes;;No;No;Yes;Yes;Unspecified, Ontology;No;No;Tool supported;Not optimized;Yes (authors, data);No;Data Retrieval;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1109/icsmc.2001.969873;https://doi.org/10.1109/icsmc.2001.969873;Modeling legislation using natural language processing;2001;"Ron van Gog; R. Van Gog; Tom van Engers; T.M. Van Engers";This paper describes the possibilities of the translation of legislation, which is written in natural language, into a formal language, i.e. UML/OCL. The tool OPAL (Object-oriented Parsing and Analysis of Legislation) is developed to support the automatic modelling of legislation with the use of appropriate NLP techniques. The aim is not to perform this modelling in a batch fashion from legislation to final model, but interactively in dialogue with the knowledge engineer. The main components of OPAL are a parser (based on a chart-parser algorithm) and a model generator. A special component called modelling interface is added to OPAL to give the knowledge engineer the possibility to keep track of the modelling process and to make adjustments to the final model.;;;;No;Wrong focus, creation not LIR, basically UML or OCL but not really specified;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;;https://d1wqtxts1xzle7.cloudfront.net/78397237/On_the_Modeling_and_Analysis_of_Regulati20220108-29700-rz45qz.pdf?1738465304=&response-content-disposition=inline%3B+filename%3DOn_the_modeling_and_analysis_of_regulati.pdf&Expires=1746287775&Signature=GOKNrJp3L7-cOhbHl6bEHlyxJY3mujhKWrD02JkKi1S-rYAJp6wtZ39MAwj2dhfIk59xQ-myphVGbk-1rMcYnoGxgCsCfUtMcCuIhPDeUO8i17mGUHfTMlSXohk258OEZTgpY-nVVb-pwysR-XAkAADiyp6JxFCXAYrmDJ70za5h-48tKcM8hFviRKmbDZ4e~fP-E18zWC2QnqNPiE2ZwsuMG3KffS1-wxDu~4VzJAnwOtPJnQ9iGOQoWV2Nmod1gkruaR6Lt9aDJyJN3Wvoh280E1kypGAqa0My2YMVsEl3YTnszGBuSYVMvTx6ele8Ifs54u1mipnQrp2KlqQb2Q__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA;On the Modeling and Analysis of Regulations;1999;"Grigoris Antoniou; Grigoris Antoniou; David P. Billington; David Billington; Guido Governatori; Guido Governatori; Michael J. Maher; Michael J. Maher";Regulations are a wide-spread and important part of government and business. They codify how products must be made and processes should be performed. Such regulations can be difficult to understand and apply. In an environment of growing complexity of, and change in, regulation, automated support for reasoning with regulations is becoming increasingly necessary. In this paper we report on ongoing work which aims at providing automated support for the drafting and use of regulations using logic modelling techniques. We highlight the support that can be provided by logic modelling, describe the technical foundation of our project, and report on the status of the project and the next steps.;;Very close to EX1, but will let slide;;No;Will go against first round decision and remove as this is basically just a research proposal and does not have enough novel things to say to make an exception warrented here;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1023/a:1008238332032;https://doi.org/10.1023/a:1008238332032;Representing Law in Partial Information Structures;1997;"Niels Peek; Niels Peek; Niels Peek; Niels Peek";This paper presents a new language for isomorphic representations of legalknowledge in feature structures. The language includes predefinedstructures based on situation theory for common-sense categories, andpredefined structures based on Van Kralingen`s (1995) frame-based conceptualmodelling language for legal rules. It is shown that the flexibility of thefeature-structure formalism can exploited to allow for structure-preservingrepresentations of non-primitive concepts, and to enable various types ofinteraction and cross-reference between language elements. A fragment of theDutch Opium Act is used to illustrate how modelling and reasoning proceed in practice.;;;;Yes;;No;No;Yes;No;feature-structure formalism (basically templates);No;No;Manual;Not optimized;No;No;Representation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1165485.1165489;https://doi.org/10.1145/1165485.1165489;Dynamics of legal provisions and its representation;2005;"Jacek Martinek; Jacek Martinek; Jolanta Cybulka; Jolanta Cybulka";Legal provisions are considered as interrelated fragments of a text with some structural relations which hold between them. Some provisions are treated as meta-provisions, in case they are used to enact, repeal or amend the substantial provisions. The meaning of a meta-provision is described by meta-norms. Every meta-norm is conditioned by a certain event, and it describes the action which should be executed in order to obtain the current properties of the provision, such as its current text content or the current structural relations holding between the provisions. The presented model of the legal provisions dynamics is based on the event calculus, which is used to represent how the provision properties change in time. The model can be easily implemented in Prolog.;;;;Yes;Is more about the metadata but still interesting;No;No;Yes;No;Predicate Logic, Prolog;No, models temporal aspects and relations between legislation but not dynamically;No;manual (Unspecified);Not optimized;No;No;Reasoning about meta infromation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/261618.261637;https://doi.org/10.1145/261618.261637;The other formalization of law: SGML modelling and tagging;1997;"Daniel Poulin; Daniel Poulin; Guy Huard; Guy Huard; Alain Lavoie; Alain Lavoie";Article Free Access Share on The other formalization of law: SGML modelling and tagging Authors: Daniel Poulin Centre de recherche en droit public, University of Montréal, C.P. 6128, succ. Centre-ville, Montréal(Québec), Canada H3C 3J7 Centre de recherche en droit public, University of Montréal, C.P. 6128, succ. Centre-ville, Montréal(Québec), Canada H3C 3J7View Profile , Guy Huard Centre de recherche en droit public, University of Montréal, C.P. 6128, succ. Centre-ville, Montréal(Québec), Canada H3C 3J7 Centre de recherche en droit public, University of Montréal, C.P. 6128, succ. Centre-ville, Montréal(Québec), Canada H3C 3J7View Profile , Alain Lavoie Centre de recherche en droit public, University of Montréal, C.P. 6128, succ. Centre-ville, Montréal(Québec), Canada H3C 3J7 Centre de recherche en droit public, University of Montréal, C.P. 6128, succ. Centre-ville, Montréal(Québec), Canada H3C 3J7View Profile Authors Info & Claims ICAIL '97: Proceedings of the 6th international conference on Artificial intelligence and lawJune 1997 Pages 82–88https://doi.org/10.1145/261618.261637Online:30 June 1997Publication History 5citation318DownloadsMetricsTotal Citations5Total Downloads318Last 12 Months0Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF;;This is basically just XML;;Yes;This is like a sibling of HTML which is interesting. Not sure how established HTML was in *97;No;Yes (court decisions);No;No;Semantic Markup;No;No;Automatic;Optimized, Markup on text;Yes (authors);No;Representation;General (Supreme Court Decisions);;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1165485.1165507;https://doi.org/10.1145/1165485.1165507;Combining structured and unstructured information in a retrieval model for accessing legislation;2005;"Marie‐Francine Moens; Marie-Francine Moens";Legislative sources are currently accessible via portal web sites. Users demand precise and exhaustive answers to their information queries. When legislation is drafted, it contains text-rich information that is increasingly marked with XML tags. The statute structure as signaled by XML markup can be exploited to more precisely answer free information queries. In this paper we report on several XML retrieval models that we explicitly designed for the retrieval of legislation. We show that the models provide more advanced access to the content of statutes.;;Retrieval only, inclusion depends on decision later;;No;Document retrieval or doc segment retrieval;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.1145/1047788.1047818;https://doi.org/10.1145/1047788.1047818;Permissions and obligations in hierarchical normative systems;2003;"Guido Boella; Guido Boella; Leendert van der Torre; Leendert van der Torre";In this paper we discuss different types of permissions and their roles in deontic logic. We study the distinction between weak and strong permissions in the context of input/output logic, combining the logic with constraints, priorities and hierarchies of normative authorities. In this setting we observe that the notion of prohibition immunity no longer applies, and we introduce a new notion of permission as exception and a new distinction between static and dynamic norms. We show that strong permissions can dynamically change a normative system by adding exceptions to obligations, provide an explicit representation of what is permitted to the subjects of the normative system and allow higher level authorities to limit the changes that lower level authorities can do to the normative system.;;Very extensive work;;Yes;;No;no;Yes;No;"Formal, rather meta in ist discussion; boolean logic (input/output logic)";Yes (Possible to modify by adding new);No;Manual;not optimized;No;No;Reasoning;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=77b7d4532130ef90bd1c01fde5d29f535c7d4b25;https://scholar.google.com/scholar?q=METAlex:%20Legislation%20in%20XML;METAlex: Legislation in XML;2002;"Alexander Boer; Alexander Boer; Rinke Hoekstra; Rinke Hoekstra; Radboud Winkels; Radboud Winkels; Tom van Engers; T.M. van Engers";;;;;Yes;;No;no;Yes;No;MetaLex: RDF + XML structural markup;No (has some meta info on how regulations relate, but does not really react dynamically);No;Manual;not optimized;Yes (authors);No;Representation;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ResearchRabbit;10.2307/794073;https://doi.org/10.2307/794073;Symbolic Logic: A Razor-Edged Tool for Drafting and Interpreting Legal Documents;///;"Layman E. Allen; Layman E. Allen";;;Bit odd as this is from a law review, but technically this is valid;;Yes;Bit meta and more of a debate on if law practitioners should work with symbol logic, but sure;No;no;Yes;No;Formal, Simple Boolean Logic;No;No;Manual;not optimized;Yes (author, law journal);No;Debate of symbolig logic used by lawyers;General;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
