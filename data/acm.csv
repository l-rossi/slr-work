"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"2QLMNZEW","journalArticle","2025","Singh, Nivedita; Do, Yejin; Yu, Yongsang; Fouad, Imane; Kim, Jungrae; Kim, Hyoungshick","Crumbled Cookies: Exploring E-commerce Websites’ Cookie Policies with Data Protection Regulations","ACM Trans. Web","","1559-1131","10.1145/3708515","https://doi.org/10.1145/3708515","Despite stringent data protection regulations, such as the General Data Protection Regulation (GDPR), the California Consumer Privacy Act (CCPA), and other country-specific laws, numerous websites continue to use cookies to track user activities, raising significant privacy concerns. This study aims to investigate the compliance of e-commerce websites with these regulations from a cookie perspective and explore potential variations in cookie policies across different countries. We conducted a comprehensive analysis of 360 popular e-commerce websites (44,323 cookies) across multiple countries, examining cookie attributes and their potential links to privacy and security breaches. Our findings revealed that 73% of third-party cookies function as tracker cookies, with around 40% breaching lifecycle regulations. Additionally, 85% are vulnerable to potential cross-site scripting (XSS) attacks, while only 349 out of 44,323 adhere to robust measures aimed at combating cross-site request forgery (CSRF) attacks. We also discovered instances of masquerading cookies, where third-party cookies disguise themselves as first-party cookies, enabling unauthorized user tracking without consent. To the best of our knowledge, this study is the first to comprehensively analyze the compliance of e-commerce websites with the GDPR, CCPA, and country-specific regulations concerning cookie policies across different jurisdictions. Our findings highlight the urgent need for uniform and consistent cookie policies across websites and jurisdictions, as well as robust enforcement mechanisms and increased transparency to ensure compliance with data protection regulations. This research contributes to the ongoing discourse on privacy protection and underscores the importance of addressing the challenges posed by insecure cookie practices in the e-commerce sector.","2025-01","2025-02-19 14:42:18","2025-02-19 14:42:18","","","","1","19","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","GDPR; CCPA; cookie; privacy; security policy; Web security","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFKFK4ME","conferencePaper","2024","Jung, Won Kyung; Kwon, Hun Yeong","Privacy and data protection regulations for AI using publicly available data: Clearview AI case","Proceedings of the 17th International Conference on Theory and Practice of Electronic Governance","979-8-4007-1780-2","","10.1145/3680127.3680200","https://doi.org/10.1145/3680127.3680200","Data are pivotal resources in artificial intelligence (AI) research and development. Acquiring enormous quantities of high-quality data is essential for improving AI performance. However, obtaining such data poses significant challenges, including high costs and accessibility barriers. A critical question arises: does using publicly available data from the Internet lead to violations of privacy and/or data protection laws? This paper examines privacy rights and data protection laws concerning the use of publicly accessible online data in AI research across the United States, Canada, Europe, and Australia. Focusing on recent controversies, particularly the Clearview AI case, it compares the legal and regulatory frameworks in these jurisdictions. The analysis highlights how digital governance in privacy and data protection must evolve in response to the growing demand for publicly available data in AI development. The central finding of this paper is that significant privacy and data protection risks and debates arise when publicly available data are used without adequate consent or legitimate purposes. The enforcement of these legal principles varies across countries, with substantial dependency on specific circumstances. The Clearview AI case, in particular, has exposed several ironies and unresolved issues surrounding data protection, privacy rights, and enforcement practices. These include disputes over the extraterritorial application of laws, inconsistent and impracticable legal enforcement, and settlements reached without judicial rulings. To foster a fair and trustworthy environment for AI development, compliance with privacy and data protection laws is critical. Achieving this requires more consistent, practical, and cooperative legal frameworks across nations to ensure safe and practical protection of personal data.","2024","2025-02-19 14:42:18","2025-02-19 14:42:18","","48–55","","","","","","","ICEGOV '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","Data protection; GDPR; AI; Privacy; Biometric data; BIPA; Facial recognition technology; First Amendment; Scraping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6AZFGNW","conferencePaper","2024","Abualhaija, Sallam; Ceci, Marcello; Sannier, Nicolas; Bianculli, Domenico; Zetzsche, Dirk; Bodellini, Marco","Toward Automated Change Impact Analysis of Financial Regulations","Proceedings of the 1st IEEE/ACM Workshop on Software Engineering Challenges in Financial Firms","979-8-4007-0568-7","","10.1145/3643665.3648046","https://doi.org/10.1145/3643665.3648046","Regulation changes over time due to amending or repealing existing legal provisions as well as introducing new ones. The finance field provides a concrete example of heavily regulated area which has seen continuous regulatory changes in the aftermath of the 2008 crisis. Software financial services like online banking or trading must constantly comply with the regulations. Monitoring and analyzing the regulatory change is essential to ensure that such services remain compliant. Regulatory changes can significantly affect existing software systems that were compliant at a certain point in time. However, tracing the regulatory changes entirely manually is time consuming and error-prone. In this position paper, we introduce our vision for automated financial regulations change impact analysis. We aim at characterizing the regulatory changes pertinent to financial regulations, and further providing automated support for both identifying and classifying the regulatory changes as well as analyzing the impact of such changes on existing (potentially compliant) software systems.","2024","2025-02-19 14:42:18","2025-02-19 14:42:18","","31–32","","","","","","","FinanSE '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Lisbon, Portugal","","","","change impact analysis; FinTech; regulatory change; regulatory compliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPJEGVQ7","conferencePaper","2023","Prakken, Henry; Sartor, Giovanni","A Formal Framework for Combining Legal Reasoning Methods","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595129","https://doi.org/10.1145/3594536.3595129","This paper proposes a novel argumentation-based approach to combine legal-reasoning methods that each solve a subproblem of an overall legal problem. The methods can be of any nature (for instance, logical, case-based or probabilistic), as long as their input-output behaviour can be described at the metalevel with deductive or defeasible rules. The model is formulated in the ASPIC+ framework, to profit from its metatheory and explanation methods, and to allow for disagreement about how to solve a subproblem. The model is not meant to be directly implementable but to serve as a semantics for architectures and implementations.","2023","2025-02-19 14:42:18","2025-02-19 14:42:18","","227–236","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","Legal argumentation; legal problem solving methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HVBGPWPS","conferencePaper","2024","Yao, Shunyu; Ke, Qingqing; Wang, Qiwei; Li, Kangtong; Hu, Jie","Lawyer GPT: A Legal Large Language Model with Enhanced Domain Knowledge and Reasoning Capabilities","Proceedings of the 2024 3rd International Symposium on Robotics, Artificial Intelligence and Information Engineering","979-8-4007-1831-1","","10.1145/3689299.3689319","https://doi.org/10.1145/3689299.3689319","The emergence of large language models has brought about revolutionary changes in the field of natural language processing and has shown extraordinary potential in general tasks and various specific domain tasks, especially in the legal field. However, there are still many factors that constrain the application of large language models in the legal field, with the main problems being the lack of domain knowledge and the ability to apply knowledge to solve problems. Therefore, we propose Lawyer GPT, a legal large model that incorporates domain knowledge by using an external knowledge retrieval module to combine an external knowledge base and possesses legal reasoning capabilities. We have collected a large amount of legal domain data and combined it with general domain data, using GPT-4 Turbo to build a high-quality legal dataset. To make Lawyer GPT's legal reasoning capabilities more reliable, we have performed supervised fine-tuning on this dataset, providing it with a good ability to apply domain knowledge to solve problems and enabling it to independently handle various legal professional issues. In addition, we have constructed a legal knowledge base and used retrieval enhancement techniques to provide Lawyer GPT with tools to retrieve external domain knowledge, thereby improving the factual and rationality of the generated content. Experimental results show that Lawyer GPT has demonstrated good performance in both subjective and objective legal domain tests, showing a strong ability to handle legal issues.","2024","2025-02-19 14:42:18","2025-02-19 14:42:18","","108–112","","","","","","","RAIIE '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"666ZYNLM","conferencePaper","2024","Cheong, Inyoung; Xia, King; Feng, K. J. Kevin; Chen, Quan Ze; Zhang, Amy X.","(A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency","979-8-4007-0450-5","","10.1145/3630106.3659048","https://doi.org/10.1145/3630106.3659048","Large language models (LLMs) are increasingly capable of providing users with advice in a wide range of professional domains, including legal advice. However, relying on LLMs for legal queries raises concerns due to the significant expertise required and the potential real-world consequences of the advice. To explore when and why LLMs should or should not provide advice to users, we conducted workshops with 20 legal experts using methods inspired by case-based reasoning. The provided realistic queries (“cases”) allowed experts to examine granular, situation-specific concerns and overarching technical and legal constraints, producing a concrete set of contextual considerations for LLM developers. By synthesizing the factors that impacted LLM response appropriateness, we present a 4-dimension framework: (1) User attributes and behaviors, (2) Nature of queries, (3) AI capabilities, and (4) Social impacts. We share experts’ recommendations for LLM response strategies, which center around helping users identify ‘right questions to ask’ and relevant information rather than providing definitive legal judgments. Our findings reveal novel legal considerations, such as unauthorized practice of law, confidentiality, and liability for inaccurate advice, that have been overlooked in the literature. The case-based deliberation method enabled us to elicit fine-grained, practice-informed insights that surpass those from de-contextualized surveys or speculative principles. These findings underscore the applicability of our method for translating domain-specific professional knowledge and practices into policies that can guide LLM behavior in a more responsible direction.","2024","2025-02-19 14:42:18","2025-02-19 14:42:18","","2454–2469","","","","","","","FAccT '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rio de Janeiro, Brazil","","","","AI chatbots; AI ethics; AI policy; AI regulation; case-based reasoning; human-AI interaction; large language model (LLM); lawyers; legal advice; professional ethics; responsible AI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XW8G3DPW","journalArticle","2024","Wintersgill, Nathan; Stalnaker, Trevor; Heymann, Laura A.; Chaparro, Oscar; Poshyvanyk, Denys","“The Law Doesn’t Work Like a Computer”: Exploring Software Licensing Issues Faced by Legal Practitioners","Proc. ACM Softw. Eng.","","","10.1145/3643766","https://doi.org/10.1145/3643766","Most modern software products incorporate open source components, which requires compliance with each component's licenses. As noncompliance can lead to significant repercussions, organizations often seek advice from legal practitioners to maintain license compliance, address licensing issues, and manage the risks of noncompliance. While legal practitioners play a critical role in the process, little is known in the software engineering community about their experiences within the open source license compliance ecosystem. To fill this knowledge gap, a joint team of software engineering and legal researchers designed and conducted a survey with 30 legal practitioners and related occupations and then held 16 follow-up interviews. We identified different aspects of OSS license compliance from the perspective of legal practitioners, resulting in 14 key findings in three main areas of interest: the general ecosystem of compliance, the specific compliance practices of legal practitioners, and the challenges that legal practitioners face. We discuss the implications of our findings.","2024-07","2025-02-19 14:42:18","2025-02-19 14:42:18","","","","FSE","1","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Legal Practitioners; Open Source Software; Software Licensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V3J8N8VT","conferencePaper","2022","Klaus, Svea; Van Hecke, Ria; Djafari Naini, Kaweh; Altingovde, Ismail Sengor; Bernabé-Moreno, Juan; Herrera-Viedma, Enrique","Summarizing Legal Regulatory Documents using Transformers","Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval","978-1-4503-8732-3","","10.1145/3477495.3531872","https://doi.org/10.1145/3477495.3531872","Companies invest a substantial amount of time and resources in ensuring the compliance to the existing regulations or in the form of fines when compliance cannot be proven in auditing procedures. The topic is not only relevant, but also highly complex, given the frequency of changes and amendments, the complexity of the cases and the difficulty of the juristic language. This paper aims at applying advanced extractive summarization to democratize the understanding of regulations, so that non-jurists can decide which regulations deserve further follow-up. To achieve that, we first create a corpus named EUR-LexSum EUR-LexSum containing 4595 curated European regulatory documents and their corresponding summaries. We then fine-tune transformer-based models which, applied to this corpus, yield a superior performance (in terms of ROUGE metrics) compared to a traditional extractive summarization baseline. Our experiments reveal that even with limited amounts of data such transformer-based models are effective in the field of legal document summarization.","2022","2025-02-19 14:42:18","2025-02-19 14:42:18","","2426–2430","","","","","","","SIGIR '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Madrid, Spain","","","","eur-lex; extractive text summarization; legal ir; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MAGDFTTK","conferencePaper","2025","Qi, Yushuai; Shi, Yuntao; Song, Zhigao; Zhang, Shufeng","Model Predictive Control-Based Secondary Dynamic Compensation for Voltage and Frequency Regulation in Islanded Microgrids","Proceedings of the 2024 2nd International Conference on Frontiers of Intelligent Manufacturing and Automation","979-8-4007-1068-1","","10.1145/3704558.3704575","https://doi.org/10.1145/3704558.3704575","In response to situations such as grid line faults or disconnection of distributed generator (DG).This requires that during isolated microgrid operation, frequency and voltage variations are controlled within acceptable ranges, and power is allocated reasonably. This paper focuses on isolated microgrid systems. Propose a dynamic voltage-frequency secondary compensation control strategy based on model predictive control (MPC)method. This strategy achieves dynamic compensation of frequency and voltage using only local measurement values and relevant information from adjacent DG. First, the article introduces the model used for controller design. Then, utilizing the model predictive control algorithm, it optimizes the objective function by designing constraints that reflect system behavior, thereby proposing a model predictive control-based secondary control strategy. Subsequently, by minimizing the objective function, the article derives the optimal solution of the system and determines the compensating amount for primary control acting on the system. Finally, through experiments in different scenarios, the feasibility and effectiveness of the proposed solution are verified.","2025","2025-02-19 14:42:18","2025-02-19 14:42:18","","269–273","","","","","","","CFIMA '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","microgrid; model predictive control; secondary control; voltage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JTVKH2KP","conferencePaper","2024","Gumusel, Ece; Xiao, Yue; Qin, Yue; Qin, Jiaxin; Liao, Xiaojing","Understanding Legal Professionals' Practices and Expectations in Data Breach Incident Reporting","Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security","979-8-4007-0636-3","","10.1145/3658644.3690357","https://doi.org/10.1145/3658644.3690357","Legal professionals are essential in analyzing data breach incident reports and guiding the response to comply with data privacy laws and regulations. Their expertise helps mitigate privacy and security risks and prevents failures in privacy compliance. However, little research has been done to understand how legal professionals perceive, react to, and face challenges within the data breach incident reporting procedure. In this study, we conducted a simulated incident report assessment experiment and semi-structured interviews with 33 legal professionals who varied in age, gender, and legal background. We reported the criteria used by legal professionals to identify privacy-related items and also uncovered that the agreement among legal professionals on the concepts of privacy-related items is low. Furthermore, we presented findings regarding the perceptions and strategies of legal professionals concerning legal and regulatory compliance, as well as the key features of incident responses that facilitate efficient analysis of data privacy and security law compliance. After taking into account the challenges and suggestions provided by legal professionals, we concluded this study with recommendations for enhancing the effectiveness of legal compliance analysis for incident responses.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","2711–2725","","","","","","","CCS '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salt Lake City, UT, USA","","","","data breach incident reporting; GDPR compliance; legal professionals' practices; security and privacy in legal contexts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"39YFB4W8","conferencePaper","2024","Franke, Lucas; Liang, Huayu; Farzanehpour, Sahar; Brantly, Aaron; Davis, James C.; Brown, Chris","An Exploratory Mixed-methods Study on General Data Protection Regulation (GDPR) Compliance in Open-Source Software","Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement","979-8-4007-1047-6","","10.1145/3674805.3686692","https://doi.org/10.1145/3674805.3686692","Background: Governments worldwide are considering data privacy regulations. These laws, such as the European Union’s General Data Protection Regulation (GDPR), require software developers to meet privacy-related requirements when interacting with users’ data. Prior research describes the impact of such laws on software development, but only for commercial software. Although open-source software is commonly integrated into regulated software, and thus must be engineered or adapted for compliance, we do not know how such laws impact open-source software development. Aims: To understand how data privacy laws affect open-source software (OSS) development, we focus on the European Union’s GDPR, as it is the most prominent such law. We investigated how GDPR compliance activities influence OSS developer activity (RQ1), how OSS developers perceive fulfilling GDPR requirements (RQ2), the most challenging GDPR requirements to implement (RQ3), and how OSS developers assess GDPR compliance (RQ4). Method: We distributed an online survey to explore perceptions of GDPR implementations from open-source developers (N=56). To augment this analysis, we further conducted a repository mining study to analyze development metrics on pull requests (N=31,462) submitted to open-source GitHub repositories. Results: Our results suggest GDPR policies complicate OSS development and introduce challenges, primarily regarding the management of users’ data, implementation costs and time, and assessments of compliance. Moreover, we observed negative perceptions of the GDPR from OSS developers and significant increases in development activity, in particular metrics related to coding and reviewing, on GitHub pull requests related to GDPR compliance. Conclusions: Our findings provide future research directions and implications for improving data privacy policies, motivating the need for relevant resources and automated tools to support data privacy regulation implementation and compliance efforts in OSS.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","325–336","","","","","","","ESEM '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","Data Privacy; Open-Source Software; Regulatory Compliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X6J7DGMT","conferencePaper","2023","Jiang, Cong; Yang, Xiaolei","Legal Syllogism Prompting: Teaching Large Language Models for Legal Judgment Prediction","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595170","https://doi.org/10.1145/3594536.3595170","Legal syllogism is a form of deductive reasoning commonly used by legal professionals to analyze cases. In this paper, we propose legal syllogism prompting (LoT), a simple prompting method to teach large language models (LLMs) for legal judgment prediction. LoT teaches only that in the legal syllogism the major premise is law, the minor premise is the fact, and the conclusion is judgment. Then the models can produce a syllogism reasoning of the case and give the judgment without any learning, fine-tuning, or examples. On CAIL2018, a Chinese criminal case dataset, we performed zero-shot judgment prediction experiments with GPT-3 models. Our results show that LLMs with LoT achieve better performance than the baseline and chain of thought prompting, the state-of-art prompting method on diverse reasoning tasks. LoT enables the model to concentrate on the key information relevant to the judgment and to correctly understand the legal meaning of acts, as compared to other methods. Our method enables LLMs to predict judgment along with law articles and justification, which significantly enhances the explainability of models.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","417–421","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","chain of thought; large language models; legal judgment prediction; legal syllogism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RCK7EDP","conferencePaper","2025","Qin, Weijian; Luo, Xudong","A Legal Fact-Finding Model Based on the T5 and LexiLaw Large Language Models","Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence","979-8-4007-1818-2","","10.1145/3709026.3709070","https://doi.org/10.1145/3709026.3709070","Fact-finding is essential in legal proceedings, where judges determine case facts from presented evidence, forming the basis of judgments. However, existing research on automatic legal fact-finding is limited. Thus, this paper proposes a novel legal fact-finding model, which integrates the T5 and LexiLaw large language models to analyse legal documents. Specifically, we use a rule-based algorithm to divide judicial documents into four parts: introduction, fact, evidence, and judgment result. Then, the introduction and fact parts are input into the final fact-finding result generation model, while the fact, evidence and judgment result parts are input into the evidence reasoning model. Finally, the outputs of the two models are integrated to obtain the fact-finding results. Extensive experiments show that our model surpasses baseline models, achieving an improvement of 10.27% in ROUGE and an increase of 0.13% in macro-F1 scores. Therefore, our model is a robust tool for finding facts and supporting evidence in complex legal judgments, significantly reducing manual workload and paving the way for more efficient legal processes.","2025","2025-02-19 14:42:19","2025-02-19 14:42:19","","229–237","","","","","","","CSAI '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","Fact-finding; Generative Model; Large Language Model.; Legal Intelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLPE6ZUH","conferencePaper","2022","Walsh, Julissa Milligan; Varia, Mayank; Cohen, Aloni; Sellars, Andrew; Bestavros, Azer","Multi-Regulation Computing: Examining the Legal and Policy Questions That Arise From Secure Multiparty Computation","Proceedings of the 2022 Symposium on Computer Science and Law","978-1-4503-9234-1","","10.1145/3511265.3550445","https://doi.org/10.1145/3511265.3550445","This work examines privacy laws and regulations that limit disclosure of personal data, and explores whether and how these restrictions apply when participants use cryptographically secure multi-party computation (MPC). By protecting data during use, MPC offers the promise of conducting data science in a way that (in some use cases) meets or even exceeds most people's conceptions of data privacy. With MPC, it is possible to correlate individual records across multiple datasets without revealing the underlying records, to conduct aggregate analysis across datasets which parties are otherwise unwilling to share for competitive reasons, and to analyze aggregate statistics across datasets which no individual party may lawfully hold. However, most adoptions of MPC to date involve data that is not subject to privacy protection under the law. We posit that a major impediment to the adoption of MPC - on the data that society has deemed most worthy of protection - is the difficulty of mapping this new technology onto the design principles of data privacy laws. While a computer scientist might reasonably believe that transforming any data analysis into its privacy-protective variant using MPC is a clear win, we show in this work that the technological guarantees of MPC do not directly imply compliance with privacy laws. Specifically, a lawyer will likely want to ask several important questions about the pre-conditions that are necessary for MPC to succeed, the risk that data might inadvertently or maliciously be disclosed to someone other than the output party, and what recourse to take if this bad event occurs. We have two goals for this work: explaining why the privacy law questions are nuanced and that the lawyer is correct to proceed cautiously, and providing a framework that lawyers can use to reason systematically about whether and how MPC implicates data privacy laws in the context of a specific use case. Our framework revolves around three questions: a definitional question on whether the encodings still constitute 'personal data,' a process question about whether the act of executing MPC constitutes a data disclosure event, and a liability question about what happens if something goes wrong. We conclude by providing advice to regulators and suggestions to early adopters to spur uptake of MPC. It is our hope that this work provides the first step toward a methodology that organizations can use when contemplating the use of MPC.","2022","2025-02-19 14:42:19","2025-02-19 14:42:19","","53–65","","","","","","","CSLAW '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington DC, USA","","","","data privacy law; secure multi-party computation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9NJQ3I2P","conferencePaper","2024","Huang, Jia-Hong; Yang, Chao-Chun; Shen, Yixian; Pacces, Alessio M.; Kanoulas, Evangelos","Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models","Proceedings of the 33rd ACM International Conference on Information and Knowledge Management","979-8-4007-0436-9","","10.1145/3627673.3680025","https://doi.org/10.1145/3627673.3680025","The legal landscape encompasses a wide array of lawsuit types, presenting lawyers with challenges in delivering timely and accurate information to clients, particularly concerning critical aspects like potential imprisonment duration or financial repercussions. Compounded by the scarcity of legal experts, there's an urgent need to enhance the efficiency of traditional legal workflows. Recent advances in deep learning, especially Large Language Models (LLMs), offer promising solutions to this challenge. Leveraging LLMs' mathematical reasoning capabilities, we propose a novel approach integrating LLM-based methodologies with specially designed prompts to address precision requirements in legal Artificial Intelligence (LegalAI) applications. The proposed work seeks to bridge the gap between traditional legal practices and modern technological advancements, paving the way for a more accessible, efficient, and equitable legal system. To validate this method, we introduce a curated dataset tailored to precision-oriented LegalAI tasks, serving as a benchmark for evaluating LLM-based approaches. Extensive experimentation confirms the efficacy of our methodology in generating accurate numerical estimates within the legal domain, emphasizing the role of LLMs in streamlining legal processes and meeting the evolving demands of LegalAI. Github: https://github.com/Jhhuangkay/Optimizing-Numerical-Estimation-and-Operational-Efficiency-in-the-Legal-Domain.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","4554–4562","","","","","","","CIKM '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","large language models; precision-oriented legal artificial intelligence; tailored prompt design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2J5C944T","conferencePaper","2024","Wolf-Brenner, Christof; Pammer-Schindler, Viktoria; Breitfuss, Gert","How Do Professionals in SMEs Engage With AI and Regulation? An Interview Study in Austria","Proceedings of Mensch Und Computer 2024","979-8-4007-0998-2","","10.1145/3670653.3677514","https://doi.org/10.1145/3670653.3677514","As Artificial Intelligence (AI) technology is becoming more widespread, small to medium sized enterprises (SMEs) are beginning to use it extensively. This paper presents the results of an interview study with eight CEOs or co-founders of SMEs. We explore the practical applications of AI technologies within these SMEs and their anticipation of forthcoming European AI regulations, specifically the AI Act. Additionally, we also investigate attitudes and dispositions towards voluntary codes of conduct as outlined within it. This study aims to shed light on the operational, regulatory, and ethical dimensions of AI integration within SMEs. It reveals that SMEs favor third-party AI systems, particularly those based on Large Language Models (LLMs), due to their convenience and minimal integration effort. Additionally, SMEs are keenly aware of their need for external support to navigate upcoming AI regulations, emphasizing the importance of tailored interventions to ensure compliance and optimal use of AI technologies. Lastly, SMEs view voluntary codes of conduct as outlined in the AI Act as a testament to a company’s commitment to go beyond mere legal compliance, thus reinforcing trust. Based on our findings, we propose three design implications for the HCI community: convenient AI integration, post-adoptive regulatory support, and proactive ethical design.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","646–650","","","","","","","MuC '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Karlsruhe, Germany","","","","AI Adoption; AI Regulation; Code of Conduct; Interview Study; SME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJVYREGZ","conferencePaper","2014","Ghanavati, Sepideh; Amyot, Daniel; Rifaut, André","Legal goal-oriented requirement language (legal GRL) for modeling regulations","Proceedings of the 6th International Workshop on Modeling in Software Engineering","978-1-4503-2849-4","","10.1145/2593770.2593780","https://doi.org/10.1145/2593770.2593780","Every year, governments introduce new or revised regulations that are imposing new types of requirements on software development. Analyzing and modeling these legal requirements is time consuming, challenging and cumbersome for software and requirements engineers. Having regulation models can help understand regulations and converge toward better compliance levels for software and systems. This paper introduces a systematic method to extract legal requirements from regulations by mapping the latter to the Legal Profile for Goal-oriented Requirements Language (GRL) (Legal GRL). This profile provides a conceptual meta-model for the anatomy of regulations and maps its elements to standard GRL with specialized annotations and links, with analysis techniques that exploit this additional information. The paper also illustrates examples of Legal GRL models for The Privacy and Electronic Communications Regulations. Existing tool support (jUCMNav) is also extended to support Legal GRL modeling.","2014","2025-02-19 14:42:19","2025-02-19 14:42:19","","1–6","","","","","","","MiSE 2014","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hyderabad, India","","","","Goal Modeling; Legal Requirements; Software Compliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EZAGLXM","journalArticle","2024","Stampf, Annika; Colley, Mark; Knuth, Ann-Kathrin; Tasci, Cagla; Rukzio, Enrico","Examining Psychological Conflict-Handling Strategies for Highly Automated Vehicles to Resolve Legal User-Vehicle Conflicts","Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.","","","10.1145/3678511","https://doi.org/10.1145/3678511","As vehicle automation progresses, with SAE levels 3 to 5 introducing varying degrees of control transfer from driver to vehicle, a key challenge emerges: aligning driver interests with the automated vehicle's (AV) operational goals. Despite technical feasibility, drivers' tendencies to intervene due to distrust in or dissatisfaction with AVs necessitate consideration of control mechanisms in future AV designs. This study investigates the potential of persuasion strategies inspired by Human-Robot Interaction research to harmonize driver actions with AV goals in legal conflict situations. We conducted a Virtual Reality driving simulator study with 36 participants, comparing 11 persuasive conflict-handling strategies and a baseline of no persuasion. Our research helps understand the effects of persuasion on users' compliance with law-abiding AV goals, trust, and acceptance towards the AV and evaluates the effectiveness of these strategies based on their working mechanism (cognitive, emotional, social, politeness) and valence (negative, neutral, positive). Results show that none of the strategies could substantially increase compliance with the AV, but neutral and positive persuasion strategies did not decrease acceptance and trust towards the AV compared to no persuasion. These findings contribute to the discourse on cooperation design and control allocation in AVs, particularly in scenarios involving legal conflicts.","2024-09","2025-02-19 14:42:19","2025-02-19 14:42:19","","","","3","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","automated vehicles; conflict-handling strategies; legal conflict; user-vehicle conflicts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8R7JWNXY","conferencePaper","2023","Governatori, Guido; Rotolo, Antonino","Deontic Ambiguities in Legal Reasoning","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595175","https://doi.org/10.1145/3594536.3595175","What happens if the way in which we handle a genuine deontic conflict —i.e., a deontic ambiguity— matters regarding the application of other norms that are not directly affected by that conflict? We argue that the law requires sometimes propagating the ambiguity to other norms and sometimes confining it to some norms only. We explore this issue and model different reasoning patterns. The problem is addressed in a new variant of Defeasible Deontic Logic. The contribution of this paper is threefold: (a) we extend the treatment of ambiguity blocking and propagation to Defeasible Deontic Logic; (b) we discuss reasoning patterns in the law, especially in criminal law, where we need to deal with both ambiguity blocking and ambiguity propagation in the same legal system and logic; (c) we devise an annotated variant of Defeasible Deontic Logic where we distinguish literals that must be obtained through an ambiguity-blocking mechanism from those that are derived using an ambiguity-propagating mechanism.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","91–100","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","Ambiguity Blocking; Ambiguity Propagation; Defeasible Deontic Logic; Deontic Ambiguities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSXPVXDN","conferencePaper","2024","Wang, Changyue; Su, Weihang; Hu, Yiran; Ai, Qingyao; Wu, Yueyue; Luo, Cheng; Liu, Yiqun; Zhang, Min; Ma, Shaoping","LeKUBE: A Knowledge Update BEnchmark for Legal Domain","Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region","979-8-4007-0724-7","","10.1145/3673791.3698407","https://doi.org/10.1145/3673791.3698407","Recent advances in Large Language Models (LLMs) have significantly shaped the applications of AI in multiple fields, including the studies of legal intelligence. Trained on extensive legal texts, including statutes and legal documents, the legal LLMs can capture important legal knowledge/concepts effectively and provide important support for downstream legal applications such as legal consultancy. Yet, the dynamic nature of legal statutes and interpretations also poses new challenges to the use of LLMs in legal applications. Particularly, how to update the legal knowledge of LLMs effectively and efficiently has become an important research problem in practice. Existing benchmarks for evaluating knowledge update methods are mostly designed for the open domain and cannot address the specific challenges of the legal domain, such as the nuanced application of new legal knowledge, the complexity and lengthiness of legal regulations, and the intricate nature of legal reasoning.To address this gap, we introduce the Legal Knowledge Update BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for legal LLMs across five dimensions. Specifically, we categorize the needs of knowledge updates in the legal domain with the help of legal professionals, and then hire annotators from law schools to create synthetic updates to the Chinese Criminal and Civil Code as well as sets of questions of which the answers would change after the updates. Through a comprehensive evaluation of state-of-the-art knowledge update methods, we reveal a notable gap between existing knowledge update methods and the unique needs of the legal domain, emphasizing the need for further research and development of knowledge update mechanisms tailored for legal LLMs.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","175–185","","","","","","","SIGIR-AP 2024","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tokyo, Japan","","","","domain-specific evaluation; knowledge update; large language model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"99GDKZNX","conferencePaper","2025","Kawakami, Anna; Wilkinson, Daricia; Chouldechova, Alexandra","Do Responsible AI Artifacts Advance Stakeholder Goals? Four Key Barriers Perceived by Legal and Civil Stakeholders","Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society","","","","","The responsible AI (RAI) community has introduced numerous processes and artifacts—such as Model Cards, Transparency Notes, and Data Cards—to facilitate transparency and support the governance of AI systems. While originally designed to scaffold and document AI development processes in technology companies, these artifacts are becoming central components of regulatory compliance under recent regulations such as the EU AI Act. Much of the existing literature has focussed on the design of new RAI artifacts or their use by practitioners within technology companies. However, as RAI artifacts begin to play key roles in enabling external oversight, it becomes critical to understand how stakeholders—particularly stakeholders situated outside of technology companies who govern and audit industry AI deployments—perceive the efficacy of RAI artifacts. In this study, we conduct semi-structured interviews and design activities with 19 government, legal, and civil society stakeholders who inform policy and advocacy around responsible AI efforts. While participants believe that RAI artifacts are a valuable contribution to the broader AI governance ecosystem, many have concerns around their potential unintended and longer-term impacts on actors outside of technology companies (e.g., downstream end-users, policymakers, civil society stakeholders). We organized these beliefs into four barriers that help explain how RAI artifacts may (inadvertently) reconfigure power relations across civil society, government, and industry, impeding civil society and legal stakeholders' ability to protect downstream end-users from potential AI harms. Participants envision how structural changes, along with changes in how RAI artifacts are designed, used, and governed, could help re-direct the role of artifacts to support more collaborative and proactive external oversight of AI systems. We discuss research and policy implications for RAI artifacts.","2025","2025-02-19 14:42:19","2025-02-19 14:42:19","","670–682","","","","","","","AIES '24","","","","AAAI Press","","","","","","","","","Place: San Jose, California, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FSH6GSWJ","conferencePaper","2024","Padhye, Rohan","Software Engineering Methods for AI-Driven Deductive Legal Reasoning","Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software","979-8-4007-1215-9","","10.1145/3689492.3690050","https://doi.org/10.1145/3689492.3690050","The recent proliferation of generative artificial intelligence (AI) technologies such as pre-trained large language models (LLMs) has opened up new frontiers in computational law. An exciting area of development is the use of AI to automate the deductive rule-based reasoning inherent in statutory and contract law. This paper argues that such automated deductive legal reasoning can now be viewed from the lens of software engineering, treating LLMs as interpreters of natural-language programs with natural-language inputs. We show how it is possible to apply principled software engineering techniques to enhance AI-driven legal reasoning of complex statutes and to unlock new applications in automated meta-reasoning such as mutation-guided example generation and metamorphic property-based testing.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","85–95","","","","","","","Onward! '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pasadena, CA, USA","","","","computational law; large language models; example generation; generative artificial intelligence; legal reasoning; mutation testing; property-based testing; software engineering; statutory reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAXCWKMP","conferencePaper","2023","De Luca, Ernesto William; Fiorelli, Manuel; Picca, Davide; Stellato, Armando; Wehnert, Sabine","Legal Information Retrieval meets Artificial Intelligence (LIRAI)","Proceedings of the 34th ACM Conference on Hypertext and Social Media","979-8-4007-0232-7","","10.1145/3603163.3610575","https://doi.org/10.1145/3603163.3610575","The Legal Information Retrieval meets Artificial Intelligence (LIRAI) workshop series aims to provide a venue hosting discussion of novel ideas, evaluations, and success stories concerning the application of Artificial Intelligence (AI) and Information Retrieval (IR) to the legal domain. All around the world, lawmakers, legal professionals, and citizens must cope with the sheer amount of legal knowledge present in legal documents. These documents can be norms, regulations, directives, legal cases, and other relevant material for legal practitioners, such as legal commentary. The continuous evolution of legal documents is a challenging setting, with implicit relationships playing an important role beyond explicit references. Recently, the adoption of shared machine-readable formats and FAIR principles, as well as methods and practices from the Semantic Web, have certainly improved the accessibility of legal knowledge and its interoperability. Still, retrieving legal knowledge and making sense of it are not solved problems. The legal community often has special requirements for retrieval systems (e.g., high recall, explainability). Artificial Intelligence (AI) is positioned as a lever to enhance our ability to find, understand, and correlate legal information, and to comprehend its relationship to reality, in terms of compliance evaluation and risk/benefit analysis. We call contributions on these topics in the form of papers, which will be collected in an open-access proceedings published on CEURWS.org and thus indexed by Scopus, DBLP, Google Scholar, and other citation databases.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","","","","","","","","HT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rome, Italy","","","","Explainable AI; FAIRness; High-Recall Retrieval; Legal Compliance; Legal Informatics; Legal Information Retrieval; Legal Knowledge Representation; Legal Text Mining; Linguistic Legal Linked Open Data; Semantic Web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IZGZ9AVQ","conferencePaper","2024","Liu, Bulou; Zhu, Zhenhao; Ai, Qingyao; Liu, Yiqun; Wu, Yueyue","LeDQA: A Chinese Legal Case Document-based Question Answering Dataset","Proceedings of the 33rd ACM International Conference on Information and Knowledge Management","979-8-4007-0436-9","","10.1145/3627673.3679154","https://doi.org/10.1145/3627673.3679154","Legal question answering based on case documents is a pivotal legal AI application and helps extract key elements from the legal case documents to promote downstream tasks. Intuitively, the form of this task is similar to legal machine reading comprehension. However, in existing legal machine reading comprehension datasets, the background information is much shorter than the legal case documents, and the questions are not designed from the perspective of legal knowledge. In this paper, we present LeDQA, the first Chinese legal case document-based question answering dataset to our best knowledge. Specifically, we build a comprehensive question schema (including 48 element-based questions) for the Chinese civil law by legal professionals. And considering the cost of human annotations are too expensive, we use one of the SOTA LLMs (i.e., GPT-4) to annotate the relevant sentences to these questions in each case document. The constructed dataset originates from Chinese civil cases and contains 100 case documents, 4,800 case-question pairs and 132,048 sentence-level relevance annotations. We implement several text matching algorithms for relevant sentence selection and various Large Language Models(LLMs) for legal question answering on LeDQA. The experimental results indicate that incorporating relevant sentences can benefit the performance of question answering models, but further efforts are still required to address the remaining challenges such as retrieving irrelevant sentences and incorrect reasoning between retrieved sentences.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","5385–5389","","","","","","","CIKM '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","large language models; datasets; legal question answering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBYTATPN","conferencePaper","2024","Zhang, Shuang","Effect of Environmental Regulation on the Transformation of Industrial Enterprises Based on DID model","Proceedings of the 2023 6th International Conference on E-Business, Information Management and Computer Science","979-8-4007-0933-3","","10.1145/3644479.3644484","https://doi.org/10.1145/3644479.3644484","This paper adopts the DID method to test the impact of environmental regulation on the transformation of industrial base enterprises based on the energy saving and emission reduction target responsibility system of China's Eleventh Five-Year Plan, with China's old industrial bases as the research object. The results of the benchmark regression show that the policy hinders the transformation and development of industrial enterprises in the industrial base. The results of the event study method show that the DID method is reasonable. This paper uses the DOP decomposition method to examine the impact mechanism, and the results show that policies affect firm transformation mainly by influencing resource allocation in the industrial sector and the entry of high-productivity firms. Our study provides empirical evidence for policy formulation for the transformation and development of industrial cities in developing countries.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","29–33","","","","","","","EBIMCS '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hong Kong, Hong Kong","","","","DID method; DOP Decomposition; Environmental regulation; Event study method; Transformation of enterprises","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAMVCEEP","conferencePaper","2024","Kempe, Evelyn; Massey, Aaron; Seaman, Carolyn; Sampath, Sreedevi; Semsar, Samin","Modeling, Analyzing and Communicating Regulatory Ambiguity: An Empirical study","Proceedings of the 1st IEEE/ACM Workshop on Multi-Disciplinary, Open, and RElevant Requirements Engineering","979-8-4007-0569-4","","10.1145/3643666.3648576","https://doi.org/10.1145/3643666.3648576","Regulations outline high-level guidance or expectations for a profession or industry. Analyzing laws or regulations is one way a software developer would derive and document regulatory compliance requirements within their software design. However, ambiguities within regulations can make it challenging to define technical software design specifications for regulatory requirements. Further, due to the subjective nature of ambiguous phrasing within a law or regulation, the interpretation of the legal text can differ based on the interpreter's perspective. Our study examines whether software developers can analyze regulatory ambiguities as a group using our modeling process and our online Ambiguity Heuristics Analysis Builder (AHAB) tool.Eleven participants formed three groups and modeled ambiguities within a regulation using our process and tool. Modeling regulatory ambiguity, while difficult for our participants, allowed them to communicate potential issues, ask meaningful questions, and deepen their knowledge of the regulation. Ambiguity modeling allows developers to articulate interpretation and compliance issues with the laws to other parties (i.e., lawyers) and document this requirement analysis step for future use. Documenting these intermediate steps is rarely highlighted in requirement analysis. However, it is useful to negotiate with regulators, avoid negligence, and show due diligence toward regulatory compliance. It can also lead to clarifying guidance software developers need to make better, more compliant choices during software design.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","28–34","","","","","","","MO2RE 2024","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Lisbon, Portugal","","","","modeling; regulatory ambiguity analysis; software development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NMVXW8NJ","conferencePaper","2025","Loefflad, Carmen; Chen, Mo; Grossklags, Jens","Social Scoring Systems for Behavioral Regulation: An Experiment on the Role of Transparency in Determining Perceptions and Behaviors","Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society","","","","","Recent developments in artificial intelligence research have advanced the spread of automated decision-making (ADM) systems used for regulating human behaviors. In this context, prior work has focused on the determinants of human trust in and the legitimacy of ADM systems, e.g., when used for decision support. However, studies assessing people's perceptions of ADM systems used for behavioral regulation, as well as the effect on behaviors and the overall impact on human communities are largely absent. In this paper, we experimentally investigate people's behavioral adaptations to, and their perceptions of an institutionalized decision-making system, which resembled a social scoring system. Using social scores as incentives, the system aimed at ensuring mutual fair treatment between members of experimental communities. We explore how the provision of transparency affected people's perceptions, behaviors, as well as the well-being of the communities. While a non-transparent scoring system led to disparate impacts both within as well as across communities, transparency helped people develop trust in each other, create wealth, and enabled them to benefit from the system in a more uniform manner. A transparent system was perceived as more effective, procedurally just, and legitimate, and led people to rely more strongly on the system. However, transparency also made people strongly discipline those with a low score. This suggests that social scoring systems that precisely disclose past behaviors may also impose significant discriminatory consequences on individuals deemed non-compliant.","2025","2025-02-19 14:42:19","2025-02-19 14:42:19","","891–904","","","","","","","AIES '24","","","","AAAI Press","","","","","","","","","Place: San Jose, California, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLENHFFV","conferencePaper","2021","Rotolo, Antonino; Smith, Clara","Modelling legal procedures","Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law","978-1-4503-8526-8","","10.1145/3462757.3466089","https://doi.org/10.1145/3462757.3466089","A legal procedure in court proceedings is a sequence of actions in which the last action is (the creation of) a(n individual) norm, where the court settles that it is obligatory in the interest of some agents that other agents bring about a certain state of affairs. This paper models legal procedures by using a variant of Propositional Dynamic Logic (PDL) enriched with a preference operator for prioritising procedural actions. The key reason towards the usage of PDL is that, in procedural law, claims and resolutions resemble programs to be executed. Requests are organised in a preference order and resolutions have their own dynamics of execution (either spontaneously by the one obliged and/or by force of law).","2021","2025-02-19 14:42:19","2025-02-19 14:42:19","","220–224","","","","","","","ICAIL '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: São Paulo, Brazil","","","","legal procedures; PDL; preferences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9BN4247G","conferencePaper","2023","Ma, Chiyuan; Hu, Xiangcheng","A Data Analysis Privacy Regulation Compliance Scheme for Lakehouse","Proceedings of the 2023 2nd International Conference on Algorithms, Data Mining, and Information Technology","979-8-4007-0762-9","","10.1145/3625403.3625405","https://doi.org/10.1145/3625403.3625405","To meet the diverse data storage and analysis needs in the Internet of Things era, businesses embrace the lakehouse approach, a hybrid deployment of data lakes and data warehouses on a single platform. Data consumers leverage data mining techniques through open APIs to explore data’s untapped potential. However, concerns arise regarding compliant data access and utilization. While privacy regulations like the General Data Protection Regulation (GDPR) offer conceptual guidance, their technical implementations remain vague. This paper proposes a privacy regulation compliance framework specific to lakehouse data analysis. By introducing a compliance verification layer between the analysis and processing layers, the scheme enables regulatory adherence. The utilization of Trusted Execution Environments (TEEs) guarantees verification of analysis requests, with blockchain serving as a storage medium for results. To mitigate unauthorized data analysis, we introduce a reputation-based punishment mechanism. Experimental results demonstrate the scheme’s feasibility.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","1–5","","","","","","","ADMIT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chengdu, China","","","","Blockchain; Data Analysis; Lakehouse; Privacy Regulation; Trusted Execution Environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XLAAIRMW","conferencePaper","2024","Ujwal, Utkarsh; Surampudi, Sai Sri Harsha; Mitra, Sayantan; Saha, Tulika","""Reasoning before Responding"": Towards Legal Long-form Question Answering with Interpretability","Proceedings of the 33rd ACM International Conference on Information and Knowledge Management","979-8-4007-0436-9","","10.1145/3627673.3680082","https://doi.org/10.1145/3627673.3680082","Long-Form Question Answering (LFQA) represents a growing interest in Legal Natural Language Processing (Legal-NLP) as many individuals encounter legal disputes at some point in their lives, but lack of knowledge about how to negotiate these complex situations might put them at risk. The endeavor to generate detailed answers to contextually rich legal questions has faced challenges, primarily due to the limited availability of specialized datasets involving intensive manual effort or incapability of existing LFQA models to produce informative responses. Addressing this, our research introduces a semi-synthetic dataset, Legal-LFQA (L2FQA) created by exploiting a large language model (LLM) and utilizing contexts derived from existing legal datasets. Additionally, we hypothesize that integrating legal reasoning into the answer generation process of the LLMs will help bolster both the quality and interpretability of the produced responses. We systematically analyze the quality of L2FQA using human evaluation and natural language inference based metrics. Next, we benchmark L2FQA on a wide range of general-purpose and domain-specific LLMs using fine-tuning and in-context learning (with zero, one and few shot) strategies. The efficacy of these techniques is gauged through several automated and human evaluations. Results indicate that incorporating legal reasoning into the answer generation process provides an avenue for improving the quality of responses in the context of Legal-LFQA task. By addressing the challenges faced in LFQA and emphasizing the potential of interpretability, this research contributes to the foundational work in enhancing question-answering systems within the legal domain.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","4922–4930","","","","","","","CIKM '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","large language models; interpretability; legal domain; long-form question answering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4T48QG5","journalArticle","2023","Baudon, Thaïs; Radanne, Gabriel; Gonnord, Laure","Bit-Stealing Made Legal: Compilation for Custom Memory Representations of Algebraic Data Types","Proc. ACM Program. Lang.","","","10.1145/3607858","https://doi.org/10.1145/3607858","Initially present only in functional languages such as OCaml and Haskell, Algebraic Data Types (ADTs) have now become pervasive in mainstream languages, providing nice data abstractions and an elegant way to express functions through pattern matching. Unfortunately, ADTs remain seldom used in low-level programming. One reason is that their increased convenience comes at the cost of abstracting away the exact memory layout of values. Even Rust, which tries to optimize data layout, severely limits control over memory representation. In this article, we present a new approach to specify the data layout of rich data types based on a dual view: a source type, providing a high-level description available in the rest of the code, along with a memory type, providing full control over the memory layout. This dual view allows for better reasoning about memory layout, both for correctness, with dedicated validity criteria linking the two views, and for optimizations that manipulate the memory view. We then provide algorithms to compile constructors and destructors, including pattern matching, to their low-level memory representation. We prove our compilation algorithms correct, implement them in a tool called ribbit that compiles to LLVM IR, and show some early experimental results.","2023-08","2025-02-19 14:42:19","2025-02-19 14:42:19","","","","ICFP","7","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Algebraic Data Types; Compilation; Data Layouts; Pattern Matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ABPMVVJ","bookSection","2025","Carpenter, Daniel; Ezell, Carson","An FDA for AI? Pitfalls and Plausibility of Approval Regulation for Frontier Artificial Intelligence","Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society","","","","","Observers and practitioners of artificial intelligence (AI) have proposed an FDA-style licensing regime for the most advanced AI models, or 'frontier' models. In this paper, we explore the applicability of approval regulation - that is, regulation of a product that combines experimental minima with government licensure conditioned partially or fully upon that experimentation - to the regulation of frontier AI. There are a number of reasons to believe that approval regulation, simplistically applied, would be inapposite for frontier AI risks. Domains of weak fit include the difficulty of defining the regulated product, the presence of Knightian uncertainty or deep ambiguity about harms from AI, the potentially transmissible nature of risks, and distributed activities among actors involved in the AI lifecycle. We conclude by highlighting the role of policy learning and experimentation in regulatory development, describing how learning from other forms of AI regulation and improvements in evaluation and testing methods can help to overcome some of the challenges we identify.","2025","2025-02-19 14:42:19","2025-02-19 14:42:19","","239–254","","","","","","","","","","","AAAI Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3XK3RRTR","conferencePaper","2023","Lucaj, Laura; van der Smagt, Patrick; Benbouzid, Djalel","AI Regulation Is (not) All You Need","Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency","979-8-4007-0192-4","","10.1145/3593013.3594079","https://doi.org/10.1145/3593013.3594079","The development of processes and tools for ethical, trustworthy, and legal AI is only beginning. At the same time, legal requirements are emerging in various jurisdictions, following a deluge of ethical guidelines. It is therefore key to explore the necessary practices that must be adopted to ensure the quality of AI systems, mitigate their potential risks and enable legal compliance. Ensuring that the potential negative impacts of AI on individuals, society, and the environment are mitigated will depend on many factors, including the capacity to properly regulate its deployment and to mandate necessary internal best practices along lifecycles. Regulatory frameworks must evolve from abstract requirements to providing concrete operational mandates that enable better oversight mechanisms in the way AI systems operate, how they are developed, and how they are deployed. In view of the above, this paper explores the necessary practices that can be adopted throughout a comprehensive lifecycle audit as a key practice to ensure the quality of AI systems and enable the development of compliance mechanisms. It also discusses novel governance tools that enable bridging the current operational gaps. Such gaps were identified by interviewing experts, analysing adaptable tools and methodologies from the software engineering domain, and by exploring the state of the art of auditing. The results present recommendations for novel tools and oversight mechanisms for governing AI systems.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","1267–1279","","","","","","","FAccT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","AI regulation; algorithmic auditing; ethical AI; machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XQHFC4LG","conferencePaper","2022","Monteiro, Lucas Henrique de Assis; Rodrigues, Cleyton Mário de Oliveira; Sousa, Aêda Monalliza Cunha de","An Information System for Law Integrating Ontological Bases with a Legal Reasoner Chatbot","Proceedings of the XVIII Brazilian Symposium on Information Systems","978-1-4503-9698-1","","10.1145/3535511.3535555","https://doi.org/10.1145/3535511.3535555","Context: The Semantic Web aims to assign meanings to resources available on the internet so that humans and computers can understand them. It can be used in the most diverse contexts, facilitating the development of systems where expert knowledge is formalized through logical-mathematical resources, mitigating potential inconsistencies, and promoting more human-friendly interaction services. Problem: The existence of semantic anomalies (use of rhetorical language, polysemy and inaccuracies) in the Brazilian Legal Domain enables the use of Semantic Web standards and technologies to mitigate these problems. Solution: This work deals with the development of an Information System that uses resources from the Semantic Web for the formal representation and the realization of legal inferences about Crimes Against Property. SI Theory: The Behavioral Decision Theory was approached, mainly in the incorporation of real patterns of decision making. Method: Bibliographic and documentary research methods were used to list the main concepts related to the Criminal Types investigated. The research is prescriptive and has a quali-quantitative approach. Summary of Results: A prototype system is presented, integrating ontologies of Brazilian Law with a chatbot that enables interaction with users in natural language, as well as performing reasoning tasks based on the knowledge formalized in these ontologies. Contributions and Impact in the IS area: The research will contribute to the automation of decision-making processes involving crimes against property, serving as an aid for professionals or law students and for legal simulations by ordinary people. Furthermore, it will serve as a reference for the development of other information systems with similar objectives in other contexts.","2022","2025-02-19 14:42:19","2025-02-19 14:42:19","","","","","","","","","SBSI '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Curitiba, Brazil","","","","Law; Ontology; Chatbot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMDUIXJ4","conferencePaper","2024","Ko, Sang-Jo; Seo, Jeong-Eun; Kwon, Hun-Yeong","A Study on the Jurisdiction and Regulation of offshore Online Gambling between trading countries","Proceedings of the 17th International Conference on Theory and Practice of Electronic Governance","979-8-4007-1780-2","","10.1145/3680127.3680138","https://doi.org/10.1145/3680127.3680138","Through the development of information and communication technology and COVID-19, the offline-oriented meandering industry is rapidly shifting its axis to online spaces. Unlike physical spaces, online spaces have no time and space constraints, easy access, and low entry barriers, and many online gambling sites have open markets and provide offshore gambling services with various gambling portal services in the form of large platforms in countries where gambling is prohibited or restricted, resulting in regulatory limitations within the scope of jurisdiction and difficulties in operating effective regulatory frames, making gray or illegal markets increasingly active. This paper compares and analyzes the gambling industry policies and systems of major countries, and refers to major WTO and EU disputes to derive institutional supplements and effective measures for technical changes to present a reasonable governance model of offshore regulation to secure freedom and jurisdiction in the provision of online gambling services between trading countries","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","166–175","","","","","","","ICEGOV '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","cross-border Jurisdiction; Illegal gambling; Offshore regulations; Online gambling services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4R88FQSY","conferencePaper","2024","Ye, Fuda; Li, Shuangyin","MileCut: A Multi-view Truncation Framework for Legal Case Retrieval","Proceedings of the ACM Web Conference 2024","979-8-4007-0171-9","","10.1145/3589334.3645349","https://doi.org/10.1145/3589334.3645349","In the search process, it is essential to strike a balance between effectiveness and efficiency to improve search experience. Thus, ranking list truncation has become increasingly crucial. Especially in the legal domain, irrelevant cases can severely increase search costs and even compromise the pursuit of legal justice. However, there are truncation challenges that mainly arise from the distinctive structure of legal case documents, where the elements such as fact, reasoning, and judgement in a case serve as different but multi-view texts, which could result in a bad performance if the multi-view texts cannot be well-modeled. Existing approaches are limited due to their inability to handle multi-view elements information and their neglect of semantic interconnections between cases in the ranking list. In this paper, we propose a multi-view truncation framework for legal case retrieval, named MileCut. MileCut employs a case elements extraction module to fully exploit the multi-view information of cases in the ranking list. Then, MileCut applies a multi-view truncation module to select the most informative view and make a more comprehensive cut-off decision, similar to how legal experts look over retrieval results. As a practical evaluation, MileCut is assessed across three datasets, including criminal and civil case retrieval scenarios, and the results show that MileCut outperforms other methods on F1, DCG, and OIE metrics.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","1341–1349","","","","","","","WWW '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","legal case retrieval; ranking list truncation; web search","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HVCDWN57","conferencePaper","2023","Nguyen, Minh Vu; Le, Ngoc Thuy; Duong, Dung; Li, Yannan; Mukherjee, Madhav","Blockchain Oracles: Implications for Smart Contracts in Legal Reasoning and Addressing the Oracle Problem","Proceedings of the 12th International Symposium on Information and Communication Technology","979-8-4007-0891-6","","10.1145/3628797.3628870","https://doi.org/10.1145/3628797.3628870","This paper presents a comprehensive investigation into the role, functionalities, and complexities of blockchain oracles, focusing particularly on the implications for smart contracts in legal reasoning contexts. Oracles serve as a vital bridge to smart contracts’ inability to interact with external or “off-chain” data, enabling them to be used in a variety of real-world situations. Oracle’s integration, however, introduces a number of complexities, including security vulnerabilities, collectively referred to as the Oracle Problem. In addition to a review of existing literature, we also provide a mathematical analysis quantifying the computational complexity associated with automating legal reasoning and a novel design framework aimed at establishing oracles that are secure, efficient, and legally compliant. The paper aims to serve as a foundational text for researchers, legal practitioners, and blockchain developers, advancing the academic discourse surrounding blockchain oracles and their role in smart contracts.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","296–303","","","","","","","SOICT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ho Chi Minh, Vietnam","","","","blockchain; legal; oracle; oracle problem; smart contracts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79PXJUW4","conferencePaper","2024","Wei, Haifeng","Intelligent Legal Document Generation System and Method Based on Knowledge Graph","Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications","979-8-4007-1814-4","","10.1145/3662739.3669909","https://doi.org/10.1145/3662739.3669909","Applying artificial intelligence to legal research will play a very important role in improving judicial efficiency and judicial quality. In order to solve the problems existing in the current automatic generation of judicial documents, such as loose logic, incomplete content and irregular language specifications, an intelligent automatic generation method of judicial documents based on knowledge graphs was applied. Based on the knowledge graph in the legal field, it uses its powerful reasoning and correlation to realize the intelligent automatic generation of legal issues. The study found that this method is superior to conventional rule-based search methods in multiple dimensions such as generation efficiency, quality, and content integrity, and its content integrity can reach up to 92%. This method can effectively conduct efficient and stable text queries, greatly improving the automation level of legal document generation. The application of knowledge graphs to legal research will greatly improve the efficiency and quality of trial document production, and is expected to bring about revolutionary changes in legal research and documentation, and promote the simplification and precision of the litigation process.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","350–354","","","","","","","MIDA '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ningbo, China","","","","Content Integrity; Document Generation; Intelligent Law; Knowledge Graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E55F5FR4","conferencePaper","2023","He, Zhenghao; Chen, Ruifan; Hou, Yayue; Xie, Fei; Gong, Xiaoliang; Cohn, Anthony G.","A Music Labeling Model Based on Traditional Chinese Music Characteristics for Emotional Regulation","Proceedings of the 2023 12th International Conference on Software and Computer Applications","978-1-4503-9858-9","","10.1145/3587828.3587837","https://doi.org/10.1145/3587828.3587837","The effectiveness of emotion regulation based on traditional Chinese music has been verified in clinical trials over thousands of years, but the reasons are unclear. This paper aims to use feature engineering to find effective music features which are effective for classifying different types of music and thus to try to provide an automatic recognition framework for building music libraries that can be used for mood regulation and music therapy. In this work, five modes (equivalent to the scales of Western music) of traditional Chinese music repertoire which can be used to regulate loneliness, anxiety, anger, joy, and fear are used. Features including Chroma, Mel-spectrogram, Tonnetz, and full feature vector features, are extracted for different length fragments of a piece of music which are then used to build a classification model for the five modes using a convolutional neural network (CNN). The results show that the highest 5-classes classification accuracy, 71.09%, is achieved from a Mel map of 5s music clips. A music mode labeling model is then constructed using a weighted combination of the different individual feature models. This model was then qualitatively evaluated on 13 pieces of music in different musical styles, and the results were reasonable from a music theory perspective. In future work, this music labeling model will be tested on more types of tracks to better assess its reliability.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","53–58","","","","","","","ICSCA '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kuantan, Malaysia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZNLP7E9","conferencePaper","2024","Da Costa Nunes, Erik Henrique; Monteiro, Ingrid Teixeira","Exploring the Accessibility Legal Landscape: Accessibility requirements in mobile applications according to ABNT NBR 17060","Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems","979-8-4007-1715-4","","10.1145/3638067.3638121","https://doi.org/10.1145/3638067.3638121","A good digital product often arises from a proper characterization of requirements. This reduces business risks, minimizing costs associated with rework or user rejection of the product. Accessibility is commonly regarded as a non-functional requirement, sometimes linked to usability, in order to ensure quality in the system. At least in the Brazilian context, acessibility has not being considered mandatory in industry settings. This work aims to investigate the change proposed by ""ABNT NBR 17060 - Accessibility in Mobile Apps - Requirements"" published in 2022, with the purpose of repositioning accessibility as a legal requirement. This study utilizes legal hermeneutics to understand how this standard reaches citizens, determining by whom, when, and what the standard must be complied with. In an effort to translate accessibility as a legal aspect into software requirements, in this paper, we report how ""User Stories"" may be employed to properly position this new type of requirement from the perspective of compliance.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","","","","","","","","IHC '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Maceió, Brazil","","","","Legal Requirements; Accessibility; Human–computer interaction; Software Requirement Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"88SBADCP","conferencePaper","2022","Yew, Rui-Jie; Xiang, Alice","Regulating Facial Processing Technologies: Tensions Between Legal and Technical Considerations in the Application of Illinois BIPA","Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency","978-1-4503-9352-2","","10.1145/3531146.3533163","https://doi.org/10.1145/3531146.3533163","Harms resulting from the development and deployment of facial processing technologies (FPT) have been met with increasing controversy. Several states and cities in the U.S. have banned the use of facial recognition by law enforcement and governments, but FPT are still being developed and used in a wide variety of contexts where they primarily are regulated by state biometric information privacy laws. Among these laws, the 2008 Illinois Biometric Information Privacy Act (BIPA) has generated a significant amount of litigation. Yet, with most BIPA lawsuits reaching settlements before there have been meaningful clarifications of relevant technical intricacies and legal definitions, there remains a great degree of uncertainty as to how exactly this law applies to FPT. What we have found through applications of BIPA in FPT litigation so far, however, points to potential disconnects between technical and legal communities. This paper analyzes what we know based on BIPA court proceedings and highlights these points of tension: areas where the technical operationalization of BIPA may create unintended and undesirable incentives for FPT development, as well as areas where BIPA litigation can bring to light the limitations of solely technical methods in achieving legal privacy values. These factors are relevant for (i) reasoning about biometric information privacy laws as a governing mechanism for FPT, (ii) assessing the potential harms of FPT, and (iii) providing incentives for the mitigation of these harms. By illuminating these considerations, we hope to empower courts and lawmakers to take a more nuanced approach to regulating FPT and developers to better understand privacy values in the current U.S. legal landscape.","2022","2025-02-19 14:42:19","2025-02-19 14:42:19","","1017–1027","","","","","","","FAccT '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Republic of Korea","","","","biometric privacy; facial recognition; privacy policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GW9UZ5X8","conferencePaper","2023","Pistilli, Giada; Muñoz Ferrandis, Carlos; Jernite, Yacine; Mitchell, Margaret","Stronger Together: on the Articulation of Ethical Charters, Legal Tools, and Technical Documentation in ML","Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency","979-8-4007-0192-4","","10.1145/3593013.3594002","https://doi.org/10.1145/3593013.3594002","The growing need for accountability of the people behind AI systems can be addressed by leveraging processes in three fields of study: ethics, law, and computer science. While these fields are often considered in isolation, they rely on complementary notions in their interpretation and implementation. In this work, we detail this interdependence and motivate the necessary role of collaborative governance tools in shaping a positive evolution of AI. We first contrast notions of compliance in the ethical, legal, and technical fields; we outline both their differences and where they complement each other, with a particular focus on the roles of ethical charters, licenses, and technical documentation in these interactions. We then focus on the role of values in articulating the synergies between the fields and outline specific mechanisms of interaction between them in practice. We identify how these mechanisms have played out in several open governance fora: an open collaborative workshop, a responsible licensing initiative, and a proposed regulatory framework. By leveraging complementary notions of compliance in these three domains, we can create a more comprehensive framework for governing AI systems that jointly takes into account their technical capabilities, their impact on society, and how technical specifications can inform relevant regulations. Our analysis thus underlines the necessity of joint consideration of the ethical, legal, and technical in AI ethics frameworks to be used on a larger scale to govern AI systems and how the thinking in each of these areas can inform the others.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","343–354","","","","","","","FAccT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","AI Governance; AI Policy; Applied Ethics; Documentation; ML Licensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KI7P52N9","conferencePaper","2024","He, Junxiang; Wang, Bojie; Gao, Zhiqiao; Hu, Jie; Liu, Dan","Explainable Similar Legal Cases Retrieval Based on Siamese Network","Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing","979-8-4007-0924-1","","10.1145/3639479.3639487","https://doi.org/10.1145/3639479.3639487","Legal case retrieval is crucial for ensuring justice across different legal systems and has attracted increasing attention. However, most of the existing methods for legal case retrieval are based on frequency-based matching of words or encoding the entire legal text for text similarity matching, resulting in the loss of a lot of granular information and interpretability. To facilitate legal practitioners in case retrieval, this paper proposes a Siamese Network-based Explainable Similar Legal Cases Retrieval model (ESLCR-SN). The ESLCR-SN encodes the factual situation and essential facts of a legal case using the Sentence Pair Classification task of BERT on the Lecard dataset and trains a dual-label model with Siamese network simultaneously. Since this method subdivides legal text according to legal norms, it provides a more granular representation of legal cases. Furthermore, it can provide further interpretation based on the matching of the two parts, i.e., the KeyElements and KeyCircumstance of the query and document cases, by extracting the similarity comparison of the Self-Attention matrix. The sorting performance of this method is superior to that of most of the existing legal case retrieval methods in terms of NDCG, MAP, and Precision indicators. Its explainable part can effectively explain the reasons for the similarity of two cases.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","33–40","","","","","","","MLNLP '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sanya, China","","","","ESLCR-SN; Explainable; Legal Cases Retrieval; Siamese Network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RK6BSTQ7","conferencePaper","2024","Bertrand, Astrid; Eagan, James R.; Maxwell, Winston; Brand, Joshua","AI is Entering Regulated Territory: Understanding the Supervisors' Perspective for Model Justifiability in Financial Crime Detection","Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems","979-8-4007-0330-0","","10.1145/3613904.3642326","https://doi.org/10.1145/3613904.3642326","Artificial intelligence (AI) has the potential to bring significant benefits to highly regulated industries such as healthcare or banking. Adoption, however, remains low. AI’s entry into complex socio-techno-legal systems raises issues of transparency, specifically for regulators. However, the perspective of supervisors, regulators who monitor compliance with applicable financial regulations, has rarely been studied. This paper focuses on understanding the needs of supervisors in anti-money laundering (AML) to better inform the design of AI justifications and explanations in highly regulated fields. Through scenario-based workshops with 13 supervisors and 6 banking professionals, we outline the auditing practices and socio-technical context of the supervisor. By combining the workshops’ insights with an analysis of compliance requirements, we identify the AML obligations that conflict with AI opacity. We then formulate seven needs that supervisors have for model justifiability. We discuss the role of explanations as reliable evidence on which to base justifications.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","","","","","","","","CHI '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Honolulu, HI, USA","","","","AI regulation; anti-money laundering; explainability; highly-regulated environment; justifiability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7UHTT265","conferencePaper","2024","Wortmann, Carolin; Vahrenhold, Jan","Regulation, Self-Efficacy, and Participation in CS1 Group Work","Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1","979-8-4007-0475-8","","10.1145/3632620.3671115","https://doi.org/10.1145/3632620.3671115","Motivation and Objectives. Group work is an integral component of many job descriptions in the computing profession. To prepare students for this, and also to be able to scale course offerings, many instructors require students to work on homework assignments in small groups. The importance of group work has contributed to an increasing interest of computer science education researchers in regulatory strategies and processes occurring during collaborative learning situations. However, so far only limited work has been done on the concept of social regulation, or more precisely co-regulation and socially shared regulation. In this paper, we extend the nomological network of regulation in CS1 group work by incorporating the students’ self-efficacy and frequency of group work participation. We also report on barriers to groups work participation reported by the students. Methods. We conducted a mixed-methods study to understand barriers, effects, and affordances of group work in an introductory programming class. For this, we assessed three different types of regulation – self-regulation, socially shared regulation, and co-regulation – as well as general self-efficacy at three times during the semester. In addition, we collected data on the frequency of participation in group work and, at the end of the semester, the group’s collective performance. We complement this quantitative data by qualitative data on reasons for not – or not frequently – participating in group work. Results. Extending previous results on regulation in CS1 group work, we found self-efficacy to moderate the correlation between self-regulation and group performance. We also found self-efficacy to be correlated with self-regulation and co-regulation, but not with socially shared regulation. Moreover, we found that students who reported to frequently, but not exclusively work in groups exhibited the highest levels of regulation. The analysis of the qualitative data revealed a broad spectrum of reasons, some of which are specific to first-year courses while others are connected to perceived self-efficacy. Discussion. Our results indicate that the nomological network of regulation in CS1 group work should be extended to also include self-efficacy, even more so because it is essential in explaining the relationship between regulation and performance. Given that algorithms for optimizing group composition usually require data about prior performance and learner characteristics, both of which are not available at the beginning of the first semester, our results also suggest to not enforce working exclusively in groups in similar contexts.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","359–373","","","","","","","ICER '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Melbourne, VIC, Australia","","","","Group Work; Self-Efficacy; Self-Regulated Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGKMEZUL","conferencePaper","2024","Pan, Yudai; Liu, Jun; Zhao, Tianzhe; Zhang, Lingling; Lin, Yun; Dong, Jin Song","A Symbolic Rule Integration Framework with Logic Transformer for Inductive Relation Prediction","Proceedings of the ACM Web Conference 2024","979-8-4007-0171-9","","10.1145/3589334.3645594","https://doi.org/10.1145/3589334.3645594","Relation prediction in knowledge graphs (KGs) aims at predicting missing relations in incomplete triples, whereas the dominant paradigm by KG embeddings has a limitation to predict the relation between unseen entities. This situation is called an inductive setting, which is more common in the real-world scenario. To handle this issue, implicit symbolic rules have shown great potential in capturing the inductive capability. However, it is still challenging to obtain precise representations of logic rules from KGs. The argument variability and predicate non-commutativity in symbolic rule integration make the modeling of component symbols difficult. To this end, we propose a novel inductive relation prediction model named SymRITa with a logic transformer integrating rules. SymRITa firstly extracts the subgraph, whose embeddings are captured by a graph network. Meanwhile, symbolic rule graphs in the subgraph can be generated. Then, the symbolic rules are modeled by a proposed logic transformer. Specifically, the input format based on the subgraph-based embeddings is to focus on the argument variability in symbolic rules. In addition, a conjunction attention mechanism in the logic transformer can resolve predicate non-commutativity in the symbolic rule integration process. Finally, the subgraph-based and symbol-based embeddings obtained from the previous steps are combined for the training regime, and prediction results as well as rules explaining the reasoning process are explicitly output. Extensive experiments on twelve inductive datasets show that SymRITa achieves outstanding effectiveness compared to state-of-the-art inductive baselines. Moreover, the logic rules with corresponding confidences provide an interpretable paradigm.","2024","2025-02-19 14:42:19","2025-02-19 14:42:19","","2181–2192","","","","","","","WWW '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","first-order logic; inductive relation prediction; knowledge graph; logic transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZQIZDCM","conferencePaper","2023","Liepiundefineda, Rūta; Wyner, Adam; Sartor, Giovanni; Lagioia, Francesca","Argumentation Schemes for Legal Presumption of Causality","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595130","https://doi.org/10.1145/3594536.3595130","Causal reasoning is a challenging topic not only in philosophy, science and in theories of human mind, but also in legal reasoning. Causality is indeed a key precondition for civil and criminal liability, in all cases dealing with the connection between human actions or omissions and harmful events. Only a partial overlap exists between natural causality (cause-in-fact) and legal causality: there are instances in which what appears to be a natural cause is not recognised as a legal one, as well as instances in which causality may be presumptively ascribed by the law in the absence of decisive evidence for natural causality. Legal policy considerations may explain these puzzling divergences, as we will discuss in the following. In this paper, we use argumentation schemes to provide simple and intuitive patterns for assessing causality in the legal domain. The analysis of these argument schemes will enable us to clarify some connections between natural and legal causation. Our schemes will include the necessary condition (but-for), overdetermination (NESS), preemption, presumptions based on the increase of risks or presumption based on statutory obligations, and interruption of causality due to unexpected events (Actus Novus). These approaches are tested on the basis of real legal cases in different domains.","2023","2025-02-19 14:42:19","2025-02-19 14:42:19","","157–166","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","legal reasoning; argumentation; causation; legal causation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V686YEBV","conferencePaper","2019","Alsaadi, Mohmood; Lisitsa, Alexei; Qasaimeh, Malik","Minimizing the ambiguities in medical devices regulations based on software requirement engineering techniques","Proceedings of the Second International Conference on Data Science, E-Learning and Information Systems","978-1-4503-7284-8","","10.1145/3368691.3368709","https://doi.org/10.1145/3368691.3368709","Trusted medical software devices, must comply with one of the healthcare regulations such as Food and Drug Administration (FDA), EU Medical Device Regulation (MDR), and Health Insurance Portability and Accountability Act (HIPAA). Since these regulations are enacted by law legislators and written in a legal text, these regulations are typically written with ambiguities. However, people have a different interpretation for the legal text for example, software developers faced challenges in identifying and understanding the regulatory requirements that are related to the software development process. Moreover, ambiguous in regulatory requirements play a big role in software compliance with regulatory particularly, when the requirements are legal text.In this paper, we intend to minimize the ambiguities in EU MDR requirements based on requirement engineering techniques in order to make MDR requirements clear and precise for software developers. In our previous work, we extracted the requirements of MDR that would affect the software development life cycle (SDLC) directly or indirectly. Herein, we will identify the ambiguity types in the extracted requirements of MDR. Moreover, this paper will present a method to minimize the ambiguities in MDR requirements based on requirement engineering techniques (user story and use case diagram). Finally, this work will be evaluated by the critical-to-quality tree measurement technique.","2019","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","DATA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Dubai, United Arab Emirates","","","","ambiguity of MD requirements; CTQ tree; MDR software requirements; medical devices regulations; requirement engineering techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAVRF3WJ","conferencePaper","2019","Anish, Preethu Rose; Joshi, Vivek; Sainani, Abhishek; Ghaisas, Smita","Towards enhanced accountability in complying with healthcare regulations","Proceedings of the 1st International Workshop on Software Engineering for Healthcare","","","10.1109/SEH.2019.00012","https://doi.org/10.1109/SEH.2019.00012","The healthcare ecosystem is highly complex. It is composed of multiple stakeholders with intersecting interests. The healthcare regulations such as Health Insurance Portability and Accountability Act, much like the systems they protect, are complex and often difficult to interpret. Regulations contain obligations that must be fulfilled by healthcare systems that form the backbone of modern healthcare. In this paper, we present a model for extracting and deconstructing obligations. The Obligation Model allows for capturing the essence of obligations in terms of their attributes such as Responsible entity, Trigger, Action, Deadline and Reference. We augment the extracted obligations with auxiliary information present in regulation documents and provide an ownership based rendering of the deconstructed obligation in an HTML format. This helps in establishing an explicit ownership of obligations and contributes towards enhancing accountability of stakeholders towards fulfilling the obligations. The rendering will be useful for building compliant healthcare systems by making the legal text more comprehensible for system designers.","2019","2025-02-19 14:42:20","2025-02-19 14:42:20","","25–28","","","","","","","SEH '19","","","","IEEE Press","","","","","","","","","Place: Montreal, Quebec, Canada","","","","machine learning; extraction; healthcare; HIPAA; obligation; ownership based rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YXJ3ATX5","conferencePaper","2018","Ghaisas, Smita; Sainani, Abhishek; Anish, Preethu Rose","Resolving ambiguities in regulations: towards achieving the kohlbergian stage of principled morality","Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Society","978-1-4503-5661-9","","10.1145/3183428.3183433","https://doi.org/10.1145/3183428.3183433","According to Kohlberg, the final stage of morality is characterized by viewing laws as a means to an end by upholding values such as human dignity and fairness as guiding principles for complying with the essence of the law. Given that purpose of compliance is indeed wellbeing of citizens, software systems should, by design, incorporate these values so that laws are followed in spirit. How can we build software systems that incorporate these values? We present our work on disambiguating Health Insurance Portability and Accountability Act (HIPAA) so as to reduce the potential incidents of breach, thereby upholding of the aforesaid guiding principles of morality. We have employed deep learning based approaches to emulate the human process of disambiguation by integrating information from multiple sources, summarizing it, and augmenting the regulatory text with the additional information. This augmented regulatory text can be used by policy makers and software engineers to achieve compliance in spirit.","2018","2025-02-19 14:42:20","2025-02-19 14:42:20","","57–60","","","","","","","ICSE-SEIS '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","ambiguity resolution; compliance; deep learning; principled morality; regulations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZIXQLCIR","conferencePaper","2024","Baloukas, Christos; Papadopoulos, Lazaros; Demestichas, Kostas; Weissenfeld, Axel; Schlarb, Sven; Aramburu, Mikel; Redó, David; García, Jorge; Gaines, Seán; Marquenie, Thomas; Eren, Ezgi; Erdogan Peter, Irmak","A Risk Assessment and Legal Compliance Framework for Supporting Personal Data Sharing with Privacy Preservation for Scientific Research","Proceedings of the 19th International Conference on Availability, Reliability and Security","979-8-4007-1718-5","","10.1145/3664476.3670878","https://doi.org/10.1145/3664476.3670878","In order to perform cutting-edge research like AI model training, a large amount of data needs to be accessed. However, data providers are often reluctant to share their data with researchers as these might contain personal data and thereby sharing may introduce serious risks with significant personal, institutional or societal impacts. Apart from the need to control these risks, data providers must also comply with regulations like GDPR, which creates an additional overhead that makes data sharing even less appealing to data providers. Technologies like anonymization can play a critical role when sharing data that may contain personal information by offering privacy preservation measures like face or license plate anonymization. Therefore, we propose a framework to support data sharing of personal data for research by integrating anonymization, risk assessment and automatic licence agreement generation. The framework offers a practical and efficient solution for organisations seeking to enhance data-sharing practices without compromising information security.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","ARES '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vienna, Austria","","","","License Agreement; Personal Data Sharing; Privacy Preservation; Risk Assessment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G78IILXA","conferencePaper","2024","Yu, Dongran; Liu, Xueyan; Yang, Bo","Zero-shot Image Classification with Logic Adapter and Rule Prompt","Proceedings of the ACM Web Conference 2024","979-8-4007-0171-9","","10.1145/3589334.3645554","https://doi.org/10.1145/3589334.3645554","Zero-shot image classification, which aims to predict unseen classes whose samples have never appeared during the training phase, is crucial in the Web domain because many new web images appear on various websites. Attributes, as annotations for class-level characteristics, are widely used semantic information for this task. However, most current methods often fail to capture discriminative image features between similar images from different classes, leading to unsatisfactory zero-shot image classification results. This is because they solely focus on limited visual-attribute feature alignment. Therefore, we propose a Zero-Shot image Classification with Logic adapter and Rule prompt method called ZSCLR, which utilizes logic adapter and rule prompts to encourage the model to capture discriminative image features and achieve reasoning. Specifically, ZSCLR consists of a visual perception module and a logic adapter. The visual perception module extracts image features from training data. At the same time, the logic adapter utilizes the Markov logic network to encode the extracted image features and rule prompts for refining the discriminative image features. Due to predicates of rule prompts representing symbolic discriminative features, the proposed model can focus more on these discriminative features and achieve more precise image classification. Additionally, the logic adapter enables the model to adapt from recognizing images in seen classes to those in unseen classes through the reasoning of the Markov logic networks. We implement experiments on three standard zero-shot image classification benchmarks, and ZSCLR achieves competitive performance. Furthermore, ZSCLR can provide explanations for its predictions through rule prompts.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","2075–2084","","","","","","","WWW '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","image classification; logic adapter; markov logic network; rule prompt; zero-shot learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YTWA7DWI","conferencePaper","2024","Habiba, Umm-E-; Bogner, Justus; Wagner, Stefan","Towards Explainability as a Functional Requirement: A Vision to Integrate the Legal, End-User, and ML Engineer Perspectives","Proceedings of the 2nd International Workshop on Responsible AI Engineering","979-8-4007-0572-4","","10.1145/3643691.3648590","https://doi.org/10.1145/3643691.3648590","The rapid advancement and integration of artificial intelligence (AI) in various sectors have accentuated the importance of explainability in AI systems. This vision paper presents an exploration into the multifaceted nature of AI explainability, consolidating insights from three critical perspectives: legal, end-user, and ML engineer. We work towards a comprehensive taxonomy by creating a detailed classification that integrates various viewpoints and establishes explainability as an essential functional requirement, despite its usual treatment as a non-functional requirement.Our taxonomy will guide towards the interdependencies and distinct requirements of each perspective. We aim to foster a more profound understanding of AI explainability, encouraging a more holistic approach to AI system development. This research will advance the explainable AI discussion, providing key insights for policymakers, developers, and users, and promoting the development of AI systems that are technically sound, trustworthy, understandable, and legally compliant.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","16–19","","","","","","","RAIE '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Lisbon, Portugal","","","","explainability; requirements engineering; XAI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XS8FCLMF","conferencePaper","2023","Xu, Tianwen; Ju, Fengkui","Multi-agent logic for reasoning about duties and powers in private law","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595133","https://doi.org/10.1145/3594536.3595133","Duties and powers are two fundamental notions in private law. In this work, we provide our conception of duties and powers and present a logic for reasoning about them. We treat duties as agents' obligations towards others to perform actions. We think that powers are agents' legal abilities, conferred by law, to change legal positions between agents. How to exercise powers is also specified by law. Many factors, including the exercise of powers, fulfillment of duties, violation of duties, and factual changes in the world, can change duties. The ontic level of the logic is a multi-agent dynamic logic, where agents have abilities to change atomic facts. At its normative level, agents have duties towards others to change atomic facts, and have powers to change duties by changing atomic facts. When agents behave, the ontic and normative aspects of the world change accordingly. The implications of the formalization are studied extensively.","2023","2025-02-19 14:42:20","2025-02-19 14:42:20","","361–370","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","abilities; actions; duties; exercise of powers; powers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKA9IDMK","conferencePaper","2023","Fang, Huang; Liu, Yang; Cai, Yunfeng; Sun, Mingming","MLN4KB: an efficient Markov logic network engine for large-scale knowledge bases and structured logic rules","Proceedings of the ACM Web Conference 2023","978-1-4503-9416-1","","10.1145/3543507.3583248","https://doi.org/10.1145/3543507.3583248","Markov logic network (MLN) is a powerful statistical modeling framework for probabilistic logic reasoning. Despite the elegancy and effectiveness of MLN, the inference of MLN is known to suffer from an efficiency issue. Even the state-of-the-art MLN engines can not scale to medium-size real-world knowledge bases in the open-world setting, i.e., all unobserved facts in the knowledge base need predictions. In this work, by focusing on a certain class of first-order logic rules that are sufficiently expressive, we develop a highly efficient MLN inference engine called MLN4KB that can leverage the sparsity of knowledge bases. MLN4KB enjoys quite strong theoretical properties; its space and time complexities can be exponentially smaller than existing MLN engines. Experiments on both synthetic and real-world knowledge bases demonstrate the effectiveness of the proposed method. MLN4KB is orders of magnitudes faster (more than 103 times faster on some datasets) than existing MLN engines in the open-world setting. Without any approximation tricks, MLN4KB can scale to real-world knowledge bases including WN-18 and YAGO3-10 and achieve decent prediction accuracy without bells and whistles. We implement MLN4KB as a Julia package called MLN4KB.jl. The package supports both maximum a posteriori (MAP) inference and learning the weights of rules. MLN4KB.jl is public available at https://github.com/baidu-research/MLN4KB .","2023","2025-02-19 14:42:20","2025-02-19 14:42:20","","2423–2432","","","","","","","WWW '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Austin, TX, USA","","","","knowledge graph completion.; Markov logic network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U6D3Q326","conferencePaper","2022","Urquhart, Lachlan D.; McGarry, Glenn; Crabtree, Andy","Legal Provocations for HCI in the Design and Development of Trustworthy Autonomous Systems","Nordic Human-Computer Interaction Conference","978-1-4503-9699-8","","10.1145/3546155.3546690","https://doi.org/10.1145/3546155.3546690","We propose a series of legal provocations emerging from the proposed European Union Artificial Intelligence Act 2021 (AIA) and explore how they open up new possibilities for HCI in the design and development of trustworthy autonomous systems. The AIA continues the ‘by design’ trend seen in recent EU regulation of emerging technologies. The AIA targets AI developments that pose risks to society and citizens’ fundamental rights, introducing mandatory design and development requirements for high-risk AI systems (HRAIS). These requirements regulate different stages of the AI development cycle including ensuring data quality and governance strategies, mandating testing of systems, ensuring appropriate risk management, designing for human oversight, and creating technical documentation. These requirements open up new opportunities for HCI that reach beyond established concerns with the ethics and explainability of AI and situate AI development in human-centered processes and methods of design to enable compliance with regulation and foster societal trust in AI.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","NordiCHI '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aarhus, Denmark","","","","European Union AI Act (AIA); mandatory design and development requirements; trustworthy AI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WYPR3LI","conferencePaper","2022","Marikyan, Davit; Papagiannidis, Savvas; Ranjan, Rajiv; Rana, Omer","General data protection regulation: an individual's perspective","Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing Companion","978-1-4503-9163-4","","10.1145/3492323.3495620","https://doi.org/10.1145/3492323.3495620","Rapid digitalisation has resulted in a massive exchange of digital data between individuals and organisations, accelerating the importance of privacy-preserving legal frameworks, such as the General Data Protection Regulation (GDPR). Despite the importance of the implementation of such a framework, current research lacks evidence about how individuals perceive GDPR compliance. Given that, the objective of this study was to explore individuals' attitudes towards GDPR compliance in line with Protection Motivation Theory. This study employed a cross-sectional research design and collected 540 valid responses to test a model using structural equational modelling. The result of the analysis showed that perceived threat severity, response efficacy and self-efficacy have positive relationships with attitude towards GDPR compliance. In addition, it was found that attitude correlates with emotional empowerment. The findings of this paper contribute to the literature on privacy-preserving mechanisms by shedding light on individuals' perceptions of the GDPR. The evidence also adds to the current body of literature on information systems management by giving insights into the factors that determine the utilisation of privacy-preserving technologies. These pieces of evidence offer implications for policymakers by providing guidelines on how to communicate the benefits of the GDPR to the public.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","UCC '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Leicester, United Kingdom","","","","GDPR; digital economy; protection motivation theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CELJ4BFC","conferencePaper","2021","Ma, Luyao; Zhang, Yating; Wang, Tianyi; Liu, Xiaozhong; Ye, Wei; Sun, Changlong; Zhang, Shikun","Legal Judgment Prediction with Multi-Stage Case Representation Learning in the Real Court Setting","Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","978-1-4503-8037-9","","10.1145/3404835.3462945","https://doi.org/10.1145/3404835.3462945","Legal judgment prediction(LJP) is an essential task for legal AI. While prior methods studied on this topic in a pseudo setting by employing the judge-summarized case narrative as the input to predict the judgment, neglecting critical case life-cycle information in real court setting could threaten the case logic representation quality and prediction correctness. In this paper, we introduce a novel challenging dataset from real courtrooms to predict the legal judgment in a reasonably encyclopedic manner by leveraging the genuine input of the case - plaintiff's claims and court debate data, from which the case's facts are automatically recognized by comprehensively understanding the multi-role dialogues of the court debate, and then learnt to discriminate the claims so as to reach the final judgment through multi-task learning. An extensive set of experiments with a large civil trial data set shows that the proposed model can more accurately characterize the interactions among claims, fact and debate for legal judgment prediction, achieving significant improvements over strong state-of-the-art baselines. Moreover, the user study conducted with real judges and law school students shows the neural predictions can also be interpretable and easily observed, and thus enhancing the trial efficiency and judgment quality.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","993–1002","","","","","","","SIGIR '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Canada","","","","case life-cycle; judgment prediction; multi-task learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X26Y46EB","conferencePaper","2024","Liu, Baojie; Yao, Weihong; Zhou, Huiwei","Logic Rule Guided Multi-hop Temporal Knowledge Graph Reasoning","Proceedings of the 2024 5th International Conference on Computing, Networks and Internet of Things","979-8-4007-1675-1","","10.1145/3670105.3670114","https://doi.org/10.1145/3670105.3670114","The Temporal Knowledge Graphs (TKGs) reasoning task aims to predict undiscovered links from the already known facts of TKG, which is crucial for areas such as user recommendation and clinical decision support. The potential logic rules in TKGs can provide guidance for the prediction process and make the inference results interpretable, but only few existing interpretable multi-hop reasoning models consider the role of logic rules. This paper proposes a Logic rule guided Multi-hop Reasoning framework (LogicMR). LogicMR extracts temporal logic rules consisting of relation paths in TKG through temporal random walk. We first train the relation embeddings using logic rules and keep the logic rule information fixed. The relation embeddings containing logic rule information will guide the training process of multi-hop reasoning to obtain the final relation embeddings. The final relation embeddings will also contain multi-hop reasoning information and be used for reasoning prediction. The results show that LogicMR reaches the state-of-the-art on the ICEWS14, ICEWS18 and ICEWS0515 datasets.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","49–55","","","","","","","CNIOT '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tokyo, Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQGXBPSY","conferencePaper","2021","Shen, Zhuoyi","The Regulatory Path of Big-Data Price Discrimination-Based on Economic Characteristics and Legal Accountability","Proceedings of the 2021 3rd International Conference on Big Data Engineering and Technology","978-1-4503-8928-0","","10.1145/3474944.3474954","https://doi.org/10.1145/3474944.3474954","Big data has not been effectively governed after it has received social attention since 2018. This paper aims to explore a more appropriate and feasible regulatory path by exploring the reasons why big-data price discrimination has failed to obtain legal regulation, as well as the economic, technological, and market structure causes of big-data price discrimination. In the argument, it is found that there are legal problems such as doubtful illegality, regulatory gaps that belong to the intersection of multiple laws, and difficulty in obtaining evidence. And because of the profit-seeking nature of the platform economy, the unconsciousness of algorithms and the uniqueness of the platform market structure, the boundaries between big-data price discrimination and reasonable marketing strategies are difficult to decide. It is not possible to totally prohibit big-data price discrimination and hinder the development of the new business model of the platform economy. However, when the platform's profit-seeking behavior infringes on the market order and consumer rights, big-data price discrimination is legally accountable. On one side, big-data price discrimination may infringe consumers’ fair trading rights, and the judgment criteria should be determined based on cost and profit rate. On the other side, in the anti-monopoly law, the boundary between reasonable transaction habits and legally accountable differential treatment should be distinguished for big-data price discrimination.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","58–62","","","","","","","BDET '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","anti-monopoly; big-data price discrimination; differential treatment; fair trading; platform economy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCEATND7","conferencePaper","2021","Sovrano, Francesco; Palmirani, Monica; Distefano, Biagio; Sapienza, Salvatore; Vitali, Fabio","A dataset for evaluating legal question answering on private international law","Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law","978-1-4503-8526-8","","10.1145/3462757.3466094","https://doi.org/10.1145/3462757.3466094","International Private Law (PIL) is a complex legal domain that presents frequent conflicting norms between the hierarchy of legal sources, legal domains, and the adopted procedures. Scientific research on PIL reveals the need to create a bridge between European and national laws. In this context, legal experts have to access heterogeneous sources, being able to recall all the norms and to combine them using case-laws and following the principles of interpretation theory. This clearly poses a daunting challenge to humans, whenever Regulations change frequently or are big-enough in size. Automated reasoning over legal texts is not a trivial task, because legal language is very specific and in many ways different from a commonly used natural language. When applying state-of-the-art language models to legalese understanding, one of the challenges is always to figure how to optimally use the available amount of data. This makes hard to apply state-of-the-art sub-symbolic question answering algorithms on legislative texts, especially the PIL ones, because of data scarcity. In this paper we try to expand previous works on legal question answering, publishing a larger and more curated dataset for the evaluation of automated question answering on PIL.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","230–234","","","","","","","ICAIL '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: São Paulo, Brazil","","","","legal question answering; knowledge graph extraction; private international law","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EP685TRY","conferencePaper","2022","Goanta, Catalina; Bertaglia, Thales; Iamnitchi, Adriana","The Case for a Legal Compliance API for the Enforcement of the EU’s Digital Services Act on Social Media Platforms","Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency","978-1-4503-9352-2","","10.1145/3531146.3533190","https://doi.org/10.1145/3531146.3533190","In the course of under a year, the European Commission has launched some of the most important regulatory proposals to date on platform governance. The Commission’s goals behind cross-sectoral regulation of this sort include the protection of markets and democracies alike. While all these acts propose sophisticated rules for setting up new enforcement institutions and procedures, one aspect remains highly unclear: how digital enforcement will actually take place in practice. Focusing on the Digital Services Act (DSA), this discussion paper critically addresses issues around social media data access for the purpose of digital enforcement and proposes the use of a legal compliance application programming interface (API) as a means to facilitate compliance with the DSA and complementary European and national regulation. To contextualize this discussion, the paper pursues two scenarios that exemplify the harms arising out of content monetization affecting a particularly vulnerable category of social media users: children. The two scenarios are used to further reflect upon essential issues surrounding data access and legal compliance with the DSA and further applicable legal standards in the field of labour and consumer law.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","1341–1349","","","","","","","FAccT '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Republic of Korea","","","","Digital Services Act; Legal Compliance API; monetization; social media platforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5435GMSL","conferencePaper","2021","Amanzholova, Saule; Akhmetova, Darya; Sagymbekova, Azhar","Development of a web-resources testing system for compliance with GDPR regulation","The 7th International Conference on Engineering &amp; MIS 2021","978-1-4503-9044-6","","10.1145/3492547.3492661","https://doi.org/10.1145/3492547.3492661","In this paper, we describe the development of a system for checking websites for compliance with the European standard on personal data processing - GDPR. The relevance of this problem is dictated by the entry into force of the General Data Protection Regulation, also known as the GDPR standard, as well as the obligation to comply with by all companies that process personal data and any other sensitive information of EU residents, regardless of the location of such a company. For a detailed study of this topic, statistical data was collected on the reaction of global companies in various spheres of life to the introduction of the GDPR personal data processing regulation, the impact of this standard on their future work and the measures taken by these companies. In addition, we examined existing Internet portals with similar processing parameters for websites. This article describes an implementation of a web application that validates a customer's site for compliance with the standard and issues a practical report with recommendations and notes in accordance with the list of fixes to the standard. We used tools and platforms such as Python, NodeJS, React.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","ICEMIS'21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Almaty, Kazakhstan","","","","GDPR; Personal data; Regulations; Cookies; Parsing; Web application; Web-scrapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5QY8KT98","conferencePaper","2022","Chen, Dangxing; Ye, Weicheng","Monotonic Neural Additive Models: Pursuing Regulated Machine Learning Models for Credit Scoring","Proceedings of the Third ACM International Conference on AI in Finance","978-1-4503-9376-8","","10.1145/3533271.3561691","https://doi.org/10.1145/3533271.3561691","The forecasting of credit default risk has been an active research field for several decades. Historically, logistic regression has been used as a major tool due to its compliance with regulatory requirements: transparency, explainability, and fairness. In recent years, researchers have increasingly used complex and advanced machine learning methods to improve prediction accuracy. Even though a machine learning method could potentially improve the model accuracy, it complicates simple logistic regression, deteriorates explainability, and often violates fairness. In the absence of compliance with regulatory requirements, even highly accurate machine learning methods are unlikely to be accepted by companies for credit scoring. In this paper, we introduce a novel class of monotonic neural additive models, which meet regulatory requirements by simplifying neural network architecture and enforcing monotonicity. By utilizing the special architectural features of the neural additive model, the monotonic neural additive model penalizes monotonicity violations effectively. Consequently, the computational cost of training a monotonic neural additive model is similar to that of training a neural additive model, as a free lunch. We demonstrate through empirical results that our new model is as accurate as black-box fully-connected neural networks, providing a highly accurate and regulated machine learning method.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","70–78","","","","","","","ICAIF '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: New York, NY, USA","","","","fairness; model explainability; neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y22FLH98","conferencePaper","2018","Patwardhan, Manasi; Sainani, Abhishek; Sharma, Richa; Karande, Shirish; Ghaisas, Smita","Towards automating disambiguation of regulations: using the wisdom of crowds","Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering","978-1-4503-5937-5","","10.1145/3238147.3240727","https://doi.org/10.1145/3238147.3240727","Compliant software is a critical need of all modern businesses. Disambiguating regulations to derive requirements is therefore an important software engineering activity. Regulations however are ridden with ambiguities that make their comprehension a challenge, seemingly surmountable only by legal experts. Since legal experts' involvement in every project is expensive, approaches to automate the disambiguation need to be explored. These approaches however require a large amount of annotated data. Collecting data exclusively from experts is not a scalable and affordable solution. In this paper, we present the results of a crowd sourcing experiment to collect annotations on ambiguities in regulations from professional software engineers. We discuss an approach to automate the arduous and critical step of identifying ground truth labels by employing crowd consensus using Expectation Maximization (EM). We demonstrate that the annotations reaching a consensus match those of experts with an accuracy of 87%.","2018","2025-02-19 14:42:20","2025-02-19 14:42:20","","850–855","","","","","","","ASE '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montpellier, France","","","","Ambiguities; Crowdsourcing; Disambiguation; Expectation-Maximization; Regulatory compliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7669VUT","conferencePaper","2022","Suffia, Gabriele","Legal issues of the digital twin cities in the current and upcoming European legislation: Can digital twin cities be used to respond to urbanisation problems?","Proceedings of the 15th International Conference on Theory and Practice of Electronic Governance","978-1-4503-9635-6","","10.1145/3560107.3560188","https://doi.org/10.1145/3560107.3560188","ASBTRACT: The paper describes the ongoing research on “Digital Twin Cities” (DTCs), aiming to investigate the possibility of combining existing instruments in legal fields, as well as best practices and projects, in order to develop a digital twin city model that is open, compliant with standards and respectful of citizens’ rights. This goes through the response to four orders of legal and ethical questions: a) the problem of the usage of personal data; b) ethics behind the software and its use; c) the compliance of the DTCs in Europe with the current and approaching legislation that aim to regulate the infosphere; d) the role of the Independent Authorities that discipline standard and technical issues. Larger and larger cities, increasingly interconnected, in search of new balances (even where “classic” surveillance tools are limited or banned), become the ideal training ground for experimenting with a new vocabulary and concepts at the basis of the governance of “native” digital communities.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","534–537","","","","","","","ICEGOV '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Guimarães, Portugal","","","","Digital Twin City; EU Legal Domain; Smart city","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RMGGUJYP","conferencePaper","2023","Morel, Victor; Santos, Cristiana; Fredholm, Viktor; Thunberg, Adam","Legitimate Interest is the New Consent - Large-Scale Measurement and Legal Compliance of IAB Europe TCF Paywalls","Proceedings of the 22nd Workshop on Privacy in the Electronic Society","979-8-4007-0235-8","","10.1145/3603216.3624966","https://doi.org/10.1145/3603216.3624966","Cookie paywalls allow visitors of a website to access its content only after they make a choice between paying a fee or accept tracking. European Data Protection Authorities (DPAs) recently issued guidelines and decisions on paywalls lawfulness, but it is yet unknown whether websites comply with them. We study in this paper the prevalence of cookie paywalls on the top one million websites using an automatic crawler. We identify 431 cookie paywalls, all using the Transparency and Consent Framework (TCF). We then analyse the data these paywalls communicate through the TCF, and in particular, the legal grounds and the purposes used to collect personal data. We observe that cookie paywalls extensively rely on legitimate interest legal basis systematically conflated with consent. We also observe a lack of correlation between the presence of paywalls and legal decisions or guidelines by DPAs.","2023","2025-02-19 14:42:20","2025-02-19 14:42:20","","153–158","","","","","","","WPES '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Copenhagen, Denmark","","","","consent; eprivacy directive; gdpr; legitimate interest; paywalls; tracking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4695QUI8","conferencePaper","2017","Mailewa Dissanayaka, Akalanka; Shetty, Roshan Ramprasad; Kothari, Samip; Mengel, Susan; Gittner, Lisa; Vadapalli, Ravi","A Review of MongoDB and Singularity Container Security in regards to HIPAA Regulations","Companion Proceedings of The10th International Conference on Utility and Cloud Computing","978-1-4503-5195-9","","10.1145/3147234.3148133","https://doi.org/10.1145/3147234.3148133","Nowadays Linux Containers which have operating system level virtualization, are very popular over virtual machines (VMs) which have hypervisor or kernel level virtualization in high performance computing (HPC) due to reasons, such as high portability, high performance, efficiency and high security[1]. Hence, LXCs can make an efficient and secure big data analytic framework with the help of secure, efficient, easily scalable, and highly available databases. A concern for security on high performance computing clusters is high for the transdisciplinary Texas Tech University (TTU) EXPOSOME Project. This project mainly focuses on sensitive healthcare data which is operating in the Quanah Linux cluster in the High Performance Computing Center of Texas Tech University. Data privacy in this project is in 4 areas: the database, the network infrastructure, web applications, and physical security, in line with the Health Insurance Portability and Accountability Act (HIPAA). The study in this paper investigates how to assure the TTU EXPOSOME Project data security by proposing a secure data analytic framework with the Singularity Linux container and the MongoDB NoSQL database, commonly available at TTU. First, the paper investigates what are the advantages of LXCs over VMs with security and performance perspectives. Then, it focuses on four main HIPAA required areas in data security, such as authentication, authorization, encryption, and auditing, in order to make sure system security is assured to handle healthcare data. Finally it shows how the TTU EXPOSOME Project strengthens security in the aforementioned four areas using MongoDB and Singularity, such that system security is approaching compliance with HIPAA.","2017","2025-02-19 14:42:20","2025-02-19 14:42:20","","91–97","","","","","","","UCC '17 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Austin, Texas, USA","","","","big data; hipaa; hpc; linux; lxc; mongodb; nosql; security; singularity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ETP5588P","conferencePaper","2021","Fungwacharakorn, Wachara; Tsushima, Kanae; Satoh, Ken","On semantics-based minimal revision for legal reasoning","Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law","978-1-4503-8526-8","","10.1145/3462757.3466075","https://doi.org/10.1145/3462757.3466075","When literal interpretation of statutes leads to counterintuitive consequences, judges, especially in high courts, may identify counterintuitive consequences and revise interpretation of statutes. Researchers have studied revisions for computational legal representation. Generally, studies on revision usually consider minimal revision to reflect limitation of judges' legislative power. However, those studies tend to minimize the number of operations used for changing rules rather than minimize the changes of semantics (the set of conclusions obtained from the program), which vary among cases. In this paper, we consider minimizing the changes of semantics of a rule-base written in a normal logic program. We consider that each possible fact-base (the representation of a case) has its corresponding semantics and corresponding dominant rule-base, which is a set of Horn clauses obtained from the subset of rule-base that is specific to the considered fact-base. Hence, we present a new sub type of semantics-based minimal revision called a dominant-based minimal revision. Furthermore, we present one guidance to obtain one dominant-based minimal revision by using legal debugging and Closed World Specification. We also compare the dominant-based minimal revision with the syntax-based minimal revision in Theory Distance Metric. As the syntax-based minimal revision minimizes the number of operations used for changing rules, the comparison shows that the syntax-based minimal revision may cause extra semantics changes compared to the dominant-based minimal revision, especially when the rule-base contains multiple rules for the same consequence. We discuss that such extra semantics changes can be considered as unintentional changes caused by the syntax-based minimal revision. Hence, legal reasoning systems can check with the user such extra semantics changes to confirm the user intention of changes.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","50–59","","","","","","","ICAIL '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: São Paulo, Brazil","","","","legal reasoning; legal representation; theory revision","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQ5SGDPR","conferencePaper","2022","Salem, Jad; Desai, Deven; Gupta, Swati","Don’t let Ricci v. DeStefano Hold You Back: A Bias-Aware Legal Solution to the Hiring Paradox","Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency","978-1-4503-9352-2","","10.1145/3531146.3533129","https://doi.org/10.1145/3531146.3533129","Companies that try to address inequality in employment face a hiring paradox. Failing to address workforce imbalance can result in legal sanctions and scrutiny, but proactive measures to address these issues might result in the same legal conflict. Recent run-ins of Microsoft and Wells Fargo with the Labor Department’s Office of Federal Contract Compliance Programs (OFCCP) are not isolated and are likely to persist. To add to the confusion, existing scholarship on Ricci v. DeStefano often deems solutions to this paradox impossible. Circumventive practices such as the 4/5ths rule further illustrate tensions between too little action and too much action. In this work, we give a powerful way to solve this hiring paradox that tracks both legal and algorithmic challenges. We unpack the nuances of Ricci v. DeStefano and extend the legal literature arguing that certain algorithmic approaches to employment are allowed by introducing the legal practice of banding to evaluate candidates. We thus show that a bias-aware technique can be used to diagnose and mitigate “built-in” headwinds in the employment pipeline. We use the machinery of partially ordered sets to handle the presence of uncertainty in evaluations data. This approach allows us to move away from treating “people as numbers” to treating people as individuals—a property that is sought after by Title VII in the context of employment.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","651–666","","","","","","","FAccT '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Republic of Korea","","","","anti-discrimination laws; bias; hiring; resume screening; uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9GHPF2XH","conferencePaper","2023","Calvi, Alessandra; Kotzinos, Dimitris","Enhancing AI fairness through impact assessment in the European Union: a legal and computer science perspective","Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency","979-8-4007-0192-4","","10.1145/3593013.3594076","https://doi.org/10.1145/3593013.3594076","How to protect people from algorithmic harms? A promising solution, although in its infancy, is algorithmic impact assessment (AIA). AIAs are iterative processes used to investigate the possible short and long terms societal impacts of AI systems before their use, but with ongoing monitoring and periodic revisiting even after their implementation. When conducted in a participatory and transparent fashion, they could create bridges across the legal, social and computer science domains, promoting the accountability of the entity performing them as well as public scrutiny. They could enable to re-attach the societal and regulatory context to the mathematical definition of fairness, thus expanding the formalistic approach thereto. Whilst the regulatory framework in the European Union currently lacks the obligation to perform such AIA, some other provisions are expected to play a role in AI development, leading the way towards more widespread adoption of AIA. These include the Data Protection Impact Assessment (DPIA) under the General Data Protection Regulation (GDPR), the risk assessment process under the Digital Services Act (DSA) and the Conformity Assessment (CA) foreseen under the AI Regulation proposal.In this paper, after briefly introducing the plurality of definitions of fairness in the legal, social and computer science domains, and explaining to which extent the current and upcoming legal framework mandates the adoption of fairness metrics, we will illustrate how AIA could create bridges between all these disciplines, allowing us to build fairer AI solutions. We will then recognise the role of DPIA, DSA risk assessment and CA by discussing the contributions they can offer towards AIA but also identify the aspects lacking therein. We will then identify how these assessment provisions could aid the overall technical discussion of introducing and assessing fairness in AI-based models and processes.","2023","2025-02-19 14:42:20","2025-02-19 14:42:20","","1229–1245","","","","","","","FAccT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BVJN53J7","conferencePaper","2023","Seymour, William; Cote, Mark; Such, Jose","Legal Obligation and Ethical Best Practice: Towards Meaningful Verbal Consent for Voice Assistants","Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems","978-1-4503-9421-5","","10.1145/3544548.3580967","https://doi.org/10.1145/3544548.3580967","To improve user experience, Alexa now allows users to consent to data sharing via voice rather than directing them to the companion smartphone app. While verbal consent mechanisms for voice assistants (VAs) can increase usability, they can also undermine principles core to informed consent. We conducted a Delphi study with experts from academia, industry, and the public sector on requirements for verbal consent in VAs. Candidate requirements were drawn from the literature, regulations, and research ethics guidelines that participants rated based on their relevance to the consent process, actionability by platforms, and usability by end-users, discussing their reasoning as the study progressed. We highlight key areas of (dis)agreement between experts, deriving recommendations for regulators, skill developers, and VA platforms towards crafting meaningful verbal consent mechanisms. Key themes include approaching permissions according to the user’s ability to opt-out, minimising consent decisions, and ensuring platforms follow established consent principles.","2023","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","CHI '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hamburg, Germany","","","","GDPR; Alexa; Consent; Conversational User Interfaces; Informed Consent; Permissions; Verbal Consent; Voice Assistants","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZEWTVJQ","conferencePaper","2015","Sunkle, Sagar; Kholkar, Deepali; Kulkarni, Vinay","Model-driven regulatory compliance: a case study of ""know your customer"" regulations","Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems","978-1-4673-6908-4","","","","Modern enterprises face an unprecedented regulatory regime. Industry governance, risk, and compliance (GRC) solutions are document-oriented and expert-driven. Formal compliance checking techniques in contrast attempt to provide ways for rigorous modeling and analysis of regulatory compliance but miss out on holistic GRC perspective due to missing integration between diverse set of (semi-) formal models. We show that streamlining regulatory compliance using multiple purposive models of various aspects of regulations, it is possible to leverage both the rigor of formal techniques and the holistic enterprise GRC perspective. Our contributions are twofold. First, we present a model-driven architecture based on a conceptual model of integrated GRC that is capable of addressing key challenges of regulatory compliance. Second, using Know Your Customer regulations in Indian context as a case study, we demonstrate the utility of this architecture. Initial results with KYC regulations are promising and point to further work in model-driven regulatory compliance.","2015","2025-02-19 14:42:20","2025-02-19 14:42:20","","436–445","","","","","","","MODELS '15","","","","IEEE Press","","","","","","","","","Place: Ottawa, Ontario, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ASUBNRAE","conferencePaper","2025","Arnold, Zachary; Schiff, Daniel S.; Schiff, Kaylyn Jackson; Love, Brian; Melot, Jennifer; Singh, Neha; Jenkins, Lindsay; Lin, Ashley; Pilz, Konstantin; Enwereazu, Ogadinma; Girard, Tyler","Introducing the AI Governance and Regulatory Archive (AGORA): An Analytic Infrastructure for Navigating the Emerging AI Governance Landscape","Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society","","","","","AI-related laws, standards, and norms are emerging rapidly. However, a lack of shared descriptive concepts and monitoring infrastructure undermines efforts to track, understand, and improve AI governance. We introduce AGORA (the AI Governance and Regulatory Archive), a rigorously compiled and enriched dataset of AI-focused laws and policies encompassing diverse jurisdictions, institutions, and contexts related to AI. AGORA is oriented around an original taxonomy describing risks, potential harms, governance strategies, incentives for compliance, and application domains addressed in AI regulatory documents. As of its launch in July 2024, AGORA included data on several hundred instruments, with new entries being added continuously. We describe the manual and automated processes through which these data are systematically compiled, screened, annotated, and validated, enabling deep, efficient, and reliable analysis of the emerging AI governance landscape. The dataset, supporting information, and analyses are available through a public web interface (https://agora.eto.tech) and bulk dataset.","2025","2025-02-19 14:42:20","2025-02-19 14:42:20","","39–48","","","","","","","AIES '24","","","","AAAI Press","","","","","","","","","Place: San Jose, California, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6PYEQXRZ","conferencePaper","2022","Ma, Yixiao; Ai, Qingyao; Wu, Yueyue; Shao, Yunqiu; Liu, Yiqun; Zhang, Min; Ma, Shaoping","Incorporating Retrieval Information into the Truncation of Ranking Lists for Better Legal Search","Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval","978-1-4503-8732-3","","10.1145/3477495.3531998","https://doi.org/10.1145/3477495.3531998","The truncation of ranking lists predicted by retrieval models is vital to ensure users' search experience. Particularly, in specific vertical domains where documents are usually complicated and extensive (e.g., legal cases), the cost of browsing results is much higher than traditional IR tasks (e.g., Web search) and setting a reasonable cut-off position is quite necessary. While it is straightforward to apply existing result list truncation approaches to legal case retrieval, the effectiveness of these methods is limited because they only focus on simple document statistics and usually fail to capture the context information of documents in the ranking list. These existing efforts also treat result list truncation as an isolated task instead of a component in the entire ranking process, limiting the usage of truncation in practical systems. To tackle these limitations, we propose LeCut, a ranking list truncation model for legal case retrieval. LeCut utilizes contextual features of the retrieval task to capture the semantic-level similarity between documents and decides the best cut-off position with attention mechanisms. We further propose a Joint Optimization of Truncation and Reranking (JOTR) framework based on LeCut to improve the performance of truncation and retrieval tasks simultaneously. Comparison against competitive baselines on public benchmark datasets demonstrates the effectiveness of LeCut and JOTR. A case study is conducted to visualize the cut-off positions of LeCut and the process of how JOTR improves both retrieval and truncation tasks.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","438–448","","","","","","","SIGIR '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Madrid, Spain","","","","legal case retrieval; ranking list truncation; efficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VYJDQ3H9","conferencePaper","2017","Lopez-Sanchez, Maite; Serramia, Marc; Rodriguez-Aguilar, Juan A.; Morales, Javier; Wooldridge, Michael","Automating Decision Making to Help Establish Norm-Based Regulations","Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems","","","","","Norms have been extensively proposed as coordination mechanisms for both agent and human societies. Nevertheless, choosing the norms to regulate a society is by no means straightforward. The reasons are twofold. First, the norms to choose from may not be independent (i.e, they can be related to each other). Second, different preference criteria may be applied when choosing the norms to enact. On the one hand, this paper considers norm representation power and cost as alternative preference criteria. On the other hand, it identifies three different norm relationships –namely, generalisation, exclusivity, and substitutability. We show that the decisionmaking problem faced by policy makers can be encoded as a linear program, and hence solved with the aid of state-of-the-art solvers.","2017","2025-02-19 14:42:20","2025-02-19 14:42:20","","1613–1615","","","","","","","AAMAS '17","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: São Paulo, Brazil","","","","optimisation; norm decision making; normative systems; policy making","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2F43WQVK","conferencePaper","2021","Sun, MingDong; Guo, ZhiXin; Deng, XiaoLong","Intelligent BERT-BiLSTM-CRF Based Legal Case Entity Recognition Method","Proceedings of the ACM Turing Award Celebration Conference - China","978-1-4503-8567-1","","10.1145/3472634.3474069","https://doi.org/10.1145/3472634.3474069","In the past decade, the main natural language processing technologies in the field of artificial intelligence are Word2Vec and ELMO traditional models in the application of intelligent legal systems. For the reason that they are basically one-way training algorithms from left to right and only one-way information is learned, so these traditional models have some disadvantages such as low efficiency and accuracy. In order to identify specific elements in the legal case intelligently, such as time, location, perpetrator, and recipient, and improve the efficiency of case processing, a new entity recognition method using the BERT (Bidirectional Encoder Representations from Transformers) model as the input layer is proposed. The BERT model is a new type of word vector model that relies on context by joint adjusting the bidirectional Transformer in all layers. Basing on BERT model, we proposed a new method comprise BERT, BiLSTM and CRF (Conditional Random Fields) to carry on the intelligent identification of legal case entities. And with abundant experiment result, the better accuracy and efficiency of our method has been proved comparing to traditional models such as Word2Vec.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","186–191","","","","","","","ACM TURC '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hefei, China","","","","BERT; Entity Recognition; Intelligent Legal Affairs; Natural Language Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NBDETF9T","conferencePaper","2019","Netto, Dorgival; Silva, Carla; Araújo, João","Identifying How the Brazilian Software Industry Specifies Legal Requirements","Proceedings of the XXXIII Brazilian Symposium on Software Engineering","978-1-4503-7651-8","","10.1145/3350768.3352730","https://doi.org/10.1145/3350768.3352730","[Background] Software requirements are usually specified in Natural Language, bringing challenges for Requirements Engineering (RE) as these specifications are inherently ambiguous. These challenges become bigger when dealing with software requirements that must comply with regulations, the so-called legal requirements. The state of practice to tackle ambiguity of legal requirements and their compliance with regulations is missing. [Goal] This work investigates how ambiguity in legal requirements specification is addressed and how the software development industry performs legal compliance. [Method] We followed a qualitative approach based on semi-structured interviews involving nine professionals from different companies who presented their views on the RE process, including legal compliance and ambiguity resolution of legal requirements. Data was collected using audio-recorded and analyzed using Grounded Theory. [Results] Findings revealed that customer and legal expert support during the project could reduce the risk of misinterpreting the legislation. Verification and Validation of Legal Compliance are customer assignments. [Conclusions] Ambiguity resolution and legal compliance of requirements are based on the tacit knowledge of experienced team members or discussions between the team and the customer.","2019","2025-02-19 14:42:20","2025-02-19 14:42:20","","181–186","","","","","","","SBES '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salvador, Brazil","","","","Legal Compliance; Ambiguity; Requirements Engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PCN85BJI","conferencePaper","2024","Saint, John; Fan, Yizhou; Gasevic, Dragan","Analytics of scaffold compliance for self-regulated learning","Proceedings of the 14th Learning Analytics and Knowledge Conference","979-8-4007-1618-8","","10.1145/3636555.3636887","https://doi.org/10.1145/3636555.3636887","The shift toward digitally-based education has emphasised the need for learners to have strong skills for self-regulated learning (SRL). The use of scaffolding prompts is seen as an effective way to stimulate SRL and enhance academic outcomes. A key aspect of SRL scaffolding prompts is the degree to which they are complied to by students. Compliance is a complex concept, one that is further complicated by the nature of scaffold design in the context of adaptability. These nuances notwithstanding, scaffold compliance demands specific exploration. To that end, we conducted a study in which we: 1) focused specifically on scaffolding interaction behaviour in a timed online assessment task, as opposed to the broader interaction with non-scaffolding artefacts; 2) identified distinct scaffold interaction patterns in the context of compliance and non-compliance to scaffold design; 3) analysed how groups of learners traverse compliant and non-compliant interaction behaviours and engage in SRL processes in response to a sequence of timed and personalised SRL-informed scaffold prompts. We found that scaffold interactions fell into two categories of compliance and non-compliance, and whilst there was a healthy engagement with compliance, it does ebb and flow during an online timed assessment.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","326–337","","","","","","","LAK '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kyoto, Japan","","","","Self-Regulated Learning; Clustering; Learning Analytics; Process Mining; Scaffolding; Scaffolding Compliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZEHAFD7","conferencePaper","2024","Reitinger, Nathan","Understanding and Addressing Online Tracking: Online Privacy's Regulatory Turn","Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security","979-8-4007-0636-3","","10.1145/3658644.3690857","https://doi.org/10.1145/3658644.3690857","Computing and storage breakthroughs over the last few decades have given rise to online tracking abilities that outpace current-day privacy-enhancing tools, social norms, and privacy regulations. Users lack the tools they need to block the types of tracking they cannot see and have very little control over; data stewards (i.e., companies processing user data) lack an understanding of what types of tracking practices users find normatively problematic; and policymakers lack effective feedback on real-world implementations of the data-focused or tracking-adjacent laws they are drafting-at a time when these regulations are in their infancy and feedback is crucial. Users should be able to navigate the web without falling victim to surreptitious tracking technologies; companies should be aware of what types of tracking users find most problematic; and legislators should be able to rely on empirically driven measurement studies to help them understand where the law falls short and where companies need help. My dissertation work focuses on improving online privacy by developing tracker-blocking tools, investigating user perceptions of online tracking, and systematizing knowledge as it relates to the measurement of statutory instruments. I focus here on the last, in-progress piece: a systematization of the measurement of legal compliance-helping researchers produce measurements that are compelling, ethical, and legally robust.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","5095–5097","","","","","","","CCS '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salt Lake City, UT, USA","","","","privacy; legal; measurement; systematization of knowledge (sok)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B3PH3KQ2","conferencePaper","2022","Rasti, Aidin; Amyot, Daniel; Parvizimosaed, Alireza; Roveri, Marco; Logrippo, Luigi; Anda, Amal Ahmed; Mylopoulos, John","Symboleo2SC: from legal contract specifications to smart contracts","Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems","978-1-4503-9466-6","","10.1145/3550355.3552407","https://doi.org/10.1145/3550355.3552407","Smart contracts (SCs) are software systems that monitor and control the execution of legal contracts to ensure compliance with the contracts' terms and conditions. They often exploit Internet-of-Things technologies to support their monitoring functions, and blockchain technology to ensure the integrity of their data. Ethereum and business blockchain platforms, such as Hyperledger Fabric, are popular choices for SC development. However, there is a gap in the knowledge of SCs between developers and legal experts. Symboleo is a formal specification language for legal contracts that was introduced to address this issue. Symboleo specifications directly encode legal concepts such as parties, obligations, and powers. In this paper, we propose a tool-supported method for translating Symboleo specifications into smart contracts. We have extended the current Symboleo IDE, implemented the ontology and semantics of Symboleo into a reusable library, and developed the Symboleo2SC tool to generate Hyperledger Fabric code exploiting this library. Symboleo2SC was evaluated with three sample contracts. The results shows that legal contract specifications in Symboleo can be fully converted to SCs for monitoring purposes. Moreover, Symboleo2SC helps simplify the SC development process, saves development effort, and helps reduce risks of coding errors.","2022","2025-02-19 14:42:20","2025-02-19 14:42:20","","300–310","","","","","","","MODELS '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, Quebec, Canada","","","","blockchain; smart contracts; code generation; domain-specific languages; legal ontology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GV7VM9CZ","conferencePaper","2019","Mok, Wai Yin; Mok, Jonathan R.","Legal Machine-Learning Analysis: First Steps towards A.I. Assisted Legal Research","Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law","978-1-4503-6754-7","","10.1145/3322640.3326737","https://doi.org/10.1145/3322640.3326737","This research project develops a methodology to utilize machine-learning analysis of live disputes to assist legal professionals in narrowing issues and comparing relevant precedents. Our first step is to extract and classify sentences in breach of contract court decisions according to type. Such court decisions have five basic sentence types: sentences on contract law, sentences on contract holding, sentences on contract issues, sentences on contract reasoning, and sentences on contract facts. The result of this project facilitates further downstream processing such as constructing decision trees that predict the likely outcome for the case at hand, displaying the rationales on which court decisions are based, and calculating the similarity of previous legal precedents.","2019","2025-02-19 14:42:20","2025-02-19 14:42:20","","266–267","","","","","","","ICAIL '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, QC, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FWR9YFZ2","conferencePaper","2024","Wang, Xiaoguo; Shi, Jiachen; Chen, Chao; Cui, Jianwen","A Graph Matching Model Based on Cohesive Hypergraph Convolutional Network for Knowledge Graphs of Financial-field Regulatory Documents","Proceedings of the 2023 4th International Conference on Computer Science and Management Technology","979-8-4007-0951-7","","10.1145/3644523.3644567","https://doi.org/10.1145/3644523.3644567","Based on the actual demand of conducting banking business compliantly for intelligent retrieval of financial-field regulatory documents (FRDs), in view of the features of containing non-pairwise semantic information, high knowledge cohesion within segments and low knowledge coupling between segments in FRDs, in this paper, the hypergraph structure is adopted, and a model based on HGNN that can effectively classify graphs in this field is constructed to implement graph classification, called Cohesive Hypergraph Convolutional Network (CHCN) model. According to existing knowledge graphs of FRDs, a graph matching model in this field based on CHCN, BERT and other models is constructed to effectively solve the problem of graph matching, called Graph Matching model for Knowledge graph of Financial-field regulatory documents (FK-GM) model. The results of the experiments show that compared with other baseline models, CHCN model outperforms in F1, Precision and Recall in the graph classification task on public datasets and a dataset of banking regulatory documents, which verifies the effectiveness of FK-GM, the graph matching model proposed in this paper.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","230–237","","","","","","","ICCSMT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Xi'an, China","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9K9UZ5QV","journalArticle","2019","López-Caamal, Fernando; Huber, Heinrich J.","Stable IL-&lt;inline-formula&gt;&lt;tex-math notation=""LaTeX""&gt;1\beta&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=""lopezcaamal-ieq1-2794971.gif""/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;-Activation in an Inflammasome Signalling Model Depends on Positive and Negative Feedbacks and Tight Regulation of Protein Production","IEEE/ACM Trans. Comput. Biol. Bioinformatics","","1545-5963","10.1109/TCBB.2018.2794971","https://doi.org/10.1109/TCBB.2018.2794971","Introduction. NLRP3-dependent inflammasome signalling is a key pathway during inflammatory processes and its deregulation is implicated in several diseases. NLRP3-inflammasome pathway activation leads to the rapid, phosphorylation-driven NFkappaκB-pathway signalling, subsequently proceeds via slower transcription/translation process for producing pro-enzymes, and finally leads to the medium-speed enzymatic activation of the central inflammatory mediator IL-1beta1β[1] . We here were interested in how the timing of the rate-limiting step of transcription/translation and the presence of a positive and negative auto-regulation would pose conditions for meaningful and stable IL-1beta1β-activation. Methods. We extracted the essential topology of the inflammasome pathway network using a linear chain of first-order reaction and a second-order reaction for inhibitory feedback. We then performed an analytical treatment of the resulting ODE set to obtain closed-form formulae. We therefore looked for the steady states and characterized their stability by using a Jacobian-based, local analysis. We employed the Small Gain Theorem from Control Theory as recently applied by us [2] and the Gershgorin Circle Theorem to obtain mathematically exact conditions for a positive ON state and stabilities for ON and OFF steady states. Results. We identified an ON- and one OFF- steady state whose properties we characterized in terms of the kinetic parameters by closed-form formulae. We found that under the assumption of a first-order information flow through the network, the existence of a biologically reasonable ON steady state required the simultaneous presence of the positive and the negative feedback. Assuming non-competitivity between IL-1beta1β entities binding to different receptors, we found that a minimum kinetics for protein production is required to sustain a steady state with IL-1beta1β activation. Assuming competitivity between IL-1beta1β entities introduced additional restrictions on the maximum protein production speed to guarantee a biologically reasonable ON steady state. Finally, for both models, we ruled out bistability, suggesting that IL-1beta1β activation would undergo a smooth change upon alterations of its parameters. Conclusion. Exemplified by the core pathway of NLRP3-inflammasome signalling, we here demonstrate that a mostly linear activation cascade containing an intermediate rate limiting step poses kinetic restrictions on this step and requires positive and negative autoregulation for obtaining a meaningful ON steady state. Due to the generality of our framework, our results are important for a wide class of receptor mediated-pathways, where a fast initial phosphorylation cascade is followed by a (slower) transcriptional response and subsequent autoregulation. Our results may further provide important design principles for synthetic biological networks involving biochemical activation and transcription/translation, by relating timing considerations and autoregulation to stable pathway activation.","2019-04","2025-02-19 14:42:20","2025-02-19 14:42:20","","627–637","","2","16","","","","","","","","","","","","","","","","","Place: Washington, DC, USA Publisher: IEEE Computer Society Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4B2HL7CQ","conferencePaper","2024","Nahar, Nadia; Rowlett, Jenny; Bray, Matthew; Omar, Zahra Abba; Papademetris, Xenophon; Menon, Alka; Kästner, Christian","Regulating Explainability in Machine Learning Applications – Observations from a Policy Design Experiment","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency","979-8-4007-0450-5","","10.1145/3630106.3659028","https://doi.org/10.1145/3630106.3659028","With the rise of artificial intelligence (AI), concerns about AI applications causing unforeseen harms to safety, privacy, security, and fairness are intensifying. While attempts to create regulations are underway, with initiatives such as the EU AI Act and the 2023 White House executive order, skepticism abounds as to the efficacy of such regulations. This paper explores an interdisciplinary approach to designing policy for the explainability of AI applications, as the widely discussed ""right to explanation"" associated with the EU General Data Protection Regulation is ambiguous. To develop practical guidance for explainability, we conducted an experimental study that involved continuous collaboration among a team of researchers with AI and policy backgrounds over the course of ten weeks. The objective was to determine whether, through interdisciplinary effort, we can reach consensus on a policy for explainability in AI–one that is clearer, and more actionable and enforceable than current guidelines. We share nine observations, derived from an iterative policy design process, which included drafting the policy, attempting to comply with it (or circumvent it), and collectively evaluating its effectiveness on a weekly basis. Key observations include: iterative and continuous feedback was useful to improve policy drafts over time, discussing evidence of compliance was necessary during policy design, and human-subject studies were found to be an important form of evidence. We conclude with a note of optimism, arguing that meaningful policies can be achieved within a moderate time frame and with limited experience in policy design, as demonstrated by our student researchers on the team. This holds promising implications for policymakers, signaling that practical and effective regulation for AI applications is attainable.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","2101–2112","","","","","","","FAccT '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rio de Janeiro, Brazil","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7D6IBSK","conferencePaper","2021","Timón López, Cristina; Alamillo Domingo, Ignacio; Valero Torrijos, Julián","Approaching the Data Protection Impact Assessment as a legal methodology to evaluate the degree of privacy by design achieved in technological proposals. A special reference to Identity Management systems","Proceedings of the 16th International Conference on Availability, Reliability and Security","978-1-4503-9051-4","","10.1145/3465481.3469207","https://doi.org/10.1145/3465481.3469207","The process of digitalization of societies and innovation is involving the fast introduction of new technologies in different sectors. However, the development of technology represents a challenge as it involves technical, legal, economic and social aspects that have to be considered since its conception or design. The aim of this paper is to offer an adaptation of an existing legal methodology, the Data Protection Impact Assessment, as a legal obligation to evaluate technological proposals and assure compliance with privacy by design requirements. For that purpose, we will refer to the specific case of Identity Management technologies. We introduce the main challenges in the sector of Digital Identity Management as well as the importance of covering the “architecture” and “user” sides in the development of safer technologies by citing concrete examples. Finally, in order to provide a more practical view of the methodology to adapt the Data Protection Impact Assessment, we refer to the work developed in the research project OLYMPUS in the evaluation of its privacy implications. By introducing this example, the paper offers a specific methodology directly reusable for the study of technological proposals in IdM but that can be adapted to any other sector.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","ARES '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vienna, Austria","","","","GDPR; Data Protection Impact Assessment; Identity Management; Privacy by design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NNKPQGQQ","conferencePaper","2018","Geko, Melisa; Tjoa, Simon","An Ontology Capturing the Interdependence of the General Data Protection Regulation (GDPR) and Information Security","Proceedings of the Central European Cybersecurity Conference 2018","978-1-4503-6515-4","","10.1145/3277570.3277590","https://doi.org/10.1145/3277570.3277590","High returns for processing personal data and low penalties for privacy violations led to the circumstance that protection of privacy was often not considered a priority. To counter this habit and to harmonize data protection laws throughout the European Union, the EU-Commission has adopted the General Data Protection Regulation (GDPR), clarifying data subject rights and ensuring an appropriate level of privacy protection.Through high penalties for non-compliance (i.e. up to 2% - 4% of the annual worldwide turnover), GDPR was able to put high pressure on organizations to comply with the requirements. However, studies have shown that organizations are often overwhelmed by the actual requirements.In this paper, we therefore aim to support organization to understand this complex topic by providing an ontology-based data protection knowledge base, which highlights the interdependency of GDPR and information security.","2018","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","CECC 2018","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ljubljana, Slovenia","","","","GDPR; Compliance; Audit; Data Protection; EU; Information Security; Legal Ontology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9X9JIUQY","conferencePaper","2013","Boella, Guido; Janssen, Marijn; Hulstijn, Joris; Humphreys, Llio; van der Torre, Leendert","Managing legal interpretation in regulatory compliance","Proceedings of the Fourteenth International Conference on Artificial Intelligence and Law","978-1-4503-2080-1","","10.1145/2514601.2514605","https://doi.org/10.1145/2514601.2514605","Maintaining regulatory compliance is an increasing area of concern for business. Legal Knowledge Management systems that combine repositories of legislation with legal ontologies can support the work of in-house compliance managers. But there are challenges to overcome, of interpreting legal knowledge and mapping that knowledge onto business processes, and developing systems that can adequately handle the complexity with clarity and ease. In this paper we extend the Legal Knowledge Management system Eunomos to deal with alternative interpretations of norms connecting it with Business Process Management systems. Moreover, we propose a workflow involving the different roles in a company, which takes legal interpretation into account in mapping norms and processes, using Eunomos as a support.","2013","2025-02-19 14:42:20","2025-02-19 14:42:20","","23–32","","","","","","","ICAIL '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rome, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMEYVNA7","conferencePaper","2024","Hrle, Temima; Milad, Mary; Li, Jingjie; Woods, Daniel","""Just a tool, until you stab someone with it"": Exploring Reddit Users' Questions and Advice on the Legality of Port Scans","Proceedings of the 2024 European Symposium on Usable Security","979-8-4007-1796-3","","10.1145/3688459.3688469","https://doi.org/10.1145/3688459.3688469","Users, particularly amateurs, face uncertainties about technology law related to both interpretation and enforcement. This uncertainty can have a chilling effect on how users experiment with technology. However, little is known about the precise uncertainties that users face and what kind of advice is available. Our paper focuses on user questions and advice surrounding the legality of port scanning, a dual-purpose technique used in both defensive and offensive security. We identified and analyzed 414 pieces of advice, in response to questions about the legality of port scanning from 36 Reddit threads. We find that users ask two types of questions: (1) reactive questions in which they have scanned and are concerned by the consequences; and (2) proactive questions in which they ask about legality and seek ways to comply with the law. We found no consensus in the advice about legality or the likelihood of prosecution. In justifying advice, users deployed a range of anecdotes, analogies, and URLs. Subtle variations on the analogy between port scanning and physical building security are used to explain why it is both legal and illegal. Users also reason from individual cases, such as arguing prosecution is unlikely because the user had not personally been prosecuted or arguing prosecution is likely because Aaron Swartz was prosecuted. Finally, the most influential URL was a “Legal Issues” page maintained as part of an open-source project. We reflect on how these results can inform forum moderation and public-policy dissemination.","2024","2025-02-19 14:42:20","2025-02-19 14:42:20","","322–336","","","","","","","EuroUSEC '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","content analysis; cybersecurity law; offensive security; security and privacy discourse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMD6IAUS","conferencePaper","2019","Im, Carl; Hemberg, Erik","On the use of context sensitive grammars in grammatical evolution for legal non-compliance detection","Proceedings of the Genetic and Evolutionary Computation Conference Companion","978-1-4503-6748-6","","10.1145/3319619.3322038","https://doi.org/10.1145/3319619.3322038","We extend the context-free grammar mapping method in the Grammatical Evolution search heuristic. Grammatical Evolution guarantees the generation of transparent and syntactically correct sentences(phenotypes), but not necessarily semantically correct or feasible ones. Generating syntactically valid phenotypes with postprocessing to filter out semantically invalid ones suffers from some issues, e.g. introduction of bias toward short phenotypes and loss in search efficiency. These issues become significant in legal application domains. We first demonstrate that applying Grammatical Evolution with a context free grammar to legal non-compliance detection problems might not be a tenable solution. Then we demonstrate how the addition of context sensitivity improves both the search efficiency and achieves a greater diversity in the case of the iBoB problem regarding legal non-compliance.","2019","2025-02-19 14:42:20","2025-02-19 14:42:20","","371–372","","","","","","","GECCO '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Prague, Czech Republic","","","","context sensitivity; genetic programming; grammar; legal non-compliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35ZS22LL","conferencePaper","2021","Suolang, Yunzhen","Innovation on the legal practice teaching under the framework of LETS system","2021 4th International Conference on Information Systems and Computer Aided Education","978-1-4503-9025-5","","10.1145/3482632.3482724","https://doi.org/10.1145/3482632.3482724","Practice teaching of law major is an important way to train and improve the legal practice ability of law students and cultivate applied legal talents, and it is an important part of law education. The importance of practical teaching is particularly prominent in the current transformation of colleges and universities. At present, the practical teaching of law majors in local colleges and universities in China generally has disadvantages such as single teaching mode, serious formalization tendency and poor teaching effectiveness. The application of LETS system, a new experimental teaching system of law, has achieved this goal. The main purpose of studying and innovating the practical teaching system of law under the background of the reform of examination is to establish a scientific, reasonable and feasible practical teaching system of law, build an educational platform integrating legal knowledge, ability and quality, and realize the benign interaction and coordinated development between judicial examination and practical teaching system of law.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","433–437","","","","","","","ICISCAE 2021","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Dalian, China","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J523NU6V","conferencePaper","2019","Sun, Fan-Yun; Chang, Yen-Yu; Wu, Yueh-Hua; Lin, Shou-De","A Regulation Enforcement Solution for Multi-agent Reinforcement Learning","Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems","978-1-4503-6309-9","","","","Human behaviors are regularized by a variety of norms or regulations, either to maintain orders or to enhance social welfare. However, if artificially intelligent (AI) agents make decisions on behalf of human beings, it is possible that an AI agent can opt to disobey the regulations (being defective) for self-interests. In this paper, we aim to answer the following question: In a decentralized environment (no centralized authority can control agents), given that not all agents are compliant to regulations at first, can we develop a mechanism such that it is in the self-interest of non-compliant agents to comply after all. We first introduce the problem as Regulation Enforcement and formulate it using reinforcement learning and game theory. Then we propose our solution based on the key idea that although we could not alter how defective agents choose to behave, we can, however, leverage the aggregated power of compliant agents to boycott the defective ones. We conducted simulated experiments on two scenarios: Replenishing Resource Management Dilemma and Diminishing Reward Shaping Enforcement, using deep multi-agent reinforcement learning algorithms. We further use empirical game-theoretic analysis to show that the method alters the resulting empirical payoff matrices in a way that promotes compliance (making mutual compliant a Nash Equilibrium).","2019","2025-02-19 14:42:20","2025-02-19 14:42:20","","2201–2203","","","","","","","AAMAS '19","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Montreal QC, Canada","","","","empirical game-theoretic analysis; multi-agent reinforcement learning; reward shaping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WR8DHCLE","conferencePaper","2021","Mazurowska, Anna","Climate change overlooked. The role of attitudes and mood regulation in visual attention to global warming","ACM Symposium on Eye Tracking Research and Applications","978-1-4503-8357-8","","10.1145/3450341.3457991","https://doi.org/10.1145/3450341.3457991","Why, in the face of climate catastrophe, do people still seem to underestimate the weight of the threat without taking adequate action to fight global warming? Among many reasons for this, the current study aims to dive into people’s cognitive abilities and explore the barriers located at the individual level, using an eye-tracking methodology. Previous findings indicate that a pro-environmental attitude does not necessarily lead to pro-environmental behavior. What may stand in the way is ignorance that can be mediated by other factors. This study will examine whether visual distraction from images depicting the impacts of climate change is mediated by mood regulation and environmental concern. This will help to fit educational and information materials to specific viewers, which may result in more pro-environmental behaviors in the future.","2021","2025-02-19 14:42:20","2025-02-19 14:42:20","","","","","","","","","ETRA '21 Adjunct","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Germany","","","","climate change; environmental psychology; mood regulation; pro-environmental attitude; visual attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YADKCC6","conferencePaper","2022","Rak, Richard","Internet of Healthcare: Opportunities and Legal Challenges in Internet of Things-Enabled Telehealth Ecosystems","Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance","978-1-4503-9011-8","","10.1145/3494193.3494260","https://doi.org/10.1145/3494193.3494260","The COVID-19 public health crisis has accelerated the transformation of health systems to become more closely tied to citizens/patients and increasingly dependent on the provision and use of telehealth services. Internet of Things (IoT)-enabled telehealth systems (deployed in conjunction with AI systems) could facilitate the smart transformation of healthcare from a merely reactive system to a data-driven and person-centred system that provides remote health diagnosis, monitoring and treatment services, integrated real-time response solutions, as well as prospective insights. However, the realisation of these health-related benefits requires the processing of vast amounts of data concerning health. These operations and the use of new enabling technologies raises significant legal concerns and questions the applicability of existing/proposed legal concepts. For this reason, the research analyses the adequateness of EU privacy, data protection, data governance, AI governance and other regulatory rules in IoT-enabled (and AI-augmented) telehealth systems. In addition, the research aims to identify technical and organisational measures (best practices), which could facilitate the implementation of normative principles in these information systems in an effective manner.","2022","2025-02-19 14:42:21","2025-02-19 14:42:21","","481–484","","","","","","","ICEGOV '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Athens, Greece","","","","data protection; AI; privacy; data governance; eHealth; Internet of Healthcare; Internet of Things; telehealth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XL36FVL3","conferencePaper","2019","Atkinson, Katie; Bench-Capon, Trevor","Reasoning with Legal Cases: Analogy or Rule Application?","Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law","978-1-4503-6754-7","","10.1145/3322640.3326695","https://doi.org/10.1145/3322640.3326695","Modelling reasoning with precedents has been a central concern of AI and Law since its inception. A recent paper has provided a discussion (in jurisprudential terms) of whether such reasoning is best seen as rule application or analogy. We review some of the prominent AI and Law approaches and find that over the years there has been a move away from analogy to rule application. Even in those approaches which do use analogy, however, the analogies handled concern only analogies between cases represented as sets of factors, and do not consider analogies between the elements of the fact situations peculiar to particular cases. In actual practice, however, analogies are used to determine which factors are relevant in a case, and which party is favoured by particular aspects of the case situation. Such analogies relate not to factors, but to real-world elements of the case and are hard to make and critique without a comprehensive common sense ontology. Thus while we may be able to construct specific ontologies to model past examples of such analogical reasoning, which can be useful for simulation and teaching, the ability to perform analogical reasoning on novel situations is, and is likely to remain, infeasible. This conclusion suggests that there will always be limits to our ability to construct systems able to handle new cases presenting novel situations.","2019","2025-02-19 14:42:21","2025-02-19 14:42:21","","12–21","","","","","","","ICAIL '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, QC, Canada","","","","argumentation; analogy; reasoning with cases","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBBZMJH3","conferencePaper","2017","Muthuri, Robert; Boella, Guido; Hulstijn, Joris; Capecchi, Sara; Humphreys, Llio","Compliance patterns: harnessing value modeling and legal interpretation to manage regulatory conversations","Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law","978-1-4503-4891-1","","10.1145/3086512.3086526","https://doi.org/10.1145/3086512.3086526","Companies must be able to demonstrate that their way of doing business is compliant with relevant rules and regulations. However, the law often has open texture; it is generic and needs to be interpreted before it can be applied in a specific case. Entrepreneurs generally lack the expertise to engage in the regulatory conversations that make up this interpretation process. In particular for the application domain of technological startups, this leads to legal risks. This research seeks to develop a robust module for legal interpretation. We apply informal logic to bridge the gap between the principles of interpretation in legal theory with the legal rules that determine compliance of business processes. Accordingly, interpretive arguments characterized by argument schemes are applied to business models represented by value modeling (VDML). The specific outcome of the argumentation process (if any) is then summarized into a compliance pattern, in a context-problem-solution format. A case study from copyright law, about an internet television company, shows that the approach is able to express the legal arguments of the case, but is also understandable for the target audience.","2017","2025-02-19 14:42:21","2025-02-19 14:42:21","","139–148","","","","","","","ICAIL '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: London, United Kingdom","","","","compliance patterns; legal interpretation; value modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YNUYFZMC","conferencePaper","2017","Guarda, Paolo; Ranise, Silvio; Siswantoro, Hari","Security Analysis and Legal Compliance Checking for the Design of Privacy-friendly Information Systems","Proceedings of the 22nd ACM on Symposium on Access Control Models and Technologies","978-1-4503-4702-0","","10.1145/3078861.3078879","https://doi.org/10.1145/3078861.3078879","Nowadays, most of business practices involve personal data-processing of customers and employees. This is strictly regulated by legislation to protect the rights of the data subject. Enforcing regulation into enterprise information system is a non-trivial task that requires an interdisciplinary approach. This paper presents a declarative framework to support the specification of information system designs, purpose-aware access control policies, and the legal requirements derived from the European Data Protection Directive. This allows for compliance checking via a reduction to policy refinement that is supported by available automated tools. We briefly discuss the results of the compliance analysis with a prototype tool on a simple but realistic scenario about the processing of personal data to produce salary slips of employees in an Italian organization.","2017","2025-02-19 14:42:21","2025-02-19 14:42:21","","247–254","","","","","","","SACMAT '17 Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Indianapolis, Indiana, USA","","","","legal compliance; access control policies; eu dpd","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YEU9BRGH","conferencePaper","2021","Zhihua, Xu","Research on the Mechanism of Data Visualization Analysis in the Cultivation of Foreign-related Legal Talents","2021 2nd International Conference on Computers, Information Processing and Advanced Education","978-1-4503-8996-9","","10.1145/3456887.3457475","https://doi.org/10.1145/3456887.3457475","This article conducts in-depth research on the mechanism of foreign-related legal personnel training, visually analyzes relevant data, based on the practical teaching model, formulates reasonable teaching training goals based on the theoretical context of foreign-related legal management and the characteristics of industry practice, and implements field research technology, by sending teaching questions to students in advance, letting students conduct project investigations in groups on the spot, trying to let students gain an in-depth understanding of the operation of foreign-related laws through cooperation and practice, and explore the mechanism of practical infiltration teaching mode for professional talent training. Build a more open pattern of legal services, and at the same time increase the training of foreign-related legal talents, the cooperation, and exchanges within and outside the lawyer industry, and improve the ability of foreign-related legal services.","2021","2025-02-19 14:42:21","2025-02-19 14:42:21","","1140–1145","","","","","","","CIPAE 2021","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ottawa, ON, Canada","","","","Data visualization analysis; foreign-related law; mechanism of action; talent training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XKQRWGX4","conferencePaper","2019","Panteli, Maria","Recommendation systems compliant with legal and editorial policies: the BBC+ app journey","Proceedings of the 13th ACM Conference on Recommender Systems","978-1-4503-6243-6","","10.1145/3298689.3346961","https://doi.org/10.1145/3298689.3346961","The BBC produces thousands of pieces of content every day and numerous BBC products deliver this content to millions of users. For many years the content has been manually curated (this is evident in the selection of stories on the front page of the BBC News website and app for example). To support content creation and curation, a set of editorial guidelines have been developed to build quality and trust in the BBC. As personalisation becomes more important for audience engagement, we have been exploring how algorithmically-driven recommendations could be integrated in our products. In this talk we describe how we developed recommendation systems for the BBC+ app that comply with legal and editorial policies and promote the values of the organisation. We also discuss the challenges we face moving forward, extending the use of recommendation systems for a public service media organisation like the BBC.The BBC+ app is the first product to host in-house recommendations in a fully algorithmically-driven application. The app surfaces short video clips and is targeted at younger audiences. The first challenge we dealt with was content metadata. Content metadata are created for different purposes and managed by different teams across the organisation making it difficult to have reliable and consistent information. Metadata enrichment strategies have been applied to identify content that is considered to be editorially sensitive, such as political content, current legal cases, archived news, commercial content, and content unsuitable for an under 16 audience. Metadata enrichment is also applied to identify content that due care has not been taken such as poor titles, and spelling and grammar mistakes. The first versions of recommendation algorithms exclude all editorially risky content from the recommendations, the most serious of which is avoiding contempt of court. In other cases we exclude content that could undermine our quality and trustworthiness.The General Data Protection Regulation (GDPR) that recently came into effect had strong implications on the design of our system architecture, the choice of the recommendation models, and the implementation of specific product features. For example, the user should be able to delete their data or switch off personalisation at any time. Our system architecture should allow us to trace down and delete all data from that user and switch to non-personalised content. The recommendations should also be explainable and this led us to sometimes choosing a simpler model so that it is possible to more easily explain why a user was recommended a particular type of content. Specific product features were also added to enhance transparency and explainability. For example, the user could view their history of watched items, delete any item, and get an explanation of why a piece of content was recommended to them.At the BBC we aim to not only entertain our audiences but also to inform and educate. These BBC values are also reflected in our evaluation strategies and metrics. While we aim to increase audience engagement we are also responsible for providing recent and diverse content that meets the needs of all our audiences. Accuracy metrics such as Hit Rate and Normalized Discounted Cumulative Gain (NDCG) can give a good estimate of the predictive performance of the model. However, recency and diversity metrics have sometimes more weight in our products, especially in applications delivering news content. What is more, qualitative evaluation is very important before releasing any new model into production. We work closely with editorial teams who provide feedback on the quality of the recommendations and flag content not adhering to the BBC's values or the legal and editorial policies.The development of the BBC+ app has been a great journey. We learned a lot about our content metadata, the implications of GDPR in our system, and our evaluation strategies. We created a minimum viable product that is compliant with legal and editorial policies. However, a lot needs to be done to ensure the recommendations meet the quality standards of the BBC. While excluding editorially sensitive content has limited the risk of contempt of court, algorithmic fairness and impartiality still need to be addressed. We encourage the community to look more into these topics and help us create the way forward towards applications with responsible machine learning.","2019","2025-02-19 14:42:21","2025-02-19 14:42:21","","529","","","","","","","RecSys '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Copenhagen, Denmark","","","","public service; recommendations; technology policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8KU52XT","conferencePaper","2019","Laukyte, Migle","AI as a Legal Person","Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law","978-1-4503-6754-7","","10.1145/3322640.3326701","https://doi.org/10.1145/3322640.3326701","The idea of the legal personhood of artificial intelligence (AI) — the idea that intelligent agents can have rights and incur obligations under the law— is controversial, and in fact is often dismissed out of hand: in this paper I will argue that, on the contrary, such legal personhood may be the next big challenge for our legal systems, and we need it to deal with the new kinds of complexity introduced by AI. Furthermore, I argue that we already have experiences we can look: to this end we can draw on the reasoning applied to the legal personhood recognized for corporations and other nonhuman entities. In order to do this, I address some of the criticisms against ascribing legal personhood to AI. I also look at the Canadian and EU ethical guidelines so as to keep the development of AI within the framework of human values, and I show that an ascription of legal personhood to AI is consistent with them. I also address a few of the big issues involved in making the legal personhood of AI a reality.","2019","2025-02-19 14:42:21","2025-02-19 14:42:21","","209–213","","","","","","","ICAIL '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, QC, Canada","","","","Ethics; Artificial Intelligence; Corporation; Legal Personhood; Rights","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LSA55MDL","conferencePaper","2020","Virkar, Shefali; Alexopoulos, Charalampos; Stavropoulou, Stefania; Tsekeridou, Sofia; Novak, Anna-Sophie","User-centric decision support system design in legal informatics: a typology of users","Proceedings of the 13th International Conference on Theory and Practice of Electronic Governance","978-1-4503-7674-7","","10.1145/3428502.3428609","https://doi.org/10.1145/3428502.3428609","Accurate, target-oriented, and timely legal information is a strategic input in effective decision-making for a plethora of actors within society. However, the ability of citizens, businesses, local administrations, national governments and European institutions to fully harness this latent potential presupposes an adequate understanding of the procedures of the legal system at all levels of government, and an advanced knowledge of where to find these data sources. As technological sophistry has increased, decision support tools, services and systems have come more and more to encompass not just hardware involved in the automation of decision-making processes, but also the software applications focusing on supporting human cognitive reasoning. Mechanisms that facilitate the systematic searching and sorting of large quantities of information within textual databases through the application of advanced document management techniques can, in fact, support actors during the process of decision-making. The envisioned system aims at the conceptualisation and development of the proper environment for semantically annotated Big Open Legal Data (BOLD), one that makes it easily searchable and exploitable with proper visualization techniques. It is founded on the premise that decision support is a specific service targeted at expert user groups, located within a larger bundle of offerings. This research paper contributes to a more nuanced understanding of the legal information ecology through the development of a taxonomy of potential users of legal information, based on a critical exploration of legal information needs and legal information search and retrieval strategies. We argue that the provision of decision support is highly relevant to a wide number of actors in differing contexts to effectuate e-government processes within society, and is, in consequence, not just a dedicated tool or service, but instead the sum total of the services that the system under consideration proposes to offer.","2020","2025-02-19 14:42:21","2025-02-19 14:42:21","","711–722","","","","","","","ICEGOV '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Athens, Greece","","","","requirements engineering; decision support systems; Legal informatics; legal information retrieval; text mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JY4ZF3PI","journalArticle","2019","Kotsios, Andreas; Magnani, Matteo; Vega, Davide; Rossi, Luca; Shklovski, Irina","An Analysis of the Consequences of the General Data Protection Regulation on Social Network Research","Trans. Soc. Comput.","","","10.1145/3365524","https://doi.org/10.1145/3365524","This article examines the principles outlined in the General Data Protection Regulation in the context of social network data. We provide both a practical guide to General Data Protection Regulation–compliant social network data processing, covering aspects such as data collection, consent, anonymization, and data analysis, and a broader discussion of the problems emerging when the general principles on which the regulation is based are instantiated for this research area.","2019-12","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","3","2","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","GDPR; General Data Protection Regulation; social media; social network analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZVVRTVTW","journalArticle","2019","Kafali, Özgür; Ajmeri, Nirav; Singh, Munindar P.","DESEN: Specification of Sociotechnical Systems via Patterns of Regulation and Control","ACM Trans. Softw. Eng. Methodol.","","1049-331X","10.1145/3365664","https://doi.org/10.1145/3365664","We address the problem of engineering a sociotechnical system (STS) with respect to its stakeholders’ requirements. We motivate a two-tier STS conception composed of a technical tier that provides control mechanisms and describes what actions are allowed by the software components, and a social tier that characterizes the stakeholders’ expectations of each other in terms of norms. We adopt agents as computational entities, each representing a different stakeholder. Unlike previous approaches, our framework, DESEN, incorporates the social dimension into the formal verification process. Thus, DESEN supports agents potentially violating applicable norms—a consequence of their autonomy. In addition to requirements verification, DESEN supports refinement of STS specifications via design patterns to meet stated requirements. We evaluate DESEN at three levels. We illustrate how DESEN carries out refinement via the application of patterns on a hospital emergency scenario. We show via a human-subject study that a design process based on our patterns is helpful for participants who are inexperienced in conceptual modeling and norms. We provide an agent-based environment to simulate the hospital emergency scenario to compare STS specifications (including participant solutions from the human-subject study) with metrics indicating social welfare and norm compliance, and other domain dependent metrics.","2019-12","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","1","29","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Agent-oriented software engineering; design patterns; norms; security and privacy requirements; simulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XHDYG2M","conferencePaper","2018","Thelisson, Eva; Sharma, Kshitij; Salam, Hanan; Dignum, Virginia","The General Data Protection Regulation: An Opportunity for the HCI Community?","Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5621-3","","10.1145/3170427.3170632","https://doi.org/10.1145/3170427.3170632","With HCI, researchers conduct studies in interdisciplinary projects involving massive volume of data, artificial intelligence and machine learning capabilities. Awareness of the responsibility is emerging as a key concern for the HCI community.This Community will be impacted by the General Data Protection Regulation (GDPR) [5], that will enter into force on the 25th of May 2018. From that date, each data controller and data processor will face an increase of its legal obligations (in particular its accountability) under certain conditions.The GDPR encourages the adoption of Soft Law mechanisms, approved by the national competent authority on data protection, to demonstrate the compliance to the Regulation. Approved Guidelines, Codes of Conducts, Labeling, Marks and Seals dedicated to data protection, as well as certification mechanisms are some of the options proposed by the GDPR.There may be discrepancies between the realities of HCI fieldwork and the formal process of obtaining Soft Law approval by Competent Authorities dedicated to data protection. Given these issues, it is important for researchers to reflect on legal and ethical encounters in HCI research as a community.This workshop will provide a forum for researchers to share experiences about Soft Law they have put in place to increase Trust, Transparency and Accountability among the shareholders. These discussions will be used to develop a white paper of practical Soft Law mechanisms (certification, labeling, marks, seals...) emerging in HCI research with the aim to demonstrate that the GDPR may be an opportunity for the HCI community.","2018","2025-02-19 14:42:21","2025-02-19 14:42:21","","1–8","","","","","","","CHI EA '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal QC, Canada","","","","privacy; codes of conduct; design; labeling; quality standards; responsible innovation; soft law","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H7MIKRP6","conferencePaper","2021","Kurshan, Eren; Shen, Hongda; Chen, Jiahao","Towards self-regulating AI: challenges and opportunities of AI model governance in financial services","Proceedings of the First ACM International Conference on AI in Finance","978-1-4503-7584-9","","10.1145/3383455.3422564","https://doi.org/10.1145/3383455.3422564","AI systems have found a wide range of application areas in financial services. Their involvement in broader and increasingly critical decisions has escalated the need for compliance and effective model governance. Current governance practices have evolved from more traditional financial applications and modeling frameworks. They often struggle with the fundamental differences in AI characteristics such as uncertainty in the assumptions, and the lack of explicit programming. AI model governance frequently involves complex review flows and relies heavily on manual steps. As a result, it faces serious challenges in effectiveness, cost, complexity, and speed. Furthermore, the unprecedented rate of growth in the AI model complexity raises questions on the sustainability of the current practices. This paper focuses on the challenges of AI model governance in the financial services industry. As a part of the outlook, we present a system-level framework towards increased self-regulation for robustness and compliance. This approach aims to enable potential solution opportunities through increased automation and the integration of monitoring, management, and mitigation capabilities. The proposed framework also provides model governance and risk management improved capabilities to manage model risk during deployment.","2021","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","","","","","","ICAIF '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: New York, New York","","","","artificial intelligence; machine learning; financial services; model governance; model risk management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UP5MFVM4","conferencePaper","2011","Marengo, Elisa; Baldoni, Matteo; Baroglio, Cristina; Chopra, Amit K.; Patti, Viviana; Singh, Munindar P.","Commitments with regulations: reasoning about safety and control in REGULA","The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 2","0-9826571-6-1","","","","Commitments provide a flexible means for specifying the business relationships among autonomous and heterogeneous agents, and lead to a natural way of enacting such relationships. However, current formalizations of commitments incorporate conditions expressed as propositions, but disregard (1) temporal regulations and (2) an agent's control over such regulations. Thus, they cannot handle realistic application scenarios where time and control are often central because of domain conventions or other requirements.We propose a new formalization of commitments that builds on an existing representation of events in which we can naturally express temporal regulations as well as what an agent can control, including indirectly as based on the commitments and capabilities of other agents. Our formalization supports a notion of commitment safety. A benefit of our consolidated approach is that by incorporating these considerations into commitments we enable agents to reason about and flexibly enact the regulations.The main contributions of this paper include (1) a formal semantics of commitments that accommodates temporal regulations; (2) a formal semantics of the notions of innate and social control; and (3) a formalization of when a temporal commitment is safe for its debtor. We evaluate our contributions using an extensive case study.","2011","2025-02-19 14:42:21","2025-02-19 14:42:21","","467–474","","","","","","","AAMAS '11","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Taipei, Taiwan","","","","business process modeling; business protocols","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4NJG5JU3","conferencePaper","2023","Atkinson, Katie; Bench-Capon, Trevor","ANGELIC II: An Improved Methodology for Representing Legal Domain Knowledge","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595137","https://doi.org/10.1145/3594536.3595137","The purpose of this paper is to provide a definitive, up-to-date account of a methodology has that been proven successful for representing and reasoning about legal domains. The ANGELIC (ADF for kNowledGe Encapsulation of Legal Information for Cases) methodology was originally developed to exploit then recent developments in knowledge representation techniques that lend themselves well to capturing factor-based reasoning about legal cases. The methodology is situated firmly within the tradition of research in AI and Law that aims to build systems that are knowledge rich in terms of the domain expertise that is emulated within the systems. When the methodology was first introduced, it was demonstrated on academic examples, but it was subsequently used in and evaluated on a variety of real world domains for external clients. This set of evaluation exercises yielded a variety of learning points as the methodology was applied to different legal domains with their own particular features. These learning points, and the extensions to the methodology that follow from them, urge a consolidation exercise to provide an updated version of the methodology that reflects how it has matured over time. This paper represents a milestone in the development of the methodology in that it presents the ANGELIC II Domain Model, along with a description of its constituent parts, and demonstrates its application through a case study in a key evaluation domain.","2023","2025-02-19 14:42:21","2025-02-19 14:42:21","","12–21","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","Legal Knowledge Representation; Design; Methodology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWFYTR3S","conferencePaper","2019","Morris, Jason","User-Friendly Open-Source Case-Based Legal Reasoning","Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law","978-1-4503-6754-7","","10.1145/3322640.3326717","https://doi.org/10.1145/3322640.3326717","The access to justice crisis is one that cannot be effectively solved without the automation of legal services. The automation of legal services cannot be efficiently done without efficiently automating legal reasoning. Legal case-based reasoning (CBR) provides a method of obtaining explainable and strong predictions for legal issues that lawyers would typically predict on the basis of analogy to prior decided cases. Automating explainable predictions with regard to these sorts of legal issues is difficult without resort to CBR.Wider adoption of CBR in the legal realm therefore has the potential to increase the scope of legal services that can be automated. Despite this potential, as of early 2018 there were no open-source or commercially-available tools for building legal case-based reasoning systems. This paper describes an open-source tool named docassemble-openlcbr[5] designed for ease of use by legal professionals in implementing CBR in the development of automated legal services.","2019","2025-02-19 14:42:21","2025-02-19 14:42:21","","270–271","","","","","","","ICAIL '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, QC, Canada","","","","demonstration; docassemble; law; legal case-based reasoning; open-source; openlcbr","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7TIT7FYW","conferencePaper","2024","Netto, Dorgival Pereira da Silva; Silva, Carla; Araújo, João","How Software Industry Specifies Requirements Compliant with Data Protection Laws: a survey-based study","Proceedings of the XXIII Brazilian Symposium on Software Quality","979-8-4007-1777-2","","10.1145/3701625.3701663","https://doi.org/10.1145/3701625.3701663","[Context] There are few studies focused on discovering the state of practice related to how Information Technology (IT) industry achieves legal compliance in software requirements activities. A previous work reported an interview-based study with seven practitioners from seven IT companies tackling with legal compliance in software requirements specification (SRS). As a result, a initial theory emerged from the interviews and explains a set of factors influencing the work practices used by public and private companies to achieve requirements specification compliance with data protection laws. [Objective] This study reviews and improves the initial theory with information obtained from 39 practitioners regarding how they produce requirements specifications compliant with data protection laws. [Method] We designed a survey protocol that contains an questionnaire composed of a set of propositions inferred from the previous interview-based study and the related literature. [Results] Findings reveal that legal requirements are specified textually and the techniques that help achieve legal compliance are basic knowledge about law for software engineers, training in ambiguity identification techniques, assigning a person for tracing laws and legal regulations, identifying relevant laws and legal regulations to be analysed by lawyers and defining a glossary for all domain-specific concepts and acronyms. [Conclusion] The factors and actions that emerged in this study can be used by researchers and practitioners to leverage the methods and tools they develop or use to specify system requirements that must comply with data protection laws.","2024","2025-02-19 14:42:21","2025-02-19 14:42:21","","242–252","","","","","","","SBQS '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","Ambiguity; Legal compliance; Privacy requirements; Qualitatve study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UNEZTCPF","journalArticle","2018","Urquhart, Lachlan","Ethical dimensions of user centric regulation","SIGCAS Comput. Soc.","","0095-2737","10.1145/3243141.3243151","https://doi.org/10.1145/3243141.3243151","In this paper, we question the role of information technology (IT) designers in IT regulation. Through our concept of user centric regulation (UCR) we unpack what a closer alignment of IT design and regulation could mean. We also situate how they can respond to their ethical and legal duties to end users. Our concept asserts that human computer interaction (HCI) designers are now regulators and as designers are not traditionally involved in the practice of regulation hence the nature of their role is ill-defined. We believe designers need support in understanding what their new role entails, particularly managing ethical dimensions that go beyond law and compliance. We use conceptual analysis to consolidate perspectives from across Human Computer Interaction and Information Technology Law and Regulation, Computer Ethics, Philosophy of Technology, and beyond. We focus in this paper on the importance of mediation and responsibility and illustrate our argument by drawing on the emerging technological setting of smart cities.","2018-07","2025-02-19 14:42:21","2025-02-19 14:42:21","","81–95","","4","47","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","human computer interaction; information technology law and regulation; smart cities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TG8T3HI","journalArticle","2025","Waller, Madeleine; Rodrigues, Odinaldo; Lee, Michelle Seng Ah; Cocarascu, Oana","Bias Mitigation Methods: Applicability, Legality, and Recommendations for Development","J. Artif. Int. Res.","","1076-9757","10.1613/jair.1.16759","https://doi.org/10.1613/jair.1.16759","As algorithmic decision-making systems (ADMS) are increasingly deployed across various sectors, the importance of research on fairness in Artificial Intelligence (AI) continues to grow. In this paper we highlight a number of significant practical limitations and regulatory compliance issues associated with the application of existing bias mitigation methods to ADMS. We present an example of an algorithmic system used in recruitment to illustrate these limitations. Our analysis of existing methods indicates a pressing need for a change in the approach to the development of new methods. In order to address the limitations, we provide recommendations for key factors to consider in the development of new bias mitigation methods that aim to be effective in real-world scenarios and comply with legal requirements in the European Union, United Kingdom and United States, such as non-discrimination, data protection and sector-specific regulations. Further, we suggest a checklist relating to these recommendations that should be included with the development of new bias mitigation methods.","2025-01","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","","81","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","Liability; Artificial Intelliegnce; Causality; social impact","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3N248ITP","conferencePaper","2020","Camungol, Isalyn F.; Gonzales, Yves I.; Roleda, Lydia","Progression of Scientific Reasoning and Metacognitive Regulation of Secondary Students in the New K-12 Curriculum in Blended Learning Environment","Proceedings of the 2020 11th International Conference on E-Education, E-Business, E-Management, and E-Learning","978-1-4503-7294-7","","10.1145/3377571.3377634","https://doi.org/10.1145/3377571.3377634","The new K-12 curriculum aims to improve the reasoning skills of the learners as they moved from one level to another. In line with this, the researcher made a cross-sectional study on the scientific reasoning skills across Grades 7,10, and 12 as well as their metacognitive regulation skills under teachers who use blended learning approach in the new K-12 curriculum which is a combination of face to face interaction and an online platform in teaching Physics. The teachers used ck12.org as an online platform for assignments and quizzes in their Physics classes. The researchers chose two sections per grade level. The study consisted of 49 grade 7 students and 54 grade 10, and 45 grade 12 students. A total of 148 students participated in the study. The researcher found out that in terms of scientific reasoning, grade 7 has no significant difference with grade 10. However, both grade 7 and grade 10 have significant difference in scientific reasoning with grade 12. In terms of metacognitive regulation, the three groups (grade 7, 10 and 12) have no significant difference. Using Pearson r correlation, the study suggested that there is no significant correlation between scientific reasoning and metacognitive regulation.","2020","2025-02-19 14:42:21","2025-02-19 14:42:21","","10–14","","","","","","","IC4E '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Osaka, Japan","","","","Blended learning; metacognitive awareness; scientific reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"368XTYQV","conferencePaper","2015","Rotolo, Antonino; Governatori, Guido; Sartor, Giovanni","Deontic defeasible reasoning in legal interpretation: two options for modelling interpretive arguments","Proceedings of the 15th International Conference on Artificial Intelligence and Law","978-1-4503-3522-5","","10.1145/2746090.2746100","https://doi.org/10.1145/2746090.2746100","This paper offers a new logical machinery for reasoning about interpretive canons. We identify some options for modelling reasoning about interpretations and show that interpretative argumentation has a distinctive structure where the claim that a legal text ought or may be interpreted in a certain way can be supported or attacked by arguments, whose conflicts may have to be assessed according to further arguments.","2015","2025-02-19 14:42:21","2025-02-19 14:42:21","","99–108","","","","","","","ICAIL '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California","","","","argumentation; legal interpretation; defeasible logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWJVUUVG","conferencePaper","2015","Rey-Moreno, C.; Tucker, W. D.; Cull, D.; Blom, R.","Making a community network legal within the South African regulatory framework","Proceedings of the Seventh International Conference on Information and Communication Technologies and Development","978-1-4503-3163-0","","10.1145/2737856.2737867","https://doi.org/10.1145/2737856.2737867","Community networks often operate at the fringe of legality with respect to spectrum, network infrastructure and providing services. We have been involved with such a network in a rural community, and together with them, have devised a way to become legal within the South African regulatory framework. A not-for-profit co-operative was formed and successfully applied for license exemption to operate the network infrastructure and offer services. Revenue is used to sustain the network and can also be used for other community needs. The network has equipment that is not 100% type-approved, and operates at a higher output power than is allowed. However, we have a simple plan to comply with such regulations. This paper offers our experience as a precedent for how to go about making a community network completely legal in South Africa and other countries that have a similar regulatory environment.","2015","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","","","","","","ICTD '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZLPF56N","conferencePaper","2015","Soltana, Ghanem; Sannier, Nicolas; Sabetzadeh, Mehrdad; Briand, Lionel C.","A model-based framework for probabilistic simulation of legal policies","Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems","978-1-4673-6908-4","","","","Legal policy simulation is an important decision-support tool in domains such as taxation. The primary goal of legal policy simulation is predicting how changes in the law affect measures of interest, e.g., revenue. Currently, legal policies are simulated via a combination of spreadsheets and software code. This poses a validation challenge both due to complexity reasons and due to legal experts lacking the expertise to understand software code. A further challenge is that representative data for simulation may be unavailable, thus necessitating a data generator. We develop a framework for legal policy simulation that is aimed at addressing these challenges. The framework uses models for specifying both legal policies and the probabilistic characteristics of the underlying population. We devise an automated algorithm for simulation data generation. We evaluate our framework through a case study on Luxembourg's Tax Law.","2015","2025-02-19 14:42:21","2025-02-19 14:42:21","","70–79","","","","","","","MODELS '15","","","","IEEE Press","","","","","","","","","Place: Ottawa, Ontario, Canada","","","","simulation; legal policies; model-driven code generation; probabilistic data generation; UML profiles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWNEZM7R","conferencePaper","2022","Lallas, Efthimios; Santouridis, Ilias; Mountzouris, Georgios; C. Gerogiannis, Vassilis; Karageorgos, Anthony","An Ontology based Conceptualization of Data Integrity Regulatory Compliance in Pharmaceutical Industry: The SPuMoNI Case","Proceedings of the 25th Pan-Hellenic Conference on Informatics","978-1-4503-9555-7","","10.1145/3503823.3503907","https://doi.org/10.1145/3503823.3503907","Data integrity plays a pivotal role in the pharmaceutical regulatory landscape, where data must be attributable, legible, contemporaneous, original, accurate, complete, consistent, enduring, and available, in other words, must be ALCOA compliant. Data in the pharmaceutical industry are complex and come in large amounts and various types, thus making the utilization of information technology systems in managing data integrity compliance, necessary. This study, has been conducted in the context of the SPuMoNI project, and it presents the conceptual design of a regulatory framework for the pharmaceutical domain, which is aligned with the data integrity ALCOA principles and based on ontology engineering technology. In doing so, it proposes the Data Integrity Ontology (DIOnt), which provides a solid basis for the semantic representation of the pharmaceutical manufacturing process and data, and the modeling and management of regulatory requirements. Moreover, a proof-of-concept prototype has been implemented and validated with real world pharmaceutical data in ALCOA principle violation scenarios.","2022","2025-02-19 14:42:21","2025-02-19 14:42:21","","460–465","","","","","","","PCI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Volos, Greece","","","","regulatory compliance; ALCOA; data integrity; ontology technology; pharmaceutical industry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DN3F287L","conferencePaper","2016","Tsakalakis, Niko; O'Hara, Kieron; Stalla-Bourdillon, Sophie","Identity assurance in the UK: technical implementation and legal implications under the eIDAS regulation","Proceedings of the 8th ACM Conference on Web Science","978-1-4503-4208-7","","10.1145/2908131.2908152","https://doi.org/10.1145/2908131.2908152","The UK Government has been designing a new Electronic Identity Management (eIDM) system that, once rolled–out, will take over how citizens authenticate against online public services. This system, Gov.UK Verify, has been promoted as a state–of–the–art privacy–preserving system, tailored to meet the requirements of UK citizens and is the first eIDM interoperability in which the government does not act as an identity provider itself, delegating the provision of identity to competing third parties. According to the recently enacted EU eIDAS Regulation, member states can allow their citizens to transact with foreign services by notifying their national eID scheme. Once a scheme is notified, all other member states are obligated to incorporate it into their electronic identification procedures. The UK Government is contemplating at the moment whether it would be beneficial to notify. This article examines Gov.UK Verify 's compliance with the requirements set forth by the Regulation and the impact on privacy and data protection. It then explores potential interoperability issues with other national eID schemes, using the German nPA, an eIDM based on national identity cards, as a reference point. The article highlights areas of attention, should the UK decide to notify Gov.UK Verify. It also contributes to relevant literature of privacy–preserving eID management by offering policy and technical recommendations for compliance with the new Regulation and an evaluation of interoperability under eIDAS between systems of different architecture.","2016","2025-02-19 14:42:21","2025-02-19 14:42:21","","55–65","","","","","","","WebSci '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hannover, Germany","","","","eID; eIDAS; eIDM; electronic identity; German nPA; Gov.UK verify; trust services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKPTIP2P","conferencePaper","2020","Duan, Xin; Gao, Jiaojiao","Third-party E-commerce Trading Platform Prevents Economic Contract Legal Risk Causes and Monitoring","Proceedings of the 2020 12th International Conference on Information Management and Engineering","978-1-4503-8752-1","","10.1145/3430279.3430281","https://doi.org/10.1145/3430279.3430281","Research on the causes and monitoring of legal risks of economic contracts for third-party e-commerce trading platforms. Taking into account the characteristics of e-commerce and inter-regionality, the legal risks involved are divided into legal risks, data security risks and patent risks related to e-contracts, and the risk of patent infringement is taken as the focus. The decision is made for detailed analysis. In view of the various legal risks existing in the e-commerce trading platform, the proposed prevention and control suggestion is: in the process of entering into the electronic contract, it is necessary to operate according to its special nature, and archive the electronic contract, and realize the contract content according to the third-party trading platform. The company shall establish a concept of respecting patent property rights, and abide by the laws and regulations related to patent property rights, pay more attention to and identify patent property rights with special patterns, and prevent some unreasonable use of various technical methods to cause patent property rights to be infringed; Companies in the e-commerce platform need to conduct a comprehensive assessment of network security and strengthen the overall security awareness and related construction of the network. It is supplemented by the development of intermediate service providers with independent characteristics, the correct positioning of roles in transactions, and the statutoryization of rights and obligations, which provide a basis for various legal risk supervision and control of e-commerce platforms.","2020","2025-02-19 14:42:21","2025-02-19 14:42:21","","7–9","","","","","","","ICIME 2020","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, Netherlands","","","","E-commerce trading platform; Economic contracts; Legal risks; monitoring; Prevention; The third party","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H43DY2W5","conferencePaper","2024","Wright, Lucas; Muenster, Roxana Mika; Vecchione, Briana; Qu, Tianyao; Cai, Pika (Senhuang); Smith, Alan; Investigators, Comm 2450 Student; Metcalf, Jacob; Matias, J. Nathan","Null Compliance: NYC Local Law 144 and the challenges of algorithm accountability","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency","979-8-4007-0450-5","","10.1145/3630106.3658998","https://doi.org/10.1145/3630106.3658998","In July 2023, New York City became the first jurisdiction globally to mandate bias audits for commercial algorithmic systems, specifically for automated employment decisions systems (AEDTs) used in hiring and promotion. Local Law 144 (LL 144) requires AEDTs to be independently audited annually for race and gender bias, and the audit report must be publicly posted. Additionally, employers are obligated to post a transparency notice with the job listing. In this study, 155 student investigators recorded 391 employers’ compliance with LL 144 and the user experience for prospective job applicants. Among these employers, 18 posted audit reports and 13 posted transparency notices. These rates could potentially be explained by a significant limitation in the accountability mechanisms enacted by LL 144. Since the law grants employers substantial discretion over whether their system is in scope of the law, a null result cannot be said to indicate non-compliance, a condition we call ""null compliance."" Employer discretion may also explain our finding that nearly all audits reported an impact factor over 0.8, a rule of thumb often used in employment discrimination cases. We also find that the benefit of LL 144 to ordinary job seekers is limited due to shortcomings in accessibility and usability. Our findings offer important lessons for policy-makers as they consider regulating algorithmic systems, particularly the degree of discretion to grant to regulated parties and the limitations of relying on transparency and end-user accountability.","2024","2025-02-19 14:42:21","2025-02-19 14:42:21","","1701–1713","","","","","","","FAccT '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rio de Janeiro, Brazil","","","","compliance; bias; algorithm audit; transparency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"59URZURP","conferencePaper","2015","Ghanavati, Sepideh; Hulstijn, Joris","Impact of legal interpretation on business process compliance","Proceedings of the First International Workshop on TEchnical and LEgal Aspects of Data PRIvacy","","","","","Regulations are often written as open norms. Thus, the development of systems that support compliance involves interpretation. Often, compliance officers consider several alternative solutions. Comparing the feasibility and deciding which alternative to select are important tasks. In this paper, we aim to show how analyzing the impact of several interpretation can be supported by requirements engineering tools, in particular, by Legal-URN. Two cases are used to illustrate the importance of interpretation and how Legal-URN facilitates it.","2015","2025-02-19 14:42:21","2025-02-19 14:42:21","","26–31","","","","","","","℡ERISE '15","","","","IEEE Press","","","","","","","","","Place: Florence, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZXXCHZG","conferencePaper","2017","Aljohani, M.; Blustein, J.; Hawkey, K.","Participatory design research to understand the legal and technological perspectives in designing health information technology","Proceedings of the 35th ACM International Conference on the Design of Communication","978-1-4503-5160-7","","10.1145/3121113.3121240","https://doi.org/10.1145/3121113.3121240","In this paper, we report applying participatory design research on the development of effective privacy compliance framework in the context of healthcare applications provided to IT designers. We aim to bridge the gap between privacy law designers and privacy IT designers by expanding the concept of end-user participation. We propose a mixed approach between Participatory Design Research and Human Computer Interaction techniques to facilitate the participation of different stakeholders during the design lifecycle.","2017","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","","","","","","SIGDOC '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Halifax, Nova Scotia, Canada","","","","privacy; e-health; electronic health records; electronic medical records; patient portals; personal health information; personal health records; privacy legislations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4SKJB7J4","conferencePaper","2008","Cheng, Chin Pang; Pan, Jiayi; Lau, Gloria T.; Law, Kincho H.; Jones, Albert","Relating taxonomies with regulations","Proceedings of the 2008 International Conference on Digital Government Research","978-1-60558-099-9","","","","Increasingly, taxonomies are being developed for a wide variety of industrial domains and specific applications within those domains. These industry or application specific taxonomies attempt to represent the vocabularies commonly used by the practitioners. These formal representations have the potential to automate information retrieval, facilitate interoperability and improve decision making. Decisions made must comply with existing government regulations and codes of practices, which are not always known to the industry practitioners. Although regulations and codes are now in digital forms and are often available online, it remains difficult to search for relevant regulatory information that are applicable to particular decisions. As industry practitioners, unlike legal practitioners, are familiar with one or more industry-specific taxonomies but not necessarily regulatory organization systems, it would be desirable to relate regulations with existing industry-specific taxonomies.The mapping from a single taxonomy to a single regulation is a trivial keyword matching task. In this paper, we examine techniques to map a single taxonomy to multiple regulations, as well as to map multiple taxonomies to a single regulation. Those techniques include cosine similarity, Jaccard coefficient and market-basket analysis. These techniques provide a metric that measures the similarity between concepts from different taxonomies. Preliminary evaluations of the three metrics are performed using examples from the building industry. These examples illustrate the potential regulatory benefits from the mapping between various taxonomies and regulations.","2008","2025-02-19 14:42:21","2025-02-19 14:42:21","","34–43","","","","","","","dg.o '08","","","","Digital Government Society of North America","","","","","","","","","Place: Montreal, Canada","","","","heterogeneous ontologies; regulation retrieval; relatedness analysis; taxonomy interoperability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JCARTMNH","conferencePaper","2011","Palmirani, Monica; Governatori, Guido; Contissa, Giuseppe","Modelling temporal legal rules","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018378","https://doi.org/10.1145/2018358.2018378","Legal reasoning involves multiple temporal dimensions but the existing state of the art of legal representation languages does not allow us to easily combine expressiveness, performance and legal reasoning requirements. Moreover we also aim at the combination of legal temporal reasoning with the defeasible logic approach, maintaining a computable complexity. The contribution of this work is to extend LKIF-rules with temporal dimensions and defeasible tools, extending our previous work [17].","2011","2025-02-19 14:42:21","2025-02-19 14:42:21","","131–135","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","LKIF-rule; rule modelling; temporal dimension","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3Z6XE285","conferencePaper","2006","Law, Kincho H.","A distributed information management framework (REGNET) for environmental laws and regulations","Proceedings of the 2006 International Conference on Digital Government Research","","","10.1145/1146598.1146730","https://doi.org/10.1145/1146598.1146730","The complexity, diversity, and volume of Federal and State regulations (as well as supplementary and supportive documents) are detrimental to businesses and hinder public understanding of government. The objective of REGNET project is to develop information infrastructure and tools for regulatory information management and to facilitate compliance assistance. As a pilot research application, the REGNET project focuses on environmental regulations. The experimental scope of this project focuses on Code of Federal Regulations (CFR) Title 40: Protection of the Environment and California Code of Regulations (CCR) Title 22: Social Security. Implementation examples include regulations and selected supplementary documents, covering hazardous waste, drinking water and the management of used oil. Furthermore, tools have been tested with additional environmental regulations from other States and regulations from other domain areas, such as CFR Title 21 on Food and Drugs, and different regulations related to accessibility from the US and UK.","2006","2025-02-19 14:42:21","2025-02-19 14:42:21","","423–424","","","","","","","dg.o '06","","","","Digital Government Society of North America","","","","","","","","","Place: San Diego, California, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGICRAM9","journalArticle","2024","Zhou, Morgana Mo; Qu, Zhiyan; Wan, Jinhan; Wen, Bo; Yao, Yaxing; Lu, Zhicong","Understanding Chinese Internet Users' Perceptions of, and Online Platforms' Compliance with, the Personal Information Protection Law (PIPL)","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3637415","https://doi.org/10.1145/3637415","The Personal Information Protection Law (PIPL) was implemented in November 2021 to safeguard the personal information rights and interests of Internet users in China. However, the impact and existing shortcomings of the PIPL remain unclear, carrying significant implications for policymakers. This study examined privacy policies on 13 online platforms before and after the PIPL. Concurrently, it conducted semi-structured interviews with 30 Chinese Internet users to assess their perceptions of the PIPL. Users were also given tasks to identify non-compliance within the platforms, assessing their ability to address related privacy concerns effectively. The research revealed various instances of non-compliance in post-PIPL privacy policies, especially concerning inadequate risk assessments for sensitive data. Although users identified some non-compliant activities like app eavesdropping, issues related to individual consent proved challenging. Surprisingly, over half of the interviewees believed that the government could access their personal data without explicit consent. Our findings and implications can be valuable for lawmakers, online platforms, users, and future researchers seeking to enhance personal privacy practices both in China and globally.","2024-04","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","CSCW1","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","chinese law; informed consent; keywordspersonal information protection law; qualitative methods; users' perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q8NDLCMF","journalArticle","2021","Singh, Jatinder; Cobbe, Jennifer; Quoc, Do Le; Tarkhani, Zahra","Enclaves in the clouds: Legal considerations and broader implications","Commun. ACM","","0001-0782","10.1145/3447543","https://doi.org/10.1145/3447543","Trusted Execution Environments ('TEEs') or 'secure enclaves' aim at enabling more secure computation and data management. There is much enthusiasm for this technology, not least as we see increasing legal and regulatory attention on issues of security, privacy, and data management and use. With cloud providing the infrastructure for underpinning applications, data processing and analytics/ML, access to enclaves and enclave-backed technologies are increasingly being offered by service (cloud) providers - with the technology described as enabling confidential computing. This paper provides a high-level overview of the common security properties provided by enclaves, and considers how such technology, in being offered by cloud providers, relates to organizational legal and regulatory concerns. Focusing on data protection regulations, we explore the aspects of TEEs that might assist compliance, and who stands to benefit from the deployment of such technology in a service provision context.","2021-04","2025-02-19 14:42:21","2025-02-19 14:42:21","","42–51","","5","64","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GXPGWDXJ","conferencePaper","2015","Luger, Ewa; Urquhart, Lachlan; Rodden, Tom; Golembewski, Michael","Playing the Legal Card: Using Ideation Cards to Raise Data Protection Issues within the Design Process","Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems","978-1-4503-3145-6","","10.1145/2702123.2702142","https://doi.org/10.1145/2702123.2702142","The regulatory climate is in a process of change. Design, having been implicated for some time, is now explicitly linked to law. This paper recognises the heightened role of designers in the regulation of ambient interactive technologies. Taking account of incumbent legal requirements is difficult. Legal rules are convoluted, uncertain, and not geared towards operationalisable heuristics or development guidelines for system designers. Privacy and data protection are a particular moral, social and legal concern for technologies. This paper seeks to understand how to make emerging European data protection regulation more accessible to our community. Our approach develops and tests a series of data protection ideation cards with teams of designers. We find that, whilst wishing to protect users, regulation is viewed as a compliance issue. Subsequently we argue for the use of instruments, such as our cards, as a means to engage designers in leading a human-centered approach to regulation.","2015","2025-02-19 14:42:21","2025-02-19 14:42:21","","457–466","","","","","","","CHI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Republic of Korea","","","","data protection; regulation; design; ideation cards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"82CLQTZ6","conferencePaper","2016","Kokaly, Sahar; Salay, Rick; Sabetzadeh, Mehrdad; Chechik, Marsha; Maibaum, Tom","Model management for regulatory compliance: a position paper","Proceedings of the 8th International Workshop on Modeling in Software Engineering","978-1-4503-4164-6","","10.1145/2896982.2896985","https://doi.org/10.1145/2896982.2896985","Software has come to mediate many of the activities in life, including financial service platforms, social networks and vehicle control. As a result, governing bodies have responded to this trend by creating standards and regulations to address issues such as safety and privacy. In this context, the compliance of software development to standards and regulations has emerged as a key issue. For software development organizations, compliance is a complex and costly goal to achieve. They may have to comply with multiple standards due to multiple jurisdictions or to address different aspects of the software and these may overlap and conflict with each other. The evolution of standards must be tracked and changes assessed. Evidence for claims of compliance must be collected and managed. Finally, maintaining families of related software products (product lines) further multiplies the effort. In this paper, we propose to exploit the connection between the field of model management and the problem of compliance management and explore how to use model management techniques to address software compliance management issues.","2016","2025-02-19 14:42:21","2025-02-19 14:42:21","","74–80","","","","","","","MiSE '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Austin, Texas","","","","regulatory compliance; assurance cases; certification; model management; standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G9U25SY6","conferencePaper","2023","Weerts, Hilde; Xenidis, Raphaële; Tarissan, Fabien; Olsen, Henrik Palmer; Pechenizkiy, Mykola","Algorithmic Unfairness through the Lens of EU Non-Discrimination Law: Or Why the Law is not a Decision Tree","Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency","979-8-4007-0192-4","","10.1145/3593013.3594044","https://doi.org/10.1145/3593013.3594044","Concerns regarding unfairness and discrimination in the context of artificial intelligence (AI) systems have recently received increased attention from both legal and computer science scholars. Yet, the degree of overlap between notions of algorithmic bias and fairness on the one hand, and legal notions of discrimination and equality on the other, is often unclear, leading to misunderstandings between computer science and law. What types of bias and unfairness does the law address when it prohibits discrimination? What role can fairness metrics play in establishing legal compliance? In this paper, we aim to illustrate to what extent European Union (EU) non-discrimination law coincides with notions of algorithmic fairness proposed in computer science literature and where they differ. The contributions of this paper are as follows. First, we analyse seminal examples of algorithmic unfairness through the lens of EU non-discrimination law, drawing parallels with EU case law. Second, we set out the normative underpinnings of fairness metrics and technical interventions and compare these to the legal reasoning of the Court of Justice of the EU. Specifically, we show how normative assumptions often remain implicit in both disciplinary approaches and explain the ensuing limitations of current AI practice and non-discrimination law. We conclude with implications for AI practitioners and regulators.","2023","2025-02-19 14:42:21","2025-02-19 14:42:21","","805–816","","","","","","","FAccT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","artificial intelligence; machine learning; algorithmic fairness; EU non-discrimination law","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P57XZKHW","conferencePaper","2007","Kiyavitskaya, Nadzeya; Zeni, Nicola; Breaux, Travis D.; Antón, Annie I.; Cordy, James R.; Mich, Luisa; Mylopoulos, John","Extracting rights and obligations from regulations: toward a tool-supported process","Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering","978-1-59593-882-4","","10.1145/1321631.1321701","https://doi.org/10.1145/1321631.1321701","Security, privacy and governance are increasingly the focus of government regulations in the U.S., Europe and elsewhere. This trendhas created a ""regulation compliance problem"", whereby companiesand developers are required to ensure that their software complies with relevant regulations, either through design or reengineering. We previously proposed a methodology for extracting stakeholder requirements, called rights and obligations, from regulations. In this paper, we examine the challenges of developing tool support for this process. We apply the Cerno framework for textual semantic annotation to propose a tool for semi-automatic semantic annotation of concepts that constitute sources of requirements","2007","2025-02-19 14:42:21","2025-02-19 14:42:21","","429–432","","","","","","","ASE '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Atlanta, Georgia, USA","","","","privacy requirements; regulation compliance; tool support","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9GUNIPJ","conferencePaper","2003","Kerrigan, Shawn; Law, Kincho H.","Logic-based regulation compliance-assistance","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047820","https://doi.org/10.1145/1047788.1047820","This paper focuses on the creation of a first order predicate calculus based regulation compliance-assistance system built upon an XML framework. Two areas of research that support the development of the compliance assistance system are discussed. The first is a document repository containing federal and state regulations and supplemental documents. The second is an XML framework for representing regulations and associated metadata. The prototype effort for the regulation assistance system has been focused on environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management. The objective of this research is to develop a formal infrastructure for regulatory information management and compliance assistance.","2003","2025-02-19 14:42:21","2025-02-19 14:42:21","","126–135","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","regulations; compliance assistance; legal informatics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6WXN5CK","conferencePaper","2017","Walker, Vern R.; Han, Ji Hae; Ni, Xiang; Yoseda, Kaneyasu","Semantic types for computational legal reasoning: propositional connectives and sentence roles in the veterans' claims dataset","Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law","978-1-4503-4891-1","","10.1145/3086512.3086535","https://doi.org/10.1145/3086512.3086535","This paper announces the creation and public availability of a dataset of annotated decisions adjudicating claims by military veterans for disability compensation in the United States. This is intended to initiate a collaborative, transparent approach to semantic analysis for argument mining from legal documents. The dataset is being used in the LUIMA argument-mining project. We address two major sub-tasks for making legal reasoning computable. First, we report the semantic types of propositional connective we use to extract information about legal rules from sentences in statutes, regulations, and appellate court decisions, and to represent those rules as integrated systems. Second, we report the semantic types of sentence role we use to extract and represent the fact-finding reasoning found in adjudicatory decisions, with the goal of identifying successful and unsuccessful patterns of evidentiary argument. For each type system, we provide explanations and examples. Thus, we hope to stimulate a shared effort to create diverse datasets in law, to empirically evolve optimal sets of semantic types for argument mining, and to refine protocols for accurately applying those types to texts.","2017","2025-02-19 14:42:21","2025-02-19 14:42:21","","217–226","","","","","","","ICAIL '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: London, United Kingdom","","","","argument mining; argumentation mining; computational argumentation; data validity; inference role; legal rule; ontology; propositional-connective type system; protocols; semantic data; sentence-role type system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJTCU9DQ","conferencePaper","2004","Law, Kincho H.; Wiederhold, Gio; Leckie, Jim; Thompson, Barton; Kerrigan, Shawn; Lau, Gloria T.; Labiosa, Bill; Heenan, Charles; Wang, Haoyi; Zhou, Liang; Trivedi, Pooja; Peng, Jun","A distributed information management framework (REGNET) for environmental laws and regulations","Proceedings of the 2004 Annual National Conference on Digital Government Research","","","","","There has been a push by the executive office that government agencies put more emphasis on compliance assistance in lieu of enforcement to encourage companies to comply with regulations. It is well recognized that the complexity, diversity, and volume of Federal and State regulations are detrimental to businesses and also hinder public understanding of government. In addition to the regulations, supplementary and supportive documents (such as preambles, interpretation guides) are also an important part of regulatory information. The objective of REGNET project is to develop a formal information infrastructure for regulatory information management and to facilitate compliance assistance. The experimental scope of this project covers Code of Federal Regulations (CFR) Title 40: Protection of the Environment. Implementation examples focus on the regulations and selected supplementary documents, covering hazardous waste, drinking water and the management of used oil.","2004","2025-02-19 14:42:21","2025-02-19 14:42:21","","","","","","","","","dg.o '04","","","","Digital Government Society of North America","","","","","","","","","Place: Seattle, WA, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QA9UU8EL","conferencePaper","2017","Roychoudhury, Suman; Sunkle, Sagar; Kholkar, Deepali; Kulkarni, Vinay","A domain-specific controlled English language for automated regulatory compliance (industrial paper)","Proceedings of the 10th ACM SIGPLAN International Conference on Software Language Engineering","978-1-4503-5525-4","","10.1145/3136014.3136018","https://doi.org/10.1145/3136014.3136018","Modern enterprises operate in an unprecedented regulatory environment where increasing regulation and heavy penalties on non-compliance have placed regulatory compliance among the topmost concerns of enterprises worldwide. Previous research in the field of compliance has established that the manual specification of the regulations used by GRC frameworks not only fails to ensure their proper coverage but also negatively affects the turnaround time both in proving and maintaining the compliance. Our key contribution in this paper is an implementation of a controlled natural English like (domain-specific) language that can be used by domain experts to specify regulations for automated compliance checking. We demonstrate this language using examples from industry regulations in banking and financial services domain.","2017","2025-02-19 14:42:21","2025-02-19 14:42:21","","175–181","","","","","","","SLE 2017","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vancouver, BC, Canada","","","","Regulatory compliance; controlled natural English; SBVR; text-to-model transformation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W9E2YFML","conferencePaper","2019","Suto, Gyuszi; Greenleaf, Geoff S.; Bhagavatula, Phanindra; Fischer, Heinrich R.; Soni, Sanjay K.; Miller, Brian H.; Hentschke, Renato F.","Declarative Language for Geometric Pattern Matching in VLSI Process Rule Modeling","Proceedings of the 2019 International Symposium on Physical Design","978-1-4503-6253-5","","10.1145/3299902.3309745","https://doi.org/10.1145/3299902.3309745","This paper presents a formal (machine readable) declarative language developed for the specific reason of modeling physical design process rules of any complexity. Case studies are presented on synthetic as well as industry known design rules of simple complexity (two objects, pair-wise relationship) as well as multi-object complex rules (n-wise relationship). The building blocks of the language are presented and a comparison is drawn between declarative and imperative (general industry practice) implementation of a rule. Automatic test layout generation is presented that would not be possible on an imperative model. Advanced language concepts are also described, including patterns - that can be embedded in each other - as well as rule exceptions using the logical NOT in conjunction with patterns. Further advanced language features are presented, including grids (discretization) and sets - all crucial elements for implementing a wide variety of rules. A strong argument is made for the advantages of this language being the precise and unambiguous description of the intent of the rule with immediate access to a rule checker as well as automatic test layout generator that can test the boundaries of the process node.","2019","2025-02-19 14:42:21","2025-02-19 14:42:21","","75–82","","","","","","","ISPD '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Francisco, CA, USA","","","","declarative; formal; process rules; rule modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7NA639KG","conferencePaper","2024","Li, Tongguang; Fan, Yizhou; Srivastava, Namrata; Zeng, Zijie; Li, Xinyu; Khosravi, Hassan; Tsai, Yi-Shan; Swiecki, Zachari; Gašević, Dragan","Analytics of Planning Behaviours in Self-Regulated Learning: Links with Strategy Use and Prior Knowledge","Proceedings of the 14th Learning Analytics and Knowledge Conference","979-8-4007-1618-8","","10.1145/3636555.3636900","https://doi.org/10.1145/3636555.3636900","A sophisticated grasp of self-regulated learning (SRL) skills has become essential for learners in computer-based learning environment (CBLE). One aspect of SRL is the plan-making process, which, although emphasized in many SRL theoretical frameworks, has attracted little research attention. Few studies have investigated the extent to which learners complied with their planned strategies, and whether making a strategic plan is associated with actual strategy use. Limited studies have examined the role of prior knowledge in predicting planned and actual strategy use. In this study, we developed a CBLE to collect trace data, which were analyzed to investigate learners’ plan-making process and its association with planned and actual strategy use. Analysis of prior knowledge and trace data of 202 participants indicated that 1) learners tended to adopt strategies that significantly deviated from their planned strategies, 2) the level of prior knowledge was associated with planned strategies, and 3) neither the act of plan-making nor prior knowledge predicted actual strategy use. These insights bear implications for educators and educational technologists to recognise the dynamic nature of strategy adoption and to devise approaches that inspire students to continually revise and adjust their plans, thereby strengthening SRL.","2024","2025-02-19 14:42:21","2025-02-19 14:42:21","","438–449","","","","","","","LAK '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kyoto, Japan","","","","learning analytics; learning strategies; self-regulated learning; strategic planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8B83LL7","conferencePaper","2023","Gray, Morgan; Savelka, Jaromir; Oliver, Wesley; Ashley, Kevin","Automatic Identification and Empirical Analysis of Legally Relevant Factors","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595157","https://doi.org/10.1145/3594536.3595157","This research addresses how to automatically identify certain factors in the texts of legal decisions and analyze their role in courts' decisions. It focuses on drug interdiction auto stop cases in which courts decide whether police officers have reasonable suspicion to detain a motorist. It illustrates how the methods to identify factors automatically can support empirical legal research in the domain and how machine learning methods of different accuracy and interpretability can be harnessed to explain case outcomes in terms legal professionals can understand.","2023","2025-02-19 14:42:21","2025-02-19 14:42:21","","101–110","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","machine learning; empirical legal analysis; factors; legal text analysis; text classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EGW5GXRA","conferencePaper","2022","Zhang, Yao; Xiong, Yun; Sun, Yiheng; Shan, Caihua; Lu, Tian; Song, Hui; Zhu, Yangyong","RuDi: Explaining Behavior Sequence Models by Automatic Statistics Generation and Rule Distillation","Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management","978-1-4503-9236-5","","10.1145/3511808.3557441","https://doi.org/10.1145/3511808.3557441","Risk scoring systems have been widely deployed in many applications, which assign risk scores to users according to their behavior sequences. Though many deep learning methods with sophisticated designs have achieved promising results, the black-box nature hinders their applications due to fairness, explainability, and compliance consideration. Rule-based systems are considered reliable in these sensitive scenarios. However, building a rule system is labor-intensive. Experts need to find informative statistics from user behavior sequences, design rules based on statistics and assign weights to each rule. In this paper, we bridge the gap between effective but black-box models and transparent rule models. We propose a two-stage method, RuDi, that distills the knowledge of black-box teacher models into rule-based student models. We design a Monte Carlo tree search-based statistics generation method that can provide a set of informative statistics in the first stage. Then statistics are composed into logical rules with our proposed neural logical networks by mimicking the outputs of teacher models. We evaluate RuDi on three real-world public datasets and an industrial dataset to demonstrate its effectiveness.","2022","2025-02-19 14:42:21","2025-02-19 14:42:21","","2651–2660","","","","","","","CIKM '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Atlanta, GA, USA","","","","rule distillation; sequence model explanation; statistics generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I78KSKEZ","journalArticle","2023","Xin, Junchang; Wang, Mingcan; Qu, Luxuan; Chen, Qi; Wang, Weiyiqi; Wang, Zhiqiong","BIC-LP: A Hybrid Higher-Order Dynamic Bayesian Network Score Function for Gene Regulatory Network Reconstruction","IEEE/ACM Trans. Comput. Biol. Bioinformatics","","1545-5963","10.1109/TCBB.2023.3345317","https://doi.org/10.1109/TCBB.2023.3345317","Reconstructing gene regulatory networks(GRNs) is an increasingly hot topic in bioinformatics. Dynamic Bayesian network(DBN) is a stochastic graph model commonly used as a vital model for GRN reconstruction. But probabilistic characteristics of biological networks and the existence of data noise bring great challenges to GRN reconstruction and always lead to many false positive/negative edges. &lt;inline-formula&gt;&lt;tex-math notation=""LaTeX""&gt;Score_Lasso&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;r&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=""wang-ieq1-3345317.gif""/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; is a hybrid DBN score function combining DBN and linear regression with good performance. Its performance is, however, limited by first-order assumption and ignorance of the initial network of DBN. In this article, an integrated model based on higher-order DBN model, higher-order Lasso linear regression model and Pearson correlation model is proposed. Based on this, a hybrid higher-order DBN score function for GRN reconstruction is proposed, namely BIC-LP. BIC-LP score function is constructed by adding terms based on Lasso linear regression coefficients and Pearson correlation coefficients on classical BIC score function. Therefore, it could capture more information from dataset and curb information loss, compared with both many existing Bayesian family score functions and many state-of-the-art methods for GRN reconstruction. Experimental results show that BIC-LP can reasonably eliminate some false positive edges while retaining most true positive edges, so as to achieve better GRN reconstruction performance.","2023-12","2025-02-19 14:42:21","2025-02-19 14:42:21","","188–199","","1","21","","","","","","","","","","","","","","","","","Place: Washington, DC, USA Publisher: IEEE Computer Society Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LH5Y8SHU","journalArticle","2013","Campos, Jordi; Lopez-Sanchez, Maite; Salamó, Maria; Avila, Pedro; Rodríguez-Aguilar, Juan A.","Robust Regulation Adaptation in Multi-Agent Systems","ACM Trans. Auton. Adapt. Syst.","","1556-4665","10.1145/2517328","https://doi.org/10.1145/2517328","Adaptive organisation-centred multi-agent systems can dynamically modify their organisational components to better accomplish their goals. Our research line proposes an abstract distributed architecture (2-LAMA) to endow an organisation with adaptation capabilities. This article focuses on regulation-adaptation based on a machine learning approach, in which adaptation is learned by applying a tailored case-based reasoning method. We evaluate the robustness of the system when it is populated by non compliant agents. The evaluation is performed in a peer-to-peer sharing network scenario. Results show that our proposal significantly improves system performance and can cope with regulation violators without incorporating any specific regulation-compliance enforcement mechanisms.","2013-09","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","3","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Machine learning; regulation; case-based reasoning; adaptation; organisation-centred MAS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KMEYFWIL","journalArticle","2020","Ironi, Liliana; Lanzarone, Ettore","Optimal Robust Search for Parameter Values of Qualitative Models of Gene Regulatory Networks","IEEE/ACM Trans. Comput. Biol. Bioinformatics","","1545-5963","10.1109/TCBB.2020.3006920","https://doi.org/10.1109/TCBB.2020.3006920","Computational and mathematical models are a must for the &lt;italic&gt;in silico&lt;/italic&gt; analysis or design of Gene Regulatory Networks (GRN)as they offer a theoretical context to deeply address biological regulation. We have proposed a framework where models of network dynamics are expressed through a class of nonlinear and temporal multiscale Ordinary Differential Equations (ODE). To find out models that disclose network structures underlying an observed or desired network behavior, and parameter values that enable the candidate models to reproduce such behavior, we follow a reasoning cycle that alternates procedures for model selection and parameter refinement. Plausible network models are first selected via qualitative simulation, and next their parameters are given quantitative values such that the ODE model solution reproduces the specified behavior. This paper gives algorithms to tackle the parameter refinement problem formulated as an optimization problem. We search, within the parameter space symbolically expressed, for the largest hypersphere whose points correspond to parameter values such that the ODE solution gives an instance of the given qualitative trajectory. Our approach overcomes the limitation of a previously proposed stochastic approach, namely computational load and very reduced scalability. Its applicability and effectiveness are demonstrated through two benchmark synthetic networks with different complexity.","2020-07","2025-02-19 14:42:22","2025-02-19 14:42:22","","1050–1063","","2","19","","","","","","","","","","","","","","","","","Place: Washington, DC, USA Publisher: IEEE Computer Society Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GY2RWCKI","journalArticle","2021","Dwivedi, Vimal; Pattanaik, Vishwajeet; Deval, Vipin; Dixit, Abhishek; Norta, Alex; Draheim, Dirk","Legally Enforceable Smart-Contract Languages: A Systematic Literature Review","ACM Comput. Surv.","","0360-0300","10.1145/3453475","https://doi.org/10.1145/3453475","Smart contracts are a key component of today’s blockchains. They are critical in controlling decentralized autonomous organizations (DAO). However, smart contracts are not yet legally binding nor enforceable; this makes it difficult for businesses to adopt the DAO paradigm. Therefore, this study reviews existing Smart Contract Languages (SCL) and identifies properties that are critical to any future SCL for drafting legally binding contracts. This is achieved by conducting a Systematic Literature Review (SLR) of white- and grey literature published between 2015 and 2019. Using the SLR methodology, 45 Selected and 28 Supporting Studies detailing 45 state-of-the-art SCLs are selected. Finally, 10 SCL properties that enable legally compliant DAOs are discovered, and specifications for developing SCLs are explored.","2021-06","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","5","54","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Blockchain; decentralized autonomous organization; expressiveness; smart contract language; suitability; systematic literature review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G9NPB7MI","conferencePaper","2015","de O. Rodrigues, Cleyton Mário; de Azevedo, Ryan Ribeiro; de Freitas, Frederico Luiz Gonçalves; da Silva, Eunice Palmeira; da Silva Barros, Patrícia Vieira","An ontological approach for simulating legal action in the Brazilian penal code","Proceedings of the 30th Annual ACM Symposium on Applied Computing","978-1-4503-3196-8","","10.1145/2695664.2695740","https://doi.org/10.1145/2695664.2695740","The applicability of Artificial Intelligence for the Legal Domain has several and non-depleted lines of research. Since Colonization, the use of ambiguity in drafting the Brazilian Legal Documents was a palliative to solve cases involving economic, political and social interests between local authorities with the European Court. Further, when conflicts between norms emerge, only time, specificity and superiority criteria are not enough to break the tie, a second degree level governing what criteria should be used in different situations need to be addressed as well. In face of these tangle legal documents, this research project aims to present the OntoCrime and OntoLegalTask: ontological representations through which one can formalize the Brazilian Penal Law to check norm violation and automate legal reasoning. Finally, an experiment with the drinking-drive law is presented.","2015","2025-02-19 14:42:22","2025-02-19 14:42:22","","376–381","","","","","","","SAC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salamanca, Spain","","","","legal reasoning; brazilian penal law; ontology engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SCQEAPJC","conferencePaper","2013","Pasetto, Davide; Franke, Hubertus; Qian, Weihong; Guo, Zhili; Guo, Honglei; Duan, Dongxu; Ni, Yuan; Pan, Yingxin; Bao, Shenghua; Cao, Feng; Su, Zhong","RTS - an integrated analytic solution for managing regulation changes and their impact on business compliance","Proceedings of the ACM International Conference on Computing Frontiers","978-1-4503-2053-5","","10.1145/2482767.2482798","https://doi.org/10.1145/2482767.2482798","Governance, Risk Management and Compliance are key success factors for corporations. Every company worldwide must ensure a proper compliance level with current and future laws and regulations, but managing the dynamic nature of the regulatory environment is a challenge, for both small and medium business as well as large corporations. Specifically the challenge is knowing and interpreting which regulations impact a particular business. Governments and standard bodies keep producing new, revised legislation, and businesses today rely on employees and consultants for tracking and understanding impact on their operations.This paper introduces a novel prototype solution that addresses these concerns through the use of advanced text analytics. In particular the system is able to discover sources of regulatory content on the world wide web, track the changes to these regulations, extract metadata and semantic information and use these to provide a semantically guided comparison of regulation versions. Moreover, by leveraging the IBM DeepQA architecture, the solution is able to cross reference business objectives with the regulatory database and provide insights about the impact of new and revised laws on a company's business.","2013","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","","","","","","CF '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ischia, Italy","","","","document processing; question answering; semantic; text analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YY2VH9B","conferencePaper","2009","Prisacariu, Cristian; Schneider, Gerardo","Abstract specification of legal contracts","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568262","https://doi.org/10.1145/1568234.1568262","The paper presents an action-based formal language called CL for abstract specification of legal contracts. The purpose of the language is to be used to reason about legal contracts (and electronic contracts on the long run). CL combines the legal notions obligation, permission, and prohibition from deontic logic with the action modality of propositional dynamic logic (PDL). The deontic modalities are applied only over actions, thus following the ought-to-do approach. The language includes a synchrony operator to model ""actions performed at the same time"", and a special complementation operation to encode the violation of obligations. The language has a formal semantics in terms of normative structures, specially defined to capture several natural properties of legal contracts. We focus on the informal presentation of the choices made when designing CL, and its semantics.","2009","2025-02-19 14:42:22","2025-02-19 14:42:22","","218–219","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PFAQGAX","conferencePaper","2019","Chowdhury, Niaz","An IoT and blockchain-based approach for ensuring transparency and accountability in regulatory compliance","Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers","978-1-4503-6869-8","","10.1145/3341162.3349320","https://doi.org/10.1145/3341162.3349320","Regulatory compliance is an essential exercise in the modern societies confirming safety and prevention of harm to consumers. Despite many efforts from international and national quality control authorities, transparency and accountability in regulatory compliance remain a challenging technical-legal problem sitting atop a heavy reliance on trust. This paper presents a theoretical model of regulatory compliance aiming at improving accountability for systems and data audit and introduces a higher degree of transparency in management and quality control. It explores the technical aspects of two emerging technologies the Internet of Things (IoT) and Blockchain, and using a common use-case in practice shows how to better align these technologies with legal concerns and trust in regulatory compliance.","2019","2025-02-19 14:42:22","2025-02-19 14:42:22","","957–962","","","","","","","UbiComp/ISWC '19 Adjunct","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: London, United Kingdom","","","","regulatory compliance; blockchain; internet of things; trust","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDFFMEMB","conferencePaper","2021","Zhang, Qingzhao; Hong, David Ke; Zhang, Ze; Chen, Qi Alfred; Mahlke, Scott; Mao, Z. Morley","A Systematic Framework to Identify Violations of Scenario-dependent Driving Rules in Autonomous Vehicle Software","Abstract Proceedings of the 2021 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems","978-1-4503-8072-0","","10.1145/3410220.3460101","https://doi.org/10.1145/3410220.3460101","Safety compliance is paramount to the safe deployment of autonomous vehicle (AV) technologies in real-world transportation systems. As AVs will share road infrastructures with human drivers and pedestrians, it is an important requirement for AVs to obey standard driving rules. Existing AV software testing methods, including simulation and road testing, only check fundamental safety rules such as collision avoidance and safety distance. Scenario-dependent driving rules, including crosswalk and intersection rules, are more complicated because the expected driving behavior heavily depends on the surrounding circumstances. However, a testing framework is missing for checking scenario-dependent driving rules on various AV software.In this paper, we design and implement a systematic framework AVChecker for identifying violations of scenario-dependent driving rules in AV software using formal methods. AVChecker represents both the code logic of AV software and driving rules in proposed formal specifications and leverages satisfiability modulo theory (SMT) solvers to identify driving rule violations. To improve the automation of systematic rule-based checking, AVChecker provides a powerful user interface for writing driving rule specifications and applies static code analysis to extract rule-related code logic from the AV software codebase. Evaluations on two open-source AV software platforms, Baidu Apollo and Autoware, uncover 19 true violations out of 28 real-world driving rules covering crosswalks, traffic lights, stop signs, and intersections. Seven of the violations can lead to severe risks of a collision with pedestrians or blocking traffic.","2021","2025-02-19 14:42:22","2025-02-19 14:42:22","","43–44","","","","","","","SIGMETRICS '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, China","","","","autonomous vehicle; formal methods; software system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2GUUG29","conferencePaper","2021","Nissim, Kobbi","Privacy: From Database Reconstruction to Legal Theorems","Proceedings of the 40th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems","978-1-4503-8381-3","","10.1145/3452021.3458816","https://doi.org/10.1145/3452021.3458816","There are significant gaps between legal and technical thinking around data privacy. Technical standards are described using mathematical language whereas legal standards are not rigorous from a mathematical point of view and often resort to concepts which they only partially define. As a result, arguments about the adequacy of technical privacy measures for satisfying legal privacy often lack rigor, and their conclusions are uncertain. The uncertainty is exacerbated by a litany of successful privacy attacks on privacy measures thought to meet legal expectations but then shown to fall short of doing so. As computer systems manipulating individual privacy-sensitive data become integrated in almost every aspect of society, and as such systems increasingly make decisions of legal significance, the need to bridge the diverging, and sometimes conflicting legal and technical approaches becomes urgent. We formulate and prove formal claims – ""legal theorems” – addressing legal questions such as whether the use of technological measures satisfies the requirements of a legal privacy standard. In particular, we analyze the notion of singling out from the GDPR and whether technologies such as k-anonymity and differential privacy prevent singling out. Our long-term goal is to develop concepts which are on one hand technical, so they can be integrated in the design of computer systems, and can be used in legal reasoning and for policymaking on the other hand.","2021","2025-02-19 14:42:22","2025-02-19 14:42:22","","33–41","","","","","","","PODS'21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, China","","","","data privacy; gdpr; differential privacy; k-anonymity; singling out","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I8FKJJIR","conferencePaper","2016","Loksa, Dastyni; Ko, Amy J.","The Role of Self-Regulation in Programming Problem Solving Process and Success","Proceedings of the 2016 ACM Conference on International Computing Education Research","978-1-4503-4449-4","","10.1145/2960310.2960334","https://doi.org/10.1145/2960310.2960334","While prior work has investigated many aspects of programming problem solving, the role of self-regulation in problem solving success has received little attention. In this paper we contribute a framework for reasoning about self-regulation in programming problem solving. We then use this framework to investigate how 37 novice programmers of varying experience used self-regulation during a sequence of programming problems. We analyzed the extent to which novices engaged in five kinds of self-regulation during their problem solving, how this self-regulation varied between students enrolled in CS1 and CS2, and how self-regulation played a role in structuring problem solving. We then investigated the relationship between self-regulation and programming errors. Our results indicate that while most novices engage in self-regulation to navigate and inform their problem solving efforts, these self-regulation efforts are only effective when accompanied by programming knowledge adequate to succeed at solving a given problem, and only some types of self-regulation appeared related to errors. We discuss the implications of these findings on problem solving pedagogy in computing education.","2016","2025-02-19 14:42:22","2025-02-19 14:42:22","","83–91","","","","","","","ICER '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Melbourne, VIC, Australia","","","","problem solving; programming; self-regulation; think-aloud","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DI4HTIC3","conferencePaper","2007","Gordon, Thomas F.","Constructing arguments with a computational model of an argumentation scheme for legal rules: interpreting legal rules as reasoning policies","Proceedings of the 11th International Conference on Artificial Intelligence and Law","978-1-59593-680-6","","10.1145/1276318.1276340","https://doi.org/10.1145/1276318.1276340","A knowledge representation language for defeasible legal rules is defined, whose semantics is purely procedural, based on Walton's theory of argumentation and Loui's break with the relational tradition in 'Process and Policy'. Legal rules are interpreted as reasoning policies, by mapping them in the semantics to argumentation schemes. The reasoning process is regulated by argumentation protocols. Reasoning with legal rules is viewed as applying schemes for arguments from rules to construct arguments to be put forward in dialogues.","2007","2025-02-19 14:42:22","2025-02-19 14:42:22","","117–121","","","","","","","ICAIL '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Stanford, California","","","","computational models of legal reasoning and argumentation; legal knowledge-based systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2ZBSVQX","conferencePaper","2011","McLaren, Bruce M.; Ashley, Kevin D.","Can temporal representation and reasoning make a difference in automated legal reasoning? lessons from an AI-based ethical reasoner","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018391","https://doi.org/10.1145/2018358.2018391","Given a renewed interest in the field of AI and Law in more complex factual representations of legal cases in terms of narratives, techniques for representing and reasoning about temporal orderings of facts will become increasingly important. The SIROCCO (&lt;u&gt;S&lt;/u&gt;ystem for &lt;u&gt;I&lt;/u&gt;ntelligent &lt;u&gt;R&lt;/u&gt;etrieval of &lt;u&gt;O&lt;/u&gt;perationalized &lt;u&gt;C&lt;/u&gt;ases and &lt;u&gt;CO&lt;/u&gt;des) program employed a representation for the temporal ordering of events in ethics cases in a way that informed determinations of whether and how ethical norms were violated and if the problem and other cases were normatively analogous at a deeper level. At the same time, the program supported ordinary case enterers in translating the facts of textually described cases into a machine-processable representation. This paper presents these previously unpublished aspects of the work including a report of an empirical evaluation of the contribution of the temporal representation to the program's success in retrieving relevant norms and cases. Although the results were negative, a consideration of the reasons why is illuminating. While SIROCCO dealt with engineering ethics cases, it is clear that similar temporal considerations apply in legal cases and that the approach is likely to be useful in legal narrative representations.","2011","2025-02-19 14:42:22","2025-02-19 14:42:22","","229–238","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","case similarity; narrative case models; representing temporal ordering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7GQ2HKQ","conferencePaper","2018","Sirur, Sean; Nurse, Jason R.C.; Webb, Helena","Are We There Yet? Understanding the Challenges Faced in Complying with the General Data Protection Regulation (GDPR)","Proceedings of the 2nd International Workshop on Multimedia Privacy and Security","978-1-4503-5988-7","","10.1145/3267357.3267368","https://doi.org/10.1145/3267357.3267368","The EU General Data Protection Regulation (GDPR), enforced from 25textsuperscriptth May 2018, aims to reform how organisations view and control the personal data of private EU citizens. The scope of GDPR is somewhat unprecedented: it regulates every aspect of personal data handling, includes hefty potential penalties for non-compliance, and can prosecute any company in the world that processes EU citizens' data. In this paper, we look behind the scenes to investigate the real challenges faced by organisations in engaging with the GDPR. This considers issues in working with the regulation, the implementation process, and how compliance is verified. Our research approach relies on literature but, more importantly, draws on detailed interviews with several organisations. Key findings include the fact that large organisations generally found GDPR compliance to be reasonable and doable. The same was found for small-to-medium organisations (SMEs/SMBs) that were highly security-oriented. SMEs with less focus on data protection struggled to make what they felt was a satisfactory attempt at compliance. The main issues faced in their compliance attempts emerged from: the sheer breadth of the regulation; questions around how to enact the qualitative recommendations of the regulation; and the need to map out the entirety of their complex data networks.","2018","2025-02-19 14:42:22","2025-02-19 14:42:22","","88–95","","","","","","","MPS '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Canada","","","","data protection; privacy; compliance; regulations; gdpr; business; cyber security; multimedia; smes/smbs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4X73D8D","conferencePaper","2020","Lie, Martin Forsberg; Sánchez-Gordón, Mary; Colomo-Palacios, Ricardo","DevOps in an ISO 13485 Regulated Environment: A Multivocal Literature Review","Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)","978-1-4503-7580-1","","10.1145/3382494.3410679","https://doi.org/10.1145/3382494.3410679","Background: Medical device development projects must follow proper directives and regulations to be able to market and sell the end-product in their respective territories. The regulations describe requirements that seem to be opposite to efficient software development and short time-to-market. As agile approaches, like DevOps, are becoming more and more popular in software industry, a discrepancy between these modern methods and traditional regulated development has been reported. Although examples of successful adoption in this context exist, the research is sparse. Aims: The objective of this study is twofold: to review the current state of DevOps adoption in regulated medical device environment; and to propose a checklist based on that review for introducing DevOps in that context. Method: A multivocal literature review is performed and evidence is synthesized from sources published between 2015 to March of 2020 to capture the opinions of experts and community in this field. Results: Our findings reveal that adoption of DevOps in a regulated medical device environment such as ISO 13485 has its challenges, but potential benefits may outweigh those in areas such as regulatory, compliance, security, organizational and technical. Conclusion: DevOps for regulated medical device environments is a highly appealing approach as compared to traditional methods and could be particularly suited for regulated medical development. However, an organization must properly anchor a transition to DevOps in top-level management and be supportive in the initial phase utilizing professional coaching and space for iterative learning; as such an initiative is a complex organizational and technical task.","2020","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","","","","","","ESEM '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bari, Italy","","","","DevOps; ISO 13485; Medical device software development; Multivocal Literature Review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQFYFNQM","journalArticle","2021","Zhao, Rui; Atkinson, Malcolm; Papapanagiotou, Petros; Magnoni, Federica; Fleuriot, Jacques","Dr.Aid: Supporting Data-governance Rule Compliance for Decentralized Collaboration in an Automated Way","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3479604","https://doi.org/10.1145/3479604","Collaboration across institutional boundaries is widespread and increasing today. It depends on federations sharing data that often have governance rules or external regulations restricting their use. However, the handling of data governance rules (aka. data-use policies) remains manual, time-consuming and error-prone, limiting the rate at which collaborations can form and respond to challenges and opportunities, inhibiting citizen science and reducing data providers' trust in compliance. Using an automated system to facilitate compliance handling reduces substantially the time needed for such non-mission work, thereby accelerating collaboration and improving productivity. We present a framework, Dr.Aid, that helps individuals, organisations and federations comply with data rules, using automation to track which rules are applicable as data is passed between processes and as derived data is generated. It encodes data-governance rules using a formal language and performs reasoning on multi-input-multi-output data-flow graphs in decentralised contexts. We test its power and utility by working with users performing cyclone tracking and earthquake modelling to support mitigation and emergency response. We query standard provenance traces to detach Dr.Aid from details of the tools and systems they are using, as these inevitably vary across members of a federation and through time. We evaluate the model in three aspects by encoding real-life data-use policies from diverse fields, showing its capability for real-world usage and its advantages compared with traditional frameworks. We argue that this approach will lead to more agile, more productive and more trustworthy collaborations and show that the approach can be adopted incrementally. This, in-turn, will allow more appropriate data policies to emerge opening up new forms of collaboration.","2021-10","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","CSCW2","5","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","data governance; automated reasoning; data policy; formal model; obligation policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2B2FAU6Z","conferencePaper","2001","Governatori, Guido; Dumas, Marlon; ter Hofstede, Arthur H. M.; Oaks, Phillipa","A formal approach to protocols and strategies for (legal) negotiation","Proceedings of the 8th International Conference on Artificial Intelligence and Law","1-58113-368-5","","10.1145/383535.383555","https://doi.org/10.1145/383535.383555","We propose a formal and executable framework for expressing protocols and strategies for automated (legal) negotiation. In this framework a party involved in a negotiation is represented through a software agent composed of four modules: (i) a communication module which manages the interaction with the other agents; (ii) a control module; (iii) a reasoning module specified as a defeasible theory; and (iv) a knowledge base which bridges the control and the reasoning modules, while keeping track of past decisions and interactions. The choice of defeasible logic is justified against a set of desirable criteria for negotiation automation languages. Moreover, the suitability of the framework is illustrated through two case studies.","2001","2025-02-19 14:42:22","2025-02-19 14:42:22","","168–177","","","","","","","ICAIL '01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: St. Louis, Missouri, USA","","","","defeasible logic; auctions; automated legal negotiation; software agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFSIH8BY","conferencePaper","2021","Armknecht, Frederik; Bohli, Jens-Matthias; Karame, Ghassan O.; Li, Wenting","Regulating Storage Overhead in Existing PoW-based Blockchains","Proceedings of the 26th ACM Symposium on Access Control Models and Technologies","978-1-4503-8365-3","","10.1145/3450569.3463564","https://doi.org/10.1145/3450569.3463564","Proof of Work (PoW) blockchains regulate the frequency and security of extensions to the blockchain in a decentralized manner by adjusting the difficulty in the network. However, analogous decentralized measures to regulate the replication level of the associated transactions and blocks data are completely missing so far. We argue that such measures are required as well. On the one hand, the smaller the number of replicas, the higher the vulnerability of the system against compromises and DoS-attacks. On the other hand, the larger the number of replicas, the higher the storage overhead, and the higher the operational blockchain cost are. In this paper, we propose a novel solution, EWoK (Entangled proofs of WOrk and Knowledge), that regulates in a decentralized manner the minimum number of replicas that should be stored by miners in the blockchain. EWoK achieves this by tying replication to the only directly-incentivized process in PoW-blockchains – which is PoW itself. EWoK only incurs small modifications to existing PoW protocols and is fully compliant with the specifications of existing mining hardware. Our implementation results confirm that EWoK can be easily integrated within existing mining pool protocols, such as GetBlockTemplate and Stratum mining, and does not impair the mining efficiency.","2021","2025-02-19 14:42:22","2025-02-19 14:42:22","","131–142","","","","","","","SACMAT '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Spain","","","","blockchain security; proof ofwork; regulating storage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PNYUMJ3J","conferencePaper","2021","Console, Marco; Kolaitis, Phokion G.; Pieris, Andreas","Model-theoretic Characterizations of Rule-based Ontologies","Proceedings of the 40th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems","978-1-4503-8381-3","","10.1145/3452021.3458310","https://doi.org/10.1145/3452021.3458310","An ontology specifies an abstract model of a domain of interest via a formal language that is typically based on logic. Although description logics are popular formalisms for modeling ontologies, tuple-generating dependencies (tgds), originally introduced as a unifying framework for database integrity constraints, and later on used in data exchange and integration, are also well suited for modeling ontologies that are intended for data-intensive tasks. The reason is that, unlike description logics, tgds can easily handle higher-arity relations that naturally occur in relational databases. In recent years, there has been an extensive study of tgd-ontologies and of their applications to several different data-intensive tasks. However, the fundamental question of whether the expressive power of tgd-ontologies can be characterized in terms of model-theoretic properties remains largely unexplored. We establish several characterizations of tgd-ontologies, including characterizations of ontologies specified by such central classes of tgds as full, linear, guarded, and frontier-guarded tgds. Our characterizations use the well-known notions of critical instance and direct product, as well as a novel locality property for tgd-ontologies. We further use this locality property to decide whether an ontology expressed by frontier-guarded (respectively, guarded) tgds can be expressed by tgds in the weaker class of guarded (respectively, linear) tgds, and effectively construct such an equivalent ontology if one exists.","2021","2025-02-19 14:42:22","2025-02-19 14:42:22","","416–428","","","","","","","PODS'21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, China","","","","finite axiomatizability; guardedness; model theory; ontologies; tuple-generating dependencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6LKYK92","conferencePaper","2015","Timmer, Sjoerd T.; Meyer, John-Jules Ch.; Prakken, Henry; Renooij, Silja; Verheij, Bart","Demonstration of a structure-guided approach to capturing bayesian reasoning about legal evidence in argumentation","Proceedings of the 15th International Conference on Artificial Intelligence and Law","978-1-4503-3522-5","","10.1145/2746090.2750370","https://doi.org/10.1145/2746090.2750370","Reasoning about statistics and probabilities can, when not treated with cautiousness, lead to reasoning errors. Over the last decades the rise of forensic sciences has led to an increase in the availability of statistical evidence. To facilitate the correct explanation of such evidence we investigate how argumentation models can help in the interpretation of statistical information. Uncertainties are by forensic experts often expressed numerically, but lawyers, judges and other legal experts have notorious difficulty interpreting these results [3, 1, 2, 5]. In this demonstration of our main paper [6] we focus on the connection between formal models of argumentation and Bayesian belief networks (BNs). We use BNs because they are a well-known model to represent and reason with complex probabilistic information. We introduce the notion of a support graph as an intermediate structure between Bayesian networks and argumentation models. A support graph captures the inferences modelled in a Bayesian network but disentangles the complicating graphical properties of such models and instead emphasises its intuitive understanding. Moreover, we show that this intermediate model can function as a template to generate different arguments based on the data.","2015","2025-02-19 14:42:22","2025-02-19 14:42:22","","233–234","","","","","","","ICAIL '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5532EQYR","journalArticle","2021","Zhang, Qingzhao; Hong, David Ke; Zhang, Ze; Chen, Qi Alfred; Mahlke, Scott; Mao, Z. Morley","A Systematic Framework to Identify Violations of Scenario-dependent Driving Rules in Autonomous Vehicle Software","Proc. ACM Meas. Anal. Comput. Syst.","","","10.1145/3460082","https://doi.org/10.1145/3460082","Safety compliance is paramount to the safe deployment of autonomous vehicle (AV) technologies in real-world transportation systems. As AVs will share road infrastructures with human drivers and pedestrians, it is an important requirement for AVs to obey standard driving rules. Existing AV software testing methods, including simulation and road testing, only check fundamental safety rules such as collision avoidance and safety distance. Scenario-dependent driving rules, including crosswalk and intersection rules, are more complicated because the expected driving behavior heavily depends on the surrounding circumstances. However, a testing framework is missing for checking scenario-dependent driving rules on various AV software.In this paper, we design and implement a systematic framework AVChecker for identifying violations of scenario-dependent driving rules in AV software using formal methods. AVChecker represents both the code logic of AV software and driving rules in proposed formal specifications and leverages satisfiability modulo theory (SMT) solvers to identify driving rule violations. To improve the automation of systematic rule-based checking, AVChecker provides a powerful user interface for writing driving rule specifications and applies static code analysis to extract rule-related code logic from the AV software codebase. Evaluations on two open-source AV software platforms, Baidu Apollo and Autoware, uncover 19 true violations out of 28 real-world driving rules covering crosswalks, traffic lights, stop signs, and intersections. Seven of the violations can lead to severe risks of a collision with pedestrians or blocking traffic.","2021-06","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","2","5","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","autonomous vehicle; formal methods; software system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54H8AQB4","conferencePaper","2015","Timmer, Sjoerd T.; Meyer, John-Jules Ch.; Prakken, Henry; Renooij, Silja; Verheij, Bart","A structure-guided approach to capturing bayesian reasoning about legal evidence in argumentation","Proceedings of the 15th International Conference on Artificial Intelligence and Law","978-1-4503-3522-5","","10.1145/2746090.2746093","https://doi.org/10.1145/2746090.2746093","Over the last decades the rise of forensic sciences has led to an increase in the availability of statistical evidence. Reasoning about statistics and probabilities in a forensic science setting can be a precarious exercise, especially so when independencies between variables are involved. To facilitate the correct explanation of such evidence we investigate how argumentation models can help in the interpretation of statistical information. In this paper we focus on the connection between argumentation models and Bayesian belief networks, the latter being a common model to represent and reason with complex probabilistic information. We introduce the notion of a support graph as an intermediate structure between Bayesian networks and argumentation models. A support graph disentangles the complicating graphical properties of a Bayesian network and enhances its intuitive interpretation. Moreover, we show that this model can provide a suitable template for argumentative analysis. Especially in the context of legal reasoning, the correct treatment of statistical evidence is important.","2015","2025-02-19 14:42:22","2025-02-19 14:42:22","","109–118","","","","","","","ICAIL '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5WEZBHKG","conferencePaper","2011","Lundström, Jenny Eriksson; Aceto, Giacomo; Hamfelt, Andreas","Towards a dynamic metalogic implementation of legal argumentation","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018370","https://doi.org/10.1145/2018358.2018370","Human argumentation in general and legal dispute in particular can be seen as highly dynamic and non-monotonic to its nature. To us this suggests that logical analysis of legal argumentation needs to be conducted in a dynamical and flexible setting in which the interaction is influenced by the parties' previous arguments. To express such approximations of legal reasoning as computational formalizations of argument, applications require dealing with knowledge representations, non-monotonic logics and a game-model able to capture the interaction as a debate between two or more disputing parties. In this paper we present some intuitions regarding the features of a full implementation and accompanying software for defeasible adversarial legal argumentation.","2011","2025-02-19 14:42:22","2025-02-19 14:42:22","","91–95","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P4VRWQPU","conferencePaper","2003","Lau, Gloria T.; Law, Kincho H.; Wiederhold, Gio","Similarity analysis on government regulations","Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","1-58113-737-0","","10.1145/956750.956845","https://doi.org/10.1145/956750.956845","Government regulations are semi-structured text documents that are often voluminous, heavily cross-referenced between provisions and even ambiguous. Multiple sources of regulations lead to difficulties in both understanding and complying with all applicable codes. In this work, we propose a framework for regulation management and similarity analysis. An online repository for legal documents is created with the help of text mining tool, and users can access regulatory documents either through the natural hierarchy of provisions or from a taxonomy generated by knowledge engineers based on concepts. Our similarity analysis core identifies relevant provisions and brings them to the user's attention, and this is performed by utilizing both the hierarchical and referential structures of regulations to provide a better comparison between provisions. Preliminary results show that our system reveals hidden similarities that are not apparent between provisions based on node content comparisons.","2003","2025-02-19 14:42:22","2025-02-19 14:42:22","","711–716","","","","","","","KDD '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington, D.C.","","","","regulations; text mining; legal informatics; similarity analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZNS29IX","journalArticle","2024","Liu, Jinhui; Zhang, Feng","Language Model Method for Collocation Rules of Parts of Speech in Machine Translation System","ACM Trans. Asian Low-Resour. Lang. Inf. Process.","","2375-4699","10.1145/3625095","https://doi.org/10.1145/3625095","With the development of the times, modern society has now entered the Internet of Things (IoT) information age and Machine Translation (MT) plays an important role in increasingly frequent cross-language communication. In recent years, China's artificial intelligence industry has been in a stage of rapid construction, and the scale of its core industries has grown explosively, and a large number of artificial intelligence companies, including issuers, have emerged. Part of speech has always been a major problem in MT. One of the reasons is that there are a large number of multi-category words in Chinese and a large number of polysemy words in English, so part of speech collocation problems account for a large proportion of MT errors, which to some extent affects the credibility and accuracy of the translation. To reduce the error problem in MT of part of speech collocation, this paper used Machine Learning (ML) methods to study the Language Model (LM) of part of speech collocation based on recurrent neural network (NN) and compared it with the traditional statistical LM. In terms of the accuracy rate of the two LMS in the automatic evaluation index of machine translation, the experimental results show that the recursive NN LM established by the ML method had an accuracy rate of 80.42% and 83.57%, respectively, for the part-of-speech matching rules of the IoT machine translation system in the dialogue between Chinese and English and the translation of articles. The accuracy of traditional statistical LM evaluation was 71.29% and 69.52%, respectively. Compared to traditional statistical LM, the accuracy of translation was higher. This showed that the recurrent NN LM reduced the number of errors in the collocation of parts of speech in MT and improved the accuracy and credibility of MT.","2024-08","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","8","23","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","machine learning; neural networks; language model; Machine translation; part collocation rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WC73C6MF","journalArticle","2022","Hacker, Philipp; Naumann, Felix; Friedrich, Tobias; Grundmann, Stefan; Lehmann, Anja; Zech, Herbert","AI Compliance – Challenges of Bridging Data Science and Law","J. Data and Information Quality","","1936-1955","10.1145/3531532","https://doi.org/10.1145/3531532","This vision article outlines the main building blocks of what we term AI Compliance, an effort to bridge two complementary research areas: computer science and the law. Such research has the goal to model, measure, and affect the quality of AI artifacts, such as data, models, and applications, to then facilitate adherence to legal standards.","2022-06","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","3","14","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","privacy; compliance; transparency; AI Act; information quality; liability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FYETYE8D","conferencePaper","2009","Dung, Phan Minh; Thang, Phan Minh; Hung, Nguyen Duy","Modular argumentation for modelling legal doctrines of performance relief","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568249","https://doi.org/10.1145/1568234.1568249","Legal doctrines provide principles, guidelines and rules for dispute resolution in reasoning with cases. To apply legal doctrines, the context of a contract consisting of different knowledge bases about beliefs and expertise of contract parties as well as about common social, legal domains need to be established. Judges then decide legal outcomes by reasoning from factors drawn in contract contexts following legal doctrines. In this paper, we model this decision making by modular argumentation. We focus on legal doctrines in contract law, especially the doctrines of impossibility and frustration of purpose.","2009","2025-02-19 14:42:22","2025-02-19 14:42:22","","128–136","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","argumentation; frustration; impossibility; legal doctrines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KLSX7GCD","conferencePaper","2015","Laboy, Pedro","Litigation support: complying with the law when handling electronic information during legal proceedings","Proceedings of the 2015 Information Security Curriculum Development Conference","978-1-4503-4049-6","","10.1145/2885990.2886002","https://doi.org/10.1145/2885990.2886002","This paper examines the Litigation Support industry and its involvement with compliance to federal and sometimes international, regulations. The focus of the research is information, in particular, electronically stored information. During legal proceedings in which electronic information can be used as evidence, there is an established set of rules and procedures that exists. This document first introduces the litigation support industry and all the various support structures that exist within it which an organization can use. It then outlines the formal laws that were implemented in relation to information. Finally, it describes how these laws affect the organization in their efforts to remain compliant throughout the entire legal process.","2015","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","","","","","","InfoSec '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kennesaw, Georgia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2KNR9TUN","conferencePaper","2017","Hasan, M. Mahmudul; Aganostopoulos, Dimosthenis; Loucopoulos, Pericles; Nikolaidou, Mara","Regulatory Requirements Compliance in e-Government System Development: an Ontology Framework","Proceedings of the 10th International Conference on Theory and Practice of Electronic Governance","978-1-4503-4825-6","","10.1145/3047273.3047341","https://doi.org/10.1145/3047273.3047341","Electronic government (e-Government) is increasingly gaining attention by the government and researcher to shape the public sector into digital society through enacting several e-Government system development policies and regulations. Hence, the compliance of regulatory requirement from these policies and regulations become an important accountability in e-Government project development where the concepts of regulatory requirements compliance is still scattered in the e-Government domain. This paper presents an ontology framework that describes the formal and explicit specification of the concepts of regulatory requirements compliance and their relations in e-Government system development. The ontology engineering technique 101 and Systematic Literature Review (SLR) were used in the process of developing the ontology framework of e-Government regulatory requirements compliance (eGovRRC). The e-Government system analyst can use this framework as a reference model to understand and conceptualize the interlinked set of clearly defined concepts of regulatory requirements compliance in e-Government system development projects.","2017","2025-02-19 14:42:22","2025-02-19 14:42:22","","441–449","","","","","","","ICEGOV '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: New Delhi AA, India","","","","e-Government; e-Government regulation and policy; Ontology Framework; Regulatory requirements Compliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQYY2UWK","conferencePaper","2015","Vlek, Charlotte; Prakken, Henry; Renooij, Silja; Verheij, Bart","Constructing and understanding Bayesian networks for legal evidence with scenario schemes","Proceedings of the 15th International Conference on Artificial Intelligence and Law","978-1-4503-3522-5","","10.1145/2746090.2746097","https://doi.org/10.1145/2746090.2746097","In a criminal trial, a judge or jury needs to reach a conclusion about 'what happened' based on the available evidence. Often this includes probabilistic evidence. Whereas Bayesian networks form a good tool for analysing evidence probabilistically, simply presenting the outcome of the network to a judge or jury does not allow them to make an informed decision. In this paper, we propose to combine Bayesian networks with a narrative approach to reasoning with legal evidence, the result of which allows a juror to reason with alternative scenarios while also incorporating probabilistic information. The proposed method aids both the construction and the understanding of Bayesian networks, using scenario schemes. We make three distinct contributions: (1) we propose to use scenario schemes to aid the construction of Bayesian networks, (2) we propose a method for producing scenarios in text form from the resulting networks and (3) we propose a format for reporting the alternative scenarios and their relations to the evidence (including strength).","2015","2025-02-19 14:42:22","2025-02-19 14:42:22","","128–137","","","","","","","ICAIL '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJ3DSBEA","conferencePaper","2016","Ford, Reginald; Denker, Grit; Elenius, Daniel; Moore, Wesley; Abi-Lahoud, Elie","Automating Financial Regulatory Compliance Using Ontology+Rules and Sunflower","Proceedings of the 12th International Conference on Semantic Systems","978-1-4503-4752-5","","10.1145/2993318.2993329","https://doi.org/10.1145/2993318.2993329","Compliance departments in the international finance industry are struggling to use traditional methods to keep up with the demands of new and more stringent regulatory and policy requirements. One initiative supported by many institutions is definition of a common Financial Industry Business Ontology (FIBO). We regard a common ontology as an important step, but in order to support real-world uses cases, the ontology needs to be augmented, and further supplemented by rules that encode the meaning of regulations and policies. We use Sunflower, which is built on top of the Flora-2 knowledge representation languages and reasoner, to add automation to the compliance lifecycle. Sunflower is domain-agnostic, and financial regulatory compliance is one of its many application areas.","2016","2025-02-19 14:42:22","2025-02-19 14:42:22","","113–120","","","","","","","SEMANTiCS 2016","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Leipzig, Germany","","","","Regulatory Compliance; Explanation; Integrated Development Environment; Ontologies; Reasoning; Rules; Sunflower","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q6XLICN7","conferencePaper","2022","Kiayias, Aggelos; Kohlweiss, Markulf; Sarencheh, Amirreza","PEReDi: Privacy-Enhanced, Regulated and Distributed Central Bank Digital Currencies","Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security","978-1-4503-9450-5","","10.1145/3548606.3560707","https://doi.org/10.1145/3548606.3560707","Central Bank Digital Currencies (CBDCs) aspire to offer a digital replacement for physical cash and as such need to tackle two fundamental requirements that are in conflict. On the one hand, it is desired they are private so that a financial ""panopticon” is avoided, while on the other, they should be regulation friendly in the sense of facilitating any threshold-limiting, tracing, and counterparty auditing functionality that is necessary to comply with regulations such as Know Your Customer (KYC), Anti Money Laundering (AML) and Combating Financing of Terrorism (CFT) as well as financial stability considerations. In this work, we put forth a new model for CBDCs and an efficient construction that, for the first time, fully addresses these issues simultaneously. Moreover, recognizing the importance of avoiding a single point of failure, our construction is distributed so that all its properties can withstand a suitably bounded minority of participating entities getting corrupted by an adversary. Achieving all the above properties efficiently is technically involved; among others, our construction uses suitable cryptographic tools to thwart man-in-the-middle attacks, it showcases a novel traceability mechanism with significant performance gains compared to previously known techniques and, perhaps surprisingly, shows how to obviate Byzantine agreement or broadcast from the optimistic execution path of a payment, something that results in an essentially optimal communication pattern and communication overhead when the sender and receiver are honest. Going beyond ""simple” payments, we also discuss how our scheme can facilitate one-off large transfers complying with Know Your Transaction (KYT) disclosure requirements. Our CBDC concept is expressed and realized in the Universal Composition (UC) framework providing in this way a modular and secure way to embed it within a larger financial ecosystem.","2022","2025-02-19 14:42:22","2025-02-19 14:42:22","","1739–1752","","","","","","","CCS '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Los Angeles, CA, USA","","","","privacy; regulatory compliance; aml; cbdc; cft; cryptography; distributed ledgers; kyc; kyt; universal composition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VFWIVIC","conferencePaper","2020","Wagner, Ben; Rozgonyi, Krisztina; Sekwenz, Marie-Therese; Cobbe, Jennifer; Singh, Jatinder","Regulating transparency? Facebook, Twitter and the German Network Enforcement Act","Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency","978-1-4503-6936-7","","10.1145/3351095.3372856","https://doi.org/10.1145/3351095.3372856","Regulatory regimes designed to ensure transparency often struggle to ensure that transparency is meaningful in practice. This challenge is particularly great when coupled with the widespread usage of dark patterns — design techniques used to manipulate users. The following article analyses the implementation of the transparency provisions of the German Network Enforcement Act (NetzDG) by Facebook and Twitter, as well as the consequences of these implementations for the effective regulation of online platforms. This question of effective regulation is particularly salient, due to an enforcement action in 2019 by Germany's Federal Office of Justice (BfJ) against Facebook for what the BfJ claim were insufficient compliance with transparency requirements, under NetzDG.This article provides an overview of the transparency requirements of NetzDG and contrasts these with the transparency requirements of other relevant regulations. It will then discuss how transparency concerns not only providing data, but also how the visibility of the data that is made transparent is managed, by deciding how the data is provided and is framed. We will then provide an empirical analysis of the design choices made by Facebook and Twitter, to assess the ways in which their implementations differ. The consequences of these two divergent implementations on interface design and user behaviour are then discussed, through a comparison of the transparency reports and reporting mechanisms used by Facebook and Twitter. As a next step, we will discuss the BfJ's consideration of the design of Facebook's content reporting mechanisms, and what this reveals about their respective interpretations of NetzDG's scope. Finally, in recognising that this situation is one in which a regulator is considering design as part of their action - we develop a wider argument on the potential for regulatory enforcement around dark patterns, and design practices more generally, for which this case is an early, indicative example.","2020","2025-02-19 14:42:22","2025-02-19 14:42:22","","261–271","","","","","","","FAT* '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7Y8D65MX","journalArticle","2024","Beck, Shannon; Goines, Timothy; Biller, Jeffrey","Lawyer Up! Joint Introductory Computer Science and Law Courses","J. Comput. Sci. Coll.","","1937-4771","","","Courses typically focus on a single discipline, limiting exposure to cross-disciplinary topics. To address this, we designed an interdisciplinary two-course set within our undergraduate Honors program: an introductory computing course and an introductory law course. This initiative breaks down barriers between computing and law, enabling students to integrate both disciplines and foster a comprehensive understanding of complex issues. The Computer Science (CS) course covers introductory programming and principles, while the Law course surveys American Law and basic legal reasoning. Initially, the topics are independent but they strongly converge in the term's second half. Students explore the intersection of CS and Law through discussions, debates, guest speakers, and a cross-disciplinary project. Conducted for two years at the United States Air Force Academy (USAFA), this report shares our curriculum and experiences, aiming to inspire wider adoption of our inter-departmental model.","2024-10","2025-02-19 14:42:22","2025-02-19 14:42:22","","62–72","","2","40","","","","","","","","","","","","","","","","","Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B7VUKSAE","conferencePaper","2018","Wang, Yuxin; Hulstijn, Joris; Tan, Yao-hua","Regulatory supervision with computational audit in international supply chains","Proceedings of the 19th Annual International Conference on Digital Government Research: Governance in the Data Age","978-1-4503-6526-0","","10.1145/3209281.3209319","https://doi.org/10.1145/3209281.3209319","Nowadays, as international trade with cross-border logistics increases, the administrative burden of regulatory authorities has been dramatically raised. In order to reduce repetitive and redundant supervisory controls and promote automatic administration procedures, electronic data interchange (EDI)1 and other forms of information sharing are introduced and implemented. Compliance monitoring ensures data quality for information exchange and audit purpose. However, failure to be compliant with various regulations is still a general phenomenon globally among stakeholders in supply chains, leading to more problems such as delay of goods delivery, missing inventory, and security issues. To address these problems, traditional physical auditing methods are widely used but turned out to be time-consuming and costly, especially when multiple stakeholders are involved. Since there is limited empirical research on compliance monitoring for regulatory supervision in international supply chains, we propose a compliance monitoring framework that can be applied with data sharing and analytics. The framework implementation is validated by an extensive case study on customs supervision in the Netherlands using process mining techniques. Practically, both public and private sectors will benefit from our descriptive and prescriptive analytics for audit purposes. Theoretically, our control strategies developed at the operational level facilitates mitigation of risks at root causes.","2018","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","","","","","","dg.o '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Delft, The Netherlands","","","","audit; compliance; process mining; regulatory supervision; supply chains","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRFGU7Q6","conferencePaper","2017","Li, Peilong; Xu, Chen; Luo, Yan; Cao, Yu; Mathew, Jomol; Ma, Yunsheng","Carenet: building regulation-compliant home-based healthcare services with software-defined infrastructure","Proceedings of the Second IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies","978-1-5090-4721-5","","10.1109/CHASE.2017.121","https://doi.org/10.1109/CHASE.2017.121","Healthcare network and computing infrastructure is rapidly changing from closed environments to open environments that incorporate new devices and new application scenarios. Home-based healthcare is such an example of leveraging pervasive sensors and analyzing sensor data (often in real-time) to guide therapy or intervene. In this paper, we address the challenges in regulatory compliance when designing and deploying healthcare applications on a heterogeneous cloud environment. We propose the CareNet framework, consisting of a set of APIs and secure data transmission mechanisms, to facilitate the specification of home-based healthcare services running on the software-defined infrastructure (SDI). This work is a collaboration among computer scientists, medical researchers, healthcare IT and healthcare providers, and its goal is to reduce the gap between the availability of SDI and meeting regulatory compliance in healthcare applications. Our prototype demonstrates the feasibility of the framework and serves as testbed for novel experimental studies of emerging healthcare applications.","2017","2025-02-19 14:42:22","2025-02-19 14:42:22","","373–382","","","","","","","CHASE '17","","","","IEEE Press","","","","","","","","","Place: Philadelphia, Pennsylvania","","","","CORD; HIPAA compliance; home-based healthcare; software-defined infrastructure; XaaS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7A7CSKQ","conferencePaper","2014","Kenneally, Erin","Revisiting signals and noise for ethical and legal research using online data","Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication","978-1-4503-3047-3","","10.1145/2638728.2641685","https://doi.org/10.1145/2638728.2641685","The stability of trust on the Internet has implications for political diplomacy, innovation, economic stability, social and civil relations, and individual self-determinism. The degree of online trust is a reflection of the gap between individual and collective Netizens' expectations formed by laws and ethics, and their capabilities enabled by technology. Law and ethics, just as with familiar offline society, act as ordering forces that inform the acceptability of our behaviors and relationships with other person and organizations. The migration of these analog activities online has exposed a rather sweeping gap between expectations and capabilities, where legal and ethical ordering forces are challenged to re-examine, -interpret, and –apply the tenets and principles upon which they moor. As this gap widens, so too does ambiguity between asserted rights, interests, and threats to same.This gap is manifest most prominently in the current industrial and geo-political struggle to define rules of engagement for cyber conflict and national security, as well as with online advertising and data brokering. A related context where ordering forces are challenged, lower on the public notoriety index but no less considerable, is information and communication technology (ICT) research. The controversy over the collection, use and disclosure of online data for research exposes gaps and deficiencies in the legal and ethical structures that directly and indirectly inform and reflect our expectations.Notably, ""consent"" has been a fundamental mechanism for protecting rights and interests in both law and ethics. As such, it serves as an institutionalized signal for persons' reasonable expectations. Yet, the ability to easily collect and combine massive amounts of existing, ""publicly-available"" information of a sensitive nature (personal or confidential) online exposes deficiencies in consent as an effective signal for expectations.More specifically, researchers increasingly encounter data online such as personal health, financial or behavioral records; usernames and passwords lists; corporate manuals and technical documents; email and voice communications databases; and, device vulnerabilities and machine-to-machine communications. It is located in various online locations ranging from normal websites and social networks to underground criminal forums, Internet relay chat rooms, and publicly-obscured/hidden sites. And, its availability is often a product of malicious, negligent, or ignorant collection or disclosure by a third party.In this context, consent as an expectation signal is strained along substantive and procedural dimensions. For example, some argue that the existence of other signals (i.e., the data was public and/or non-identifiable, the purpose of the research is to study a system or threat and not individual persons) pre-empts the need for consent. In addition, obtaining consent for what amounts to secondary use of online data may be impracticable in light of the distance between researchers and data subjects, or outweighed by countervailing intended benefits or academic freedom interests.With research using data available online, researcher conduct is not fully prescribed or proscribed by formal ethical codes of conduct or law because current expectations signals are ill-fitting. This presentation is intended to advance the collective dialogue toward a path that revisits and harmonizes ethical and legal signals for research using online data among researchers, oversight entities, policymakers and society. It does not dictate answers but aims to point out where current ordering forces breakdown in the context of online research and to suggest how to identify and respond to these grey areas by applying common legal and ethical tenets.","2014","2025-02-19 14:42:22","2025-02-19 14:42:22","","621–622","","","","","","","UbiComp '14 Adjunct","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seattle, Washington","","","","technology policy; law; ethics; research ethics; risk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QC2A8ESA","conferencePaper","2024","Wu, Bing; Song, Yuanbin; Cao, Jinhao","Automatic Generation of GIM Data Audit Rules Based on Sentence Embedding Vectors","Proceedings of the 6th International Conference on Information Technologies and Electrical Engineering","979-8-4007-0829-9","","10.1145/3640115.3640224","https://doi.org/10.1145/3640115.3640224","The digital design results of power substations establish the foundation for their running and maintaining. Currently, the digital design of substations is delivered in the format of Grid Information Model (GIM), an alternative Building Information Modeling (BIM) format for describing power grid infrastructure in China. Since the correctness, compliance, and consistency of GIM data are necessary conditions for information sharing and business decision support, the GIM data must be audited before sharing among the stakeholders. The traditional manual review of GIM data is too inefficient and costly to execute, and thus the power grid industry seeks automatic review approaches. However, one challenge for automated auditing of GIM data is the lack of auditing rules. In order to establish such a rule base for GIM data auditing, this study first categorizes the audit rules, and proposes an XML encoding method for the audit rules. Meanwhile, the methodology of converting the rules described in natural language into XML is also rules proposed using the SBERT model. The application of the developed tool is demonstrated and verified through case studies.","2024","2025-02-19 14:42:22","2025-02-19 14:42:22","","668–673","","","","","","","ICITEE '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Changde, Hunan, China","","","","Natural language processing; Controlled natural language; Grid information model; Model audit; Rule representation; Sentence BERT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RIU3WNIU","conferencePaper","2013","Bench-Capon, Trevor; Prakken, Henry; Wyner, Adam; Atkinson, Katie","Argument schemes for reasoning with legal cases using values","Proceedings of the Fourteenth International Conference on Artificial Intelligence and Law","978-1-4503-2080-1","","10.1145/2514601.2514604","https://doi.org/10.1145/2514601.2514604","Argument schemes can provide a means of explicitly describing reasoning methods in a form that lends itself to computation. The reasoning required to distinguish cases in the manner of CATO has been previously captured as a set of argument schemes. Here we present argument schemes that encapsulate another way of reasoning with cases: using preferences between social values revealed in past decisions to decide cases which have no exact matching precedents when the cases are described in terms of factors. We provide a set of schemes, with variations to capture different ways of comparing sets and varying degrees of promotion of values; we formalise these schemes; and we illustrate them with some examples.","2013","2025-02-19 14:42:22","2025-02-19 14:42:22","","13–22","","","","","","","ICAIL '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rome, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTJ3W9UL","conferencePaper","2011","Riveret, Régis; Rotolo, Antonino; Contissa, Giuseppe; Sartor, Giovanni; Vasconcelos, Wamberto","Temporal accommodation of legal argumentation","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018368","https://doi.org/10.1145/2018358.2018368","This paper proposes to integrate an argumentation framework with techniques from Temporal Constraint Satisfaction. Temporal constraints are thus embedded into legal argumentation to account for temporal aspects of legal reasoning. Through the accommodation of temporal constraints, the validity of arguments and of their conclusions is made relative to the time-points when the applied norms are alive, according to the adopted temporal perspective. A fixed-point semantics and an associated dialogue game are given.","2011","2025-02-19 14:42:22","2025-02-19 14:42:22","","71–80","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","legal reasoning; argumentation; constraints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AIIBGCPH","conferencePaper","2024","Oldenburg, Ninell; Zhi-Xuan, Tan","Learning and Sustaining Shared Normative Systems via Bayesian Rule Induction in Markov Games","Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems","979-8-4007-0486-4","","","","A universal feature of human societies is the adoption of systems of rules and norms in the service of cooperative ends. How can we build learning agents that do the same, so that they may flexibly cooperate with the human institutions they are embedded in? We hypothesize that agents can achieve this by assuming there exists a shared set of norms that most others comply with while pursuing their individual desires, even if they do not know the exact content of those norms. By assuming shared norms, a newly introduced agent can infer the norms of an existing population from observations of compliance and violation. Furthermore, groups of agents can converge to a shared set of norms, even if they initially diverge in their beliefs about what the norms are. This in turn enables the stability of the normative system: since agents can bootstrap common knowledge of the norms, this leads the norms to be widely adhered to, enabling new entrants to rapidly learn those norms. We formalize this framework in the context of Markov games and demonstrate its operation in a multi-agent environment via approximately Bayesian rule induction of obligative and prohibitive norms. Using our approach, agents are able to rapidly learn and sustain a variety of cooperative institutions, including resource management norms and compensation for pro-social labor, promoting collective welfare while still allowing agents to act in their own interests.","2024","2025-02-19 14:42:22","2025-02-19 14:42:22","","1510–1520","","","","","","","AAMAS '24","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Auckland, New Zealand","","","","normative systems; bayesian learning; cooperative intelligence; markov games; norm emergence; norm learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VVICPCU2","conferencePaper","2011","Wyner, Adam Z.; Bench-Capon, Trevor J. M.; Atkinson, Katie M.","Towards formalising argumentation about legal cases","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018359","https://doi.org/10.1145/2018358.2018359","In this paper we offer an account of reasoning with legal cases in terms of argumentation schemes. These schemes, and undercutting attacks associated with them, are expressed as defeasible rules of inference that will lend themselves to formalisation within the AS-PIC+ framework. We begin by modelling the style of reasoning with cases developed by Aleven and Ashley in the CATO project, which describes cases using factors, and then extend the account to accommodate the dimensions used in Rissland and Ashley's earlier HYPO project. Some additional scope for argumentation is then identified and formalised.","2011","2025-02-19 14:42:22","2025-02-19 14:42:22","","1–10","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHQCL5I9","conferencePaper","2019","Vijeev, Abhishek; Ganapathy, Vinod; Bhattacharyya, Chiranjib","Regulating Drones in Restricted Spaces","Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications","978-1-4503-6273-3","","10.1145/3301293.3302370","https://doi.org/10.1145/3301293.3302370","Commercial and end-user drones come equipped with a wide array of sensors. Unregulated use of such drones in public airspaces poses a serious threat to the privacy of citizens. We make the case for restricted spaces for drones, which are geographic areas for which a host can specify its privacy policies. Guest drones must prove to the host that they are in compliance with the host's policies before entering the restricted space. We then make the case for an information-flow control-based policy enforcement framework on drones, and sketch the design of a prototype framework atop the Robot Operating System (ROS).","2019","2025-02-19 14:42:22","2025-02-19 14:42:22","","27–32","","","","","","","HotMobile '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Santa Cruz, CA, USA","","","","privacy; drones; restricted spaces; trusted hardware","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5D96IYUJ","conferencePaper","2011","Bex, Floris; Verheij, Bart","Legal shifts in the process of proof","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018360","https://doi.org/10.1145/2018358.2018360","In this paper, we continue our research on a hybrid narrative-argumentative approach to evidential reasoning in the law by showing the interaction between factual reasoning and legal reasoning. We therefore emphasize the role of legal story schemes (as opposed to factual story schemes that formed the heart of our previous proposal). Legal story schemes steer what needs to be proven, but are also selected on the basis of what can be proven. They provide a coherent, holistic legal perspective on a criminal case that steers investigation and decision making. We present an extension of our previously proposed hybrid theory of reasoning with evidence, by making the connection with reasoning towards legal consequences. We discuss the phenomenon of legal shifts that shows that the step from evidence to (proven) facts cannot be isolated from the step from proven facts to legal consequences. We show how legal shifts can be modelled in terms of legal story schemes. Our model is illustrated by a discussion of the Dutch Wamel murder case.","2011","2025-02-19 14:42:22","2025-02-19 14:42:22","","11–20","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","legal argumentation; legal evidence and proof; stories","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTN6PAQK","conferencePaper","2022","Stach, Christoph; Gritti, Clémentine; Przytarski, Dennis; Mitschang, Bernhard","Can blockchains and data privacy laws be reconciled? a fundamental study of how privacy-aware blockchains are feasible","Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing","978-1-4503-8713-2","","10.1145/3477314.3506986","https://doi.org/10.1145/3477314.3506986","Due to the advancing digitalization, the importance of data is constantly increasing. Application domains such as smart cars, smart cities, or smart healthcare rely on the permanent availability of large amounts of data to all parties involved. As a result, the value of data increases, making it a lucrative target for cyber-attacks. Particularly when human lives depend on the data, additional protection measures are therefore important for data management and provision. Blockchains, i. e., decentralized, immutable, and tamper-proof data stores, are becoming increasingly popular for this purpose. Yet, from a data protection perspective, the immutable and tamper-proof properties of blockchains pose a privacy concern. In this paper, we therefore investigate whether blockchains are in compliance with the General Data Protection Regulation (GDPR) if personal data are involved. To this end, we elaborate which articles of the GDPR are relevant in this regard and present technical solutions for those legal requirements with which blockchains are in conflict. We further identify open research questions that need to be addressed in order to achieve a privacy-by-design blockchain system.","2022","2025-02-19 14:42:22","2025-02-19 14:42:22","","1218–1227","","","","","","","SAC '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event","","","","GDPR; blockchains; immutable; privacy assessment; tamper-proof","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9APAWDD3","journalArticle","2014","Nekvi, Md Rashed I.; Madhavji, Nazim H.","Impediments to Regulatory Compliance of Requirements in Contractual Systems Engineering Projects: A Case Study","ACM Trans. Manage. Inf. Syst.","","2158-656X","10.1145/2629432","https://doi.org/10.1145/2629432","Large-scale contractual systems engineering projects often need to comply with myriad government regulations and standards as part of contractual obligations. A key activity in the requirements engineering (RE) process for such a project is to demonstrate that all relevant requirements have been elicited from the regulatory documents and have been traced to the contract as well as to the target system components. That is, the requirements have met regulatory compliance. However, there are impediments to achieving this level of compliance due to such complexity factors as voluminous contract, large number of regulatory documents, and multiple domains of the system. Little empirical research has been conducted in the scientific community on identifying these impediments. Knowing these impediments is a driver for change in the solutions domain (i.e., creating improved or new methods, tools, processes, etc.) to deal with such impediments. Through a case study of an industrial RE project, we have identified a number of key impediments to achieving regulatory compliance in a large-scale, complex, systems engineering project. This project is an upgrade of a rail infrastructure system. The key contribution of the article is a number of hitherto uncovered impediments described in qualitative and quantitative terms. The article also describes an artefact model, depicting key artefacts and relationships involved in such a compliance project. This model was created from data gathered and observations made in this compliance project. In addition, the article describes emergent metrics on regulatory compliance of requirements that can possibly be used for estimating the effort needed to achieve regulatory compliance of system requirements.","2014-12","2025-02-19 14:42:22","2025-02-19 14:42:22","","","","3","5","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","compliance of requirements; effort estimation; Legal requirements elicitation; rail infrastructure system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87HY8JE9","conferencePaper","2011","Abrahams, Brooke; Condliffe, Peter; Zeleznikow, John","Using an OWL ontology to support legal negotiation about owners corporation disputes","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018386","https://doi.org/10.1145/2018358.2018386","The paper describes the development of a legal negotiation support guide for owners corporation cases in the state of Victoria, Australia that uses an OWL ontology and Bayesian Network to perform legal reasoning and provide advice about BATNAs. The rate of growth of owners corporations (also known as body corporate or strata title properties) has increased significantly in the last two decades. Because of this growth, and the need to manage a rapidly expanding population, the governance and management of these entities has become an important concern for government. Conflict and its management within them is an essential element of this concern. Cases that can't be settled through negotiation are often referred to the Victorian Civil and Administrative appeals Tribunal (VCAT). Using an OWL ontology we have systematically modeled legal arguments and outcomes of past cases heard by VCAT to facilitate both stand alone and Web based information retrieval, extraction and case based reasoning. A Bayesian Belief network is also used to deal with assumptions that tend to be prevalent in commonsense reasoning. Through our system we aim to provide negotiation decision support to help guide owners corporation disputants through the grievance process.","2011","2025-02-19 14:42:23","2025-02-19 14:42:23","","194–198","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","ontologies; BATNA; Bayesian belief networks; case based legal reasoning; negotiation decision support; OWL; owners corporation disputes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSAG69VW","conferencePaper","2011","Dechesne, Francien; Dignum, Virginia; Tan, Yao-Hua","Understanding compliance differences between legal and social norms: the case of smoking ban","Proceedings of the 10th International Conference on Advanced Agent Technology","978-3-642-27215-8","","10.1007/978-3-642-27216-5_5","https://doi.org/10.1007/978-3-642-27216-5_5","The values shared within a society influence the (social) behaviour of the agents in that society. This connection goes through implicit and explicit norms. Agents act in situations where different, possibly conflicting, norms are applicable. In the case of a norm conflict, an agent will decide to comply with one or more of the applicable norms, while violating others. Our interest is how the type of the norms may play a role in such decision, and take the chosen behaviour of an agent to depend on a personal preference order on the norm types.We distinguish three different types of norms: legal norms, social norms and private norms. We use the introduction of the law prohibiting smoking in cafes as illustration: we present a simulation of this situation involving agents' preferences over different norm types. The results of this simulation are used for an explorative a model for normative reasoning based on norm types. We discuss a possible connection between the composition of a society in terms of these profiles and its culture and the relevance of the model with respect to value sensitive design of socio-technological systems.","2011","2025-02-19 14:42:23","2025-02-19 14:42:23","","50–64","","","","","","","AAMAS'11","","","","Springer-Verlag","Berlin, Heidelberg","","","","","","","","event-place: Taipei, Taiwan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NA5RD7FV","journalArticle","2013","Betz, Hariolf; Frühwirth, Thom","Linear-Logic Based Analysis of Constraint Handling Rules with Disjunction","ACM Trans. Comput. Logic","","1529-3785","10.1145/2422085.2422086","https://doi.org/10.1145/2422085.2422086","Constraint Handling Rules (CHR) is a declarative rule-based programming language that has cut out its niche over the course of the last 20 years. It generalizes concurrent constraint logic programming to multiple heads, thus closing the gap to multiset transformation systems. Its popular extension CHR with Disjunction (CHR∨) is a multiparadigm declarative programming language that allows embedding of Horn programs with SLD resolution.We analyze the assets and the limitations of the classical declarative semantics of CHR∨ and highlight its natural relationship with linear-logic. We furthermore develop two linear-logic semantics for CHR∨ that differ in the reasoning domain for which they are instrumental. We show their idempotence and their soundness and completeness with respect to the operational semantics. We show how to apply the linear-logic semantics to decide program properties and to reason about operational equivalence of CHR∨ programs.","2013-02","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","1","14","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Constraint handling rules; declarative semantics; linear logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YGLTUMNW","conferencePaper","2009","Gordon, Thomas F.; Walton, Douglas","Legal reasoning with argumentation schemes","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568250","https://doi.org/10.1145/1568234.1568250","Legal reasoning typically requires a variety of argumentation schemes to be used together. A legal case may raise issues requiring argument from precedent cases, rules, policy goals, moral principles, jurisprudential doctrine, social values and evidence. We present an extensible software architecture which allows diverse computational models of argumentation schemes to be used together in an integrated way to construct and search for arguments. The architecture has been implemented in Carneades, a software library for building argumentation tools. The architecture is illustrated with models of schemes for argument from ontologies, rules, cases and testimonial evidence and compared to blackboard systems for hybrid reasoning.","2009","2025-02-19 14:42:23","2025-02-19 14:42:23","","137–146","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FWIRI7JP","conferencePaper","2008","Piolle, Guillaume; Demazeau, Yves","Obligations with Deadlines and Maintained Interdictions in Privacy Regulation Frameworks","Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 02","978-0-7695-3496-1","","10.1109/WIIAT.2008.168","https://doi.org/10.1109/WIIAT.2008.168","We aim at providing artificial agents with logical tools to reason specifically on privacy-related regulations, in order to comply with them. In order to express these regulations, we propose a deontic and temporal logic based on predicates dealing with personal data management. Using an example, we show the need for specific operators to express obligations with deadlines and maintained interdictions. We define a set of eight specific requirements for such operators, we evaluate the existing proposals with respect to these requirements and we adapt our own ones, to better suit to our formalism.","2008","2025-02-19 14:42:23","2025-02-19 14:42:23","","162–168","","","","","","","WI-IAT '08","","","","IEEE Computer Society","USA","","","","","","","","","","","","privacy; deadlines; deontic logic; obligations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMEB35XQ","conferencePaper","1993","Schobbens, Pierre-Yves","A logic for legal hierarchies","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.159010","https://doi.org/10.1145/158976.159010","The theory of non-monotonic reasoning has interesting applications for the formalization and automated use of legal concepts, specially:In this paper, we use a logic [37, 38], that ranks contradictory formulae using two new paraconsistent variants of conjunction: “but” and “on the other hand”. Its algebraic proof theory is presented.","1993","2025-02-19 14:42:23","2025-02-19 14:42:23","","272–281","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECS3FK28","conferencePaper","2017","Madaan, Nishtha; Karanam, Hima; Gupta, Ankush; Jain, Nitisha; Kumar, Arun; Tamilselvam, Srikanth","Visual Exploration of Unstructured Regulatory Documents","Companion Proceedings of the 22nd International Conference on Intelligent User Interfaces","978-1-4503-4893-5","","10.1145/3030024.3038261","https://doi.org/10.1145/3030024.3038261","Governmental authorities publish rules and directives that govern the operations of an industry. These documents, called regulations, are meant to safeguard the interests of consumers. With increasing number, size and complexity of such documents, companies face an uphill task to comply with them. We present a cognitive system, called Cogpliance, for exploring and understanding regulatory documents with the goal of assisting compliance officers in attaining regulatory compliance. Cogpliance automatically reads natural language regulatory documents, extracts key concepts and presents an interactive information exploration user interface for answering compliance officers queries.","2017","2025-02-19 14:42:23","2025-02-19 14:42:23","","129–132","","","","","","","IUI '17 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Limassol, Cyprus","","","","none; SOLR; SQL; user interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35Y6IV2W","conferencePaper","2011","Grabmair, Matthias; Ashley, Kevin D.","Facilitating case comparison using value judgments and intermediate legal concepts","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018382","https://doi.org/10.1145/2018358.2018382","This paper explains and illustrates in an example context how case comparison in legal case-based reasoning can be modeled in the value judgment formalism. It presents a set of argument schemes corresponding to typical moves in case-based reasoning which make use of intermediate legal concepts and their impact on the applicable values.","2011","2025-02-19 14:42:23","2025-02-19 14:42:23","","161–170","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","case-based reasoning; legal reasoning; intermediate legal concepts; value-based argumentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6TVSIJTP","journalArticle","2021","Bidwell, Nicola J.; Cibin, Roberto; Linehan, Conor; Maye, Laura; Robinson, Sarah","Being Regulated: Licence to Imagine New Technology for Community Radio","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3449228","https://doi.org/10.1145/3449228","Licencing frameworks are embedded with sociotechnical imaginaries that limit the potential for networked technologies to make traditional media forms, like radio, more inclusive. We sought to refine and extend a platform, RootIO, which aims to enable diverse people to run small radio stations by using internet and mobile networks that avoid the costs of studios and specialist equipment. We situated design and refinement in the activities of groups that set up and ran four community stations in rural Romania and some Irish islands over three-years and found national regulations limited who articulated requirements. Activities in applying for, and complying with, licences shaped design priorities, embedded temporal demands, certain organisational structures and division of responsibilities, and assumptions about studios and professionalism. Indeed, small radio stations are subject to the same values as large media corporations that pursue market power. Regulatory frameworks are specific to nations and media form, yet our analysis illustrates that they impede designing platforms to widen inclusion by enacting broader sociotechnical imaginaries. We hope this reflection provokes discussion, in HCI and CSCW, about our responsibilities in engaging with the policies that shape possible futures.","2021-04","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","CSCW1","5","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","regulation; articulating requirements; community radio; participatory design; policy knot; sociotechnical imaginary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWTWZX8C","conferencePaper","2017","Clara, Angela Maria Cristina; Canedo, Edna Dias; de Sousa Júnior, Rafael Timóteo","Elements that Orient the Regulatory Compliance Verification Audits on ICT Governance","Proceedings of the 18th Annual International Conference on Digital Government Research","978-1-4503-5317-5","","10.1145/3085228.3085286","https://doi.org/10.1145/3085228.3085286","The expression Information and Communications Technology (ICT) refers to a large integrated set of structures and functions employed to access, transfer, store and treat all forms of information, i.e., actually, text, voice, data and image, which continue to be an important factor for improving organizational management and achieving competitive advantage, since ICT can be used to add value, continuously, to almost all business processes. This paper presents and discusses elements that are considered important to guide verification actions regarding regulatory compliance of ICT management practices. Designated hereinafter as Elements that Orient Regulatory Compliance Verification Audits (ECVAs), these elements are characterized in this paper from a survey of literature, international and national regulations, and best practices bodies. Their selection aims at improving ICT Governance in a Brazilian public company which is used as a reference to validate our choices.","2017","2025-02-19 14:42:23","2025-02-19 14:42:23","","177–184","","","","","","","dg.o '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Staten Island, NY, USA","","","","Compliance; ICT Governance; Information and Communications Technology (ICT); Management Elements; Public Company","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9323KWRR","bookSection","2025","Han, Jessy Xinyi; Miller, Andrew Cesare; Watkins, S. Craig; Winship, Christopher; Christia, Fotini; Shah, Devavrat","A Causal Framework To Evaluate Racial Bias in Law Enforcement Systems","Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society","","","","","We are interested in developing a data-driven method to evaluate race-induced biases in law enforcement systems. While the recent works have addressed this question in the context of police-civilian interactions using police stop data, they have two key limitations. First, bias can only be properly quantified if true criminality is accounted for in addition to race, but it is absent in prior works. Second, law enforcement systems are multi-stage and hence it is important to isolate the true source of bias within the ""causal chain of interactions"" rather than simply focusing on the end outcome; this can help guide reforms.In this work, we address these challenges by presenting a multi-stage causal framework incorporating criminality. We provide a theoretical characterization and an associated data-driven method to evaluate (a) the presence of any form of racial bias, and (b) if so, the primary source of such a bias in terms of race and criminality. Our framework identifies three canonical scenarios with distinct characteristics: in settings like (1) airport security, the primary source of observed bias against a race is likely to be bias in law enforcement against innocents of that race; (2) AI-empowered policing, the primary source of observed bias against a race is likely to be bias in law enforcement against criminals of that race; and (3) police-civilian interaction, the primary source of observed bias against a race could be bias in law enforcement against that race or bias from the general public in reporting (e.g. via 911 calls) against the other race. Through an extensive empirical study using police-civilian interaction (stop) data and 911 call data, we find an instance of such a counterintuitive phenomenon: in New Orleans, the observed bias is against the majority race and the likely reason for it is the over-reporting (via 911 calls) of incidents involving the minority race by the general public.","2025","2025-02-19 14:42:23","2025-02-19 14:42:23","","562–572","","","","","","","","","","","AAAI Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EKQNBD6T","conferencePaper","2008","Nallapati, Ramesh; Manning, Christopher D.","Legal docket-entry classification: where machine learning stumbles","Proceedings of the Conference on Empirical Methods in Natural Language Processing","","","","","We investigate the problem of binary text classification in the domain of legal docket entries. This work presents an illustrative instance of a domain-specific problem where the state-of-the-art Machine Learning (ML) classifiers such as SVMs are inadequate. Our investigation into the reasons for the failure of these classifiers revealed two types of prominent errors which we call conjunctive and disjunctive errors. We developed simple heuristics to address one of these error types and improve the performance of the SVMs. Based on the intuition gained from our experiments, we also developed a simple propositional logic based classifier using hand-labeled features, that addresses both types of errors simultaneously. We show that this new, but simple, approach outperforms all existing state-of-the-art ML models, with statistically significant gains. We hope this work serves as a motivating example of the need to build more expressive classifiers beyond the standard model classes, and to address text classification problems in such non-traditional domains.","2008","2025-02-19 14:42:23","2025-02-19 14:42:23","","438–446","","","","","","","EMNLP '08","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Honolulu, Hawaii","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPQF2VZ8","conferencePaper","2009","Loza Mencía, Eneldo","Segmentation of legal documents","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568245","https://doi.org/10.1145/1568234.1568245","An overwhelming number of legal documents is available in digital form. However, most of the texts are usually only provided in a semi-structured form, i.e. the documents are structured only implicitly using text formatting and alignment. In this form the documents are perfectly understandable by a human, but not by a machine. This is an obstacle towards advanced intelligent legal information retrieval and knowledge systems. The reason for this lack of structured knowledge is that the conversion of texts in conventional form into a structured, machine-readable form, a process called segmentation, is frequently done manually and is therefore very expensive.We introduce a trainable system based on state-of-the-art Information Extraction techniques for the automatic segmentation of legal documents. Our system makes special use of the implicitly given structure in the source digital file as well as of the explicit knowledge about the target structure. Our evaluation on the French IPR Law demonstrates that the system is able to learn an effective segmenter given only a few manually processed training documents. In some cases, even only one seen example is sufficient in order to correctly process the remaining documents.","2009","2025-02-19 14:42:23","2025-02-19 14:42:23","","88–97","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FV845H7F","conferencePaper","2008","Maggenti, Giada; Bracciali, Andrea; Mancarella, Paolo","Abduction and legal reasoning","Proceedings of the 1st International Conference on Forensic Applications and Techniques in Telecommunications, Information, and Multimedia and Workshop","978-963-9799-19-6","","","","In this paper we present LAILA+, an extension of the LAILA coordination language for abductive logic agents, i.e. reasoning agents that collaborate towards the solution of a given problem exploiting a set of distributed, possibly partial, knowledge of the application domain. The extension consists of i) the possibility for agents to communicate with each other hypotheses while devising a coordinated solution, and ii) a relaxed consistency mechanism based on a given agent hierarchy: stronger agent coherence may overcome weaker agent inconsistency. We argue that the framework well adapts to legal reasoning, with agents that try to prove/disprove evidences from different, possibly partial and hierarchical, viewpoints, as often happens for instance in a trial.","2008","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","e-Forensics '08","","","","ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)","Brussels, BEL","","","","","","","","event-place: Adelaide, Australia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2TGTNTV8","conferencePaper","2022","Liu, Qu; Ge, Tingjian","RL2: A Call for Simultaneous Representation Learning and Rule Learning for Graph Streams","Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining","978-1-4503-9385-0","","10.1145/3534678.3539309","https://doi.org/10.1145/3534678.3539309","Heterogeneous graph streams are very common in the applications today. Although representation learning has advantages in prediction accuracy, it is inherently deficient in the abilities to interpret or to reason well. It has long been realized as far back as in 1990 by Marvin Minsky that connectionist networks and symbolic rules should co-exist in a system and overcome the deficiencies of each other. The goal of this paper is to show that it is feasible to simultaneously and efficiently perform representation learning (for connectionist networks) and rule learning spontaneously out of the same online training process for graph streams. We devise such a system called RL^2, and show, both analytically and empirically, that it is highly efficient and responsive for graph streams, and produces good results for both representation learning and rule learning in terms of prediction accuracy and returning top-quality rules for interpretation and building dynamic Bayesian networks.","2022","2025-02-19 14:42:23","2025-02-19 14:42:23","","1109–1119","","","","","","","KDD '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington DC, USA","","","","graph streams; representation learning; rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GF8X26VV","conferencePaper","2010","Sanjeevi, S. G.; Bhattacharyya, P.","Connectionist predicate logic model with parallel execution of rule chains","Proceedings of the International Conference and Workshop on Emerging Trends in Technology","978-1-60558-812-4","","10.1145/1741906.1742060","https://doi.org/10.1145/1741906.1742060","In this paper, we describe a model for reasoning using forward chaining for predicate logic rules and facts with coarse-coded distributed representations for instantiated predicates in a connectionist frame work. Distributed representations are known to give advantages of good generalization, error correction and graceful degradation of performance under noise conditions. The system supports usage of complex rules which involve multiple conjunctions and disjunctions. The system supports parallel and independent execution of predicate logic rule chains in a connectionist environment. The system solves the variable binding problem in a new way using coarse-coded distributed representations of instantiated predicates. Its performance with regard to generalization on unseen inputs and its ability to exhibit fault tolerance under noise conditions is studied and has been found to give good results.","2010","2025-02-19 14:42:23","2025-02-19 14:42:23","","674–677","","","","","","","ICWET '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Mumbai, Maharashtra, India","","","","coarse-coding; connectionist; fault tolerance; parallel rule chains; reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HDFD9A4","conferencePaper","2004","Lau, Gloria T.; Kerrigan, Shawn; Law, Kincho H.; Wiederhold, Gio","An e-government information architecture for regulation analysis and compliance assistance","Proceedings of the 6th International Conference on Electronic Commerce","1-58113-930-6","","10.1145/1052220.1052279","https://doi.org/10.1145/1052220.1052279","The complexity and diversity of government regulations make understanding the regulations a non-trivial task. One of the issues is the existence of multiple sources of regulations and interpretive guides. In this work, we propose an information infrastructure for regulation analysis, which includes a document repository and tools for compliance assistance and similarity analysis. A regulatory repository is developed based on an XML format, and important features, such as concepts and measurements, are extracted using handcrafted rules and a text mining tool. Our framework provides compliance assistance using a reasoning tool based on First Order Predicate Calculus logic, where users are alerted of detected conflicts or otherwise compliance with the regulation. A relatedness analysis is performed by comparing the extracted features as well as structural and referential information from regulations. Examples of an electronic-rulemaking scenario and a compliance checking procedure are shown to demonstrate current capabilities of the prototype system.","2004","2025-02-19 14:42:23","2025-02-19 14:42:23","","461–470","","","","","","","ICEC '04","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Delft, The Netherlands","","","","text mining; legal informatics; similarity analysis; compliance check; e-government; e-rulemaking; shallow parsing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWY6KBV8","conferencePaper","2023","Blass, Joseph; Forbus, Kenneth D.","Analogical Reasoning, Generalization, and Rule Learning for Common Law Reasoning","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595121","https://doi.org/10.1145/3594536.3595121","Research in AI &amp; Law has sought to model common-law case-based reasoning by creating analogies from cases, extracting and applying rules from cases, or both. This paper presents a new approach to extracting legal information from cases and several methods to apply it to new cases, including by analogy and by conversion to logical rules. It evaluates the approaches on a dataset of real-world cases and compares the results to off-the-shelf machine-learning techniques. We conclude that abstract legal information can be extracted from similar cases through analogical generalization, and that the extracted legal schemas can be used to reason about and solve other cases both by analogy and by rules.","2023","2025-02-19 14:42:23","2025-02-19 14:42:23","","32–41","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","Analogy; Legal Schemas; Precedential Reasoning; Rule Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V2GJHUX2","conferencePaper","2013","Masci, Paolo; Ayoub, Anaheed; Curzon, Paul; Harrison, Michael D.; Lee, Insup; Thimbleby, Harold","Verification of interactive software for medical devices: PCA infusion pumps and FDA regulation as an example","Proceedings of the 5th ACM SIGCHI Symposium on Engineering Interactive Computing Systems","978-1-4503-2138-9","","10.1145/2494603.2480302","https://doi.org/10.1145/2494603.2480302","Medical device regulators such as the US Food and Drug Administration (FDA) aim to make sure that medical devices are reasonably safe before entering the market. To expedite the approval process and make it more uniform and rigorous, regulators are considering the development of reference models that encapsulate safety requirements against which software incorporated in to medical devices must be verified. Safety, insofar as it relates to interactive systems and its regulation, is generally a neglected topic, particularly in the context of medical systems. An example is presented here that illustrates how the interactive behaviour of a commercial Patient Controlled Analgesia (PCA) infusion pump can be verified against a reference model. Infusion pumps are medical devices used in healthcare to deliver drugs to patients, and PCA pumps are particular infusion pump devices that are often used to provide pain relief to patients on demand. The reference model encapsulates the Generic PCA safety requirements provided by the FDA, and the verification is performed using a refinement approach. The contribution of this work is that it demonstrates a concise and semantically unambiguous approach to representing what a regulator's requirements for a particular interactive device might be, in this case focusing on user-interface requirements. It provides an inspectable and repeatable process for demonstrating that the requirements are satisfied. It has the potential to replace the considerable documentation produced at the moment by a succinct document that can be subjected to careful and systematic analysis.","2013","2025-02-19 14:42:23","2025-02-19 14:42:23","","81–90","","","","","","","EICS '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: London, United Kingdom","","","","model-based system development; software engineering methods and processes - formal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDTJFQYG","conferencePaper","2009","Ashley, Kevin D.","Ontological requirements for analogical, teleological, and hypothetical legal reasoning","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568236","https://doi.org/10.1145/1568234.1568236","In 1993, Berman and Hafner criticized case-based models of legal reasoning for not modeling analogical and teleological elements. Another lesson learned since then is the role of ontologies in representing domain knowledge so that a legal reasoning system can represent and solve problems. If the reasoning involves drawing abstract analogies, reasoning teleologically about rules for deciding a case, and posing hypothetical cases to test decision rules, however, it is not clear what requirements the ontology should satisfy. This paper presents an extended example of such legal reasoning to illustrate what an ontology for case-based legal reasoning should provide. The example centers on a microworld of legal discourse, an ensemble of real legal cases, hypothetical examples, concepts, factors, principles and policies. Beginning with any case in the microworld, the system's goal is to generate arguments that a law professor and students might reasonably make in discussing the legal case in class. The example illustrates three roles the ontology should play in providing representational support for the system, distills the ontological requirements, and suggests an incremental approach to making good on Berman's and Hafner's challenge.","2009","2025-02-19 14:42:23","2025-02-19 14:42:23","","1–10","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","analogical reasoning; hypothetical reasoning; legal ontologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMFGDCJ3","conferencePaper","2018","Edwards, Autumn; Edwards, Chad; Gambino, Andrew","Preference for Rhetorical Messages from a Social Robot in Regulatory Situations","Proceedings of the Technology, Mind, and Society","978-1-4503-5420-2","","10.1145/3183654.3183687","https://doi.org/10.1145/3183654.3183687","Message design logics (MDLs) are working models of communication that lead to different conceptions of how to rationally construct messages, or reason from goals to messages1. The three MDLs are expressive (transmitting thoughts and feelings), conventional (following socially appropriate rules to coordinate activity), and rhetorical (using language to constitute and negotiate social realities). In dilemmatic tasks, there is an observed preference for rhetorical messages and their sources. This study sought to determine whether the message sophistication preferred among human partners applies to encounters with social robots. In this online experiment (511 U.S. American adults), participants were shown an image of Softbank's Pepper robot. Using a modified Group Leader Scenario, Pepper was described as the leader of a group of college students working on project. Pepper was charged with quality control and recommending grades to the professor. After a group member exhibits behavior that threatens project completion, Pepper must respond to him. Participants were randomly assigned to view Pepper delivering an expressive, conventional, or rhetorical response to the offending member. Analysis of participants' open-ended responses to Pepper's messages demonstrated that preference for and evaluation of Pepper's communication competence differed as a function of MDL. Expressive Pepper was described as affective, unedited, and straightforward. Conventional Pepper was described as rule-bound, situational appropriate, and goal-oriented. Rhetorical Pepper was described as sophisticated, having an in-depth read on the situation, and sensitive to face-wants while pursuing project goals. These results mirror the findings of earlier human communication research.","2018","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","TechMindSociety '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington, DC, USA","","","","Communication; Message Design Logic; Social Robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNG9UXQW","conferencePaper","2017","Laukkarinen, Teemu; Kuusinen, Kati; Mikkonen, Tommi","DevOps in regulated software development: case medical devices","Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track","978-1-5386-2675-7","","10.1109/ICSE-NIER.2017.20","https://doi.org/10.1109/ICSE-NIER.2017.20","DevOps and continuous development are getting popular in the software industry. Adopting these modern approaches in regulatory environments, such as medical device software, is not straightforward because of the demand for regulatory compliance. While DevOps relies on continuous deployment and integration, regulated environments require strict audits and approvals before releases. Therefore, the use of modern development approaches in regulatory environments is rare, as is the research on the topic. However, as software is more and more predominant in medical devices, modern software development approaches become attractive. This paper discusses the fit of DevOps for regulated medical device software development. We examine two related standards, IEC 62304 and IEC 82304-1, for obstacles and benefits of using DevOps for medical device software development. We found these standards to set obstacles for continuous delivery and integration. Respectively, development tools can help fulfilling the requirements of traceability and documentation of these standards.","2017","2025-02-19 14:42:23","2025-02-19 14:42:23","","15–18","","","","","","","ICSE-NIER '17","","","","IEEE Press","","","","","","","","","Place: Buenos Aires, Argentina","","","","DevOps; agile development; medical software development standards; regulated software","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZL6EZMS3","conferencePaper","2004","Lau, Gloria T.; Kerrigan, Shawn; Wang, Haoyi; Law, Kincho H.; Wiederhold, Gio","A software infrastructure for government regulation analysis and compliance assistance","Proceedings of the 2004 Annual National Conference on Digital Government Research","","","","","Government regulations are voluminous, heavily cross-referenced and often ambiguous. To cope with the complexity and diversity of regulations, we developed a formal information infrastructure for regulation management, analysis and compliance assistance. In this system demonstration, several aspects of the project are shown - a regulatory document repository, a regulation assistance system and an e-rulemaking analysis prototype. Together, our system aids in understanding and compliance of government regulations and related documents. In order to develop a prototype system, we focus on accessibility and environmental regulations. The compliance assistance system is illustrated in the domain of used oil management, while the e-rulemaking analysis is performed on accessible public rights-of-way rules.","2004","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","dg.o '04","","","","Digital Government Society of North America","","","","","","","","","Place: Seattle, WA, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KBULEIFJ","conferencePaper","2010","Chikara, Noriaki; Koshimura, Miyuki; Fujita, Hiroshi; Hasegawa, Ryuzo","Rule Extraction from Blog Using Inductive Logic Programming","Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 03","978-0-7695-4191-4","","10.1109/WI-IAT.2010.235","https://doi.org/10.1109/WI-IAT.2010.235","Information recommender system attempts to present information that is likely to be useful for the user. Showing recommendation reason is an important role of the system. However, current recommender systems give only simple or quantitative reasons for the recommendation. In this paper, we aim at giving precise and non-quantitative reasons which are also easy to understand. We make use of formulas in first-order predicate logic for explaining the reason. In order to build such formulas, we use Inductive Logic Programming. We succeeded to extract several useful formulas from blogs.","2010","2025-02-19 14:42:23","2025-02-19 14:42:23","","269–272","","","","","","","WI-IAT '10","","","","IEEE Computer Society","USA","","","","","","","","","","","","blog; Inductive Logic Programming; recommender system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XBPE8XXP","conferencePaper","2005","Law, Kincho H.","ITR/IM+SII: a distributed information management framework (REGNET) for environmental laws and regulations","Proceedings of the 2005 National Conference on Digital Government Research","","","","","The complexity, diversity, and volume of Federal and State regulations (as well as supplementary and supportive documents) are detrimental to businesses and hinder public understanding of government. The objective of REGNET project is to develop information infrastructure and tools for regulatory information management and to facilitate compliance assistance. As a pilot research application, the REGNET project focuses on environmental regulations. The basic research tasks include: (1) textual parsing and storage, (2) semi-structured, indexed storage, (3) means to resolve semantic ambiguities, (4) cross-referencing appropriate for automated retrieval and analysis of relevant documents, and (5) on-line compliance checking of governmental regulations. The experimental scope of this project focuses on Code of Federal Regulations (CFR) Title 40: Protection of the Environment and California Code of Regulations (CCR) Title 22: Social Security. Implementation examples include regulations and selected supplementary documents, covering hazardous waste, drinking water and the management of used oil.","2005","2025-02-19 14:42:23","2025-02-19 14:42:23","","295–296","","","","","","","dg.o '05","","","","Digital Government Society of North America","","","","","","","","","Place: Atlanta, Georgia, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37P7A7AG","conferencePaper","2012","Kontopoulos, Efstratios; Zetta, Thetida; Bassiliades, Nick","Semantically-enhanced authoring of defeasible logic rule bases in the semantic web","Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics","978-1-4503-0915-8","","10.1145/2254129.2254199","https://doi.org/10.1145/2254129.2254199","The Semantic Web represents an initiative to improve the current Web, by augmenting content with semantics and encouraging cooperation among human and software agents. The development of the logic and proof layers of the Semantic Web is currently concentrating the related research effort and is vital, since these layers allow systems to infer new knowledge from existing information, assisting them in explaining their actions and, ultimately, increasing user trust towards the Semantic Web. However, there is a lack of applications that could contribute towards developing logic-based applications. Consequently, users resort to inadequate tools that offer syntactic support, without being able to support the user semantically as well. This work presents S2DRREd, a software tool that introduces a supplementary level of semantic assistance during rule base development. The tool allows creating meta-models of the main notions of the loaded rule sets and assists the user in authoring rule bases, independently of the explicitly chosen rule language syntax. The domain of application is defeasible logic, a type of logic that allows reasoning with incomplete and conflicting information and, as such, it can play an increasingly important role in a drastically dynamic environment like the Web.","2012","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","WIMS '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Craiova, Romania","","","","defeasible logic; non-monotonic reasoning; rule bases; RuleML; semantic web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGEUFKTC","conferencePaper","2001","Prakken, Henry","Modelling reasoning about evidence in legal procedure","Proceedings of the 8th International Conference on Artificial Intelligence and Law","1-58113-368-5","","10.1145/383535.383550","https://doi.org/10.1145/383535.383550","This article investigates the modelling of reasoning about evidence in legal procedure. To this end, a dialogue game model of the relevant parts of Dutch civil procedure is developed with three players: two adversaries and a judge. The model aims to be both legally realistic and technically well-founded. Legally, the main achievement is a more realistic account of the judge's role in legal procedures than that provided by current models. Technically, the model aims to preserve the features of an earlier-developed framework for two-player argumentative dialogue systems.","2001","2025-02-19 14:42:23","2025-02-19 14:42:23","","119–128","","","","","","","ICAIL '01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: St. Louis, Missouri, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W8H36DPK","conferencePaper","2004","Lau, Gloria T.; Kerrigan, Shawn; Wang, Haoyi; Law, Kincho H.; Wiederhold, Gio","An information infrastructure for government regulation analysis and compliance assistance","Proceedings of the 2004 Annual National Conference on Digital Government Research","","","","","The complexity and diversity of government regulations make understanding the regulations a non-trivial task. One of the issues is the existence of multiple sources of regulations and interpretive guides; the latter are often independent of governing bodies. In this work, we describe a research prototype system that combines text mining and knowledge management techniques to help better manage, understand and analyze regulatory documents. This regulatory information infrastructure includes three integral parts: a document repository, a tool for similarity analysis and a compliance assistance system. This paper first presents the development of a legal corpus with multiple sources of regulatory documents consolidated into a unified format. A shallow parser is developed to consolidate different regulations into a unified XML format, which is well suited for handling semi-structured data such as legal documents. Important features, such as concepts, measurements, definitions and so on, are extracted and incorporated into the corpus by using handcrafted rules and text mining tools. A regulation compliance assistance system is introduced next, where First Order Predicate Calculus (FOPC) logic sentences are implemented to help users to perform compliance check in a question and answer session. Finally, a similarity analysis for regulations is developed, where Information Retrieval (IR) and structural matching techniques are used to identify related provisions among regulations.","2004","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","dg.o '04","","","","Digital Government Society of North America","","","","","","","","","Place: Seattle, WA, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQ3XIE68","conferencePaper","2003","Brasil, Samuel Meira; Garcia, Berilhes Borges","Modelling legal reasoning in a mathematical environment through model theoretic semantics","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047833","https://doi.org/10.1145/1047788.1047833","We introduce a mathematical model of legal reasoning using an underlying conditional logic semantics, to allow its tractability in some special cases. The main idea is to capture the entailment of legal consequences through a model of 0-1 programming. For such task, first we model legal reasoning with Lehmann's Lexicographic semantics and then we translate it to an instance of weighted MAXSAT problem, in order to compute the logical consequences of legal reasoning. Hence, combinatorial optimization algorithms can be used to yield the legal consequences of defeasible reasoning over legal conditional knowledge bases.","2003","2025-02-19 14:42:23","2025-02-19 14:42:23","","195–203","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","legal reasoning; artificial intelligence and law; lexicographic semantics; MAX-SAT; nonmonotonic reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y4XU5DBL","conferencePaper","2008","Bosse, Tibor; de Lange, Frank P. J.","Development of Virtual Agents with a Theory of Emotion Regulation","Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 02","978-0-7695-3496-1","","10.1109/WIIAT.2008.65","https://doi.org/10.1109/WIIAT.2008.65","In order to endow virtual agents with more realistic affective behavior, it is important to provide them not only the capability to generate and regulate emotions, but also the ability to reason about the emotion regulation processes of other agents. To this end, this paper introduces a computational model for a Theory of Emotion Regulation (ToER). The model has been implemented and tested using the modeling language LEADSTO. In addition, a virtual environment application has been developed, which is inhabited by agents that are equipped with the model for ToER. A first evaluation indicates that the model indeed enables the agents to show more realistic affective behavior.","2008","2025-02-19 14:42:23","2025-02-19 14:42:23","","461–468","","","","","","","WI-IAT '08","","","","IEEE Computer Society","USA","","","","","","","","","","","","emotion regulation; theory of mind; virtual agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8STS5P5","journalArticle","2024","Zakhour, George; Weisenburger, Pascal; Salvaneschi, Guido","Automated Verification of Fundamental Algebraic Laws","Proc. ACM Program. Lang.","","","10.1145/3656408","https://doi.org/10.1145/3656408","Algebraic laws of functions in mathematics – such as commutativity, associativity, and idempotence – are often used as the basis to derive more sophisticated properties of complex mathematical structures and are heavily used in abstract computational thinking. Algebraic laws of functions in coding, however, are rarely considered. Yet, they are essential. For example, commutativity and associativity are crucial to ensure correctness of a variety of software systems in numerous domains, such as compiler optimization, big data processing, data flow processing, machine learning or distributed algorithms and data structures. Still, most programming languages lack built-in mechanisms to enforce and verify that operations adhere to such properties. In this paper, we propose a verifier specialized on a set of fundamental algebraic laws that ensures that such laws hold in application code. The verifier can conjecture auxiliary properties and can reason about both equalities and inequalities of expressions, which is crucial to prove a given property when other competitors do not succeed. We implement these ideas in the Propel verifier. Our evaluation against five state-of-the-art verifiers on a total of 142 instances of algebraic properties shows that Propel is able to automatically deduce algebraic properties in different domains that rely on such properties for correctness, even in cases where competitors fail to verify the same properties or time out.","2024-06","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","PLDI","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Algebraic Properties; Type Systems; Verification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TUP6FFIG","conferencePaper","2007","Pagallo, Ugo; Ruffo, Giancarlo","P2P systems in legal networks: another","Proceedings of the 11th International Conference on Artificial Intelligence and Law","978-1-59593-680-6","","10.1145/1276318.1276374","https://doi.org/10.1145/1276318.1276374","The ""small world""-paradigm offers a new interesting view-point for the analysis of contemporary legal networks and artificial intelligence. This topological approach sheds further light on such different fields as case-based legal reasoning, knowledge discovery in legal databases, or legal ontologies, as far as clustering coefficients, diameter and hubs of the network are involved. Moreover, empirical evidence shows that even P2P systems as Gnutella present small world-features. So it becomes possible to deepen our understanding of how spontaneous communities organize themselves in the network. While opening new horizons in the field of recommender systems, it also widens our perspective in dealing with such important issues as privacy and digital copyright.","2007","2025-02-19 14:42:23","2025-02-19 14:42:23","","287–288","","","","","","","ICAIL '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Stanford, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VV2NZPLH","journalArticle","2009","North, Matthew M.; North, Max M.; North, Sarah M.","Security from the bottom-up: compliance regulations and the trend toward design-oriented web applications","J. Comput. Sci. Coll.","","1937-4771","","","This paper explores the push toward more ""bottom-up"" design strategies for the creation of web applications, a push which has produced a strengthening of code auditing, training, and education. Part of that push arises from compliance issues, particularly government regulations such as Sarbanes- Oxley and PCI DSS, regulations which require long-term, cost-efficient strategies to maintain. In web application design, this means businesses must place greater emphasis on these bottom-up strategies.","2009-04","2025-02-19 14:42:23","2025-02-19 14:42:23","","54–60","","4","24","","","","","","","","","","","","","","","","","Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KNSRK2C","conferencePaper","2022","Henderson, Peter; Chugg, Ben; Anderson, Brandon; Ho, Daniel E.","Beyond Ads: Sequential Decision-Making Algorithms in Law and Public Policy","Proceedings of the 2022 Symposium on Computer Science and Law","978-1-4503-9234-1","","10.1145/3511265.3550439","https://doi.org/10.1145/3511265.3550439","We explore the promises and challenges of employing sequential decision-making algorithms – such as bandits, reinforcement learning, and active learning – in law and public policy. While such algorithms have well-characterized performance in the private sector (e.g., online advertising), the tendency to naively apply algorithms motivated by one domain, often online advertisements, can be called the ”advertisement fallacy.” Our main thesis is that law and public policy pose distinct methodological challenges that the machine learning community has not yet addressed. Machine learning will need to address these methodological problems to move ”beyond ads.” Public law, for instance, can pose multiple objectives, necessitate batched and delayed feedback, and require systems to learn rational, causal decision-making policies, each of which presents novel questions at the research frontier. We discuss a wide range of potential applications of sequential decision-making algorithms in regulation and governance, including public health, environmental protection, tax administration, occupational safety, and benefits adjudication. We use these examples to highlight research needed to render sequential decision making policy-compliant, adaptable, and effective in the public sector. We also note the potential risks of such deployments and describe how sequential decision systems can also facilitate the discovery of harms. We hope our work inspires more investigation of sequential decision making in law and public policy, which provide unique challenges for machine learning researchers with potential for significant social benefit.","2022","2025-02-19 14:42:23","2025-02-19 14:42:23","","87–100","","","","","","","CSLAW '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington DC, USA","","","","active learning; ai and society; bandits; law and ai; reinforcement learning; sequential decision-making","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCC4YPPP","conferencePaper","2003","van Engers, Tom M.; Boekenoogen, Margherita R.","Improving legal quality: an application report","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047844","https://doi.org/10.1145/1047788.1047844","Problems with legal quality will not only increase effort and costs of the law enforcement organisations, but also undermines the regulating power of the legislator. Unintended use or even abuse of the law may be the result. Governments therefore should improve their legal quality. The complexity of legislation however makes this task a hard one. The Dutch Tax and Customs Administration (DTCA in Dutch: Belastingdienst) has developed a method and supporting tools that support a systematic translation of (new) legislation into the DTCA's processes. This POWER-method and tools help to improve the quality of (new) legislation and codify the knowledge used in the translation processes in which legislation and regulations are transformed into procedures, computer programs and other designs. Thereby the time-to-market of the implementation of legislation will be reduced. In this article we explain some knowledge representation techniques that we use to improve legal quality. We will also show its application and give real-life examples of anomalies detected. In contrast to other knowledge modelling approaches the POWER-approach is focused on modelling legal sources rather than expert knowledge. Expert knowledge however is still needed to find the correct interpretations but also for efficiency reasons. Starting with representing the (legal) experts' knowledge (using scenarios) helps us to find the adequate scope (the legal sources to be analysed). Confronting the expert with differences between the model build out of the experts' knowledge and the ones we make out of the other knowledge sources (specifically the law) causes the legal experts to see things in a different light and has often led to changes in the law.","2003","2025-02-19 14:42:23","2025-02-19 14:42:23","","284–292","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","AI and law; knowledge engineering; knowledge modeling; knowledge representation; legal quality; verification and validation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L9B5QQ8C","conferencePaper","2008","Bosse, Tibor; de Lange, Frank P. J.","Estimating emotion regulation capabilities","Proceedings of the 1st International Conference on PErvasive Technologies Related to Assistive Environments","978-1-60558-067-8","","10.1145/1389586.1389691","https://doi.org/10.1145/1389586.1389691","To improve the performance and wellbeing of humans in complex human-computer interaction settings, ambient (or pervasive) systems need the capability to recognize the emotions of humans, but also the ability to reason about their emotion regulation processes. To this end, this paper introduces a computational model to estimate and reason about emotion regulation. The model has been implemented and tested using the high-level modeling language LEADSTO. A first evaluation indicates that the model is successful in estimating a person's emotion regulation dynamics, and is robust to different parameter settings.","2008","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","PETRA '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Athens, Greece","","","","simulation; emotion regulation; theory of mind; BDI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ZXEW3M8","conferencePaper","2019","Silva, Jefferson; Calegari, Newton; Gomes, Eduardo","After Brazil’s General Data Protection Law: Authorization in Decentralized Web Applications","Companion Proceedings of The 2019 World Wide Web Conference","978-1-4503-6675-5","","10.1145/3308560.3316461","https://doi.org/10.1145/3308560.3316461","Decentralized web applications do not offer fine-grained access controls to users’ data, which potentially creates openings for data breaches. For software companies that need to comply with Brazil’s General Data Protection Law (LGPD), data breaches not only might harm application users but also could expose the companies to hefty fines. In this context, engineering fine-grained authorization controls (that comply with the LGPD) to decentralized web application requires creating audit trails, possibly in the source code. Although the literature offers some solutions, they are scattered. We present Esfinge Guardian, an authorization framework that completely separates authorization from other concerns, which increases compliance with the LGPD. We conclude the work with a brief discussion.","2019","2025-02-19 14:42:23","2025-02-19 14:42:23","","819–822","","","","","","","WWW '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Francisco, USA","","","","Access control; Decentralized Web Applications; Frameworks; Guardian; Solid","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STNYPY4J","journalArticle","2017","Christiansen, Henning; Kirkeby, Maja H.","On proving confluence modulo equivalence for Constraint Handling Rules","Form. Asp. Comput.","","0934-5043","10.1007/s00165-016-0396-9","https://doi.org/10.1007/s00165-016-0396-9","Previous results on proving confluence for Constraint Handling Rules are extended in two ways in order to allow a larger and more realistic class of CHR programs to be considered confluent. Firstly, we introduce the relaxed notion of confluence modulo equivalence into the context of CHR: while confluence for a terminating program means that all alternative derivations for a query lead to the exact same final state, confluence modulo equivalence only requires the final states to be equivalent with respect to an equivalence relation tailored for the given program. Secondly, we allow non-logical built-in predicates such as var/1 and incomplete ones such as is/2, that are ignored in previous work on confluence.To this end, a new operational semantics for CHR is developed which includes such predicates. In addition, this semantics differs from earlier approaches by its simplicity without loss of generality, and it may also be recommended for future studies of CHR.For the purely logical subset of CHR, proofs can be expressed in first-order logic, that we show is not sufficient in the present case. We have introduced a formal meta-language that allows reasoning about abstract states and derivations with meta-level restrictions that reflect the non-logical and incomplete predicates. This language represents subproofs as diagrams, which facilitates a systematic enumeration of proof cases, pointing forward to a mechanical support for such proofs.The Project is supported by The DanishCouncil for IndependentResearch, Natural Sciences, Grant No. DFF4181-00442. The second author’s contribution received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under Grant Agreement No. 318337, ENTRA—Whole-Systems Energy Transparency.","2017-01","2025-02-19 14:42:23","2025-02-19 14:42:23","","57–95","","1","29","","","","","","","","","","","","","","","","","Place: Berlin, Heidelberg Publisher: Springer-Verlag","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VH296BWK","conferencePaper","2011","Gordon, David G.; Breaux, Travis D.","Managing multi-jurisdictional requirements in the cloud: towards a computational legal landscape","Proceedings of the 3rd ACM Workshop on Cloud Computing Security Workshop","978-1-4503-1004-8","","10.1145/2046660.2046678","https://doi.org/10.1145/2046660.2046678","Although cloud services allow organizations to transfer the planning and setup to the service provider and thus reduce costs through reuse, these services raise new questions regarding the privacy and security of personal information stored in and transferred across systems in the cloud. Prior to cloud services, personal information was commonly stored within the owning or licensing company's locality where the company maintained its facilities. Cloud services, however, move data to remote, potentially unknown, locations maintained by third parties. The responsibility for data protection and integrity no longer remains exclusively with its owner or licensee, but with these third parties. Thus, both parties must identify and manage the many regulatory requirements that govern their services and products in this multi-jurisdictional environment. To simplify this problem, we are developing methods to extract and codify regulatory requirements from government laws. We apply previously validated metrics to measure gaps and overlaps between the codified regulations. Our findings include a semi-formalization of the legal landscape using operational constructs for high- and low-watermark practices, which correspond to high- and low standards of care, respectively. Business analysts and system developers can use these watermarks to reason about compliance trade-offs based on perceived businesses costs and risks. We discovered and validated these constructs using seven U.S. state data breach notification laws that govern transactions of financial and health information of residents of these seven states.","2011","2025-02-19 14:42:23","2025-02-19 14:42:23","","83–94","","","","","","","CCSW '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, Illinois, USA","","","","regulation; multi-jurisdictional; requirements specification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYZSFV32","conferencePaper","2023","Xavier Ferreira, Matheus Venturyne; Parkes, David C.","Credible Decentralized Exchange Design via Verifiable Sequencing Rules","Proceedings of the 55th Annual ACM Symposium on Theory of Computing","978-1-4503-9913-5","","10.1145/3564246.3585233","https://doi.org/10.1145/3564246.3585233","Trading on decentralized exchanges has been one of the primary use cases for permissionless blockchains with daily trading volume exceeding billions of U.S. ‍dollars. In the status quo, users broadcast transactions they wish to execute in the exchange and miners are responsible for composing a block of transactions and picking an execution ordering — the order in which transactions execute in the exchange. Due to the lack of a regulatory framework, it is common to observe miners exploiting their privileged position by front-running transactions and obtaining risk-fee profits. Indeed, the Flashbots service institutionalizes this exploit, with miners auctioning the right to front-run transactions. In this work, we propose to modify the interaction between miners and users and initiate the study of verifiable sequencing rules. As in the status quo, miners can determine the content of a block; however, they commit to respecting a sequencing rule that constrains the execution ordering and is verifiable (there is a polynomial time algorithm that can verify if the execution ordering satisfies such constraints). Thus in the event a miner deviates from the sequencing rule, anyone can generate a proof of non-compliance. We ask if there are sequencing rules that limit price manipulation from miners in a two-token liquidity pool exchange. Our first result is an impossibility theorem: for any sequencing rule, there is an instance of user transactions where the miner can obtain non-zero risk-free profits. In light of this impossibility result, our main result is a verifiable sequencing rule that provides execution price guarantees for users. In particular, for any user transaction A, it ensures that either (1) the execution price of A is at least as good as if A was the only transaction in the block, or (2) the execution price of A is worse than this “standalone” price and the miner does not gain when including A in the block. Our framework does not require users to use countermeasures against predatory trading strategies, for example, set limit prices or split large transactions into smaller ones. This is likely to improve user experience relative to the status quo.","2023","2025-02-19 14:42:23","2025-02-19 14:42:23","","723–736","","","","","","","STOC 2023","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Orlando, FL, USA","","","","Decentralized Exchange; Front-running; Market Design; Order Execution; Pricing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HI2XP6K5","conferencePaper","2015","Plachouras, Vassilis; Leidner, Jochen L.","Information Extraction of Regulatory Enforcement Actions: From Anti-Money Laundering Compliance to Countering Terrorism Finance","Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015","978-1-4503-3854-7","","10.1145/2808797.2809368","https://doi.org/10.1145/2808797.2809368","Financial fines imposed by regulatory bodies to penalize illegal activities and violations against regulations (cases of non-compliance) have recently become more common, and the sizes of fines have increased. This development coincides with the ongoing increase of complexity of regulatory rules. Huge fines have been imposed on banks for financial fraud and regulations have been made more stringent after 9/11 to curb funding of terrorist groups. Market players would also like to have available a database of fine events for a range of applications, such as to benchmark their competitors performance, or to use it as an early warning system for detecting shifts in regulators' enforcement behavior. To this end, we introduce the task of extracting fines from regulatory enforcement actions and we present a method to extract such fine event instances from timeline-like descriptions of regulatory investigation activities authored by legal professionals for a commercial product. We evaluate how well a rule-based method can extract information about fine events and we compare its performance to a machine-learning baseline. To the best of our knowledge, this work is the first one addressing this task.","2015","2025-02-19 14:42:23","2025-02-19 14:42:23","","950–953","","","","","","","ASONAM '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Paris, France","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UCEPCQYC","conferencePaper","2009","Luck, Michael","Flexible behaviour regulation in agent based systems","Proceedings of the 6th International Conference on Autonomic Computing","978-1-60558-564-2","","10.1145/1555228.1555265","https://doi.org/10.1145/1555228.1555265","Cooperation is the fundamental underpinning of multi-agent systems, allowing agents to interact to achieve their goals. However, agents must manage the risk associated with interacting with others who have different objectives, or who may fail to fulfill their commitments. There are many ways in which such a desirable social order may be encouraged or even mandated. For example, trust oers a mechanism for modeling and reasoning about reliability, honesty, etc., while organisations and norms provide a framework within which to apply them, and motivations provide a means for representing and reasoning about overall objectives. In this talk, I will consider the role of trust, organisations and norms in a motivation-based view of agency that seeks to regulate behaviour, and will illustrate some of these issues with aspects of several projects, including the CONTRACT project, concerned with contract-based electronic business systems. Finally, I will also seek to identify some key themes entwining these notions of behaviour regulation with autonomic computing.","2009","2025-02-19 14:42:23","2025-02-19 14:42:23","","147–148","","","","","","","ICAC '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","norms; behaviour regulation; multiagent systems; organisations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZC72PDQ7","conferencePaper","2001","Brüninghaus, Stefanie; Ashley, Kevin D.","Improving the representation of legal case texts with information extraction methods","Proceedings of the 8th International Conference on Artificial Intelligence and Law","1-58113-368-5","","10.1145/383535.383540","https://doi.org/10.1145/383535.383540","The prohibitive cost of assigning indices to textual cases is a major obstacle for the practical use of AI and Law systems supporting reasoning and arguing with cases. While progress has been made toward extracting certain facts from well-structured case texts or classifying case abstracts under Key Number concepts, these methods still do not suffice for the complexity of indexing concepts in CBR systems.In this paper, we lay out how a better example representation may facilitate classification-based indexing. Our hypotheses are that (1) abstracting from the individual actors and events in cases, (2) capturing actions in multi-word features, and (3) recognizing negation, can lead to a better representation of legal case texts for automatic indexing. We discuss how to implement these techniques with state-of-the-art NLP tools. Preliminary experimental results suggest that a combination of domain-specific knowledge and information extraction techniques can be used to generalize from the examples and derive more powerful features.","2001","2025-02-19 14:42:23","2025-02-19 14:42:23","","42–51","","","","","","","ICAIL '01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: St. Louis, Missouri, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5QMBP8FE","conferencePaper","2021","Hamdani, Rajaa El; Mustapha, Majd; Amariles, David Restrepo; Troussel, Aurore; Meeùs, Sébastien; Krasnashchok, Katsiaryna","A combined rule-based and machine learning approach for automated GDPR compliance checking","Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law","978-1-4503-8526-8","","10.1145/3462757.3466081","https://doi.org/10.1145/3462757.3466081","The General Data Protection Regulation (GDPR) requires data controllers to implement end-to-end compliance. Controllers must therefore ensure that the terms agreed with the data subject and their own obligations under GDPR are respected in the data flows from data subject to controllers, processors and sub processors (i.e. data supply chain). This paper seeks to contribute to bridge both ends of compliance checking through a two-pronged study. First, we conceptualize a framework to implement a document-centric approach to compliance checking in the data supply chain. Second, we develop specific methods to automate compliance checking of privacy policies. We test a two-modules system, where the first module relies on NLP to extract data practices from privacy policies. The second module encodes GDPR rules to check the presence of mandatory information. The results show that the text-to-text approach outperforms local classifiers and enables the extraction of both coarse-grained and fine-grained information with only one model. We implement full evaluation of our system on a dataset of 30 privacy policies annotated by legal experts. We conclude that this approach could be generalized to other documents in the data supply as a means to improve end-to-end compliance.","2021","2025-02-19 14:42:23","2025-02-19 14:42:23","","40–49","","","","","","","ICAIL '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: São Paulo, Brazil","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Y8VFUD8","conferencePaper","2020","Brosens, Lore","Self-regulating Soft Skills in Group Project-Based Design Education","Companion Proceedings of the 2020 ACM International Conference on Supporting Group Work","978-1-4503-6767-7","","10.1145/3323994.3371013","https://doi.org/10.1145/3323994.3371013","Design education finds itself at a crossroad, having to deal with an emerging industry 4.0 and global issues such as, sustainability. The engineering design curriculum needs to arm students with 21st century soft skills to be able to cope with an ever-evolving world. One of the most important soft skills is self-regulation, so that students can adapt to changing situations; know what skills they are lacking; and function efficiently in a multidisciplinary team. This application includes an introduction to self-regulation in design education. Additionally, it includes the setup and findings of a first pilot study the Ph.D. researcher conducted. The study used an online platform to assess students' involvement in a team and the group dynamics within the team. Afterwards the results were communicated and students were asked to reflect and propose solutions for group related challenges. Lastly, this application includes an overview of the reasons why the Ph.D. researcher would like to participate in the doctoral colloquium.","2020","2025-02-19 14:42:23","2025-02-19 14:42:23","","1–5","","","","","","","GROUP '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sanibel Island, Florida, USA","","","","self-regulation; cscl; cscw; engineering design education; group dynamics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBEMEJXB","conferencePaper","2018","Elder, Sarah; Mattapallil, Anna; Williams, Laurie","A comparative analysis of manual methods for analyzing security requirements in regulatory documents: POSTER","Proceedings of the 5th Annual Symposium and Bootcamp on Hot Topics in the Science of Security","978-1-4503-6455-3","","10.1145/3190619.3191684","https://doi.org/10.1145/3190619.3191684","Developing security requirements that are compliant with security regulations is key for developing secure software systems. Statements within regulatory documents are frequently overlapping, both within and between documents. Approaches to identifying and address this overlap have been developed in academia and industry. However, these approaches have largely been evaluated in isolation. The goal of this research is to assist analysts in selecting an appropriate approach for developing security requirements from regulatory documents by comparing the output of approaches from academic publications with similar outputs from industry. Our initial results show that there is wide variance in how information is aggregated from security regulations at the requirement level.","2018","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","HoTSoS '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Raleigh, North Carolina","","","","regulatory documents; security requirements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZN6FQWG6","conferencePaper","2022","Hsu, Shu-Yi; Tutwiler, M. Shane","How Much and for Whom? A Multi-Wave Study of the Impact of Self-Regulated Learning Scaffolds on MOOC Student Academic Performance","Proceedings of the Ninth ACM Conference on Learning @ Scale","978-1-4503-9158-0","","10.1145/3491140.3528312","https://doi.org/10.1145/3491140.3528312","With an effort to ameliorate the high dropout rates and the low performance in the massive open online courses (MOOCs), this paper presents multi-wave, experimental studies with a longitudinal intervention of self-regulated learning scaffolds on 24 MOOCs for 2650 learners. The self-regulated learning user interface (SRLUI) is designed based on Zimmerman's SRL cyclical model with a learning dashboard, interactive user interface, nudging effect. SRLUI is designed with two goals: 1. manifesting learner self-regulated learning behavior 2. enhancing learning outcomes. In this study, our primary research question is, ""What is the marginal effect of SRLUI on learning as evidenced by final course grade?"" To answer the research question, we employed a multilevel Bayesian beta regression modeling approach, first to each intervention and then across all three interventions in the aggregate. Our findings were mixed. We found some evidence of enhanced learning for passing and non-passing students across some of the individual interventions. On the whole, we determined that there was no statistical evidence of positive impacts on learning for students who pass a given course, though there is evidence of a small positive impact on learning for students who did not ultimately pass a given course. We discuss potential reasons for this differential impact and its implication for future course design and research.","2022","2025-02-19 14:42:23","2025-02-19 14:42:23","","350–354","","","","","","","L@S '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: New York City, NY, USA","","","","learning analytics; self-regulated learning; bayesian regression; moocs; multilevel modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2PJAA57N","conferencePaper","2019","Majdoubi, Driss El; Bakkali, Hanan El","A survey of major data privacy laws, languages and approaches in smart cities environments","Proceedings of the 4th International Conference on Smart City Applications","978-1-4503-6289-4","","10.1145/3368756.3369013","https://doi.org/10.1145/3368756.3369013","Nowadays, the adoption of smart cities worldwide is accelerating the digital transformation of urban environments. Besides, a huge amount of data is being exchanged through the smart devices, networks, cloud infrastructure, big data analysis and Internet of Things (IoT) applications both in private and public sector. This exchange of data aims to provide better services and to ensure a good quality of life for citizens. However, the use of smart applications raises several concerns regarding the violation of data privacy. Various privacy-preserving approaches have been proposed in the literature treating specific aspects of privacy in smart cities environments. Hence, comprehensive mechanisms are needed towards protecting data privacy including privacy preferences of citizens, organizations privacy policies, and privacy laws and regulations. In this paper, we provide a review of recent work dealing with privacy in smart cities. Furthermore, we make a comparison between some of the most known privacy laws and regulations. The aim is to show the importance of legal compliance in the privacy preserving process. In addition, a case study is presented to show these laws can be considered by the different stakeholders.","2019","2025-02-19 14:42:23","2025-02-19 14:42:23","","","","","","","","","SCA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Casablanca, Morocco","","","","privacy policy; smart cities; privacy law; privacy preferences; privacy preserving approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YUZE4A5E","conferencePaper","2015","Cawley, Oisín; Richardson, Ita; Wang, Xiaofeng; Kuhrmann, Marco","A conceptual framework for lean regulated software development","Proceedings of the 2015 International Conference on Software and System Process","978-1-4503-3346-7","","10.1145/2785592.2794401","https://doi.org/10.1145/2785592.2794401","A growing number of companies are discovering that their software development processes must be in compliance with some form of regulation. This is particularly so when it comes to safety-critical or business-critical systems such as Automotive Software, Robotics, Medical Devices or Finan- cial Management systems. These regulations aect the soft- ware development process itself in various forms. Further- more, much attention is being given to ways of improving the eciency of businesses, for example, by adopting lean principles. This raises the question for how to adopt lean principles for software development within a regulated envi- ronment? This poster presents the results of our empirical research into lean and regulated software development. Built from a combination of data sources, we have developed a conceptual framework comprising ve primary components. In addition the relationships they have with both the central focus of the framework (the situated software development practices) and with each other are indicated.","2015","2025-02-19 14:42:23","2025-02-19 14:42:23","","167–168","","","","","","","ICSSP '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tallinn, Estonia","","","","software development; regulations; agile; conceptual framework; lean; software Engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQL23ZW8","conferencePaper","2022","Kantarcioglu, Murat; Carminati, Barbara; Samtani, Sagar; Mittal, Sudip; Gupta, Maanak","Enforcement of Laws and Privacy Preferences in Modern Computing Systems","Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy","978-1-4503-9220-4","","10.1145/3508398.3519315","https://doi.org/10.1145/3508398.3519315","Modern civilization is highly dependent on computing systems, touching all aspects of business, government, and individual life. At the same time, there has been an increase in laws and privacy preferences whose implementation and effectiveness depend on software. Whereas organizations and individuals have been expected to comply with laws and regulations, now computing systems must also be compliant and accountable. Computing systems need to be designed with privacy preferences and legal statutes in mind, and should be adaptable to change.","2022","2025-02-19 14:42:23","2025-02-19 14:42:23","","338–339","","","","","","","CODASPY '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Baltimore, MD, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6HUKIMKD","conferencePaper","2017","Fenton, Norman; Lagnado, David; Dahlman, Christian; Neil, Martin","The opportunity prior: a simple and practical solution to the prior probability problem for legal cases","Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law","978-1-4503-4891-1","","10.1145/3086512.3086519","https://doi.org/10.1145/3086512.3086519","One of the greatest impediments to the use of probabilistic reasoning in legal arguments is the difficulty in agreeing on an appropriate prior probability for the ultimate hypothesis, (in criminal cases this is normally ""Defendant is guilty of the crime for which he/she is accused""). Even strong supporters of a Bayesian approach prefer to ignore priors and focus instead on considering only the likelihood ratio (LR) of the evidence. But the LR still requires the decision maker (be it a judge or juror during trial, or anybody helping to determine beforehand whether a case should proceed to trial) to consider their own prior; without it the LR has limited value. We show that, in a large class of cases, it is possible to arrive at a realistic prior that is also as consistent as possible with the legal notion of 'innocent until proven guilty'. The approach can be considered as a formalisation of the 'island problem' whereby if it is known the crime took place on an island when n people were present, then each of the people on the island has an equal prior probability 1/n of having carried out the crime. Our prior is based on simple location and time parameters that determine both a) the crime scene/time (within which it is certain the crime took place) and b) the extended crime scene/time which is the 'smallest' within which it is certain the suspect was known to have been 'closest' in location/time to the crime scene. The method applies to cases where we assume a crime has taken place and that it was committed by one person against one other person (e.g. murder, assault, robbery). The paper considers both the practical and legal implications of the approach. We demonstrate how the opportunity prior probability is naturally incorporated into a generic Bayesian network model that allows us to integrate other evidence about the case.","2017","2025-02-19 14:42:23","2025-02-19 14:42:23","","69–76","","","","","","","ICAIL '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: London, United Kingdom","","","","bayesian networks; crime scene and time; island problem; opportunity prior probability; prior probability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDL49K8N","conferencePaper","2010","Hammouda, Imed; Mikkonen, Tommi; Oksanen, Ville; Jaaksi, Ari","Open source legality patterns: architectural design decisions motivated by legal concerns","Proceedings of the 14th International Academic MindTrek Conference: Envisioning Future Media Environments","978-1-4503-0011-7","","10.1145/1930488.1930533","https://doi.org/10.1145/1930488.1930533","Complications emerge when various open source software components, governed by different licenses, are used in the same software system. For various reasons, these licenses introduce different privileges and requirements on the use and distribution of composed code, and are therefore often fundamentally incompatible with each other when combined arbitrarily. Consequently the way the different components can be integrated requires attention at the level of software architecture. In this paper, we introduce open source legality patterns – architectural design decisions motivated by legal concerns associated with open source licensing issues and licenses themselves. Towards the end of the paper, we also review some related work and discuss why it is important to create common guidelines for designs that mix and match different open source systems and proprietary software, and provide directions for future work.","2010","2025-02-19 14:42:24","2025-02-19 14:42:24","","207–214","","","","","","","MindTrek '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tampere, Finland","","","","design patterns; legal concerns; open source licensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4RXJFRGK","conferencePaper","1999","Kerner, Yaakov HaCohen; Schild, Uri; Zeleznikow, John","Developing computational models of discretion to build legal knowledge based systems","Proceedings of the 7th International Conference on Artificial Intelligence and Law","1-58113-165-8","","10.1145/323706.323799","https://doi.org/10.1145/323706.323799","Few legal knowledge based systems have been constructed which provide numerical advice. None have been built in discretionary domains. Our research, directed towards the domains of sentencing and family law property division has lead to the development of three distinct forms of judicial discretion.To model these different discretionary domains we use diverse artificial intelligence tools including case-based reasoning and knowledge discovery from databases. We carry out a detailed comparison of two discretionary legal knowledge based systems. Judge's Apprentice is a case-based reasoner which recommends ranges of sentences for convicted Israeli rapists and robbers. SplitUp uses Knowledge Discovery from Databases to learn what percentage of marital property the partners to a divorce in Australia will receive. The systems are compared with regard to reasoning, explanation, evaluation and coping with conflicting cases.","1999","2025-02-19 14:42:24","2025-02-19 14:42:24","","206–213","","","","","","","ICAIL '99","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Oslo, Norway","","","","classifying discretionary domains; dicretion; evaluation; explanation; learning from cases","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4JIKNGT","conferencePaper","2011","Ingolfo, Silvia; Siena, Alberto; Mylopoulos, John","Establishing regulatory compliance for software requirements","Proceedings of the 30th International Conference on Conceptual Modeling","978-3-642-24605-0","","","","A software system complies with a regulation if its operation is consistent with the regulation under all circumstances. The importance of regulatory compliance for software systems has been growing, as regulations are increasingly impacting both the functional and nonfunctional requirements of legacy and new systems. HIPAA and SOX are recent examples of laws with broad impact on software systems, as attested by the billions of dollars spent in the US alone on compliance. In this paper we propose a framework for establishing regulatory compliance for a given set of software requirements. The framework assumes as inputs models of the requirements (expressed in i*) and the regulations (expressed in Nòmos). In addition, we adopt and integrate with i* and Nòmos a modeling technique for capturing arguments and establishing their acceptability. Given these, the framework proposes a systematic process for revising the requirements, and arguing through a discussion among stakeholders that the revisions make the requirements compliant. Our proposed framework is illustrated through a case study involving fragments of the HIPAA regulation.","2011","2025-02-19 14:42:24","2025-02-19 14:42:24","","47–61","","","","","","","ER'11","","","","Springer-Verlag","Berlin, Heidelberg","","","","","","","","event-place: Brussels, Belgium","","","","regulatory compliance; argumentation; requirement engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YD74RLUH","conferencePaper","2024","Roscam Abbing, Roel; Light, Ann","Make Friends Not Art: Mapping Law, Power and Participation in Designing an Online Platform during documenta fifteen","Proceedings of the Participatory Design Conference 2024: Full Papers - Volume 1","979-8-4007-0808-4","","10.1145/3666094.3666107","https://doi.org/10.1145/3666094.3666107","This paper follows the development of a participatory platform as part of an arts exhibition involving 53 arts collectives, predominantly from the Global South. While the platform was global in scope and designed with worldwide participation from intended users, this participation was impacted in significant ways by the local European laws that the exhibition makers had to abide by. We describe how the socio-legal elements constrained participation and the development of the platform’s features. We reflect on the impact of different actors, the power imbalances involved in the design project and the disappointing outcome - a platform with no obvious users. In doing so, we visit key moments in its production and explore the context for what it can teach us about managing the broader impacts of globalised legal norms on cultural producers and radical arts practice. We use actor-networks to show the play of colonialism and capitalism.","2024","2025-02-19 14:42:24","2025-02-19 14:42:24","","86–97","","","","","","","PDC '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sibu, Malaysia","","","","legal frameworks; participatory design; capitalist; colonial; Free and Open Source Software; institutional constraints; lumbung; socio-legal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZ6GHXDC","conferencePaper","2011","Sapkota, Krishna; Aldea, Arantza; Duce, David A.; Younas, Muhammad; Bañares-Alcántara, René","Towards semantic methodologies for automatic regulatory compliance support","Proceedings of the 4th Workshop on Workshop for Ph.D. Students in Information &amp; Knowledge Management","978-1-4503-0953-0","","10.1145/2065003.2065021","https://doi.org/10.1145/2065003.2065021","Businesses and organizations must comply with requirements and expectations such as regulations, policies, mandates and guidelines to meet public standards and avoid hefty penalties. Checking compliance manually is a laborious, extensive and error-prone process. The problems in the process are, to some extent, alleviated by using computerized compliance management systems. However, these systems are experiencing challenges in coping with the frequent changes and updates in the regulations. This paper describes our research on the use of semantic web technologies to support compliance management. In particular, we propose a methodology, RegCMatic that supports the management of the compliance system. Its originality lies on automating the extraction of regulatory information from regulatory texts, and mapping regulations to organizational internal processes. Our proposed methodology is applied to the Pharmaceutical industry, where regulatory information is extracted from the Eudralex EU regulation and modeled using a semantic formalism.","2011","2025-02-19 14:42:24","2025-02-19 14:42:24","","83–86","","","","","","","PIKM '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland, UK","","","","regulatory compliance; ontology; reasoning; compliance management; information extraction; natural language processing; semantic annotation; text analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJVWDMNT","conferencePaper","2024","Fenske, Ellis; Brown, Christopher W.; Kosseff, Jeff","Courting Consensus: How Class Action Lawsuits Shape Data Privacy Rights and Obligations in the US","Proceedings of the 23rd Workshop on Privacy in the Electronic Society","979-8-4007-1239-5","","10.1145/3689943.3695044","https://doi.org/10.1145/3689943.3695044","The United States does not have a unified legal or regulatory framework governing data security. In the absence of clear regulations, lawsuits are a primary method by which companies that store user data face consequences for poor security practices. However, these lawsuits must proceed through a layered system of courts comprised of hundreds of individual judges with individual ideas regarding privacy and security, resulting in a complex patchwork of legal reasoning about data breaches which is not well understood. We assess the reasoning, arguments, and standards employed by US federal courts in data breach litigation from 2022-2023. We focus on how courts understand harm, attribution, the value and meaning of private data, and the obligations of data holders in the context of federal class action data breach litigation in the US, and finally identify where consensus has emerged and where it has yet to.","2024","2025-02-19 14:42:24","2025-02-19 14:42:24","","172–185","","","","","","","WPES '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salt Lake City, UT, USA","","","","privacy; data breach; litigation; united states law","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQC2EQCX","conferencePaper","2022","Cooper, A. Feder; Frankle, Jonathan; De Sa, Christopher","Non-Determinism and the Lawlessness of Machine Learning Code","Proceedings of the 2022 Symposium on Computer Science and Law","978-1-4503-9234-1","","10.1145/3511265.3550446","https://doi.org/10.1145/3511265.3550446","Legal literature on machine learning (ML) tends to focus on harms, and thus tends to reason about individual model outcomes and summary error rates. This focus has masked important aspects of ML that are rooted in its reliance on randomness — namely, stochasticity and non-determinism. While some recent work has begun to reason about the relationship between stochasticity and arbitrariness in legal contexts, the role of non-determinism more broadly remains unexamined. In this paper, we clarify the overlap and differences between these two concepts, and show that the effects of non-determinism, and consequently its implications for the law, become clearer from the perspective of reasoning about ML outputs as distributions over possible outcomes. This distributional viewpoint accounts for randomness by emphasizing the possible outcomes of ML. Importantly, this type of reasoning is not exclusive with current legal reasoning; it complements (and in fact can strengthen) analyses concerning individual, concrete outcomes for specific automated decisions. By illuminating the important role of non-determinism, we demonstrate that ML code falls outside of the cyberlaw frame of treating ""code as law,” as this frame assumes that code is deterministic. We conclude with a brief discussion of what work ML can do to constrain the potentially harm-inducing effects of non-determinism, and we indicate where the law must do work to bridge the gap between its current individual-outcome focus and the distributional approach that we recommend.","2022","2025-02-19 14:42:24","2025-02-19 14:42:24","","1–8","","","","","","","CSLAW '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington DC, USA","","","","machine learning; arbitrariness; non-determinism; stochasticity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BAPQ5G8L","journalArticle","2011","Gandhi, R. A.; Lee, S. W.","Discovering Multidimensional Correlations among Regulatory Requirements to Understand Risk","ACM Trans. Softw. Eng. Methodol.","","1049-331X","10.1145/2000799.2000802","https://doi.org/10.1145/2000799.2000802","Security breaches most often occur due to a cascading effect of failure among security constraints that collectively contribute to overall secure system behavior in a socio-technical environment. Therefore, during security certification activities, analysts must systematically take into account the nexus of causal chains that exist among security constraints imposed by regulatory requirements. Numerous regulatory requirements specified in natural language documents or listed in spreadsheets/databases do not facilitate such analysis. The work presented in this article outlines a stepwise methodology to discover and understand the multidimensional correlations among regulatory requirements for the purpose of understanding the potential for risk due to noncompliance during system operation. Our lattice algebraic computational model helps estimate the collective adequacy of diverse security constraints imposed by regulatory requirements and their interdependencies with each other in a bounded scenario of investigation. Abstractions and visual metaphors combine human intuition with metrics available from the methodology to improve the understanding of risk based on the level of compliance with regulatory requirements. In addition, a problem domain ontology that classifies and categorizes regulatory requirements from multiple dimensions of a socio-technical environment promotes a common understanding among stakeholders during certification and accreditation activities. A preliminary empirical investigation of our theoretical propositions has been conducted in the domain of The United States Department of Defense Information Technology Security Certification and Accreditation Process (DITSCAP). This work contributes a novel approach to understand the level of compliance with regulatory requirements in terms of the potential for risk during system operation.","2011-09","2025-02-19 14:42:24","2025-02-19 14:42:24","","","","4","20","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","risk; knowledge engineering; certification and accreditation; ontology-based domain modeling; requirements visualization; Software requirements engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTB93V59","conferencePaper","2003","Kimbrough, Steven O.; Lee, Thomas Y.; Padmanabhan, Balaji; Yang, Yinghui","On original generation of structure in legal documents","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047826","https://doi.org/10.1145/1047788.1047826","This position paper advocates a vision in the development of automated legal reasoning and presents evidence supporting the plausibility of that vision. The paper observes that original creation of documents of legal import in either fully formal or semistructured form offers the prospect of greatly reducing the cost and expanding the scope of knowledge engineering for legal reasoning. This, it is claimed, is most likely to be achieved via formalization of various sublanguages of legal discourse. SeaSpeak is an example of such a sublanguage and it appears to be amenable to full formalization. Short of that, much can be done with partial formalization and semistructured documents. The paper presents a tabular format for message expression, motivated by a formal agent communication language.","2003","2025-02-19 14:42:24","2025-02-19 14:42:24","","152–161","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2S9HDMS","conferencePaper","2010","Siena, Alberto; Armellin, Giampaolo; Mameli, Gianluca; Mylopoulos, John; Perini, Anna; Susi, Angelo","Establishing regulatory compliance for information system requirements: an experience report from the health care domain","Proceedings of the 29th International Conference on Conceptual Modeling","3-642-16372-6","","","","Adherence to laws and regulations imposes important constraints on organizations, for legacy and new systems, both for their design and operation. Nòmos is a framework that supports the development of compliant software systems. In this paper, we report on the application of Nòmos in an industrial project, to provide model-based evidence that a set of requirements for a healthcare information system are compliant with a specific law. Compliance is treated as a collection of assigned responsibilities to social and system actors. The design of compliance pays special attention to auditability, i.e., making sure that design-time compliance is actually being adhered to.","2010","2025-02-19 14:42:24","2025-02-19 14:42:24","","90–103","","","","","","","ER'10","","","","Springer-Verlag","Berlin, Heidelberg","","","","","","","","event-place: Vancouver, BC, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVF8TKB7","conferencePaper","2016","Kim, Wooju; Lee, Youna; Kim, Donghe; Won, Minjae; Jung, HaeMin","Ontology-based model of law retrieval system for R&amp;D projects","Proceedings of the 18th Annual International Conference on Electronic Commerce: E-Commerce in Smart Connected World","978-1-4503-4222-3","","10.1145/2971603.2971629","https://doi.org/10.1145/2971603.2971629","Research and development projects have close relationship with laws. In some cases, new technologies resulted from R&amp;D projects can't be used because some statutes restrict them. The reason of this problem is that researchers don't know exactly which laws can affect their R&amp;D projects. To solve the issue, we suggest a model for law retrieval system that can be used by researchers of R&amp;D projects to find related statutes. Input of this model is a query document that describes the main contents of a project. By using ontology, legal terms are extracted from the document and statutes defining them are retrieved as a set of related laws. After this searching process, statutes are provided to researchers with their ranks, which are assigned using relevance scores we developed. By using this model, we can make a system for researchers to search a list of statutes that may affect R&amp;D projects, and finally, they can adjust their project's direction by checking the list, preventing their works from being useless.","2016","2025-02-19 14:42:24","2025-02-19 14:42:24","","","","","","","","","ICEC '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Suwon, Republic of Korea","","","","ontology; D; law retrieval system; R&amp","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3QFLK343","conferencePaper","2012","El Kharbili, Marwane","Business process regulatory compliance management solution frameworks: a comparative evaluation","Proceedings of the Eighth Asia-Pacific Conference on Conceptual Modelling - Volume 130","978-1-921770-11-1","","","","Regulatory compliance management (RCM) is a problem gaining wide interest in the business process management (BPM) community. However, research has not yet provided a non-ambiguous and agreed-upon definition of RCM, and it is hard for newcomers to this field of research to get a clear overview of available results. This paper surveys and analyzes solutions proposed in research on RCM from the perspective of BPM, and gives an insight into the current strengths and limitations of solutions to RCM applied to BPM. We extract a set of evaluation criteria on RCM elicited from the surveyed works and proceed to a comparative analysis of the latter against the identified requirements.","2012","2025-02-19 14:42:24","2025-02-19 14:42:24","","23–32","","","","","","","APCCM '12","","","","Australian Computer Society, Inc.","AUS","","","","","","","","event-place: Melbourne, Australia","","","","regulatory compliance; business process management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFTRSKXM","conferencePaper","2005","Brüninghaus, Stefanie; Ashley, Kevin D.","Generating legal arguments and predictions from case texts","Proceedings of the 10th International Conference on Artificial Intelligence and Law","1-59593-081-7","","10.1145/1165485.1165497","https://doi.org/10.1145/1165485.1165497","In this paper, we present methods for automatically finding abstract, legally relevant concepts in case texts and demonstrate how they can be used to make predictions of case outcomes, given the texts as inputs.In a set of experiments to test these methods, we focus on the open question of how best to represent legal text for finding abstract concepts. We compare different ways of representing legal case texts in order to test whether adding domain knowledge and some linguistic information can improve performance.We found that replacing individual names by roles in the case texts led to better indexing, and that adding certain syntactic and semantic information, in the form of Propositional Patterns that capture a sense of ""who did what"", led to better prediction. Our experiments also showed that of three learning algorithms, Nearest Neighbor worked best in learning how to identify indexing concepts in texts.In these experiments, we introduced a prototype system that can reason with text cases; it analyzes a case, predicts its outcome considering other cases in the database, and explains the prediction, all starting with a textual description of the case's facts as input.","2005","2025-02-19 14:42:24","2025-02-19 14:42:24","","65–74","","","","","","","ICAIL '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bologna, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPWPRRGV","conferencePaper","2009","Walker, Vern R.","Plausibility schemas: templates for legal factfinding","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568260","https://doi.org/10.1145/1568234.1568260","This paper describes a default-logic framework (plausibility schemas) and software tools (Decision Apprentice™ and Legal Apprentice™) for modeling, guiding and automating the reasoning from evidence in a legal record to a finding of fact.","2009","2025-02-19 14:42:24","2025-02-19 14:42:24","","214–215","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","default logic; evidence assessment; non-monotonic logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZX3PL46L","conferencePaper","2001","Guedj, Richard A.","Law and regulation to include elderly in innovations stream","Proceedings of the 2001 EC/NSF Workshop on Universal Accessibility of Ubiquitous Computing: Providing for the Elderly","1-58113-424-X","","10.1145/564526.564555","https://doi.org/10.1145/564526.564555","In this paper we explore the issue of a systematic and seamless way to link future innovations in Information Technology and segments of the population that might -for different reasons of deficiencies - be left aside from advanced services coming with those innovations.The approach is to try to transpose and extend the current concepts of universal access and of universal service mission from the context of Telecommunications to the context of ubiquitous computing and the elderly. This approach owes much for the data and historical perspective to an essay by Robert M. Frieden (2000), [1] on universal service in telecommunications (in the USA).In this position paper, the notions of Technological Change and Technological Convergence are presented and their main characteristics described..The concepts of universal access and universal service mission are viewed in the historical context of the world of telecommunications.Several implications are drawn; in particular why the universal service in telecommunications is bound to evolve and new answers to shape legislative and regulatory policies must be found.The Telecommunications Act of 1996 - which reflects the present legislative situation (in the USA) - is briefly sketched with its implications on universal access to telecommunications services.A proposal of legislative action on two levels -immediate and long term- is made.In conclusion, taking the example of the Patent Act, a general spirit of balance of incentives and obligations is recommended for action on legislation towards ensuring enhanced services for segments of population with some deficiencies.","2001","2025-02-19 14:42:24","2025-02-19 14:42:24","","111–114","","","","","","","WUAUC'01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Alcácer do Sal, Portugal","","","","regulation; law; elderly people; enhanced services; incentives and obligations; intellectual property rights; patent law; principles (to base universal service); technological innovations; ubiquitous computing; universal access; universal service","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XSGJ2QG4","conferencePaper","2013","Fitzgerald, Brian; Stol, Klaas-Jan; O'Sullivan, Ryan; O'Brien, Donal","Scaling agile methods to regulated environments: an industry case study","Proceedings of the 2013 International Conference on Software Engineering","978-1-4673-3076-3","","","","Agile development methods are growing in popularity with a recent survey reporting that more than 80% of organizations now following an agile approach. Agile methods were seen initially as best suited to small, co-located teams developing non-critical systems. The first two constraining characteristics (small and co-located teams) have been addressed as research has emerged describing successful agile adoption involving large teams and distributed contexts. However, the applicability of agile methods for developing safety-critical systems in regulated environments has not yet been demonstrated unequivocally, and very little rigorous research exists in this area. Some of the essential characteristics of agile approaches appear to be incompatible with the constraints imposed by regulated environments. In this study we identify these tension points and illustrate through a detailed case study how an agile approach was implemented successfully in a regulated environment. Among the interesting concepts to emerge from the research are the notions of continuous compliance and living traceability.","2013","2025-02-19 14:42:24","2025-02-19 14:42:24","","863–872","","","","","","","ICSE '13","","","","IEEE Press","","","","","","","","","Place: San Francisco, CA, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LFYFXLU5","conferencePaper","2005","Urban, Christian; Norrish, Michael","A formal treatment of the barendregt variable convention in rule inductions","Proceedings of the 3rd ACM SIGPLAN Workshop on Mechanized Reasoning about Languages with Variable Binding","1-59593-072-8","","10.1145/1088454.1088458","https://doi.org/10.1145/1088454.1088458","Barendregt's variable convention simplifies many informal proofs in the λ-calculus by allowing the consideration of only those bound variables that have been suitably chosen. Barendregt does not give a formal justification for the variable convention, which makes it hard to formalise such informal proofs. In this paper we show how a form of the variable convention can be built into the reasoning principles for rule inductions. We give two examples explaining our technique.","2005","2025-02-19 14:42:24","2025-02-19 14:42:24","","25–32","","","","","","","MERLIN '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tallinn, Estonia","","","","nominal logic; POPLmark challenge; λ-calculus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BNKXJSBW","conferencePaper","2001","Hage, J. C.","Formalizing legal coherence","Proceedings of the 8th International Conference on Artificial Intelligence and Law","1-58113-368-5","","10.1145/383535.383538","https://doi.org/10.1145/383535.383538","This paper briefly argues for a (particular variant of) a coherence theory of legal justification and theory construction. It does so by placing coherentism in a tradition of general epistemology and practical reasoning. One part of the theory, namely the part that deals with the relation between abstract goals and concrete regulations, is described in detail, and formalized.","2001","2025-02-19 14:42:24","2025-02-19 14:42:24","","22–31","","","","","","","ICAIL '01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: St. Louis, Missouri, USA","","","","coherence; goal-based reasoning; legal justification; theory construction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GWLAUYWM","conferencePaper","2023","Fratrič, Peter; Parizi, Mostafa Mohajeri; Sileno, Giovanni; van Engers, Tom; Klous, Sander","Do agents dream of abiding by the rules? Learning norms via behavioral exploration and sparse human supervision","Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law","979-8-4007-0197-9","","10.1145/3594536.3595153","https://doi.org/10.1145/3594536.3595153","In recent years, several normative systems have been presented in the literature. Relying on formal methods, these systems support the encoding of legal rules into machine-readable formats, enabling, e.g. to check whether a certain workflow satisfies or agents abide by these rules. However, not all rules can be easily expressed (see for instance the unclear boundaries between tax planning and tax avoidance). The paper introduces a framework for norm identification and norm induction that automates the formalization of norms about non-compliant behavior by exploring the behavioral space via simulation, and integrating inputs from humans via active learning. The proposed problem formulation sets also a bridge between AI &amp; law and more general branches of AI concerned by the adaptation of artificial agents to human directives.","2023","2025-02-19 14:42:24","2025-02-19 14:42:24","","81–90","","","","","","","ICAIL '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Braga, Portugal","","","","Compliance checking; Non-compliance; Norm identification; Norm induction; Normative systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2MNHJBDF","conferencePaper","2010","Baumgartner, Jason; Case, Michael; Mony, Hari","Coping with Moore's law (and more): supporting arrays in state-of-the-art model checkers","Proceedings of the 2010 Conference on Formal Methods in Computer-Aided Design","","","","","State-of-the-art hardware model checkers and equivalence checkers rely upon a diversity of synergistic algorithms to achieve adequate scalability and automation. While higher-level decision procedures have enhanced capacity for problems of amenable syntax, little prior work has addressed (1) the generalization of many critical synergistic algorithms beyond bit-blasted representations, nor (2) the issue of bridging higher-level techniques to problems of complex circuit-accurate syntax. In this paper, we extend a variety of bit-level algorithms to designs with memory arrays, and introduce techniques to rewrite arrays from circuit-accurate to verification-amenable behavioral syntax. These extensions have numerous motivations, from scaling formal methods to verify ever-growing design components, to enabling hardware model checkers to reason about software-like systems, to allowing state-of-the-art model checkers to support temporally-consistent function- and predicate-abstraction.","2010","2025-02-19 14:42:24","2025-02-19 14:42:24","","61–69","","","","","","","FMCAD '10","","","","FMCAD Inc","Austin, Texas","","","","","","","","event-place: Lugano, Switzerland","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7U5K4JCC","conferencePaper","1993","Sartor, Giovanni","A simple computational model for nonmonotonic and adversarial legal reasoning","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.159001","https://doi.org/10.1145/158976.159001","In many commonsense contexts only incoherent and conflicting information is available. In such contexts reasonable conclusions must be derived from inconsistent sets of premises. This is especially the case in legal reasoning: legal norms can be issued by different authorities, in different times, to reach incompatible socio-political objectives, and the meaning of those norms can be semantically indeterminate.Logic deduction alone is insufficient to derive justified conclusions out of inconsistent legal premises, since in the most popular logical systems (such as classical or intuitionistic logic) everything can be deduced from any contradiction. Nevertheless, much research now underway shows that formal methods can be developed for reasoning with conflicting information. The possibility of obtaining justified conclusions from an inconsistent set of premises increases when an ordering is defined over that set, since the ordering of the premises can be translated into an ordering of the competing arguments. This fact is particularly relevant for legal reasoning, since lawyers effectively solve normative conflicts by using ordering relations.In the following page, a model for reasoning with ordered defaults, interpreted as unidirectional inference rules, is proposed: a language for representing (possibly) contradictory rules is introduced, a notion of argument is defined, and types of arguments are distinguished. A simple interpreter in Prolog able to develop those arguments is also illustrated. Finally, the significance of the proposed model (and, more generally, of the acceptance of inconsistency) for the formal analysis of legal systems is discussed.","1993","2025-02-19 14:42:24","2025-02-19 14:42:24","","192–201","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","nonmonotonic reasoning; knowledge representation; arguments; legal system; rules and exceptions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2Z6QGFN","conferencePaper","2016","Singh, Jatinder; Pasquier, Thomas; Bacon, Jean; Powles, Julia; Diaconu, Raluca; Eyers, David","Big ideas paper: Policy-driven middleware for a legally-compliant Internet of Things","Proceedings of the 17th International Middleware Conference","978-1-4503-4300-8","","10.1145/2988336.2988349","https://doi.org/10.1145/2988336.2988349","Internet of Things (IoT) applications, systems and services are subject to law. We argue that for the IoT to develop lawfully, there must be technical mechanisms that allow the enforcement of specified policy, such that systems align with legal realities. The audit of policy enforcement must assist the apportionment of liability, demonstrate compliance with regulation, and indicate whether policy correctly captures legal responsibilities. As both systems and obligations evolve dynamically, this cycle must be continuously maintained.This poses a huge challenge given the global scale of the IoT vision. The IoT entails dynamically creating new services through managed and flexible data exchange. Data management is complex in this dynamic environment, given the need to both control and share information, often across federated domains of administration.We see middleware playing a key role in managing the IoT. Our vision is for a middleware-enforced, unified policy model that applies end-to-end, throughout the IoT. This is because policy cannot be bound to things, applications, or administrative domains, since functionality is the result of composition, with dynamically formed chains of data flows.We have investigated the use of Information Flow Control (IFC) to manage and audit data flows in cloud computing; a domain where trust can be well-founded, regulations are more mature and associated responsibilities clearer. We feel that IFC has great potential in the broader IoT context. However, the sheer scale and the dynamic, federated nature of the IoT pose a number of significant research challenges.","2016","2025-02-19 14:42:24","2025-02-19 14:42:24","","","","","","","","","Middleware '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trento, Italy","","","","regulation; Law; audit; policy specification and enforcement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GBYZ4AGV","journalArticle","2023","Bembenek, Aaron; Greenberg, Michael; Chong, Stephen","From SMT to ASP: Solver-Based Approaches to Solving Datalog Synthesis-as-Rule-Selection Problems","Proc. ACM Program. Lang.","","","10.1145/3571200","https://doi.org/10.1145/3571200","Given a set of candidate Datalog rules, the Datalog synthesis-as-rule-selection problem chooses a subset of these rules that satisfies a specification (such as an input-output example). Building off prior work using counterexample-guided inductive synthesis, we present a progression of three solver-based approaches for solving Datalog synthesis-as-rule-selection problems. Two of our approaches offer some advantages over existing approaches, and can be used more generally to solve arbitrary SMT formulas containing Datalog predicates; the third—an encoding into standard, off-the-shelf answer set programming (ASP)—leads to significant speedups (∼ 9× geomean) over the state of the art while synthesizing higher quality programs. Our progression of solutions explores the space of interactions between SAT/SMT and Datalog, identifying ASP as a promising tool for working with and reasoning about Datalog. Along the way, we identify Datalog programs as monotonic SMT theories, which enjoy particularly efficient interactions in SMT; our plugins for popular SMT solvers make it easy to load an arbitrary Datalog program into the SMT solver as a custom monotonic theory. Finally, we evaluate our approaches using multiple underlying solvers to provide a more thorough and nuanced comparison against the current state of the art.","2023-01","2025-02-19 14:42:24","2025-02-19 14:42:24","","","","POPL","7","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Datalog; inductive logic programming; program synthesis; satisfiability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2SSIHW6M","conferencePaper","2005","Hamfelt, Andreas; Eriksson, Jenny; Nilsson, Jørgen Fischer","A metalogic formalization of legal argumentation as game trees with defeasible reasoning","Proceedings of the 10th International Conference on Artificial Intelligence and Law","1-59593-081-7","","10.1145/1165485.1165533","https://doi.org/10.1145/1165485.1165533","We outline an approach to logical analysis and formalization of legal argumentation and dispute as game trees, wellknown in AI, using metalogic programming. The argument/counter-argument dialectic is facilitated through defeasible reasoning, and the applied principles are sought demonstrated by unravelling of a legal case within statutory law.","2005","2025-02-19 14:42:24","2025-02-19 14:42:24","","250–251","","","","","","","ICAIL '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bologna, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8L7DZFW4","conferencePaper","2003","Bruninghaus, Stefanie; Ashley, Kevin D.","Predicting outcomes of case based legal arguments","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047838","https://doi.org/10.1145/1047788.1047838","In this paper, we introduce IBP, an algorithm that combines reasoning with an abstract domain model and case-based reasoning techniques to predict the outcome of case-based legal arguments. Unlike the predictions generated by statistical or machine-learning techniques, IBP's predictions are accompanied by explanations.We describe an empirical evaluation of IBP, in which we compare our algorithm to prediction based on Hypo's and CATO's relevance criteria, and to a number of widely used machine learning algorithms. IBP reaches higher accuracy than all competitors, and hypothesis testing shows that the observed differences are statistically significant. An ablation study indicates that both sources of knowledge in IBP contribute to the accuracy of its predictions.","2003","2025-02-19 14:42:24","2025-02-19 14:42:24","","233–242","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35QCDNZM","journalArticle","2021","Aljeraisy, Atheer; Barati, Masoud; Rana, Omer; Perera, Charith","Privacy Laws and Privacy by Design Schemes for the Internet of Things: A Developer’s Perspective","ACM Comput. Surv.","","0360-0300","10.1145/3450965","https://doi.org/10.1145/3450965","Internet of Things applications have the potential to derive sensitive information about individuals. Therefore, developers must exercise due diligence to make sure that data are managed according to the privacy regulations and data protection laws. However, doing so can be a difficult and challenging task. Recent research has revealed that developers typically face difficulties when complying with regulations. One key reason is that, at times, regulations are vague and could be challenging to extract and enact such legal requirements. In this article, we have conducted a systematic analysis of the privacy and data protection laws that are used across different continents, namely (i) General Data Protection Regulations, (ii) the Personal Information Protection and Electronic Documents Act, (iii) the California Consumer Privacy Act, (iv) Australian Privacy Principles, and (v) New Zealand’s Privacy Act 1993. Then, we used framework analysis method to attain a comprehensive view of different privacy and data protection laws and highlighted the disparities to assist developers in adhering to the regulations across different regions, along with creating a Combined Privacy Law Framework (CPLF). After that, the key principles and individuals’ rights of the CPLF were mapped with Privacy by Design (PbD) schemes (e.g., privacy principles, strategies, guidelines, and patterns) developed previously by different researchers to investigate the gaps in existing schemes. Subsequently, we have demonstrated how to apply and map privacy patterns into IoT architectures at the design stage and have also highlighted the complexity of doing such mapping. Finally, we have identified the major challenges that should be addressed and potential research directions to take the burden off software developers when applying privacy-preserving techniques that comply with privacy and data protection laws. We have released a companion technical report [3] that comprises all definitions, detailed steps on how we developed the CPLF, and detailed mappings between CPLF and PbD schemes.","2021-05","2025-02-19 14:42:24","2025-02-19 14:42:24","","","","5","54","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","software engineering; Internet of Things; human-centered design; privacy and data protection laws; privacy by design; programming environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4GJZGKR","conferencePaper","2007","Surden, Harry; Genesereth, Michael; Logu, Bret","Representational complexity in law","Proceedings of the 11th International Conference on Artificial Intelligence and Law","978-1-59593-680-6","","10.1145/1276318.1276355","https://doi.org/10.1145/1276318.1276355","Computationally represented laws should accurately model their real-world counterparts in rules-based legal compliance systems. Legal theoretical considerations, however, often complicate the task of faithful representation. One approach to this problem has been to create sophisticated models capable of representing rules of arbitrary legal complexity. An alternative approach, which we advocate in this paper, is to focus on a subset of individual legal rules which are more amenable to simplified computational representation from a legal theoretical perspective. We propose a measure of such a tendency that we term the representational complexity of a legal rule. Our approach involves a systematic examination of particular legal rules along all of the relevant dimensions of legal theoretical complexity identified by the legal scholarship. In this way, we suggest that is possible to identify discrete legal rules which are likely to be, from a legal theoretical standpoint, amenable to simpler computational representation.","2007","2025-02-19 14:42:24","2025-02-19 14:42:24","","193–194","","","","","","","ICAIL '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Stanford, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3FBCUH4A","conferencePaper","2023","Reddy, Harita; Chandrasekharan, Eshwar","Evolution of Rules in Reddit Communities","Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing","979-8-4007-0129-0","","10.1145/3584931.3606973","https://doi.org/10.1145/3584931.3606973","Reddit communities (subreddits) govern themselves through rules. Existing work does not study how rules change within a subreddit, and when different types of rules are added since subreddit creation. As current datasets lack information about subreddits’ past rules, we present an approach to get all rules in the history of a subreddit using the Wayback Machine, and study rule trajectories within 496 subreddits. We find that at least 50% of the first rule additions occurred in less than a year from subreddit creation. Rules about civility and relevance are most common in the first rules. In contrast, rules that prohibit certain content are frequently added over time. Studying rule trajectories can help us answer whether early rule establishment helps with community success, improving key factors like user retention, norm compliance, and overall desirable behavior within the subreddit.","2023","2025-02-19 14:42:24","2025-02-19 14:42:24","","278–282","","","","","","","CSCW '23 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Minneapolis, MN, USA","","","","content moderation; online governance; rule changes; rule creation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZTBT2AV","journalArticle","2002","May, Wolfgang; Ludäscher, Bertram","Understanding the global semantics of referential actions using logic rules","ACM Trans. Database Syst.","","0362-5915","10.1145/582410.582411","https://doi.org/10.1145/582410.582411","Referential actions are specialized triggers for automatically maintaining referential integrity in databases. While the local effects of referential actions can be grasped easily, it is far from obvious what the global semantics of a set of interacting referential actions should be. In particular, when using procedural execution models, ambiguities due to the execution ordering can occur. No global, declarative semantics of referential actions has yet been defined.We show that the well-known logic programming semantics provide a natural global semantics of referential actions that is based on their local characterization: To capture the global meaning of a set RA of referential actions, we first define their abstract (but non-constructive) intended semantics. Next, we formalize RA as a logic program PRA. The declarative, logic programming semantics of PRA then provide the constructive, global semantics of the referential actions. So, we do not define a semantics for referential actions, but we show that there exists a unique natural semantics if one is ready to accept (i) the intuitive local semantics of local referential actions, (ii) the formalization of those and of the local ""effect-propagating"" rules, and (iii) the well-founded or stable model semantics from logic programming as ""reasonable"" global semantics for local rules.We first focus on the subset of referential actions for deletions only. We prove the equivalence of the logic programming semantics and the abstract semantics via a game-theoretic characterization, which provides additional insight into the meaning of interacting referential actions. In this case a unique maximal admissible solution exists, computable by a ptime algorithm.Second, we investigate the general case—including modifications. We show that in this case there can be multiple maximal admissible subsets and that all maximal admissible subsets can be characterized as 3-valued stable models of PRA. We show that for a given set of user requests, in the presence of referential actions of the form ON UPDATE CASCADE, the admissibility check and the computation of the subsequent database state, and (for non-admissible updates) the derivation of debugging hints all are in ptime. Thus, full referential actions can be implemented efficiently.","2002-12","2025-02-19 14:42:24","2025-02-19 14:42:24","","343–397","","4","27","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Database theory; game theory; logic programming; referential actions; referential integrity; relational databases","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CM875B6M","conferencePaper","2016","Carpineto, Caudio; Lo Re, Davide; Romano, Giovanni","Automatic Assessment of Website Compliance to the European Cookie Law with CooLCheck","Proceedings of the 2016 ACM on Workshop on Privacy in the Electronic Society","978-1-4503-4569-9","","10.1145/2994620.2994622","https://doi.org/10.1145/2994620.2994622","We study the problem of automatically assessing whether a website meets the requirements of the Cookie Law, in particular to check that when some tracking cookie is installed the user is asked to give consent to its use. We present a methodology based on cookie disclosure and classification together with identification of natural language consent requests by web information retrieval techniques. This approach performs real time analysis and is very accurate. Using the 500 most popular websites in Italy as a test set, we found that the automatic diagnosis was always correct, except for the case when the consent request was expressed in a language not supported by the system. We also report the results of a systematic evaluation of the 23000 Italian Public Administration websites showing large-scale infringement. Our approach has been implemented as a web application named CooLCheck, which is currently being used by the Italian Data Protection Authority as a support tool for evaluating and monitoring the compliance of websites to the Cookie Law.","2016","2025-02-19 14:42:24","2025-02-19 14:42:24","","135–138","","","","","","","WPES '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vienna, Austria","","","","cookies; information retrieval; privacy policies; privacy protection; web mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LKWY6V2G","conferencePaper","2012","Hrgarek, Nadica","Certification and regulatory challenges in medical device software development","Proceedings of the 4th International Workshop on Software Engineering in Health Care","978-1-4673-1843-3","","","","The critical nature of safety in medical device software requires a repeatable and compliant software engineering process. This process should take into account the whole development life cycle, risk management, and software verification and validation activities that would commensurate with the device's complexity and risk. This paper discusses some of the key challenges medical device manufacturers are facing in the development and certification of medical device software. These challenges include: compliance with the EU and US regulatory requirements for medical device software, making software development and maintenance processes more agile in the medical device regulatory environment, integrating usability engineering process/human factors into software development, regulation of networked medical devices and mobile medical applications (apps). The MED-EL case study highlights some of the challenges described in this paper, and the approaches taken to overcome these challenges.","2012","2025-02-19 14:42:24","2025-02-19 14:42:24","","40–43","","","","","","","SEHC '12","","","","IEEE Press","","","","","","","","","Place: Zurich, Switzerland","","","","regulatory compliance; medical device software; mobile medical apps; usability engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IAHRIXL6","conferencePaper","2018","Morales, Jose Andre; Yasar, Hasan; Volkman, Aaron","Implementing DevOps practices in highly regulated environments","Proceedings of the 19th International Conference on Agile Software Development: Companion","978-1-4503-6422-5","","10.1145/3234152.3234188","https://doi.org/10.1145/3234152.3234188","In this paper, we discuss implementing DevOps practices in highly regulated environments (HREs). DevOps has become a standard option for entities seeking to streamline and increase participation by all stakeholders in their Software Development Lifecycle (SDLC). For a large portion of industry, academia, and government, applying DevOps is a straight forward process. There is, however, a subset of entities in these three sectors where applying DevOps can be very challenging. These are entities mandated by policies to conduct all or a portion of their SDLC activities in HREs. Often, the reason for an HRE is general security and protection of intellectual property. Even if an entity is functioning in a highly regulated environment, its SDLC can still benefit from implementing DevOps as long as the implementation conforms to all imposed policies. In this paper, we discuss the process of performing a DevOps assessment and implementation in an HRE which we refer to as HRE-DevOps.","2018","2025-02-19 14:42:24","2025-02-19 14:42:24","","","","","","","","","XP '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Porto, Portugal","","","","DevOps; DevOps assessment; highly regulated environment; SDLC; secure DevOps","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8JNFBAGR","journalArticle","2012","Wang, Daifeng; Markey, Mia K.; Wilke, Claus O.; Arapostathis, Ari","Eigen-Genomic System Dynamic-Pattern Analysis (ESDA): Modeling mRNA Degradation and Self-Regulation","IEEE/ACM Trans. Comput. Biol. Bioinformatics","","1545-5963","10.1109/TCBB.2011.150","https://doi.org/10.1109/TCBB.2011.150","High-throughput methods systematically measure the internal state of the entire cell, but powerful computational tools are needed to infer dynamics from their raw data. Therefore, we have developed a new computational method, Eigen-genomic System Dynamic-pattern Analysis (ESDA), which uses systems theory to infer dynamic parameters from a time series of gene expression measurements. As many genes are measured at a modest number of time points, estimation of the system matrix is underdetermined and traditional approaches for estimating dynamic parameters are ineffective; thus, ESDA uses the principle of dimensionality reduction to overcome the data imbalance. Since degradation rates are naturally confounded by self-regulation, our model estimates an effective degradation rate that is the difference between self-regulation and degradation. We demonstrate that ESDA is able to recover effective degradation rates with reasonable accuracy in simulation. We also apply ESDA to a budding yeast data set, and find that effective degradation rates are normally slower than experimentally measured degradation rates. Our results suggest that either self-regulation is widespread in budding yeast and that self-promotion dominates self-inhibition, or that self-regulation may be rare and that experimental methods for measuring degradation rates based on transcription arrest may severely overestimate true degradation rates in healthy cells.","2012-03","2025-02-19 14:42:24","2025-02-19 14:42:24","","430–437","","2","9","","","","","","","","","","","","","","","","","Place: Washington, DC, USA Publisher: IEEE Computer Society Press","","","","Eigenvalues and eigenvectors; genome-wide gene expression; singular value decomposition.; systems theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q933B7TY","conferencePaper","1993","Prakken, Henry","A logical framework for modelling legal argument","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.158977","https://doi.org/10.1145/158976.158977","This paper investigates the relevance of the logical study of argumentation systems for AI-and-law research, in particular for modelling the adversarial aspect of legal reasoning. It does so in applying the argumentation framework of Prakken (1993a/b) to the legal domain. Three elements of the framework are particularly illustrated: firstly, its generality, in that it leaves room for any standard for comparing pairs of arguments; secondly, its ability to model the combined use of these standards; and finally, its relevance for modelling metalevel reasoning. These three features make the framework suitable as a logical framework for any theory of legal argument.","1993","2025-02-19 14:42:24","2025-02-19 14:42:24","","1–9","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VFMLUQ5F","conferencePaper","2015","Cherouana, Amina; Aouine, Amina; Mahdaoui, Latifa","A Workflow-Based Solution for the Law Study Process Management","Proceedings of the 2015 2nd International Conference on Electronic Governance and Open Society: Challenges in Eurasia","978-1-4503-4070-0","","10.1145/2846012.2846022","https://doi.org/10.1145/2846012.2846022","In the context of e-government engineering, legal requirements capture is arguably the most important phase in order to ensure the compliance of public e-services with the rigorous legal basis characterizing public institutions. This step is a strongly cooperative process that brings into interaction three roles with different skills and prerequisites. This paper proposes a workflow-based solution providing a cooperative space for these involved roles and an execution environment of the instances of the law study process. In addition, it also allows the assessment and the validation of the resulting legal requirements through a law meta-model.","2015","2025-02-19 14:42:24","2025-02-19 14:42:24","","133–138","","","","","","","EGOSE '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: St. Petersburg, Russian Federation","","","","Legal Compliance; Cooperative Work; E-Government; Law Modeling; Workflow Management System (WfMS)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBQLBB6I","conferencePaper","1999","Kakuta, Tokuyasu; Haraguchi, Makoto","A demonstration of a legal reasoning system based on teleological analogies","Proceedings of the 7th International Conference on Artificial Intelligence and Law","1-58113-165-8","","10.1145/323706.323798","https://doi.org/10.1145/323706.323798","In this article, we demonstrate our analogical legal reasoning system based on a teleological approach to interpret laws, using an actual example. By this demonstration, we show the validity of our approach. The example is based on a real legal problem and consists of an actual case, the actual decision on the case by the Japanese Supreme Court and two major doctrines on the case in Japan. The problem and the doctrines are also analyzed from the viewpoint of GDA (Goal-Dependent Abstraction) framework in this article. We further show that our system using GDA can provide helpful information to evaluate and revise interpretations of legal rules.","1999","2025-02-19 14:42:24","2025-02-19 14:42:24","","196–205","","","","","","","ICAIL '99","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Oslo, Norway","","","","analogy; goal-dependent abstraction; legal reasoning system; order-sorted logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LGNIH7K","conferencePaper","2012","Steibel, Fabro","Designing online deliberation using web 2.0 technologies: drafting a bill of law on internet regulation in Brazil","Proceedings of the 6th International Conference on Theory and Practice of Electronic Governance","978-1-4503-1200-4","","10.1145/2463728.2463738","https://doi.org/10.1145/2463728.2463738","In this paper, we describe the formatting guidelines for the role of institutions and political practitioners in designing online consultation projects. As a case study we evaluate the Brazilian government-run initiative known as Marco Civil Regulatório that used web 2.0 tools to draft a bill of law on Internet legislation with the aid of citizen's participation. Findings presented in this article are based on a set of interviews held with policy makers responsible for designing and promoting the aforementioned project.This article contributes to the debates on how deliberative rules and technology overlap in early stages of policy design. Our case study supports the argument that Internet has potential to provide a democratic space, but public consultations need to be established, funded, promoted and regulated; tasks that are performed by institutions (not by technology or citizens alone). For that reason, institutions are key to understand how web 2.0 technologies can be useful for citizens and governments in designing tools for consultation, deliberation and decision-making","2012","2025-02-19 14:42:24","2025-02-19 14:42:24","","38–43","","","","","","","ICEGOV '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Albany, New York, USA","","","","e-democracy; online consultation; web 2.0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YPBZ8TEK","conferencePaper","2007","zur Muehlen, Michael; Indulska, Marta; Kamp, Gerrit","Business process and business rule modeling languages for compliance management: a representational analysis","Tutorials, Posters, Panels and Industrial Contributions at the 26th International Conference on Conceptual Modeling - Volume 83","978-1-920682-64-4","","","","Organizations are under increasing scrutiny to document their compliance to regulatory requirements. To this end, they have to formally document their operating procedures to support their compliance management efforts. Both process modeling languages and rule modeling languages are candidates for the documentation of organizational policies and procedures. While both types of languages are currently used to document organizational practices, little work has been done to understand their synergies and overlap. Accordingly, in this paper we use the Bunge-Wand-Weber (BWW) representation theory as a basis for such an analysis. We perform a representational analysis of two popular rule modeling languages, viz., SRML and SBVR. We compare their representation capabilities with those of four popular conceptual business process modeling languages, and focus on the aspects of maximum ontological completeness and minimum ontological overlap. The outcome of this study shows that a combination of two languages, viz. SRML and BPMN, is more suitable for documenting compliance than any single modeling language, and that the combination of process and rule modeling languages shows synergies.","2007","2025-02-19 14:42:24","2025-02-19 14:42:24","","127–132","","","","","","","ER '07","","","","Australian Computer Society, Inc.","AUS","","","","","","","","event-place: Auckland, New Zealand","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCHY2FYS","conferencePaper","2003","van der Meer, Erik R.; Henriksen, Ioanna Stavrinidou; Andersen, Henrik Reif","Using configuration technology as the core of a legal decision support system","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047824","https://doi.org/10.1145/1047788.1047824","This paper is concerned with the development of a logical model of a given legal act and the realization of a web-based decision support system on the basis of this model. The system is implemented using a configuration engine, which provides full propositional reasoning in polynomial time (after an off-line compilation step), and a good web-coupling infrastructure. To the best of our knowledge it is the first decision support system that is based on such an engine. Further issues that are addressed are the main problems that were encountered during the modeling of the act and the techniques that have been used to overcome them, as well as a number of user interface issues that are of crucial importance if such a system is to be accepted by its users.","2003","2025-02-19 14:42:24","2025-02-19 14:42:24","","147–151","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8DGV2TT","conferencePaper","2021","Mayer, Ruben; Jacobsen, Hans-Arno","Hybrid Edge Partitioner: Partitioning Large Power-Law Graphs under Memory Constraints","Proceedings of the 2021 International Conference on Management of Data","978-1-4503-8343-1","","10.1145/3448016.3457300","https://doi.org/10.1145/3448016.3457300","Distributed systems that manage and process graph-structured data internally solve a graph partitioning problem to minimize their communication overhead and query run-time. Besides computational complexity—optimal graph partitioning is NP-hard—another important consideration is the memory overhead. Real-world graphs often have an immense size, such that loading the complete graph into memory for partitioning is not economical or feasible. Currently, the common approach to reduce memory overhead is to rely on streaming partitioning algorithms. While the latest streaming algorithms lead to reasonable partitioning quality on some graphs, they are still not completely competitive to in-memory partitioners. In this paper, we propose a new system, Hybrid Edge Partitioner (HEP), that can partition graphs that fit partly into memory while yielding a high partitioning quality. HEP can flexibly adapt its memory overhead by separating the edge set of the graph into two sub-sets. One sub-set is partitioned by NE++, a novel, efficient in-memory algorithm, while the other sub-set is partitioned by a streaming approach. Our evaluations on large real-world graphs show that in many cases, HEP outperforms both in-memory partitioning and streaming partitioning at the same time. Hence, HEP is an attractive alternative to existing solutions that cannot fine-tune their memory overheads. Finally, we show that using HEP, we achieve a significant speedup of distributed graph processing jobs on Spark/GraphX compared to state-of-the-art partitioning algorithms.","2021","2025-02-19 14:42:24","2025-02-19 14:42:24","","1289–1302","","","","","","","SIGMOD '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, China","","","","distributed graph processing; graph partitioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"73GZYJ2K","journalArticle","2010","Burns, Randal; Peterson, Zachary","Security constructs for regulatory-compliant storage","Commun. ACM","","0001-0782","10.1145/1629175.1629206","https://doi.org/10.1145/1629175.1629206","IntroductionIn response to a growing body of electronic records legislation, the storage community has enhanced data stores to include privacy, auditability, and a ""chain-of-custody"" for data. There are currently over 4,000 federal, state, and local regulations that govern the storage, management, and retrieval of electronic records. Most notably, the Sarbanes-Oxley Act of 2002, which regulates corporate financial records. Storage vendors provide ""compliance"" platforms that store and manage data in accordance with regulations, which aids customers in meeting compliance guidelines. Examples include: EMC Centera Compliance Edition,™ NetApp SnapLock,™ and IBM Tivoli Security Compliance Manage.™Many of these platforms add storage management policy to existing systems. Vendors start with systems that manage versions of files or volumes. They add immutability to past versions by preventing writes by policy. They also enforce data retention guidelines by not allowing the deletion of protected files. Enhanced metadata allows users and auditors to examine the store at any point-in-time and investigate the manner in which data have changed throughout their history.While these features aid organizations in complying with regulations, they do not provide strong evidence of compliance. By following storage management policies, data are versioned and retained for mandated periods. However, there are many opportunities and motivations to subvert such storage policies. In fact, the file system owner represents the most likely attacker. For example, a corporation might alter or destroy data after the corporation comes under suspicion of malfeasance. The shredding of Enron audit documents at Arthur Anderson in 2001 provides a notable paper analog. Similarly, a hospital or private medical practice might attempt to amend or delete a patient's medical records to hide evidence of malpractice. In policy-based storage systems, past data may be altered or destroyed by reverse engineering file system formats and editing the file data on disk–a common and well understood data forensics task.We assert that these features need to be cryptographically strong, providing irrefutable evidence of compliance with regulations. This can be achieved for data retention and chain of custody. A storage system commits to a version history so that, at a later time, an auditor may access past data and gain conclusive evidence that the data have been retained and are unmodified. Further, all data should be bound to the users that modify, create, or delete that data. Such constructs improve the evidentiary value of electronic records within the courts, increase an auditor's confidence in the veracity of the information on which they report (and for which they are responsible), and enhance an organization's quality of data management.To these ends, we review three security constructs for versioning file systems. Digital audit trails allow a file system to prove to an independent auditor that it stored data in conformance with regulated retention guidelines. Fine-grained, secure deletion allows a system to efficiently delete individual versions of files to meet confidentiality requirements, limit liability, and allow data to be redacted. Per-block authenticated encryption adds authenticity guarantees to the confidentiality provided by encryption. We also include a distillation of requirements based on a review of relevant legislation and a brief characterization of the performance impact of these techniques based on their implementation within the ext3cow file system.","2010-01","2025-02-19 14:42:24","2025-02-19 14:42:24","","126–130","","1","53","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDM9PABA","conferencePaper","2022","Woods, Daniel W; Ceross, Aaron","Blessed Are The Lawyers, For They Shall Inherit Cybersecurity","Proceedings of the 2021 New Security Paradigms Workshop","978-1-4503-8573-2","","10.1145/3498891.3501257","https://doi.org/10.1145/3498891.3501257","This paper considers which types of evidence guide cybersecurity decisions. We argue that the “InfoSec belongs to the quants” paradigm will not be realised despite its normative appeal. In terms of progress to date, we find few empirical results that can guide risk mitigation decisions. We suggest the knowledge base about quantitative cybersecurity is continually eroded by increasing complexity, technological flux, and strategic adversaries. Given these secular forces will not abate any time soon, we argue that legal reasoning will increasingly influence cybersecurity decisions relative to technical and quantitative reasoning. The law as a system of social control bristles with ambiguity and so legal mechanisms exist to resolve uncertainties over time. Actors with greater claims to authority over this knowledge base, predominantly lawyers, will accrue decision making power within organisations. We speculate about the downstream impacts of lawyers inheriting cybersecurity, and also sketch the limits of the paradigm’s explanatory power.","2022","2025-02-19 14:42:24","2025-02-19 14:42:24","","1–12","","","","","","","NSPW '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, USA","","","","lawyers; technology policy; cybersecurity policy; philosophy of security; quantitative cybersecurity; risk management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4ZZYFTZ","conferencePaper","2020","Vink, Marco; Netten, Niels; Bargh, Mortaza S.; van den Braak, Susan; Choenni, Sunil","Mapping crime descriptions to law articles using deep learning","Proceedings of the 13th International Conference on Theory and Practice of Electronic Governance","978-1-4503-7674-7","","10.1145/3428502.3428507","https://doi.org/10.1145/3428502.3428507","In the operational systems of the Dutch Public Prosecution Service, data about criminal cases are registered. This information is used to generate crime statistics or other management information as input for policymaking. A key element for these statistics is the crime type of a case, which is normally deduced from the registered law articles of each case. However the quality of these registered law articles has shortcomings. Additional data describing the crime could be useful to enhance the equality of these law articles. In this paper we investigate the possibility to map additional descriptions of the crime to the formal notations of law articles using a deep learning neural network approach called sequence-to-sequence learning. We describe the characteristics of the data and carry out a number of experiments on these data. Subsequently, we compare two approaches: a) one-hot encoding for the words in a sentence and b) pre-trained word embeddings. The results show that the mapping of the crime description to law articles works reasonably well: a measured accuracy of 91% is reached, and when some issues in the dataset would be resolved the performance could be even higher.","2020","2025-02-19 14:42:24","2025-02-19 14:42:24","","33–43","","","","","","","ICEGOV '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Athens, Greece","","","","Natural language processing; deep learning; crime type; data quality; sequence-to-sequence learning; word embeddings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SUGG2KH","conferencePaper","2015","Brezovan, Marius; Badica, Costin","Event-B Modeling of a Rule Base for an Expert System Using Forward Chaining","Proceedings of the 7th Balkan Conference on Informatics Conference","978-1-4503-3335-1","","10.1145/2801081.2801101","https://doi.org/10.1145/2801081.2801101","Methods for verification and validation of expert systems are important activities for assuring the quality of these systems. The research in this area is related to three main criteria, by analysing the consistency, completeness, and correctness of the knowledge base associated to an expert system. This paper aims to study the consistency of a rule base associated to a rule-based system with forward chaining by modeling the rule base using the Event-B method. The Event-B language was chosen for two reasons: (a) Event-B uses a mathematical language that can be used to prove the consistency of a modeled system, and (b) because it is a tool-supported formal specification language, which uses the Rodin platform, an Eclipse-based IDE for Event-B. An example related to the CLIPS expert system is provided in the paper.","2015","2025-02-19 14:42:24","2025-02-19 14:42:24","","","","","","","","","BCI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Craiova, Romania","","","","Event-B modeling; knowledge base verification; rule-bases systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICRIYMAG","conferencePaper","1993","Sakurai, Seiichiro; Yoshino, Hajime","Identification of implicit legal requirements with legal abstract knowledge","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.159013","https://doi.org/10.1145/158976.159013","In order to acquire legal rules from legal texts, legal requirements and legal effects must be identified. However, some of legal requirements are expressed implicitly. Such implicit legal requirements can be found by lawyers when they understand legal texts. In this paper, to mechanize legal knowledge acquisition process, a lawyer's understanding process of legal texts is analyzed. The lawyer's understanding process can be viewed as an abductive reasoning process, since the lawyer can introduce implicit legal requirements which have not appeared in legal texts. This paper models such a reasoning process when lawyers understand legal texts. Based on the analysis of lawyer's understanding process, a knowledge acquisition support system is proposed.","1993","2025-02-19 14:42:24","2025-02-19 14:42:24","","298–305","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAMVJYZS","conferencePaper","1987","Goldman, S. R.; Dyer, M. C.; Flowers, M.","Precedent-based legal reasoning and knowledge acquisition in contract law: A process model","Proceedings of the 1st International Conference on Artificial Intelligence and Law","0-89791-230-6","","10.1145/41735.41759","https://doi.org/10.1145/41735.41759","In the law, decisions in previous cases play a significant role in the presentation, understanding, and outcome of new cases. This is particularly true in the area of contract law where few statutes (explicit legal rules) exist. When presented with a new case, a lawyer must be able to identify important issues and make some predictions about how the case might be decided. The lawyer will often recall past cases which bear similarities to the current case and reason analogically to make these predictions. In order to perform these tasks, a lawyer must be able to remember past cases, organize them in memory so that cases that are conceptually similar are stored together (a lawyer normally won't be reminded of an irrelevant case), and make analogies between cases. Thus the organization and representation of knowledge in memory is crucial in building a model of lawyer's cognitive processes. This paper describes a process model, implemented in a computer program called STARE, which addresses these issues in the context of first-year law students learning contract law.","1987","2025-02-19 14:42:24","2025-02-19 14:42:24","","210–221","","","","","","","ICAIL '87","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYLHB7F8","conferencePaper","2013","Chowdhury, Omar; Gampe, Andreas; Niu, Jianwei; von Ronne, Jeffery; Bennatt, Jared; Datta, Anupam; Jia, Limin; Winsborough, William H.","Privacy promises that can be kept: a policy analysis method with application to the HIPAA privacy rule","Proceedings of the 18th ACM Symposium on Access Control Models and Technologies","978-1-4503-1950-8","","10.1145/2462410.2462423","https://doi.org/10.1145/2462410.2462423","Organizations collect personal information from individuals to carry out their business functions. Federal privacy regulations, such as the Health Insurance Portability and Accountability Act (HIPAA), mandate how this collected information can be shared by the organizations. It is thus incumbent upon the organizations to have means to check compliance with the applicable regulations. Prior work by Barth et. al. introduces two notions of compliance, weak compliance (WC) and strong compliance (SC). WC ensures that present requirements of the policy can be met whereas SC also ensures obligations can be met. An action is compliant with a privacy policy if it is both weakly and strongly compliant. However, their definitions of compliance are restricted to only propositional linear temporal logic (pLTL), which cannot feasibly specify HIPAA. To this end, we present a policy specification language based on a restricted subset of first order temporal logic (FOTL) which can capture the privacy requirements of HIPAA. We then formally specify WC and SC for policies of our form. We prove that checking WC is feasible whereas checking SC is undecidable. We then formally specify the property WC entails SC, denoted by Δ, which requires that each weakly compliant action is also strongly compliant. To check whether an action is compliant with such a policy, it is sufficient to only check whether the action is weakly compliant with that policy. We also prove that when a policy ℘ has the Δ-property, the present requirements of the policy reduce to the safety requirements imposed by ℘. We then develop a sound, semi-automated technique for checking whether practical policies have the Δ-property. We finally use HIPAA as a case study to demonstrate the efficacy of our policy analysis technique.","2013","2025-02-19 14:42:24","2025-02-19 14:42:24","","3–14","","","","","","","SACMAT '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","privacy policy; HIPAA; obligations; policy analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBXNNWZL","conferencePaper","2012","Law, Kincho H.; Lau, Gloria","REGNET: regulatory information management, compliance and analysis","Proceedings of the 6th International Conference on Theory and Practice of Electronic Governance","978-1-4503-1200-4","","10.1145/2463728.2463764","https://doi.org/10.1145/2463728.2463764","This paper describes a research effort that aims to develop information infrastructure and tools to facilitate access, compliance and analysis of government regulations. It is well recognized that the complexity, diversity, and volume of government regulations are detrimental to business and hinder public understanding of government. The burden of complying with regulations can fall disproportionately on small businesses since these businesses may not have the expertise or resources to keep track of the regulations and the requirements. The situation can potentially be improved by developing appropriate tools that can help facilitate the regulatory and compliance process. To illustrate, this paper discusses the applications of information technology for selected services related to regulations, such as compliance assistance, comparison of regulation from diverse sources, and e-rulemaking.","2012","2025-02-19 14:42:24","2025-02-19 14:42:24","","175–183","","","","","","","ICEGOV '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Albany, New York, USA","","","","regulations; relatedness analysis; compliance assistance; e-government; e-rulemaking; information retrieval","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GS6IUSU3","conferencePaper","2010","Cleland-Huang, Jane; Czauderna, Adam; Gibiec, Marek; Emenecker, John","A machine learning approach for tracing regulatory codes to product specific requirements","Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1","978-1-60558-719-6","","10.1145/1806799.1806825","https://doi.org/10.1145/1806799.1806825","Regulatory standards, designed to protect the safety, security, and privacy of the public, govern numerous areas of software intensive systems. Project personnel must therefore demonstrate that an as-built system meets all relevant regulatory codes. Current methods for demonstrating compliance rely either on after-the-fact audits, which can lead to significant refactoring when regulations are not met, or else require analysts to construct and use traceability matrices to demonstrate compliance. Manual tracing can be prohibitively time-consuming; however automated trace retrieval methods are not very effective due to the vocabulary mismatches that often occur between regulatory codes and product level requirements. This paper introduces and evaluates two machine-learning methods, designed to improve the quality of traces generated between regulatory codes and product level requirements. The first approach uses manually created traceability matrices to train a trace classifier, while the second approach uses web-mining techniques to reconstruct the original trace query. The techniques were evaluated against security regulations from the USA government's Health Insurance Privacy and Portability Act (HIPAA) traced against ten healthcare related requirements specifications. Results demonstrated improvements for the subset of HIPAA regulations that exhibited high fan-out behavior across the requirements datasets.","2010","2025-02-19 14:42:24","2025-02-19 14:42:24","","155–164","","","","","","","ICSE '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cape Town, South Africa","","","","regulatory compliance; requirements classification; traceability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FX8CF4FL","conferencePaper","2015","Kebbedies, Jörg; Spillner, Josef; Braun, Iris; Schill, Alexander","Conceptualized policy design for user-regulated trusted clouds","Proceedings of the 8th International Conference on Utility and Cloud Computing","978-0-7695-5697-0","","","","The term ""trust"" in the area of cloud computing has always been one of the most problematic issues. The cloud user becomes willing to accept insecure conditions and unconsciously increases these conditions' security level if he is able to find a strategy that provides trust. This level of trust, once established, is difficult to maintain if any deception takes place. The indications of proven trust can only be seen in future usage of a cloud service. For this reason, specific control instruments are required to ascertain the accuracy of one's trust. The establishment of trust in a public cloud environment requires a paradigm change: a holistic strategy that enforces regulation requirements throughout the cloud architecture. The movement of the root of trust into hardware reduces vulnerability to compromise, as hardware attacks require a high expenditure of time and effort.Cloud users would define regulation standards through trustworthy IT instruments and enforce them in specific cloud-service layers. The extension of this approach is the regulation of SaaS-based applications to enforce requirements for separation and availability. This work introduces a conceptual approach to establish a chain of policy by using hardware-oriented root of trust. The conceptual description of a chain of policy outlines the main principles to enforce regulations accurately for each architectural cloud layer based on an established chain of trust.","2015","2025-02-19 14:42:24","2025-02-19 14:42:24","","601–606","","","","","","","UCC '15","","","","IEEE Press","","","","","","","","","Place: Limassol, Cyprus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54WQ4BZ3","conferencePaper","1989","Skalak, D. B.","Taking advantage of models for legal classification","Proceedings of the 2nd International Conference on Artificial Intelligence and Law","0-89791-322-1","","10.1145/74014.74044","https://doi.org/10.1145/74014.74044","Legal reasoning is often couched in terms of legal classification. We examine how three models of classification — Classical, Probabilistic and Exemplar — are used to perform legal classification. We argue that all three models of classification are implicitly applied by existing AI methods. The CABARET (“CAse-BAsed REasoning Tool”) system is suggested as an architecture that applies all three models. The relative difficulty of revising knowledge in rule form, in HYPO-style dimension form, and exemplar form is considered.","1989","2025-02-19 14:42:24","2025-02-19 14:42:24","","234–241","","","","","","","ICAIL '89","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vancouver, British Columbia, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PN36HN5A","conferencePaper","2022","Sychev, Oleg; Penskoy, Nikita; Terekhov, Grigory","A Tool to Teach Expressions with Feedback About Broken Laws","Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2","978-1-4503-9071-2","","10.1145/3478432.3499082","https://doi.org/10.1145/3478432.3499082","We developed a web-based tool for learning the order of evaluating expressions in C++ and Python languages. The variety of operator precedence and associativity among programming languages and the lack of direct visualization make understanding expression evaluation difficult for some students. The key feature of the new system is a detailed explanation of errors, containing fault reasons—the subject domain laws that the student violated. We evaluated the tool with 14 first-year Computer Science students and received positive feedback. This tool can be used for learning new concepts during homework without requiring more class time because it provides enough feedback for students to learn on their own.","2022","2025-02-19 14:42:25","2025-02-19 14:42:25","","1158","","","","","","","SIGCSE 2022","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Providence, RI, USA","","","","constraint-based intelligent tutor; expressions; introductory programming course; order of evaluation; software reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WF66SHG","conferencePaper","2017","Abyaa, Abir; Idrissi, Mohammed Khalidi; Bennani, Samir","An adult learner's knowledge model based on ontologies and rule reasoning","Proceedings of the Mediterranean Symposium on Smart City Application","978-1-4503-5211-6","","10.1145/3175628.3175656","https://doi.org/10.1145/3175628.3175656","One of the biggest challenges of Adaptive e-learning systems is learner modelling. The learner model should represent the learner's characteristics as faithfully as possible in order to provide adaptive learning. Among these characteristics, the learner's knowledge is considered to be the core characteristic of the learner model, as adaptive e-learning systems are centered on the learner's knowledge, since acquiring « knowledge » about a specific domain or concept is considered the main goal of learning and instruction. In this paper, we propose a novel adult learner's knowledge model using ontologies and rule reasoning, by trying to define the different components that construct the learner's knowledge in an exhaustive yet a simple way. The proposed model takes into account different elements of the learner's knowledge, such as the different knowledge types and categories, the learner's prior knowledge accumulated through his/her experiences, his/her misconceptions, errors and the previously learned but forgotten knowledge.","2017","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","SCAMS '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tangier, Morocco","","","","rule modelling; ontology; OWL; adaptive learning; adult learner; learner model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SWQB85NZ","conferencePaper","2010","Malone, Paul; McLaughlin, Mark; Leenes, Ronald; Ferronato, Pierfranco; Lockett, Nick; Guillen, Pedro Bueso; Heistracher, Thomas; Russello, Giovanni","ENDORSE: a legal technical framework for privacy preserving data management","Proceedings of the 2010 Workshop on Governance of Technology, Information and Policies","978-1-4503-0446-7","","10.1145/1920320.1920325","https://doi.org/10.1145/1920320.1920325","The ENDORSE project is concerned with providing assurances for data protection for both data controllers and data subjects. The project will define a rules based language called PRDL (Privacy Rules Definition Language) which can be used to express legislative requirements, organizational privacy policy as well as user consent. ENDORSE will provide a rules engine to ensure that privacy policies expressed in this language are compliant with legislative requirements for the applicable jurisdictions. In addition a set of technology adapters will be developed which will provide transformations from PRDL to target access control and policy configuration instances, which in turn can be used by organizations to ensure that internal data handling practices are in turn compliant. In parallel to this effort a certification methodology will be developed to provide a means of generating a privacy seals. This paper describes an overview of the project, the motivation behind the initiative, its aims and objectives as well as an introduction to the approach taken and technologies foreseen to achieves these aims. The paper also provides a discussion of how the results of the project can be applied in different scenarios.","2010","2025-02-19 14:42:25","2025-02-19 14:42:25","","27–34","","","","","","","GTIP '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Austin, Texas, USA","","","","data protection; privacy; compliance; data management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZZKXFGP5","conferencePaper","2021","Mendes, João; Viana, Davi; Rivero, Luis","Developing an Inspection Checklist for the Adequacy Assessment of Software Systems to Quality Attributes of the Brazilian General Data Protection Law: An Initial Proposal","Proceedings of the XXXV Brazilian Symposium on Software Engineering","978-1-4503-9061-3","","10.1145/3474624.3477069","https://doi.org/10.1145/3474624.3477069","The General Data Protection Law (LGPD) in Brazil was created with the goal of regulating how associations collect, transmit and store users’ personal data. Although it became applicable in 2020, several software development teams still don’t know what quality attributes are necessary for a system to comply with such law and to avoid legal and monetary penalties. Furthermore, there are still no checklists for verifying quality criteria related to the Brazilian LGPD. In this paper, an inspection checklist is proposed to evaluate software systems regarding their adherence to the Brazilian LGPD. We identified the attributes from papers describing the impact of the law in the development of Brazilian software systems; and from papers describing existing techniques and quality attributes for evaluating the adherence of software systems to laws from other countries. The final evaluation checklist contains a total of 52 attributes distributed in evaluation categories, such as: transparency, legal rights, security, contentment and responsibility. To assess the proposed checklist, we applied the checklist to evaluate a government web application. The initial results indicate that the current version of the checklist allows the identification of problems regarding the adherence of software systems to the Brazilian LGPD.","2021","2025-02-19 14:42:25","2025-02-19 14:42:25","","263–268","","","","","","","SBES '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Joinville, Brazil","","","","General Data Protection Law; Inspection Checklist; LGPD; Quality Attributes; Review Analysis; Software Systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89UDXRNJ","conferencePaper","1993","Yamaguti, Takahira; Kurematsu, Masaki","Legal knowledge acquisition using case-based reasoning and model inference","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.159003","https://doi.org/10.1145/158976.159003","Although Case-Based Reasoning comes out in order to solve knowledge acquisition bottleneck, a case structure acquisition bottleneck has emerged, superseding it. Because we cannot decide an appropriate case structure in advance, a framework for CBR should be able to improve a case structure dynamically, collecting and analyzing cases. Here is discussed a new framework for knowledge acquisition using CBR and model inference. Model Inference tries to obtain new descriptors(predicates) with interaction of a domain expert, regarding the predicate as the slots that compose a case structure, with an eye to the function of theoretical term generation. The framework has two features: (1) CBR obtains a more suitable group of slots (a case structure) incrementally through cooperation with model inference, and (2) model inference with theoretical term capability discovers the rules which deal with a given task better. Furthermore, we evaluate the feasibility of the framework by implementing it to deal with law interpretation and certify two features with the framework.","1993","2025-02-19 14:42:25","2025-02-19 14:42:25","","212–217","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SGJNQIZZ","conferencePaper","2002","Jermann, Patrick","Task and interaction regulation in controlling a traffic simulation","Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community","","","","","In collaborative problem solving, metacognition not only covers strategic reasoning related to the task but also reasoning related to the interaction itself. The hypothesis underlying this work states that regulation of the interaction and regulation of the task are closely related mechanisms and that their co-occurrence facilitates coordination. These assumptions are tested experimentally with a traffic simulator. The results show that co-occurrence of task and interaction regulation allows quicker solving of the problem, thus better performance. The experimental treatment aims at observing the effects of interaction meters on the accuracy of subjects' estimation of their participation. Interaction meters are visualization tools that represent the number of contributions related to the discussion and to the implementation of the solution.","2002","2025-02-19 14:42:25","2025-02-19 14:42:25","","601–602","","","","","","","CSCL '02","","","","International Society of the Learning Sciences","","","","","","","","","Place: Boulder, Colorado","","","","interaction meters; interaction regulation; metacognition; reflective tools; task regulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JK48IQRP","conferencePaper","2024","Feng, Cheng","PARs: Predicate-based Association Rules for Efficient and Accurate Anomaly Explanation","Proceedings of the 33rd ACM International Conference on Information and Knowledge Management","979-8-4007-0436-9","","10.1145/3627673.3679625","https://doi.org/10.1145/3627673.3679625","While new and effective methods for anomaly detection are frequently introduced, many studies prioritize the detection task without considering the need for explainability. Yet, in real-world applications, anomaly explanation, which aims to provide explanation of why specific data instances are identified as anomalies, is an equally important task. In this work, we present a novel approach for efficient and accurate model-agnostic anomaly explanation for tabular data using Predicate-based Association Rules (PARs). PARs can provide intuitive explanations not only about which features of the anomaly instance are abnormal, but also the reasons behind their abnormality. Our user study indicates that the anomaly explanation form of PARs is better comprehended and preferred by regular users of anomaly detection systems as compared to existing model-agnostic explanation options. Furthermore, we conduct extensive experiments on various benchmark datasets, demonstrating that PARs compare favorably to state-of-the-art model-agnostic methods in terms of computing efficiency and explanation accuracy on anomaly explanation tasks. The code for our experiments is available at https://github.com/cfeng783/PARs.","2024","2025-02-19 14:42:25","2025-02-19 14:42:25","","612–621","","","","","","","CIKM '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","model-agnostic anomaly explanation; predicate-based association rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ5ATNVP","journalArticle","2008","Motik, Boris; Rosati, Riccardo","Reconciling description logics and rules","J. ACM","","0004-5411","10.1145/1754399.1754403","https://doi.org/10.1145/1754399.1754403","Description logics (DLs) and rules are formalisms that emphasize different aspects of knowledge representation: whereas DLs are focused on specifying and reasoning about conceptual knowledge, rules are focused on nonmonotonic inference. Many applications, however, require features of both DLs and rules. Developing a formalism that integrates DLs and rules would be a natural outcome of a large body of research in knowledge representation and reasoning of the last two decades; however, achieving this goal is very challenging and the approaches proposed thus far have not fully reached it. In this paper, we present a hybrid formalism of MKNF+ knowledge bases, which integrates DLs and rules in a coherent semantic framework. Achieving seamless integration is nontrivial, since DLs use an open-world assumption, while the rules are based on a closed-world assumption. We overcome this discrepancy by basing the semantics of our formalism on the logic of minimal knowledge and negation as failure (MKNF) by Lifschitz. We present several algorithms for reasoning with MKNF+ knowledge bases, each suitable to different kinds of rules, and establish tight complexity bounds.","2008-06","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","5","57","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","answer set programming; combined complexity; data complexity; Description logics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SA8EQ98G","conferencePaper","1999","Brüninghaus, Stefanie; Ashley, Kevin D.","Toward adding knowledge to learning algorithms for indexing legal cases","Proceedings of the 7th International Conference on Artificial Intelligence and Law","1-58113-165-8","","10.1145/323706.323709","https://doi.org/10.1145/323706.323709","Case-based reasoning systems have shown great promise for legal argumentation, but their development and wider availability are still slowed by the cost of manually representing cases. In this paper, we present our recent progress toward automatically indexing legal opinion texts for a CBR system. Our system SMILE uses a classification-based approach to find abstract fact situations in legal texts. To reduce the complexity inherent in legal texts, we take the individual sentences from a marked-up collection of case summaries as examples. We illustrate how integrating a legal thesaurus and linguistic information with a machine learning algorithm can help to overcome the difficulties created by legal language. The paper discusses results from a preliminary experiment with a decision tree learning algorithm. Experiments indicate that learning on the basis of sentences, rather than full documents, is effective. They also confirm that adding a legal thesaurus to the learning algorithm leads to improved performance for some, but not all, indexing concepts.","1999","2025-02-19 14:42:25","2025-02-19 14:42:25","","9–17","","","","","","","ICAIL '99","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Oslo, Norway","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N2NVFMAX","conferencePaper","1993","Yoshino, Hajime; Haraguchi, Makoto; Sakurai, Seiichiro; Kagayama, Sigeru","Towards a legal analogical reasoning system: knowledge representation and reasoning methods","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.158990","https://doi.org/10.1145/158976.158990","Analogy has many important functions in the domain of law. Since the number of legal rules is restricted and their content is often incomplete, it is necessary at times for a lawyer to opt for an analogical application of a legal rule to a given case in order to decide the case properly. He may apply the rule, though it may not have originally been deemed related to such an event, on the basis of some similarity between the event of the case and the requirement of the relevant legal rule. This type of reasoning is called legal analogy. This paper analyzes an actual case of legal analogy in the field of Japanese civil law in order to clarify the reasoning methods used in analogy, as well as knowledge to justify the analogy. Finally it will be shown how the knowledge is utilized in a symbolic reasoning system both in terms of inverse and standard resolution.","1993","2025-02-19 14:42:25","2025-02-19 14:42:25","","110–116","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52UQI3SR","conferencePaper","2011","Wlodarczyk, Tomasz Wiktor; Rong, Chunming; O'Connor, Marting; Musen, Mark","SWRL-F: a fuzzy logic extension of the semantic web rule language","Proceedings of the International Conference on Web Intelligence, Mining and Semantics","978-1-4503-0148-0","","10.1145/1988688.1988735","https://doi.org/10.1145/1988688.1988735","Enhancing Semantic Web technologies with ability to express uncertainty and imprecision is widely discussed topic. While SWRL can provide additional expressivity to OWL-based ontologies, it does not provide any way to handle uncertainty or imprecision. There is a pressing need to provide a standard-based, simple and functioning solution. We describe an extension of SWRL called SWRL-F that we believe can provides such a solution. SWRL-F is based on SWRL rule language and uses SWRL's strong semantic foundation as its formal underpinning. We extend it with a SWRL-F ontology to enable fuzzy reasoning in the rule base basing on the fuzzy control systems approach. The resulting language provides small but powerful set of fuzzy operations that do not introduce inconsistencies in the host ontology. We present it basing on the example of risk assessment in oil and gas industry which was a driving use case for this project.","2011","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","WIMS '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sogndal, Norway","","","","risk; fuzzy; fuzzy logic; fuzzy rules; rule language; SWRL; SWRL-F","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NYWU6NUD","conferencePaper","2020","Wang, Guan-Ren; Chen, Peng-Sheng","A GCC-based Compliance Checker for Single-translation-unit, Identifier-related MISRA-C Rules","Workshop Proceedings of the 49th International Conference on Parallel Processing","978-1-4503-8868-9","","10.1145/3409390.3409396","https://doi.org/10.1145/3409390.3409396","MISRA-C is a well-defined software specification for the C programming language that gives programmers criteria to develop reliable programs. This paper implements a MISRA-C compliance checker based on the GCC compiler infrastructure. It focuses on identifier-related rules that are single-translation-unit-labeled. We describe and develop strategies for implementing the checking codes. We also discuss the rules that can be detected by existing GCC options. For the tested benchmark programs, the modified GCC compiler can correctly assess compliance with the target MISRA- C rules.","2020","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","ICPP Workshops '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Edmonton, AB, Canada","","","","compiler; GCC; MISRA-C; reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQ6HK8P5","conferencePaper","2014","Jain, Ritika; Ghaisas, Smita; Sureka, Ashish","SANAYOJAN: a framework for traceability link recovery between use-cases in software requirement specification and regulatory documents","Proceedings of the 3rd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering","978-1-4503-2846-3","","10.1145/2593801.2593804","https://doi.org/10.1145/2593801.2593804","User requirement specification (URS) documents written in the form of free-form natural language text contain system use-case descriptions as one of the elements in the URS. For a few application domains, some of the system use-cases in SRS define services and functionality which needs to comply with law, rules and regulations pertaining to the application domain. In this paper, we present a multi-step approach to automatically extract system use-cases from URS and construct traceability links between system-uses and appropriate regulations in the regulatory documents. We define lexicon-based, syntactic and semantic features to discriminate system use-cases from other elements in the SRS. We investigate the application of five semantic similarity methods implemented in the SEMILAR semantic similarity toolkit to compute similarity between a given system use-case with regulations in a regulatory document. We conduct a series of experiments on real-world data obtained from software projects of a large global Information Technology (IT) services company to validate the proposed approach. Experimental results demonstrate effectiveness (accuracy of 83.3% for system use-case extraction and 72% for constructing traceability links) and limitations of the proposed approach.","2014","2025-02-19 14:42:25","2025-02-19 14:42:25","","12–18","","","","","","","RAISE 2014","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hyderabad, India","","","","Regulatory Compliance; Natural Language Processing; Requirements Engineering; Mining Software Repositories; Text Mining; Traceability Link Recovery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NFBBXI2","journalArticle","1997","Pal, Kamalendu; Campbell, John A.","An application of rule-based and case-based reasoning within a single legal knowledge-based system","SIGMIS Database","","0095-0033","10.1145/277339.277344","https://doi.org/10.1145/277339.277344","A knowledge-based system, Advisory Support for Home Settlement in Divorce (ASHSD), which gives advice on different aspects of matrimonial-home-settlement in English divorce law is described. The system employs two reasoning methods, rule-based reasoning (RBR) and case-based reasoning (CBR) in an integrated framework. It automates the estimation of the relative suitability of these reasoning methods for any given new case. This relative suitability is judged by matching the features of the selected best case and best rule against the new case. Standard methods of numerical taxonomy are used to determine which of the matches is best, and therefore whether a new case is better solved by calling on rules that express the usual legal knowledge in the area or by referring to a past case that has a interpretation of an ambiguous situation which rules fail to underpin.","1997-09","2025-02-19 14:42:25","2025-02-19 14:42:25","","48–63","","4","28","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","case-based reasoning; law; knowledge-based system; numerical taxonomy; rule-based reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N43LS67P","journalArticle","2018","Gall, Daniel; Frühwirth, Thom","An Operational Semantics for the Cognitive Architecture ACT-R and Its Translation to Constraint Handling Rules","ACM Trans. Comput. Logic","","1529-3785","10.1145/3218818","https://doi.org/10.1145/3218818","Computational psychology has the aim to explain human cognition by computational models of cognitive processes. The cognitive architecture Adaptive Control of Thought–Rational (ACT-R) is popular to develop such models. Although ACT-R has a well-defined psychological theory and has been used to explain many cognitive processes, there are two problems that make it hard to reason formally about its cognitive models: First, ACT-R lacks a computational formalization of its underlying production rule system, and, second, there are many different implementations and extensions of ACT-R with many technical artifacts complicating formal reasoning even more.This article describes a formal operational semantics—the very abstract semantics—that abstracts from as many technical details as possible, keeping it open to extensions and different implementations of the ACT-R theory. In a second step, this semantics is refined to define some of its abstract features that are found in many implementations of ACT-R—called the abstract semantics. It concentrates on the procedural core of ACT-R and is suitable for analysis of the general transition system, since it still abstracts from details like timing, the sub-symbolic layer of ACT-R or conflict resolution.Furthermore, a translation of ACT-R models to the declarative programming language Constraint Handling Rules (CHR) is defined. This makes the abstract semantics an executable specification of ACT-R. CHR has been used successfully to embed other rule-based formalisms like graph transformation systems or functional programming. There are many theoretical results and practical tools that support formal reasoning about and analysis of CHR programs. The translation of ACT-R models to CHR is proven sound and complete w.r.t. the abstract operational semantics of ACT-R. This paves the way to analysis of ACT-R models through CHR analysis results and tools. Therefore, to the best of our knowledge, our abstract semantics is the first abstract formulation of ACT-R suitable for both analysis and execution.","2018-09","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","3","19","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","ACT-R; Computational cognitive modeling; Constraint Handling Rules; operational semantics; source to source transformation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JIDRS7Y","conferencePaper","2012","Hu, Yuh-Jong; Wu, Win-Nan; Cheng, Di-Rong","Towards law-aware semantic cloud policies with exceptions for data integration and protection","Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics","978-1-4503-0915-8","","10.1145/2254129.2254162","https://doi.org/10.1145/2254129.2254162","The main issues related to cloud computing implementation are security, privacy, and law-awareness. We consider data protection with law-awareness as the major concern for cloud service providers (CSPs) and their customers. Therefore, we provide Law-as-a-Service (LaaS) for CSPs on our law-aware semantic cloud policy infrastructure. The semantic legal policies in compliance with the laws are enforced automatically at the super-peer to enable LaaS. This allows CSPs to deploy their cloud resources and services without worrying about law violations. Afterward, users could query data from the law-aware super-peer within a super-peer domain. Each query is also compliant with the laws. Policies are shown as a combination of OWL-DL ontologies and stratified Datalog rules with negation for a policy's exceptions handling through defeasible (or non-monotonic) reasoning. Finally, the proof-of-concepts prototype systems have been implemented for an H1N1 pandemic investigation scenario in the semantic cloud to justify our approach.","2012","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","WIMS '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Craiova, Romania","","","","privacy; legal policies; semantic web; privacy protection; cloud computing; defeasible reasoning; Law-as-a-Service (LaaS); semantic cloud; stratified datalog with negation; WWW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C9WKUMTC","journalArticle","2010","Vimercati, Sabrina De Capitani Di; Foresti, Sara; Jajodia, Sushil; Paraboschi, Stefano; Samarati, Pierangela","Encryption policies for regulating access to outsourced data","ACM Trans. Database Syst.","","0362-5915","10.1145/1735886.1735891","https://doi.org/10.1145/1735886.1735891","Current access control models typically assume that resources are under the strict custody of a trusted party which monitors each access request to verify if it is compliant with the specified access control policy. There are many scenarios where this approach is becoming no longer adequate. Many clear trends in Web technology are creating a need for owners of sensitive information to manage access to it by legitimate users using the services of honest but curious third parties, that is, parties trusted with providing the required service but not authorized to read the actual data content. In this scenario, the data owner encrypts the data before outsourcing and stores them at the server. Only the data owner and users with knowledge of the key will be able to decrypt the data. Possible access authorizations are to be enforced by the owner. In this article, we address the problem of enforcing selective access on outsourced data without need of involving the owner in the access control process. The solution puts forward a novel approach that combines cryptography with authorizations, thus enforcing access control via selective encryption. The article presents a formal model for access control management and illustrates how an authorization policy can be translated into an equivalent encryption policy while minimizing the amount of keys and cryptographic tokens to be managed. The article also introduces a two-layer encryption approach that allows the data owner to outsource, besides the data, the complete management of the authorization policy itself, thus providing efficiency and scalability in dealing with policy updates. We also discuss experimental results showing that our approach is able to efficiently manage complex scenarios.","2010-05","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","2","35","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","privacy; Data outsourcing; encryption policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7SZQWNR","conferencePaper","2011","Thi, Thanh Thoa Pham; Helfert, Markus; Hossain, Fakir; Dinh, Thang Le","Discovering business rules from business process models","Proceedings of the 12th International Conference on Computer Systems and Technologies","978-1-4503-0917-2","","10.1145/2023607.2023652","https://doi.org/10.1145/2023607.2023652","Discovering business rules from business process models are of advantage to ensure the compliance of business processes with business rules. Furthermore it provides the agility of business processes in case of business rules evolution. Current approaches are limited on types of rules that can be discovered. This paper analyses the expression power of some popular business process modelling languages in embedding business rules in its presentation and provides indicators to extract various types of business rules from business process models.","2011","2025-02-19 14:42:25","2025-02-19 14:42:25","","259–265","","","","","","","CompSysTech '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vienna, Austria","","","","business process models; business rules; EPC; Petri nets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWZBZ2XU","conferencePaper","2021","Hussain, Shahid; Chicoine, Kaley; Norris, Boyana","Empirical Investigation of Code Quality Rule Violations in HPC Applications","Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering","978-1-4503-9053-8","","10.1145/3463274.3463787","https://doi.org/10.1145/3463274.3463787","In large, collaborative open-source projects, developers must follow good coding standards to ensure the quality and sustainability of the resulting software. This is especially a challenge in high-performance computing projects, which admit a diverse set of contributions over decades of development. Some successful projects, such as the Portable, Extensible Toolkit for Scientific Computation (PETSc), have created comprehensive developer documentation, including specific code quality rules, which should be followed by contributors. However, none of the widely used and highly active open-source HPC projects have a way to automatically check whether these rules, typically expressed informally in English, are being violated. Hence, compliance checking is labor-intensive and difficult to ensure. To address this issue, we propose an automated method for detecting rule violations in HPC applications based on the PETSc development rules. In our empirical study, we consider 46 PETSc-based applications and assess the violations of two C-usage rules. The experimental results demonstrate the efficacy of the proposed method in identifying PETSc rule violations, which can be broadened to other HPC frameworks and extended by us and others in the community to include more rules.","2021","2025-02-19 14:42:25","2025-02-19 14:42:25","","402–411","","","","","","","EASE '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trondheim, Norway","","","","Code quality; developer rules violations; high-performance applications; libclang; LLVM; PETSc; process improvement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CUW87US7","conferencePaper","1993","Cuthill, Barbara; McCartney, Robert","Issue spotting in legal cases","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.159007","https://doi.org/10.1145/158976.159007","For any system that uses previous experience to solve problems in new situations, it is necessary to identify the features in the situation that should match features in the previous cases through some process of situation analysis. In this paper, we examine as issue spotting; in particular, we present how issues spotting is implemented in CHASER, a legal reasoning system that works in the domain of tort law.The approach presented here is a compromise between generality and efficiency, and is applicable to a range of problems and domains outside of legal reasoning. In particular, it presents a principled way to use multiple cases for a single problem by exploiting the inherent structure present in many domains.","1993","2025-02-19 14:42:25","2025-02-19 14:42:25","","245–253","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZWQ5V532","conferencePaper","2014","Durand, William; Salva, Sébastien","Inferring models with rule-based expert systems","Proceedings of the 5th Symposium on Information and Communication Technology","978-1-4503-2930-9","","10.1145/2676585.2676615","https://doi.org/10.1145/2676585.2676615","Many works related to software engineering rely upon formal models, e.g., to perform model-checking or automatic test case generation. Nonetheless, producing such models is usually tedious and error-prone. Model inference is a research field helping in producing models by generating partial models from documentation or execution traces (observed action sequences). This paper presents a new model generation method combining model inference and expert systems. It appears that an engineer is able to recognise the functional behaviours of an application from its traces by applying deduction rules. We propose a framework, applied to Web applications, simulating this reasoning mechanism, with inference rules organised into layers. Each yields partial IOSTSs (Input Output Symbolic Transition Systems), which become more and more abstract and understandable.","2014","2025-02-19 14:42:25","2025-02-19 14:42:25","","92–101","","","","","","","SoICT '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hanoi, Viet Nam","","","","automatic testing; expert system; IOSTS; model inference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QH8YVMT9","conferencePaper","2016","Touretzky, David S.; Gardner-McCune, Christina; Aggarwal, Ashish","Teaching ""Lawfulness"" With Kodu","Proceedings of the 47th ACM Technical Symposium on Computing Science Education","978-1-4503-3685-7","","10.1145/2839509.2844652","https://doi.org/10.1145/2839509.2844652","This paper introduces reasoning about lawful behavior as an important computational thinking skill and provides examples from a novel introductory programming curriculum using Microsoft's Kodu Game Lab. We present an analysis of assessment data showing that rising 5th and 6th graders can understand the lawfulness of Kodu programs. We also discuss some misconceptions students may develop about Kodu, their causes, and potential remedies.","2016","2025-02-19 14:42:25","2025-02-19 14:42:25","","621–626","","","","","","","SIGCSE '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Memphis, Tennessee, USA","","","","formal reasoning; kodu game lab; programming idioms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C867LPD4","journalArticle","2021","Wiese, Eliane S.; Linn, Marcia C.","“It Must Include Rules”: Middle School Students’ Computational Thinking with Computer Models in Science","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/3415582","https://doi.org/10.1145/3415582","When middle school students encounter computer models of science phenomenon in science class, how do they think those computer models work? Computer models operationalize real-world behaviors of selected variables, and can simulate interactions between the modeled elements through programmed instructions. This study explores how middle school students think about the high-level semantic meaning of those instructions, which we term rules. To investigate this aspect of students’ computational thinking, we developed the Computational Modeling Inventory and administered it to 253 7th grade students. The Inventory included three computer models that students interacted with during the assessment. In our sample, 99% of students identified at least one key rule underlying a model, but only 14% identified all key rules; 65% believed that model rules can contradict; and 98% could not distinguish between emergent patterns and behaviors that directly resulted from model rules. Despite these misconceptions, compared to the “typical” questions about the science content alone, questions about model rules elicited deeper science thinking, with 2–10 times more responses including reasoning about scientific mechanisms. These results suggest that incorporating computational thinking instruction into middle school science courses might yield deeper learning and more precise assessments around scientific models.","2021-04","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","2","28","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","computer models; computer models in science; Middle school science","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHLN28DL","conferencePaper","2003","Kerrigan, Shawn; Heenan, Charles; Wang, Haoyi; Law, Kincho H.; Wiederhold, Gio","Regulatory information management and compliance assistance","Proceedings of the 2003 Annual National Conference on Digital Government Research","","","","","The REGNET Project aims to develop a formal information infrastructure for regulatory information management and compliance assistance. This paper discusses three components of current research and development efforts. The first is a document repository containing federal and state regulations and supplemental documents. This repository includes a suite of concept hierarchies that enable users to browse documents according to the terms they contain. The second is an XML framework for representing regulations and associated metadata. The XML framework enables the augmentation of regulation text with tools and information that will help users understand and comply with the regulation. The third component is the creation of a compliance assistance system built upon the XML framework. The compliance assistance system and the document repository can serve as a backend for the development of application-specific compliance guidance systems. The prototype effort for the document repository has been focused on environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management.","2003","2025-02-19 14:42:25","2025-02-19 14:42:25","","1–6","","","","","","","dg.o '03","","","","Digital Government Society of North America","","","","","","","","","Place: Boston, MA, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QCFKLZY6","conferencePaper","1987","Belzer, M.","Legal reasoning in 3-D","Proceedings of the 1st International Conference on Artificial Intelligence and Law","0-89791-230-6","","10.1145/41735.41753","https://doi.org/10.1145/41735.41753","This article contains a theory of normative defeasible reasoning based on the modal deontic logic 3-D. The concept of “relative weight” between competing norms is defined, and 3-D is used to formalize two types of legal reasoning (“subsumptive” and “means/end”). A general overview is given of a PROLOG program, 3dpr, that implements the 3-D based theory of normative reasoning.","1987","2025-02-19 14:42:25","2025-02-19 14:42:25","","155–163","","","","","","","ICAIL '87","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V3EM9ZVH","conferencePaper","2024","Hou, Yi; Jin, Wuxia; Wang, Zhijun; Wang, Liuming; Chen, Shuguang; Wang, Yihan; Sang, Lei; Wang, Haijun; Liu, Ting","ERD-CQC : Enhanced Rule and Dependency Code Quality Check for Java","Proceedings of the 15th Asia-Pacific Symposium on Internetware","979-8-4007-0705-6","","10.1145/3671016.3674820","https://doi.org/10.1145/3671016.3674820","In the field of software development, the application of code quality check tools has become a key factor in improving product quality and development efficiency. While many existing tools are effective at detecting common problems in code, there are still some limitations. Firstly, these tools rely on predefined rules that may not fully encompass real-world coding challenges. Secondly, a lack of consideration of dependencies leads to failure to report violations occurring across files or modules. Third, the metrics used by these tools primarily focus on object-oriented programming, limiting their ability to assess software quality from the perspective of nationalized standards. To address these issues, this work proposes a dependency-enhanced method namely ERD-CQC for code quality detection and measurement. ERD-CQC provides 88 detection rules and 45 metrics, supplementing checking rules in categories such as Circuit Breaking, Serializable, and Security. ERD-CQC constructs an infused graph by integrating abstract syntax trees (ASTs), entities, and dependencies for violation detection. Based on the detection results, ERD-CQC provides a code quality measurement system with 4 nationalized standard dimensions for the purpose of measuring code quality from multiple perspectives. To validate the effectiveness of ERD-CQC, we manually examined 647 compliant and 528 non-compliant code snippets. ERD-CQC achieves the recall and F1 score exceeding 98%. We also collected open-source projects and closed-source projects in the real world, containing a total of 4,319 non-compliant code snippets. On this real-world benchmark, the average F1 score of ERD-CQC is 11.44% higher than the advanced tool SonarQube. Finally, we visualized the quality measurement results based on metrics and found that open-source and closed-source projects have certain patterns in metric performance. Our work will benefit developers in checking, evaluating, and monitoring their software quality comprehensively.","2024","2025-02-19 14:42:25","2025-02-19 14:42:25","","377–386","","","","","","","Internetware '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Macau, China","","","","Code Quality check tools; Metrics; Scanning rules; Software quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PKSRF2LL","conferencePaper","2003","Kerrigan, Shawn; Heenan, Charles; Wang, Haoyi; Law, Kincho H.; Wiederhold, Gio","Regulatory information management and compliance assistance","Proceedings of the 2003 Annual National Conference on Digital Government Research","","","","","The REGNET Project aims to develop a formal information infrastructure for regulatory information management and compliance assistance. This demo illustrates three components of current research and development efforts. The first is a document repository containing federal and state regulations and supplemental documents. This repository includes a suite of concept hierarchies that enable users to browse documents according to the terms they contain. The second is an XML framework for representing regulations and associated metadata. The XML framework enables the augmentation of regulation text with tools and information that will help users understand and comply with the regulation. The third component is the creation of a compliance assistance system built upon the XML framework. The compliance assistance system and the document repository can serve as a backend for the development of application-specific compliance guidance systems. The prototype effort for the document repository has been focused on environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management. Our paper in the dg.o 2003 conference proceedings describes this research in greater detail.","2003","2025-02-19 14:42:25","2025-02-19 14:42:25","","1","","","","","","","dg.o '03","","","","Digital Government Society of North America","","","","","","","","","Place: Boston, MA, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TK7QFTJW","conferencePaper","2019","Locke, Daniel; Zuccon, Guido","Towards Automatically Classifying Case Law Citation Treatment Using Neural Networks","Proceedings of the 24th Australasian Document Computing Symposium","978-1-4503-7766-9","","10.1145/3372124.3372128","https://doi.org/10.1145/3372124.3372128","In common law legal systems, judges decide issues between parties (legal decision or case law) by reference to previous decisions that consider similar factual situations. Accordingly, these decisions typically feature rich citation networks, i.e., a new decision frequently cites previous relevant decisions (citation). These citations may, in varying degrees, express that a cited decision is applicable, not-applicable, or no longer current law. Such treatment label is important to a lawyer's process of determining whether a case is proper law. These labels serve as a matter of convenience in citation indices enabling lawyers to prioritise decisions to examine to understand the current state of the law. They also prove useful in other areas such as prioritisation for manual summarisation of cases, where not all cases can be summarised, and automatic summarisation, or, potentially, as a ranking feature in case law retrieval. While a lawyer can determine the treatment of a cited case by reading a decision, this is time consuming and can increase legal costs. Currently, not all newly decided cases feature these treatment labels. Further, older cases typically do not. Given the large amount of new legal decisions decided each year, manual annotation of such treatment is not feasible. In this paper, we explore the effectiveness of neural network architectures for identifying case law citation treatment and importance (whether a case is important to a lawyer's reasoning process). We find that these tasks are very difficult and various methods for text classification perform poorly. We address more comprehensively the task of citation importance for this reason while limiting our examination of the task of citation treatment to the modelling of the problem and the highlight of the intrinsic difficulty of the task. We make a test dataset available at github.com/ielab/caselaw-citations to stimulate further research that tackles this challenging problem. We also contribute a range of word embeddings learned over a large amount of processed case law text.","2019","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","ADCS '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sydney, NSW, Australia","","","","Case law retrieval; Citation networks; Neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H7L2TET6","journalArticle","2024","Shahrzad, Hormoz; Hodjat, Babak; Miikkulainen, Risto","EVOTER: Evolution of Transparent Explainable Rule sets","ACM Trans. Evol. Learn. Optim.","","","10.1145/3702651","https://doi.org/10.1145/3702651","Most AI systems are black boxes generating reasonable outputs for given inputs. Some domains, however, have explainability and trustworthiness requirements that cannot be directly met by these approaches. Various methods have therefore been developed to interpret black-box models after training. This paper advocates an alternative approach where the models are transparent and explainable to begin with. This approach, EVOTER, evolves rule sets based on extended propositional logic expressions. The approach is evaluated in several prediction/classification and prescription/policy search domains with and without a surrogate. It is shown to discover meaningful rule sets that perform similarly to black-box models. The rules can provide insight into the domain and make hidden biases explicit. It may also be possible to edit the rules directly to remove biases and add constraints. EVOTER thus forms a promising foundation for building trustworthy AI systems for real-world applications in the future.","2024-11","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Explainable AI; XAI; Genetic Algorithms; rule set Evolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FF93EMIF","conferencePaper","2010","Heymans, Stijn; Korf, Roman; Erdmann, Michael; Puhrer, Jorg; Eiter, Thomas","F-Logic#: Loosely Coupling F-Logic Rules and Ontologies","Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 01","978-0-7695-4191-4","","10.1109/WI-IAT.2010.44","https://doi.org/10.1109/WI-IAT.2010.44","In W3C’s Rule Interchange Format (RIF), F-Logic rules have received considerable attention as a major logical rule formalism, while combinations of rules with Description Logic (DL) ontologies in RIF, let alone with F-Logic rules, are far less developed. To mend this, we first present F-Logic# knowledge bases, a framework based on the semantics of the well-investigated dl-programs, that provides a loose coupling approach to integrating F-Logic rules and DL ontologies by allowing rules to query the ontology using external atoms. We investigate the semantical properties of this framework and define a stratified fragment that allows for fast reasoning — a necessity on a Web with large amounts of data. We then shape F-Logic# as a RIF dialect, setting it firmly in a Web context and providing an expressive combination of F-Logic rules with DL ontologies in RIF. Finally, we show how to extend the F-Logic rule engine OntoBroker towards reasoning with F-Logic#, enabling as such a first commercial implementation for loosely-coupled ontologies and rules.","2010","2025-02-19 14:42:25","2025-02-19 14:42:25","","248–255","","","","","","","WI-IAT '10","","","","IEEE Computer Society","USA","","","","","","","","","","","","ontologies; F-Logic; integration; logical rules; Ontobroker","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KBK4GSX3","conferencePaper","2014","Denil, Joachim; Mosterman, Pieter J.; Vangheluwe, Hans","Rule-based model transformation for, and in simulink","Proceedings of the Symposium on Theory of Modeling &amp; Simulation - DEVS Integrative","","","","","Over the past decade, the design of embedded systems has come to rely on models as electronic artifacts that are both analysable and executable. Such executable models are at the core of Model-Based Design. Simulink® is a popular Model-Based Design tool that supports simulation of models in various stages of design. While Simulink supports relating the various different models used in design, the technology to do so relies on the underlying Simulink code base. Instead, this paper employs explicit models of the relations between the various different design models. In particular, a rule-based approach is presented for model-to-model transformations. The abstraction from the code base provides benefits such as a more intuitive representation and the ability to more effectively reason about the transformations. The transformation rules and schedules are designed by augmenting standard Simulink model elements (e.g., blocks) for use in model transformation based on the structured RAMification approach. The approach is illustrated by the transformation of a continuous-time model, part of an adaptive controller, to a disrete-time counterpart, which is consecutively optimized for simulation.","2014","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","DEVS '14","","","","Society for Computer Simulation International","San Diego, CA, USA","","","","","","","","event-place: Tampa, Florida","","","","model-based design; model-driven engineering; model-transformation; simulink","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YW9NF5Y7","conferencePaper","2010","Vineetha, S.; Bhat, C. Chandra Shekara; Idicula, Sumam Mary","Gene regulatory network from microarray data using dynamic neural fuzzy approach","Proceedings of the International Symposium on Biocomputing","978-1-60558-722-6","","10.1145/1722024.1722044","https://doi.org/10.1145/1722024.1722044","The paper presents a multilayered dynamic neural fuzzy network (DNFN) to extract regulatory relationship among genes and reconstruct gene regulatory network for circulating plasma RNA data from colon cancer patients. This method combines the merits of connectionist and fuzzy approaches. It encodes the knowledge learned in the form of fuzzy rules and processes data following fuzzy reasoning principles. While the dynamic aspect of gene regulation was taken into account through the on-line learning of fuzzy rules, the structural learning together with the parameter learning form a fast learning algorithm for building a small, yet powerful, dynamic neural fuzzy network. One of the main advantages of DNFN is that there is no predetermination of hidden nodes, since it can find its optimal structure automatically and quickly. The inferred knowledge using the above network may provide biological insights that can be used to design and interpret further experiments.","2010","2025-02-19 14:42:25","2025-02-19 14:42:25","","","","","","","","","ISB '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Calicut, Kerala, India","","","","fuzzy logic; gene regulatory networks; microarray data; neurofuzzy logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XC7K77JC","conferencePaper","2021","Yudhistyra, Wecka Imam; Raungratanaamporn, I-soon; Ratanavaraha, Vatanavongs","Implementation of Big Data Analytics: Customers Analyzing using an Association Rule Modeling in a Gold, Silver, and Precious Metal Trading Company in Indonesia","Proceedings of the 2020 International Conference on Big Data in Management","978-1-4503-7506-1","","10.1145/3437075.3437078","https://doi.org/10.1145/3437075.3437078","The underlying reason for this manuscript is to implement big data analytics to find meaningful patterns and offer useful insights from a large amount of big data available. Since many companies are still struggling to optimize big data to support their business, it is essential to minimize the gap between a large amount of data available now and the skills to analyze it. In addition, there is also a deficiency in related publications in scientific journals regarding the implementation of Big Data Analytics (BDA), which makes this manuscript significant. In addition, BDA is a new interesting thing (particularly in a developing country like Indonesia or other ASEAN countries), it is hard to be implemented, and this manuscript tries to resolve most of that complex problem of practice including the critical issue and leverages it in ways that could positively influence the organization's decision-making process. Finally, the results of this manuscript are some recommendations for companies in conducting big data analytics.","2021","2025-02-19 14:42:25","2025-02-19 14:42:25","","3–7","","","","","","","ICBDM 2020","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Manchester, United Kingdom","","","","machine learning; analytics; association rules; Big data; enterprise computing; enterprise information systems; information visualization; knowledge discovery; modeling and simulation; pattern","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HX72PLA7","conferencePaper","2011","Sapkota, Krishna; Aldea, Arantza; Duce, David A.; Younas, Muhammad; Bañares-Alcántara, René","Semantic-ART: a framework for semantic annotation of regulatory text","Proceedings of the Fourth Workshop on Exploiting Semantic Annotations in Information Retrieval","978-1-4503-0958-5","","10.1145/2064713.2064727","https://doi.org/10.1145/2064713.2064727","Converting regulatory texts to machine interpretable models can enhance the automation of compliance management (CM) processes. The process poses serious research challenges as the information to be extracted from the regulatory texts comes from different regulatory bodies and is in different formats. In this paper, we present the main problems that we have faced in this area and how we have tackled them. Our proposed framework, Semantic-ART, considers the use of semantic annotation (SA) techniques to extract the regulations automatically.","2011","2025-02-19 14:42:25","2025-02-19 14:42:25","","23–24","","","","","","","ESAIR '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland, UK","","","","regulation; ontology; information extraction; semantic annotation; text analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7NUTIBC","conferencePaper","2013","Ingolfo, Silvia; Souza, Vítor E. Silva","Law and adaptivity in requirements engineering","Proceedings of the 8th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","978-1-4673-4401-2","","","","The great impact that law has on the design of software systems has been widely recognized in past years. However, little attention has been paid to the challenge of coping with variability characterizing the legal domain (e.g., multiple ways to comply with a given law, frequent updates to regulations, different jurisdictions, etc.) on the design of software systems. This position paper advocates the use of adaptation mechanisms in order to support regulatory compliance for software systems. First we show an example of how Zanshin, a requirements-based adaptation framework, can be used to design a system that adapts to legal requirements to accommodate legal variability. Then we examine how legal texts can be analyzed as sources for parameters and indicators needed to support adaptation. As motivating running example we consider legal situations concerning the Google driverless car and its recent legalization in the highways of Nevada and soon also in California.","2013","2025-02-19 14:42:25","2025-02-19 14:42:25","","163–168","","","","","","","SEAMS '13","","","","IEEE Press","","","","","","","","","Place: San Francisco, California","","","","regulatory compliance; requirements engineering; adaptation framework; legal variability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MFSJR3ZN","conferencePaper","2010","Maxwell, Jeremy C.; Antón, Annie I.","The production rule framework: developing a canonical set of software requirements for compliance with law","Proceedings of the 1st ACM International Health Informatics Symposium","978-1-4503-0030-8","","10.1145/1882992.1883092","https://doi.org/10.1145/1882992.1883092","The cost of noncompliance, as well as lost reputation and brand damage resulting from noncompliance, makes legal compliance critical in software systems. In this paper, we present a production rule framework that software engineers can to specify compliance requirements for software. A component of our framework is the production rule modeling methodology, which we have introduced in previous work [12, 14]. We apply the framework to check iTrust, an open source electronic medical records system, for compliance with the Health Insurance Portability and Accountability Act (HIPAA) Security Rule. We model the Security Rule using production rules and employ the model to analyze the iTrust requirements for legal compliance. Using the framework, we were able to identify 13 functional and 5 non-functional requirements that were previously overlooked using an agile driven software engineering approach. These new requirements are critical for compliance with the Security Rule.","2010","2025-02-19 14:42:25","2025-02-19 14:42:25","","629–636","","","","","","","IHI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Arlington, Virginia, USA","","","","legal compliance; software engineering; requirements engineering; security; healthcare it; production rule modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KC6A2D9F","conferencePaper","1993","Schild, Uri J.; Herzog, Shai","The use of meta-rules in rule based legal computer systems","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.158989","https://doi.org/10.1145/158976.158989","Rule-Based Systems in the legal domain are often obtained by formalizing legislation. We consider the addition of meta-knowledge in the form of meta-rules to such a system. Such an approach has many advantages both for control and for dealing with the intrinsic vagueness of legal rules. Legal computer systems of different kinds have been proposed and built over the years. In this paper we shall present a legal reasoning system which uses concepts discussed in this paper. The system consists of a knowledge base, obtained by formalizing legislation, and uses a meta-rules mechanism for deduction and legal reasoning.","1993","2025-02-19 14:42:25","2025-02-19 14:42:25","","100–109","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APW2TJWP","conferencePaper","2021","Loster, Michael; Mottin, Davide; Papotti, Paolo; Ehmüller, Jan; Feldmann, Benjamin; Naumann, Felix","Few-Shot Knowledge Validation using Rules","Proceedings of the Web Conference 2021","978-1-4503-8312-7","","10.1145/3442381.3450040","https://doi.org/10.1145/3442381.3450040","Knowledge graphs (KGs) form the basis of modern intelligent search systems – their network structure helps with the semantic reasoning and interpretation of complex tasks. A KG is a highly dynamic structure in which facts are continuously updated, added, and removed. A typical approach to ensure data quality in the presence of continuous changes is to apply logic rules. These rules are automatically mined from the data using frequency-based approaches. As a result, these approaches depend on the data quality of the KG and are susceptible to errors and incompleteness. To address these issues, we propose Colt, a few-shot rule-based knowledge validation framework that enables the interactive quality assessment of logic rules. It evaluates the quality of any rule by asking a user to validate only a few facts entailed by such rule on the KG. We formalize the problem as learning a validation function over the rule’s outcomes and study the theoretical connections to the generalized maximum coverage problem. Our model obtains (i)&nbsp;an accurate estimate of the quality of a rule with fewer than 20 user interactions and (ii)&nbsp;75% quality (F1) with 5% annotations in the task of validating facts entailed by any rule.","2021","2025-02-19 14:42:25","2025-02-19 14:42:25","","3314–3324","","","","","","","WWW '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ljubljana, Slovenia","","","","knowledge graph; neural networks; deep kernel learning; few-shot learning; knowledge base; knowledge validation; logic rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VXVZVN22","conferencePaper","1989","Wahlgren, P.","Legal reasoning - a jurisprudential description","Proceedings of the 2nd International Conference on Artificial Intelligence and Law","0-89791-322-1","","10.1145/74014.74034","https://doi.org/10.1145/74014.74034","This paper provides a description of a legal reasoning process. The presentation originates from a research project combining Law and Artificial Intelligence (AI) and contains theoretical results from system-developing activities that have been carried out in cooperation with the Swedish Court Administration and a major Swedish employer's association. The research project, and several parallel projects at the Swedish Law and Informatics Research Institute (IRI), is being documented in the series IRI-reports.Related work, especially focusing on computerized formalization of legal norms and legal decision processes from a jurisprudential perspective is carried out at The Norwegian Research Center for Computers and Law, but contributions have also been made by many others1 and legal reasoning has been investigated from somewhat different perspectives2.","1989","2025-02-19 14:42:25","2025-02-19 14:42:25","","147–156","","","","","","","ICAIL '89","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vancouver, British Columbia, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LRVSF9X","conferencePaper","1999","Yearwood, John; Stranieri, Andrew","The integration of retrieval, reasoning and drafting for refugee law: a third generation legal knowledge based system","Proceedings of the 7th International Conference on Artificial Intelligence and Law","1-58113-165-8","","10.1145/323706.323724","https://doi.org/10.1145/323706.323724","We identify an argument to be the basic unit of reasoning of a system that supports the construction of arguments and drafting of determinations in refugee law. Collaboration with the Refugee Review Tribunal of Australia has led to the development of a framework for argument construction that includes over 200 generic arguments. However, these arguments may not encompass all arguments used in any particular case. The construction of non-generic arguments involves the integration of information retrieval within reasoning. This retrieval is passage based from a wide variety of text sources. The framework also acts as the illocutionary structure in a document drafting process. In conceptualising this system we have found it useful to propose a classification of knowledge based systems in law.","1999","2025-02-19 14:42:25","2025-02-19 14:42:25","","117–125","","","","","","","ICAIL '99","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Oslo, Norway","","","","reasoning; information retrieval; argument structure; document drafting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVWQIR3L","conferencePaper","1989","Branting, L. K.","Representing and reusing explanations of legal precedents","Proceedings of the 2nd International Conference on Artificial Intelligence and Law","0-89791-322-1","","10.1145/74014.74029","https://doi.org/10.1145/74014.74029","Precedent-based legal reasoning depends on accurate assessment of relevant similarities between new cases and existing precedents. Determining the relevant similarities between a new case and a precedent with respect to a legal category requires knowing the explanation of the precedent's membership in the category. GREBE is a system that uses both general legal rules and specific explanations of precedents to evaluate legal predicates in new cases. GREBE assesses the similarity of a new case to a precedent of a legal category by attempting to find a pattern of relations in the new case that corresponds to the facts of the precedent responsible for its category membership. Missing relations in the new case are inferred by reusing other explanations from past cases.","1989","2025-02-19 14:42:25","2025-02-19 14:42:25","","103–110","","","","","","","ICAIL '89","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vancouver, British Columbia, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PKSYGB7N","conferencePaper","2003","Kimbrough, Steven O.; Lee, Thomas Y.; Padmanabhan, Balaji; Yang, Yinghui","Generating original structure in regulatory documents","Proceedings of the 2003 Annual National Conference on Digital Government Research","","","","","As technology and society continue to evolve, the size of the corpus of government policies and procedures continues to more than keep pace. The U.S. Federal Tax Code today consumes over 2.8 million words or 6000 pages. There are more than 20,000 cross-references both within the code itself and to external regulations. Navigating the sea of information is a daunting task for the IRS let alone a well-intentioned tax payer, or policy-maker seeking to eliminate redundancies, inconsistencies, or loopholes. While tools for tasks such as compliance checking or query answering have long held promise, automated reasoning, however intelligent, needs something to reason upon, a formalized knowledge base of some kind. In other domains people may be the primary targets of knowledge engineering; in the policy realm, much of the requisite knowledge resides in legal and regulatory documents.","2003","2025-02-19 14:42:25","2025-02-19 14:42:25","","1–4","","","","","","","dg.o '03","","","","Digital Government Society of North America","","","","","","","","","Place: Boston, MA, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8F7FHCWL","journalArticle","2020","Calvanese, Diego; Fodor, Paul; Montali, Marco","Report on the 3rd International Joint Conference on Rules and Reasoning (RuleML+RR 2019)","ACM SIGLOG News","","","10.1145/3397619.3397623","https://doi.org/10.1145/3397619.3397623","The annual International Joint Conference on Rules and Reasoning (RuleML+RR) is an international conference on research, applications, languages and standards for rule technologies, rule-based programming and rule-based systems including production rules systems, logic programming rule engines, as well as business-rule engines and management systems; Semantic Web rule languages and rule standards, including RuleML (e.g., Datalog+ RuleML, Reaction RuleML and LegalRuleML), SWRL, RIF, Common Logic, PRR, decision rules and Decision Model and Notation (DMN), as well as Semantics of Business Vocabulary and Business Rules (SBVR); rule-based Event Processing Languages (EPLs) and technologies; and foundational research on inference rules, transformation rules, decision rules, production rules, and Event-Condition-Action (ECA) rules. In 2017, RuleML+RR joined the efforts of two wellestablished conference series: the International Web Rule Symposia (RuleML) and the Web Reasoning and Rule Systems (RR) conferences, and it is now the leading conference to build bridges between academia and industry in the field of Web rules and its applications, especially as part of the Semantic Technology stack. RuleML+RR is commonly listed together with and related to other major high-impact Artificial Intelligence conferences worldwide, starting with IJCAI in 2011 and 2016, ECAI in 2012, AAAI in 2013, ECAI in 2014, the AI Summit London in 2017, and GCAI in 2018 and 2019. The RuleML symposia and RR conferences have been held since 2002 and 2007, respectively. The RR conferences have been a forum for discussion and dissemination of new results on Web reasoning and rule systems, with an emphasis on rule-based approaches and languages. The RuleML symposia have been devoted to disseminating research, applications, languages, and standards for rule technologies, with attention to both theoretical and practical developments, to challenging new ideas, and to industrial applications. Building on the tradition of both, RuleML and RR, the joint conference series RuleML+RR aims at bridging academia and industry in the field of rules, and at fostering the cross-fertilization between the different communities focused on the research, development, and applications of rule-based systems. RuleML+RR aims at being the leading conference series for all subjects concerning theoretical advances, novel technologies, and innovative applications about knowledge representation and reasoning with rules.","2020-04","2025-02-19 14:42:26","2025-02-19 14:42:26","","16–18","","2","7","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4ECYESF","journalArticle","2005","Peterson, Zachary; Burns, Randal","Ext3cow: a time-shifting file system for regulatory compliance","ACM Trans. Storage","","1553-3077","10.1145/1063786.1063789","https://doi.org/10.1145/1063786.1063789","The ext3cow file system, built on the popular ext3 file system, provides an open-source file versioning and snapshot platform for compliance with the versioning and audtitability requirements of recent electronic record retention legislation. Ext3cow provides a time-shifting interface that permits a real-time and continuous view of data in the past. Time-shifting does not pollute the file system namespace nor require snapshots to be mounted as a separate file system. Further, ext3cow is implemented entirely in the file system space and, therefore, does not modify kernel interfaces or change the operation of other file systems. Ext3cow takes advantage of the fine-grained control of on-disk and in-memory data available only to a file system, resulting in minimal degradation of performance and functionality. Experimental results confirm this hypothesis; ext3cow performs comparably to ext3 on many benchmarks and on trace-driven experiments.","2005-05","2025-02-19 14:42:26","2025-02-19 14:42:26","","190–212","","2","1","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","copy-on-write; Versioning file systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U8IA7PRA","conferencePaper","2019","Uliana, Emanuele; Stathis, Kostas; Jago, Robert","MagnetDroid: security-oriented analysis for bridging privacy and law for Android applications","Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law","978-1-4503-6754-7","","10.1145/3322640.3326729","https://doi.org/10.1145/3322640.3326729","MagnetDroid is a novel artificial intelligence framework that integrates a security ontology, a multi-agent organisation, and a logical reasoning procedure to help build a bridge between the worlds of Android application analysis and law, with respect to privacy. Our contribution helps identify violations of the law by Android applications, as well as predict legal consequences. The resulting implementation of MagnetDroid can be useful to privacy-concerned users in order to acknowledge problems with the privacy of the applications they use, to application developers/publishers to help them identify which problems to fix, and to lawyers in order to provide an additional level of interpretation for any court when considering the privacy of Android applications.","2019","2025-02-19 14:42:26","2025-02-19 14:42:26","","123–132","","","","","","","ICAIL '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, QC, Canada","","","","Law; Privacy; Ontologies; Android; Intelligent Agents; Logic Programming; Security","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UQNG8RT","conferencePaper","2015","Vinu, P. V.; Sherimon, P. C.; Krishnan, Reshmy","Modeling of Test Specifications of Raw Materials in Seafood Ontology using Semantic Web Rule Language (SWRL)","Proceedings of the 2015 International Conference on Advanced Research in Computer Science Engineering &amp; Technology (ICARCSET 2015)","978-1-4503-3441-9","","10.1145/2743065.2743066","https://doi.org/10.1145/2743065.2743066","The environmental risks of seafood are enormous which include, water pollution, metal pollution and other bacterial pollution. So the quality of seafood is a major concern to food processors and public health authorities around the world. Seafood companies implement the quality management systems in their platforms; mostly database oriented one. We have proposed ontology-based system for assuring the quality of seafood. Ontology based systems are semantically rich and have better clarity compared to database systems. Such systems enable information retrieval in a more meaningful way. Our model analyses the different lab test results with the standard specification guidelines, generates hazard reports, seafood quality reports, etc. This paper focuses on the ontology modeling of test specifications of raw material using Semantic Web Rule Language (SWRL). Protege 3.5 is used to implement the user interfaces of the model. As a case study, molluscus raw material is considered. The lab test results of molluscus sample are input to the system. Ontology reasoners check whether the test results satisfy the criteria according to the test specifications of molluscus, expressed in SWRL and display appropriate messages. An individual OWL (web ontology language) file is automatically created for each instance of the sample tested.","2015","2025-02-19 14:42:26","2025-02-19 14:42:26","","","","","","","","","ICARCSET '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Unnao, India","","","","ontology; chemical; microbiological; Protégé; Seafood; taxonomy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPDAWRF6","conferencePaper","1989","Lambert, K. A.; Grunewald, M. H.","LESTER: using paradigm cases in a Quasi-Precedential legal domain","Proceedings of the 2nd International Conference on Artificial Intelligence and Law","0-89791-322-1","","10.1145/74014.74027","https://doi.org/10.1145/74014.74027","We are developing LESTER (Legal Expert System for Termination of Employment Review), a case-based reasoning program to advise in the area of unjust discharge from employment under collective bargaining agreements. LESTER uses paradigm cases to reason in a legal domain that is not governed by a strong concept of precedent. This paper describes the domain and gives an overview of the current version of the program.","1989","2025-02-19 14:42:26","2025-02-19 14:42:26","","87–92","","","","","","","ICAIL '89","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vancouver, British Columbia, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDTHYASG","conferencePaper","2023","Bozzato, Loris; Serafini, Luciano","Ontology-Mediated Data Migration: Deriving Migration Rules by Reasoning on Schema Descriptions","Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing","978-1-4503-9517-5","","10.1145/3555776.3577616","https://doi.org/10.1145/3555776.3577616","Migration of data across information systems is a knowledge intensive task: the definition of mappings between systems requires knowledge of the source and target (relational) schemas and their interpretation of the shared domain. Moreover, direct schema mappings need often to be re-defined for each new migration instance, in order to accommodate the variations caused by the change of systems and representation conventions. A possible solution to such problems is the use of an intermediate ontological model, that can be used as a lingua franca for the description of schemas, by defining mappings from and to the ontology. While this helps in making explicit the semantics of the schemas, the problem remains on how to extract a direct mapping from source to target schema from this intermediate representation.In this paper, we present our ongoing work in building an ontology-based migration system in the scenario of banking information systems. In the architecture of the system, an ontology defines an intermediate semantic description for the source and target schemas. We introduce a reasoning method for the automatic extraction of migration rules starting from the semantic descriptions of the schemas. The procedure for computation of migration rules is then implemented via reasoning over an Answer Set Programming encoding.","2023","2025-02-19 14:42:26","2025-02-19 14:42:26","","1724–1731","","","","","","","SAC '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tallinn, Estonia","","","","data migration; ontology mediated migration; relational schema mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3ZSJYDX","book","2017","","ICAIL '17: Proceedings of the 16th edition of the International Conference on Articial Intelligence and Law","","978-1-4503-4891-1","","","","ICAIL 2017 is the 16th edition of the International Conference on Arti!cial Intelligence and Law and it is held at the King's College London. In addition to traditional AI and Law topics such as legal information retrieval, e-discovery, argumentation, formal model of legal reasoning, this edition solicited contributions on legal and ethical aspects of arti!cial intelligence to address the growing general interest and practical and emerging real life applications of AI techniques (for example, the emergence of autonomous vehicles). The !eld of Arti!cial Intelligence and Law proved to o""er a fruitful ground for applications in the real worlds. Accordingly, all contributions have to provide theoretical advancements as well as demonstration of how the techniques presented address real world problems in the legal domain.","2017","2025-02-19 14:42:26","2025-02-19 14:42:26","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6XFB4CE","journalArticle","2021","Salam, Abdus; Schwitter, Rolf; Orgun, Mehmet A.","Probabilistic Rule Learning Systems: A Survey","ACM Comput. Surv.","","0360-0300","10.1145/3447581","https://doi.org/10.1145/3447581","This survey provides an overview of rule learning systems that can learn the structure of probabilistic rules for uncertain domains. These systems are very useful in such domains because they can be trained with a small amount of positive and negative examples, use declarative representations of background knowledge, and combine efficient high-level reasoning with the probability theory. The output of these systems are probabilistic rules that are easy to understand by humans, since the conditions for consequences lead to predictions that become transparent and interpretable. This survey focuses on representational approaches and system architectures, and suggests future research directions.","2021-05","2025-02-19 14:42:26","2025-02-19 14:42:26","","","","4","54","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","probabilistic logic programming; Probabilistic rule learning; sub-symbolic rule learning; symbolic rule learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFFF8K88","conferencePaper","2018","Savage, Stefan","Lawful Device Access without Mass Surveillance Risk: A Technical Design Discussion","Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security","978-1-4503-5693-0","","10.1145/3243734.3243758","https://doi.org/10.1145/3243734.3243758","This paper proposes a systems-oriented design for supporting court-ordered data access to locked"" devices with system-encrypted storage, while explicitly resisting large-scale surveillance use. We describe a design that focuses entirely on passcode self-escrow (i.e., storing a copy of the user passcode into a write-only component on the device) and thus does not require any changes to underlying cryptographic algorithms. Further, by predicating any lawful access on extended-duration physical seizure, we foreclose mass-surveillance use cases while still supporting reasonable investigatory interests. Moreover, by couching per-device authorization protocols with the device manufacturer, this design avoids creating new trusted authorities or organizations while providing particularity (i.e., no ""master keys"" exist). Finally, by providing a concrete description of one such approach, we hope to encourage further technical consideration of the possibilities and limitations of trade-offs in this design space.","2018","2025-02-19 14:42:26","2025-02-19 14:42:26","","1761–1774","","","","","","","CCS '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HAUDXZCR","conferencePaper","2014","Gavaldà-Miralles, Arnau; Otto, John S.; Bustamante, Fabián E.; Amaral, Luís A.N.; Duch, Jordi; Guimerà, Roger","User Behavior and Change: File-sharers and Copyright Laws","Proceedings of the 10th ACM International on Conference on Emerging Networking Experiments and Technologies","978-1-4503-3279-8","","10.1145/2674005.2675009","https://doi.org/10.1145/2674005.2675009","Though the impact of file-sharing of copyrighted content has been discussed for over a decade, only in the past few years have countries begun to adopt legislation to criminalize this behavior. These laws impose penalties ranging from warnings and monetary fines to disconnecting Internet service. While their supporters are quick to point out trends showing the efficacy of these laws at reducing use of file-sharing sites, their analyses rely on brief snapshots of activity that cannot reveal long- and short-term trends.In this paper, we introduce an approach to model user behavior based on a hidden Markov model and apply it to analyze a two-year-long user-level trace of download activity of over 38k users from around the world. This approach allows us to quantify the true impact of file-sharing laws on user behavior, identifying behavioral trends otherwise difficult to identify. For instance, despite an initial reduction in activity in New Zealand when a three-strikes law took effect, after two months activity had returned to the level observed prior to the law being enacted. Given that punishment seems to, at best, result in short-term compliance, we suggest that incentives-based approaches may be more effective at changing user behavior.","2014","2025-02-19 14:42:26","2025-02-19 14:42:26","","319–324","","","","","","","CoNEXT '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sydney, Australia","","","","copyright law; file-sharing; user behavior","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KLFH4H3X","conferencePaper","2022","Zhang, Wen; Deng, Shumin; Chen, Mingyang; Wang, Liang; Chen, Qiang; Xiong, Feiyu; Liu, Xiangwen; Chen, Huajun","Knowledge Graph Embedding in E-commerce Applications: Attentive Reasoning, Explanations, and Transferable Rules","Proceedings of the 10th International Joint Conference on Knowledge Graphs","978-1-4503-9565-6","","10.1145/3502223.3502232","https://doi.org/10.1145/3502223.3502232","Knowledge Graphs (KGs), representing facts as triples, have been widely adopted in many applications. Reasoning tasks such as link prediction and rule induction are important for the development of KGs. Knowledge Graph Embeddings (KGEs) embedding entities and relations of a KG into continuous vector spaces, have been proposed for these reasoning tasks and proven to be efficient and robust. But the plausibility and feasibility of applying and deploying KGEs in real-work applications has not been well-explored. In this paper, we discuss and report our experiences of deploying KGEs in a real domain application: e-commerce. We first identity three important desiderata for e-commerce KG systems: 1) attentive reasoning, reasoning over a few target relations of more concerns instead of all; 2) explanation, providing explanations for a prediction to help both users and business operators understand why the prediction is made; 3) transferable rules, generating reusable rules to accelerate the deployment of a KG to new systems. While non existing KGE could meet all these desiderata, we propose a novel one, an explainable knowledge graph attention network that make prediction through modeling correlations between triples rather than purely relying on its head entity, relation and tail entity embeddings. It could automatically selects attentive triples for prediction and records the contribution of them at the same time, from which explanations could be easily provided and transferable rules could be efficiently produced. We empirically show that our method is capable of meeting all three desiderata in our e-commerce application and outperform typical baselines on datasets from real domain applications.","2022","2025-02-19 14:42:26","2025-02-19 14:42:26","","71–79","","","","","","","IJCKG '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Thailand","","","","Explainable AI; Reasoning; Rules; E-commerce; Knowledge Graphs; Representation Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NPZ79F6C","conferencePaper","2007","Sion, Radu; Winslett, Marianne","Regulatory-compliant data management","Proceedings of the 33rd International Conference on Very Large Data Bases","978-1-59593-649-3","","","","Digital societies and markets increasingly mandate consistent procedures for the access, processing and storage of information. In the United States alone, over 10,000 such regulations can be found in financial, life sciences, health - care and government sectors, including the Gramm - Leach - Bliley Act, Health Insurance Portability and Accountability Act, and Sarbanes - Oxley Act. A recurrent theme in these regulations is the need for regulatory - compliant data management as an underpinning to ensure data confidentiality, access integrity and authentication; provide audit trails, guaranteed deletion, and data migration; and deliver Write Once Read Many (WORM) assurances, essential for enforcing long - term data retention and life - cycle policies.","2007","2025-02-19 14:42:26","2025-02-19 14:42:26","","1433–1434","","","","","","","VLDB '07","","","","VLDB Endowment","","","","","","","","","Place: Vienna, Austria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P92BC6G6","conferencePaper","1993","Hage, Jaap","Monological reason-based logic: a low level integration of rule-based reasoning and case-based reasoning","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.158980","https://doi.org/10.1145/158976.158980","This paper contains an informal introduction to a theory about legal reasoning (reason-based logic) that takes the notion of a reason to be central. Arguing for a conclusion comes down to first collecting the reasons that plead for and against the conclusion, and second weighing them. The paper describes how we can establish the presence of a reason and how we can argue whether the reasons for or the reasons against the conclusion prevail. It also addresses the topic of meta-level reasoning about the use of rules in concrete cases. It is shown how both rule-based reasoning and case-based reasoning are naturally incorporated in the theory of reason-based logic.","1993","2025-02-19 14:42:26","2025-02-19 14:42:26","","30–39","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBPWLJH7","journalArticle","2018","Evans, Richard; Grefenstette, Edward","Learning explanatory rules from noisy data","J. Artif. Int. Res.","","1076-9757","","","Artificial Neural Networks are powerful function approximators capable of modelling solutions to a wide variety of problems, both supervised and unsupervised. As their size and expressivity increases, so too does the variance of the model, yielding a nearly ubiquitous over_tting problem. Although mitigated by a variety of model regularisation methods, the common cure is to seek large amounts of training data–which is not necessarily easily obtained–that sufficiently approximates the data distribution of the domain we wish to test on. In contrast, logic programming methods such as Inductive Logic Programming offer an extremely data-efficient process by which models can be trained to reason on symbolic domains. However, these methods are unable to deal with the variety of domains neural networks can be applied to: they are not robust to noise in or mislabelling of inputs, and perhaps more importantly, cannot be applied to non-symbolic domains where the data is ambiguous, such as operating on raw pixels. In this paper, we propose a Differentiable Inductive Logic framework, which can not only solve tasks which traditional ILP systems are suited for, but shows a robustness to noise and error in the training data which ILP cannot cope with. Furthermore, as it is trained by backpropagation against a likelihood objective, it can be hybridised by connecting it with neural networks over ambiguous data in order to be applied to domains which ILP cannot address, while providing data efficiency and generalisation beyond what neural networks on their own can achieve.","2018-01","2025-02-19 14:42:26","2025-02-19 14:42:26","","1–64","","1","61","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BE5LEPPR","conferencePaper","1993","Yang, Soon-Ae; Robertson, Dave; Lee, John","KICS: a knowledge-intensive case-based reasoning system for statutory building regulations and case histories","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.159008","https://doi.org/10.1145/158976.159008","There have been several knowledge-based systems for statutory building regulations during the last decade, such as Fenves et al's systems using the SASE model, Stone and Wilcox's system using a rule-based approach, and Waard's system using Cornick et al;'s model-based approach. However, they take into account only one side of building regulations, considering them only in the context of design systems and ignoring the existence of case histories. Building regulations are also part of a legal system and have characteristics of law. In this paper, we propose a Knowledge-Intensive Case-based reasoning System which can be used for the retrieval and maintenance of building regulations and case histories. First, we propose a unified knowledge representation scheme for both statutory building regulations and case histories. Second, we describe the retrieval of regulations information, which uses the notion of implied similarity as well as structural mapping. Finally, we describe knowledge acquisition from case histories, which is guided by knowledge gained from statutory regulations and case histories.","1993","2025-02-19 14:42:26","2025-02-19 14:42:26","","254–263","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8JMM7CDG","conferencePaper","2015","Al-Abdulkarim, Latifa; Atkinson, Katie; Bench-Capon, Trevor","Evaluating the use of abstract dialectical frameworks to represent case law","Proceedings of the 15th International Conference on Artificial Intelligence and Law","978-1-4503-3522-5","","10.1145/2746090.2746111","https://doi.org/10.1145/2746090.2746111","Abstract Dialetical Frameworks (ADFs) are a recent development in computational argumentation which are, it has been suggested, a fruitful way of implementing theories of case law expressed in terms of factors. In this paper we evaluate this proposal, by representing the CATO analysis using ADFs. We evaluate the ease of implementation, the efficacy of the resulting program, ease of refinement of the program, transparency of the reasoning, relation to formal argumentation techniques, and transferability across domains.","2015","2025-02-19 14:42:26","2025-02-19 14:42:26","","156–160","","","","","","","ICAIL '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8T7LB9YX","conferencePaper","1993","Dayal, Surendra; Harmer, Michael; Johnson, Peter; Mead, David","Beyond knowledge representation: commercial uses for legal knowledge bases","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.158997","https://doi.org/10.1145/158976.158997","At the 1991 Conference, SoftLaw presented a paper dealing with issue which arise in the modelling of legislation as English sentences and rules which a computer can process. Using the techniques outlined in that article, knowledge bases may be constructed to model areas of the law, especially those concerned with public administration. This paper illustrates the incorporation of such knowledge bases into a large scale application. This type of application may be used to drive the business of any organisation which primarily administers a large body of rules (legislative or otherwise).Firstly, the paper gives a background description of the role played by ASSESS, a large scale application whose processing is based around legal knowledge bases.Secondly, the system architecture of ASSESS is examined, focusing on: (i) the overall architecture of the application, and why that architecture was adopted, (ii) the structure of the knowledge based component of the application, and the reasons for that structure.","1993","2025-02-19 14:42:26","2025-02-19 14:42:26","","167–174","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"343ZK885","conferencePaper","2010","Kamath, Uday; De Jong, Kenneth A.; Shehu, Amarda","Selecting predictive features for recognition of hypersensitive sites of regulatory genomic sequences with an evolutionary algorithm","Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation","978-1-4503-0072-8","","10.1145/1830483.1830516","https://doi.org/10.1145/1830483.1830516","This paper proposes a method to improve the recognition of regulatory genomic sequences. Annotating sequences that regulate gene transcription is an emerging challenge in genomics research. Identifying regulatory sequences promises to reveal underlying reasons for phenotypic differences among cells and for diseases associated with pathologies in protein expression. Computational approaches have been limited by the scarcity of experimentally-known features specific to regulatory sequences. High-throughput experimental technology is finally revealing a wealth of hypersensitive (HS) sequences that are reliable markers of regulatory sequences and currently the focus of classification methods. The contribution of this paper is a novel method that combines evolutionary computation and SVM classification to improve the recognition of HS sequences. Based on experimental evidence that HS regions employ sequence features to interact with enzymes, the method seeks motifs to discriminate between HS and non-HS sequences. An evolutionary algorithm (EA) searches the space of sequences of different lengths to obtain such motifs. Experiments reveal that these motifs improve recognition of HS sequences by more than 10% compared to state-of-the-art classification methods. Analysis of these motifs reveals interesting insight into features employed by regulatory sequences to interact with DNA-binding enzymes.","2010","2025-02-19 14:42:26","2025-02-19 14:42:26","","179–186","","","","","","","GECCO '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","dnase i hypersensitive sites; evolutionary algorithms; support vector machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F4W44TAK","conferencePaper","2022","Cheng, Kewei; Liu, Jiahao; Wang, Wei; Sun, Yizhou","RLogic: Recursive Logical Rule Learning from Knowledge Graphs","Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining","978-1-4503-9385-0","","10.1145/3534678.3539421","https://doi.org/10.1145/3534678.3539421","Logical rules are widely used to represent domain knowledge and hypothesis, which is fundamental to symbolic reasoning-based human intelligence. Very recently, it has been demonstrated that integrating logical rules into regular learning tasks can further enhance learning performance in a label-efficient manner. Many attempts have been made to learn logical rules automatically from knowledge graphs (KGs). However, a majority of existing methods entirely rely on observed rule instances to define the score function for rule evaluation and thus lack generalization ability and suffer from severe computational inefficiency. Instead of completely relying on rule instances for rule evaluation, RLogic defines a predicate representation learning-based scoring model, which is trained by sampled rule instances. In addition, RLogic incorporates one of the most significant properties of logical rules, the deductive nature, into rule learning, which is critical especially when a rule lacks supporting evidence. To push deductive reasoning deeper into rule learning, RLogic breaks a big sequential model into small atomic models in a recursive way. Extensive experiments have demonstrated that RLogic is superior to existing state-of-the-art algorithms in terms of both efficiency and effectiveness.","2022","2025-02-19 14:42:26","2025-02-19 14:42:26","","179–189","","","","","","","KDD '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington DC, USA","","","","knowledge graph; logical rule learning; recursive","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W99FF6SP","conferencePaper","2005","van der Hoek, Wiebe; Roberts, Mark; Wooldridge, Michael","Knowledge and social laws","Proceedings of the Fourth International Joint Conference on Autonomous Agents and Multiagent Systems","1-59593-093-0","","10.1145/1082473.1082576","https://doi.org/10.1145/1082473.1082576","In this paper we combine existing work in the area of social laws with a framework for reasoning about knowledge in multi-agent systems. The unifying framework in which this is done is based on Alternating-time Temporal Logic (ATL), to which semantics we add epistemic accessibility relations (to deal with the knowledge), actions (in order to naturally talk about allowed and forbidden actions) and updates (to model the effect of the implementation of the constraint in a social law). Apart from a constraint, a social law has an objective: in our formalism, such objectives may refer to the knowledge that agents possess or do not possess. The result is a framework in which we can, for example, express that a desirable property (objective) of a social law is that one agent has the ability to bring about a certain type of knowledge in another agent, or that if one agent knows something, then it should behave in a certain way. We illustrate our approach with a case study, and we use model checking to demonstrate that properties of social laws with respect to this case study.","2005","2025-02-19 14:42:26","2025-02-19 14:42:26","","674–681","","","","","","","AAMAS '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: The Netherlands","","","","alternating-time temporal epistemic logic; knowledge; social laws","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBN3GDFK","conferencePaper","2007","Seay, A. Fleming; Kraut, Robert E.","Project massive: self-regulation and problematic use of online gaming","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-59593-593-9","","10.1145/1240624.1240749","https://doi.org/10.1145/1240624.1240749","A longitudinal design was employed to collect three waves of survey data over a 14 month period from 2790 online gamers. Respondents were asked questions about their gaming activity, motivations, personality, social and emotional environment, and the effect gaming has had on their lives. Prospective analysis was used to establish causal and temporal linkages among the repeatedly measured factors. While the data provide some indication that a player's reasons for playing do influence the development of problematic usage, these effects are overshadowed by the central importance of self-regulation in managing both the timing and amount of play. An individual's level of self-regulatory activity is shown to be very important in allowing them to avoid negative outcomes like problematic use. The role of depression is also discussed. With responsible use, online gaming appears to be a healthy recreational activity that provides millions of people with hours of social entertainment and adaptive diversion. However, failure to manage play behavior can lead to feelings of dependency.","2007","2025-02-19 14:42:26","2025-02-19 14:42:26","","829–838","","","","","","","CHI '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Jose, California, USA","","","","self-regulation; addiction; depression; MMORPG; online games; play motivation; social integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XAKDQQN","conferencePaper","2023","Varde, Aparna S.; De Melo, Gerard; Dong, Boxiang","Temporal Ordinance Mining for Event-Driven Social Media Reaction Analytics","Companion Proceedings of the ACM Web Conference 2023","978-1-4503-9419-2","","10.1145/3543873.3587674","https://doi.org/10.1145/3543873.3587674","As a growing number of policies are adopted to address the substantial rise in urbanization, there is a significant push for smart governance, endowing transparency in decision-making and enabling greater public involvement. The thriving concept of smart governance goes beyond just cities, ultimately aiming at a smart planet. Ordinances (local laws) affect our life with regard to health, business, etc. This is particularly notable during major events such as the recent pandemic, which may lead to rapid changes in ordinances, pertaining for instance to public safety, disaster management, and recovery phases. However, many citizens view ordinances as impervious and complex. This position paper proposes a research agenda enabling novel forms of ordinance content analysis over time and temporal web question answering (QA) for both legislators and the broader public. Along with this, we aim to analyze social media posts so as to track the public opinion before and after the introduction of ordinances. Challenges include addressing concepts changing over time and infusing subtle human reasoning in mining, which we aim to address by harnessing terminology evolution methods and commonsense knowledge sources, respectively. We aim to make the results of the historical ordinance mining and event-driven analysis seamlessly accessible, relying on a robust semantic understanding framework to flexibly support web QA.","2023","2025-02-19 14:42:26","2025-02-19 14:42:26","","1225–1227","","","","","","","WWW '23 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Austin, TX, USA","","","","NLP; machine learning; text mining; social media; A; Commonsense knowledge; historical data; local laws; smart governance; terminology evolution; urban policy; web Q&amp","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWWR6M2D","journalArticle","1989","Berman, Donald H.; Hafner, Carole D.","The potential of artificial intelligence to help solve the crisis in our legal system","Commun. ACM","","0001-0782","10.1145/65971.65972","https://doi.org/10.1145/65971.65972","The laws that govern affluent clients and large institutions are numerous, intricate and applied by highly sophisticated practitioners. In this section of society, rules proliferate, lawsuits abound, and the cost of legal services grows much faster than the cost of living. For the bulk of the population, however, the situation is very different. Access to the courts may be open in principle. In practice, however, most people find their legal rights severely compromised by the cost of legal services, the baffling complications of existing rules and procedures, and the long, frustrating delays involved in bringing proceedings to a conclusion . . . There is far too much law for those who can afford it and far too little for those who cannot. No one can be satisfied with this state of affairs.Derek Bok [5]The American legal system1 is widely viewed as being in a state of crisis, plagued by excessive costs, long delays, and inconsistency leading to a growing lack of public confidence. One reason for this is the vast amount of information that must be collected and integrated in order for the legal system to function properly. In many traditional areas of law, evolving legal doctrines have led to uncertainty and increased litigation at a high cost to both individuals and society. And in discretionary areas such as sentencing, alimony awards, and welfare administration, evidence has shown a high degree of inconsistency in legal decision making, leading to public dissatisfaction and a growing demand for ""determinate"" rules.In this article, we consider the potential of artificial intelligence to contribute to a more fair and efficient legal system. First, using the example of a middle income home buyer who was misled by the statements of a real estate broker, we show how a predictive expert system could help each side assess its legal position. If expert systems were reasonably accurate predictors, some disputes could be voluntarily settled that are now resolved by costly litigation, and many others could be settled more quickly. We then consider the process of discretionary decision making, using the example of a judge sentencing a criminal. We describe how diagnostic expert systems developed in the medical domain could be adapted to criminal sentencing, and describe a process by which this technology could be used—first to build a consensus on sentencing norms, and then to make those norms accessible.In the ideal case, legal decisions are made after lengthy study and debate, recorded in published justifications, and later scrutinized in depth by other legal experts. In contrast to this ideal, most day-to-day legal decisions are made by municipal and state court judges, police officers, prosecuting attorneys, insurance claims adjusters, welfare administrators, social workers, and lawyers advising their clients on whether to settle or litigate. These decisions must often be made under severe pressures of limited time, money, and information. Expert systems can provide decision makers with tools to better understand, evaluate and disseminate their decisions. At the same time, it is important to reiterate that expert systems should not and cannot replace human judgement in the legal decision making process.","1989-08","2025-02-19 14:42:26","2025-02-19 14:42:26","","928–938","","8","32","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBV8HBBI","conferencePaper","2007","Lapadula, Alessandro; Pugliese, Rosario; Tiezzi, Francesco","Regulating data exchange in service oriented applications","Proceedings of the 2007 International Conference on Fundamentals of Software Engineering","3-540-75697-3","","","","We define a type system for COWS, a formalism for specifying and combining services, while modelling their dynamic behaviour. Our types permit to express policies constraining data exchanges in terms of sets of service partner names attachable to each single datum. Service programmers explicitly write only the annotations necessary to specify the wanted policies for communicable data, while a type inference system (statically) derives the minimal additional annotations that ensure consistency of services initial configuration. Then, the language dynamic semantics only performs very simple checks to authorize or block communication. We prove that the type system and the operational semantics are sound. As a consequence, we have the following data protection property: services always comply with the policies regulating the exchange of data among interacting services. We illustrate our approach through a simplified but realistic scenario for a service-based electronic marketplace.","2007","2025-02-19 14:42:26","2025-02-19 14:42:26","","223–239","","","","","","","FSEN'07","","","","Springer-Verlag","Berlin, Heidelberg","","","","","","","","event-place: Tehran, Iran","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VT45HZLU","journalArticle","2005","Wang, Qianxiang","Towards a rule model for self-adaptive software","SIGSOFT Softw. Eng. Notes","","0163-5948","10.1145/1039174.1039198","https://doi.org/10.1145/1039174.1039198","Most self-adaptive software use rules explicitly or implicitly to decide how to react to monitored events. Meanwhile, rules are usually scattered in different procedures, which makes procedures more complex. This paper proposes a Rule Model, which is used to extract scattered rules from different procedures, so as to enhance the self-adaptive ability of software. The paper presents what is Rule Model, including: three key concepts (event, parameter, and rule), hierarchical organization, role in application, and XML-based representation. The paper also introduces how to map declarative rules inside one deployable application to executable rules inside one rule engine, based on one J2EE-compliant application server.","2005-01","2025-02-19 14:42:26","2025-02-19 14:42:26","","8","","1","30","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","rule model; self-adaptive software","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XKXAVQR4","journalArticle","2010","Madeira, Sara C.; Teixeira, Miguel C.; Sa-Correia, Isabel; Oliveira, Arlindo L.","Identification of Regulatory Modules in Time Series Gene Expression Data Using a Linear Time Biclustering Algorithm","IEEE/ACM Trans. Comput. Biol. Bioinformatics","","1545-5963","10.1109/TCBB.2008.34","https://doi.org/10.1109/TCBB.2008.34","Although most biclustering formulations are NP-hard, in time series expression data analysis, it is reasonable to restrict the problem to the identification of maximal biclusters with contiguous columns, which correspond to coherent expression patterns shared by a group of genes in consecutive time points. This restriction leads to a tractable problem. We propose an algorithm that finds and reports all maximal contiguous column coherent biclusters in time linear in the size of the expression matrix. The linear time complexity of CCC-Biclustering relies on the use of a discretized matrix and efficient string processing techniques based on suffix trees. We also propose a method for ranking biclusters based on their statistical significance and a methodology for filtering highly overlapping and, therefore, redundant biclusters. We report results in synthetic and real data showing the effectiveness of the approach and its relevance in the discovery of regulatory modules. Results obtained using the transcriptomic expression patterns occurring in Saccharomyces cerevisiae in response to heat stress show not only the ability of the proposed methodology to extract relevant information compatible with documented biological knowledge but also the utility of using this algorithm in the study of other environmental stresses and of regulatory modules in general.","2010-01","2025-02-19 14:42:26","2025-02-19 14:42:26","","153–165","","1","7","","","","","","","","","","","","","","","","","Place: Washington, DC, USA Publisher: IEEE Computer Society Press","","","","Biclustering; expression patterns; regulatory modules.; time series gene expression data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ9WFMFI","conferencePaper","2017","Sabir, Shaista; Qamar, Usman; Ahmed, Tanveer; Ali, Mubashir","A preconception gender assessment using data mining techniques based on implementation of natural laws &amp; favoring factors","Proceedings of the 1st International Conference on Internet of Things and Machine Learning","978-1-4503-5243-7","","10.1145/3109761.3158405","https://doi.org/10.1145/3109761.3158405","Healthcare field1 is vital organization of our society as it directly affects the living being A balanced society is the need of the hour that we can achieve by a balanced family structure. In all over the world especially in Asia and Africa, couples show a preference for a particular gender of child, either male or female (1). This preference may be the result of economic, social pressure, custom of the people or it may simply be due to the reason of ""Gender balanced family"" (2). A lot of research in medical field is present which shows how to achieve the goal of getting a child of desired gender in a way that is more natural. Similarly, in this era of advanced technology data mining techniques are becoming more and more popular in medical field. In this paper, we analyzed different research methods in medical field based on Natural Laws &amp; Favoring Factors, extracted different macroscopic factors affecting directly the possible gender of offspring in the womb of the mother before conception and generated our dataset using these macroscopic factors. Then we applied different Data mining classification techniques on our dataset to classify the possible gender as male or female.","2017","2025-02-19 14:42:26","2025-02-19 14:42:26","","","","","","","","","IML '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Liverpool, United Kingdom","","","","ACM proceedings; data mining classification; favoring factors; gender balanced family; inducing environment; natural laws &amp; preconception gender classification; preconception-gender assessment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKSVAIP8","conferencePaper","2008","De Lima, Jader A.; Pimenta, Wallace A.","A current limiter for DC/DC regulators with internal compensation for process and temperature","Proceedings of the 21st Annual Symposium on Integrated Circuits and System Design","978-1-60558-231-3","","10.1145/1404371.1404404","https://doi.org/10.1145/1404371.1404404","A current limiter that securely clamps the LDO output current upon load over-current is presented. Although the approach relies on absolute values of parameters such as resistance and MOSFET threshold voltage on subsequent I/V and V/I conversions of the LDO sensed current, a reference current to the arbitration circuit is derived in such a manner that the dependence of the clamping value ICLP on process and temperature variations is canceled out at good extent. Furthermore, the sense circuit uses a p-MOSFET depletion device to comply with very low dropouts. For a nominal value of 750mA, minimum and maximum simulated values of ICLP are 630mA and 804mA, respectively, for a broad biases and process spread and temperatures ranging from -40°C to 150°C. An LDO with 400mA-current capability and 250mV-dropout embedding the proposed limiter was integrated on a high-voltage process. Experimental data attest the clamping functionality and its accuracy for low and large dropouts","2008","2025-02-19 14:42:26","2025-02-19 14:42:26","","94–99","","","","","","","SBCCI '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gramado, Brazil","","","","current limitation; DC/DC converter; LDO; PVT compensation; switcher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8LN7TE49","conferencePaper","2017","Fosch Villaronga, Eduard; Heldeweg, Michiel A.","HRI and the Future of Law","Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4885-0","","10.1145/3029798.3038313","https://doi.org/10.1145/3029798.3038313","Following Sinek's what-how-why model, this project is about the creation of a dynamic regulatory instrument that co-evolves with robot technology development (what), using a robot and a regulatory impact assessments and evaluation settings (simulation and living labs) for empirical testing (how), for three reasons (why): (1) to provide the robot users with a comprehensive protection (not only focused on technical matters); (2) to provide roboticists with a practical tool to know what regulations have to take into consideration into the life-cycle process of the robot; and (3) to fill the existing regulatory gaps caused by the fastness of the technological progress and avoid over-/under- regulated scenarios.","2017","2025-02-19 14:42:26","2025-02-19 14:42:26","","117–118","","","","","","","HRI '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vienna, Austria","","","","simulation; dynamic regulation; iteration; lifecycle process; living lab; regulatory impact assessment; robot impact assessment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVUBCDPN","conferencePaper","2011","Sottara, D.; Mello, P.; Sartori, C.; Fry, E.","Enhancing a production rule engine with predictive models using pmml","Proceedings of the 2011 Workshop on Predictive Markup Language Modeling","978-1-4503-0837-3","","10.1145/2023598.2023604","https://doi.org/10.1145/2023598.2023604","In this paper we describe how the Predictive Model Markup Language (PMML) standard enhances the JBoss Drools production rule engine with native support for using predictive models in business rules. The historic debate between symbolic and connectionist approaches to rule/model orchestration provides numerous examples of hybrid systems combining ""hard"" and ""soft"" computing techniques to achieve different levels of integration. Rules are often used to decide when and which model to invoke; model outputs, in turn, can be used to evaluate the preconditions of a rule. In a loosely coupled system, the rule engine calls an external component implementing the predictive model, but this has several disadvantages, most notably the need to setup proper communications and reconcile any difference in the way the components encode the data. We propose instead, a tightly integrated system where predictive models and rules become part of the same reasoning framework. The models, encoded using the PMML 4 standard, are loaded and processed by a compiler implemented using the rule engine itself. The PMML document is transformed into a set of facts that define the model, and a series of rules that formalize the model's behavior. In addition, most PMML data processing, validation, and transformation procedures are also implemented using auto-generated rules. Finally, in oder to integrate model inputs and outputs seamlessly in the inference process, we exploit an extension of the Drools engine which adds native support for uncertainty and/or fuzziness.","2011","2025-02-19 14:42:26","2025-02-19 14:42:26","","39–47","","","","","","","PMML '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California, USA","","","","pmml; predictive models; rule-based systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R77AT8IW","conferencePaper","2024","Cranefield, Stephen; Srivathsan, Sriashalya; Pitt, Jeremy","Inferring Lewisian Common Knowledge using Theory of Mind Reasoning in a Forward-chaining Rule Engine","Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems","979-8-4007-0486-4","","","","This paper presents a practical technique for inferring common knowledge based on the approach of David Lewis, who identified three conditions that are sufficient for information about the world and other agents' reasoning mechanisms to lead to chains of iterated mutual knowledge. We consider agents with theory-of-mind rules that model other agents' beliefs. We prove that only two levels of nested models of other agents are necessary to achieve common knowledge. We illustrate this approach with an implemented scenario involving information on monuments in a public forum.","2024","2025-02-19 14:42:26","2025-02-19 14:42:26","","2222–2224","","","","","","","AAMAS '24","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Auckland, New Zealand","","","","theory of mind; common knowledge; david lewis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJ6NRSFF","conferencePaper","2018","Alfano, Gianvincenzo; Greco, Sergio; Parisi, Francesco; Simari, Gerardo I.; Simari, Guillermo R.","Incremental computation of warranted arguments in dynamic defeasible argumentation: the rule addition case","Proceedings of the 33rd Annual ACM Symposium on Applied Computing","978-1-4503-5191-1","","10.1145/3167132.3167232","https://doi.org/10.1145/3167132.3167232","Defeasible Logic Programming (DeLP) is an argumentation-based reasoning tool that allows users to contemplate reasons for and against certain conclusions—the warrant status of literals in the knowledge base is the main output of this dialectical process. Since the computation of these warrant statuses is a costly endeavor, any update to the knowledge base has a huge impact if carried out naively. In this paper, we study the case of updates consisting only of additions of either strict or defeasible rules, identifying conditions under which we can avoid wasted effort and proposing a data structure to keep track of which literals' warrant status can potentially be affected by a given update. We report the results of a preliminary set of experiments showing that our incremental algorithm affords significantly lower running times in practice.","2018","2025-02-19 14:42:26","2025-02-19 14:42:26","","911–917","","","","","","","SAC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pau, France","","","","argumentation systems; defeasible logic programming; incremental computation; structured argumentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMWY3MCZ","conferencePaper","2016","Law, Effie Lai-Chong; Watkins, Dawn E.; Barwick, Joanna P. L.; Kirk, Elee S.","An Experiential Approach to the Design and Evaluation of a Gamified Research Tool for Law in Children's Lives","Proceedings of the The 15th International Conference on Interaction Design and Children","978-1-4503-4313-8","","10.1145/2930674.2930722","https://doi.org/10.1145/2930674.2930722","The aim of the project Law in Children's Lives is to gamify the research activity of collecting data with a digital game to assess children's awareness of law in their everyday lives. Our main research goal is to address the theoretical and practical concerns in gamification through a user(child)-centred experiential approach. We grounded the design and evaluation of the game in the established User Experience (UX) theoretical frameworks – Hassenzahl's hedonic-pragmatic model and McCarthy &amp; Wright's four threads of experience. The game prototype consists of four microworlds with each comprising a set of scenarios where children are asked to select an action option and record their reasons by talking to the non-player character. The game was evaluated with 634 children aged 7-11 years. The levels of perceived fun, interestingness and ease of playing were generally high. The game could stimulate the children to think about the given scenarios and beyond them.","2016","2025-02-19 14:42:26","2025-02-19 14:42:26","","322–333","","","","","","","IDC '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Manchester, United Kingdom","","","","Law; Children; Gamification; Theories; User Experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KHBBQXTT","conferencePaper","2002","Kerrigan, Shawn; Heenan, Charles; Law, Kincho H.","Regnet: an infrastructure for regulatory information management and compliance assistance","Proceedings of the 2002 Annual National Conference on Digital Government Research","","","","","The Regnet Project aims to develop a formal information infrastructure for regulatory information management and compliance assistance. This paper discusses three basic milestones of current research and development efforts. The first is the creation of a document repository containing federal and state regulations and supplemental documents. This repository includes a suite of concept hierarchies that enable users to browse documents according to the terms they contain. The second is an XML framework for representing regulations and associated metadata. The XML framework enables the augmentation of regulation text with tools and information that will help users understand and comply with the regulation. The third milestone is the creation of a compliance assistance system built upon the XML framework. The prototype effort for the document repository has been focused on environmental regulations and related documents. The compliance assistance system is illustrated in the domain of used oil management.","2002","2025-02-19 14:42:26","2025-02-19 14:42:26","","1–6","","","","","","","dg.o '02","","","","Digital Government Society of North America","","","","","","","","","Place: Los Angeles, California, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8F72V6F4","journalArticle","1986","Lucash, Richard M","Legal liability for malfunction and misuse of expert systems","SIGCHI Bull.","","0736-6906","10.1145/15698.15700","https://doi.org/10.1145/15698.15700","The expert system represents the evolution of the computer from a tool to manipulate data to one which applies attributes of humans - reasoning, judgment, experience and ""intelligence"" - to the data, or at least appears to do so. Questions are thus raised about whether this evolution requires a concomitant evolution in the law governing liability for malfunction or misuse of computer systems. Historically, malfunctions of a computer system have been viewed as ultimately traceable to human error, usually in engineering or programming. The ability of an expert system to mimic a human expert has suggested that the humans involved in the creation or use of the system might be less liable than in the case of the nonexpert system, or that some form of liability should attach to the system itself. This article will explore how existing law would apply to expert systems, and consider whether new legal developments are required to deal with such systems.","1986-07","2025-02-19 14:42:26","2025-02-19 14:42:26","","35–43","","1","18","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FRUIMIUA","conferencePaper","2006","DeWitt, Janine; Cicalese, Cynthia","Contextual integration: a framework for presenting social, legal, and ethical content across the computer security and information assurance curriculum","Proceedings of the 3rd Annual Conference on Information Security Curriculum Development","1-59593-437-5","","10.1145/1231047.1231054","https://doi.org/10.1145/1231047.1231054","The computer security and information assurance (CSIA) curriculum framework introduced in this paper presents technical computer security issues in terms of their social, legal, and ethical context. This approach to CSIA education fosters ethical reasoning by connecting skills and knowledge of technical and contextual content to real world situations; applying ethical reasoning when assessing CSIA problems and potential CSIA solutions in multiple settings; and framing the ethical dilemmas or competing value systems which are intrinsically a part of implementing CSIA technologies. Initial implementation of this integrative framework occurred at Marymount University in an introductory graduate-level computer security course, which is the first in a series of courses based on this model. Preliminary results from that pilot course are presented with a list of the resulting challenges that will be addressed in subsequent course offerings.","2006","2025-02-19 14:42:26","2025-02-19 14:42:26","","30–40","","","","","","","InfoSecCD '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kennesaw, Georgia","","","","ethics; active learning; authentic learning; case studies; cognitive apprenticeship; computer security; curriculum; education; ethical reasoning; information assurance; integrative learning; situated learning; social context","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZIKB4TY","conferencePaper","2021","Guizzi, Guido; Vespoli, Silvestro; Grassi, Andrea; Santillo, Liberatina Carmela","Simulation-based performance assessment of a new job-shop dispatching rule for the semi-heterarchical industry 4.0 architecture","Proceedings of the Winter Simulation Conference","978-1-7281-9499-8","","","","In the recent years, the advent of the Industry 4.0, the concepts of Cyber-Physical System and Internet of Things arises, allowing to shift from a classical hierarchical approach to the Manufacturing Planning and Control (MPC) system, to a new class of more decentralised architecture. This paper proposes a decentralised scheduling approach able to improve the performances of a Job-Shop production system, compliant to a semi-heterarchical Industry 4.0 architectures. To this extent, to face with the increasingly complexity of such a scenario, a parametric simulation model able to represent a wide number of Job Shop systems is introduced. Then, through a simulation experimental campaign, the performances of the proposed approach are assessed in function of different control parameter settings. The results showed that the Dispatching Rule Proposed (DRP) led to a significant productivity increase, showing that a semi-heterarchical architecture may be feasible and effective also in a Job-Shop production environment.","2021","2025-02-19 14:42:26","2025-02-19 14:42:26","","1664–1675","","","","","","","WSC '20","","","","IEEE Press","","","","","","","","","Place: Orlando, Florida","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YNGNWM2","conferencePaper","2022","Shahrzad, Hormoz; Hodjat, Babak; Miikkulainen, Risto","Evolving explainable rule sets","Proceedings of the Genetic and Evolutionary Computation Conference Companion","978-1-4503-9268-6","","10.1145/3520304.3534023","https://doi.org/10.1145/3520304.3534023","Most AI systems work like black boxes tasked with generating reasonable outputs for given inputs. Many domains, however, have explainablity and trustworthiness requirements not fulfilled by these approaches. Various methods exist to analyze or interpret black-box models post training. When it comes down to sensitive domains in which there is a mandate for white-box models, a better choice would be to use transparent models. In this work, we present a method which evolves explainable rule-sets using inherently transparent ordinary logic to make models. We showcase some sample domains we tackled and discuss their major desirable properties like bias detection, knowledge discovery, and modifiablity, to name a few.","2022","2025-02-19 14:42:26","2025-02-19 14:42:26","","1779–1784","","","","","","","GECCO '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts","","","","XAI; explainable AI; genetic algorithms; rule-set evolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P4ZT9TWK","conferencePaper","2006","","A rule-based model of computation for SystemC: integrating SystemC and Bluespec for co-design","Proceedings of the Fourth ACM/IEEE International Conference on Formal Methods and Models for Co-Design","1-4244-0421-5","","10.1109/MEMCOD.2006.1695899","https://doi.org/10.1109/MEMCOD.2006.1695899","Bluespec's rule-based model of computation (MoC) for hardware concurrency has gained attention for several reasons. From its basis in term rewriting systems, rules have the property of atomicity, which improves correctness by construction, particularly in large-scale concurrency with finegrained, dynamic resource sharing (typical in complex hardware). Rule-based interface methods extend atomicity across module boundaries, have a natural transactional reading, and precisely and formally characterize resource-sharing constraints. All this can be synthesized to hardware with competitive quality. SystemC expresses concurrency with threading and events, just like RTL, where it is difficult to deal with fine-grain concurrency and resource sharing. Further, there is no systematic methodology for module composition. Thus, while SystemC is suitable for very coarse modeling and for embedded software development, its limitations make it difficult to model correct by construction hardware systems accurately. In this paper, we show how to integrate Bluespec's rule-based MoC into SystemC. We augment SystemC modules with rules and rule-based interface methods, and augment the SystemC simulation kernel with a rule execution kernel. The integration is augmentative in that a model can contain both rule-based modules (where hardware accuracy is desired) as well as core SystemC or TLM modules (for embedded software, instruction-set simulators, existing SystemC IP, or pure behavioral models), thus providing the advantages of each MoC where appropriate","2006","2025-02-19 14:42:26","2025-02-19 14:42:26","","39–48","","","","","","","MEMOCODE '06","","","","IEEE Computer Society","USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TIZSB4RH","conferencePaper","2017","Goldwasser, Shafi; Park, Sunoo","Public Accountability vs. Secret Laws: Can They Coexist? A Cryptographic Proposal","Proceedings of the 2017 on Workshop on Privacy in the Electronic Society","978-1-4503-5175-1","","10.1145/3139550.3139565","https://doi.org/10.1145/3139550.3139565","""Our Laws are not generally known; they are kept secret by the small group of nobles who rule us. We are convinced that these ancient laws are scrupulously administered; nevertheless it is an extremely painful thing to be ruled by laws that one does not know.""–Franz Kafka, Parables and Paradoxes.Post 9/11, journalists, scholars and activists have pointed out that it secret laws - a body of law whose details and sometime mere existence is classified as top secret - were on the rise in all three branches of the US government due to growing national security concerns. Amid heated current debates on governmental wishes for exceptional access to encrypted digital data, one of the key issues is: which mechanisms can be put in place to ensure that government agencies follow agreed-upon rules in a manner which does not compromise national security objectives? This promises to be especially challenging when the rules, according to which access to encrypted data is granted, may themselves be secret.In this work we show how the use of cryptographic protocols, and in particular, the idea of zero knowledge proofs can ensure accountability and transperancy of the government in this extraordinary, seemingly deadlocked, setting. We propose an efficient record-keeping infrastructure with versatile publicly verifiable audits that preserve (information-theoretic) privacy of record contents as well as of the rules by which the records are attested to abide. Our protocol is based on existing blockchain and cryptographic tools including commitments and zero-knowledge SNARKs, and satisfies the properties of indelibility (i.e., no back-dating), perfect data privacy, public auditability of secret data with secret laws, accountable deletion, and succinctness. We also propose a variant scheme where entities can be required to pay fees based on record contents (e.g., for violating regulations) while still preserving privacy. Our scheme can be directly instantiated on the Ethereum blockchain (and a simplified version with weaker guarantees can be instantiated with Bitcoin).","2017","2025-02-19 14:42:26","2025-02-19 14:42:26","","99–110","","","","","","","WPES '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Dallas, Texas, USA","","","","accountability; cryptography; snark; zero knowledge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L2NPT7G6","journalArticle","2006","Pe'er, Dana; Tanay, Amos; Regev, Aviv","MinReg: A Scalable Algorithm for Learning Parsimonious Regulatory Networks in Yeast and Mammals","J. Mach. Learn. Res.","","1532-4435","","","In recent years, there has been a growing interest in applying Bayesian networks and their extensions to reconstruct regulatory networks from gene expression data. Since the gene expression domain involves a large number of variables and a limited number of samples, it poses both computational and statistical challenges to Bayesian network learning algorithms. Here we define a constrained family of Bayesian network structures suitable for this domain and devise an efficient search algorithm that utilizes these structural constraints to find high scoring networks from data. Interestingly, under reasonable assumptions on the underlying probability distribution, we can provide performance guarantees on our algorithm. Evaluation on real data from yeast and mouse, demonstrates that our method cannot only reconstruct a high quality model of the yeast regulatory network, but is also the first method to scale to the complexity of mammalian networks and successfully reconstructs a reasonable model over thousands of variables.","2006-12","2025-02-19 14:42:26","2025-02-19 14:42:26","","167–189","","","7","","","","","","","","","","","","","","","","","Publisher: JMLR.org","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WTPLXJRG","journalArticle","2024","Mai, Yubo; Gao, Zhipeng; Hu, Xing; Bao, Lingfeng; Liu, Yu; Sun, JianLing","Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning","Proc. ACM Softw. Eng.","","","10.1145/3660811","https://doi.org/10.1145/3660811","Inspired by the great potential of Large Language Models (LLMs) for solving complex coding tasks, in this paper, we propose a novel approach, named Code2API, to automatically perform APIzation for Stack Overflow code snippets. Code2API does not require additional model training or any manual crafting rules and can be easily deployed on personal computers without relying on other external tools. Specifically, Code2API guides the LLMs through well-designed prompts to generate well-formed APIs for given code snippets. To elicit knowledge and logical reasoning from LLMs, we used chain-of-thought (CoT) reasoning and few-shot in-context learning, which can help the LLMs fully understand the APIzation task and solve it step by step in a manner similar to a developer. Our evaluations show that Code2API achieves a remarkable accuracy in identifying method parameters (65%) and return statements (66%) equivalent to human-generated ones, surpassing the current state-of-the-art approach, APIzator, by 15.0% and 16.5% respectively. Moreover, compared with APIzator, our user study demonstrates that Code2API exhibits superior performance in generating meaningful method names, even surpassing the human-level performance, and developers are more willing to use APIs generated by our approach, highlighting the applicability of our tool in practice. Finally, we successfully extend our framework to the Python dataset, achieving a comparable performance with Java, which verifies the generalizability of our tool.","2024-07","2025-02-19 14:42:26","2025-02-19 14:42:26","","","","FSE","1","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","In-context learning; APIs; Chain-of-thought; Large language models; Stack Overflow","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VF33FC5","conferencePaper","2017","Hecham, Abdelraouf; Croitoru, Madalina; Bisquert, Pierre","Argumentation-Based Defeasible Reasoning For Existential Rules","Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems","","","","","Logic based argumentation allows for defeasible reasoning over monotonic logics. In this paper, we introduce DEFT, a tool implementing argumentative defeasible reasoning over existential rules. We explain how DEFT overcomes derivation loss and discuss DEFT's empirical behavior.","2017","2025-02-19 14:42:26","2025-02-19 14:42:26","","1568–1569","","","","","","","AAMAS '17","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: São Paulo, Brazil","","","","defeasible reasoning; existential rules; forward chaining; logic based argumentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BXK5SUS8","journalArticle","2016","Kirkham, Reuben","How disability discrimination law can enable new assistive technologies","SIGACCESS Access. Comput.","","1558-2337","10.1145/3023851.3023854","https://doi.org/10.1145/3023851.3023854","Disability Discrimination Law is a relatively recent innovation whose principles have now been accepted by the vast majority of the world's nations. Chief amongst these is the elastic yet mercurial concept of reasonable adjustments, which can have some surprising yet potent implications for this rights of people with disabilities. This article is an overview of my varied work aimed at exploring how disability discrimination law can enable new assistive technologies, including systems of general utility (e.g. Google Glass) which as a side effect, can also assist in helping ameliorate disability related disadvantages. At the same time, I also discuss some of the existing limitations with respect to disability discrimination law and its implementation.","2016-12","2025-02-19 14:42:26","2025-02-19 14:42:26","","22–31","","116","","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2EP3QLYE","conferencePaper","2012","Hwang, Woochang; Hwang, Youngdeuk; Lee, Sunjae; Lee, Doheon","Rule-based whole body modeling for analyzing multi-compound effects","Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics","978-1-4503-1716-0","","10.1145/2390068.2390083","https://doi.org/10.1145/2390068.2390083","Essential reasons including robustness, redundancy, and crosstalk of biological systems, have been reported to explain the limited efficacy and unexpected side-effects of drugs. Many pharmaceutical laboratories have begun to develop multi-compound drugs to remedy this situation, and some of them have shown successful clinical results. Simultaneous application of multiple compounds could increase efficacy as well as reduce side-effects through pharmacodynamics and pharmacokinetic interactions. However, such approach requires overwhelming cost of preclinical experiments and tests as the number of possible combinations of compound dosages increases exponentially. Computer model-based experiments have been emerging as one of the most promising solutions to cope with such complexity. Though there have been many efforts to model specific molecular pathways using qualitative and quantitative formalisms, they suffer from unexpected results caused by distant interactions beyond their localized models.Here we propose a rule-based whole-body modeling platform. We have tested this platform with Type 2 diabetes (T2D) model, which involves the malfunction of numerous organs such as pancreas, circulation system, liver, and muscle. We have extracted T2D-related 117 rules by manual curation from literature and different types of existing models. The results of our simulation show drug effect pathways of T2D drugs and how combination of drugs could work on the whole-body scale. We expect that it would provide the insight for identifying effective combination of drugs and its mechanism for the drug development.","2012","2025-02-19 14:42:26","2025-02-19 14:42:26","","77–84","","","","","","","DTMBIO '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Maui, Hawaii, USA","","","","combination drug; drug effect; multi-scale modeling; rule-based simulation; type 2 diabetes; whole-body simulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WN5IBHQ5","conferencePaper","2010","de Moura Araujo, Bruno; Schmitz, Eber Assis; Correa, Alexandre Luis; Alencar, Antonio Juarez","A method for validating the compliance of business processes to business rules","Proceedings of the 2010 ACM Symposium on Applied Computing","978-1-60558-639-7","","10.1145/1774088.1774117","https://doi.org/10.1145/1774088.1774117","Regulatory compliance of business operations and practices is increasingly becoming an area of great concern for management, costing tens of billions of dollars in compliance actions a year. This paper presents a method for validating business processes with respect to the business rules. In the proposed method, business processes are modeled with UML activity diagrams, whilst business rules are represented as OCL expressions attached to process activities and the business conceptual model. The model validation is based on the simulation of the execution of process instances based on specific scenarios. The simulation algorithm steps through the process model executing the actions associated to the activities with the help of the USE tool and checking for violations of the associated business rules. The proposed method allows the modeler to have an early feedback of possible defects that may exist in a business process model.","2010","2025-02-19 14:42:26","2025-02-19 14:42:26","","145–149","","","","","","","SAC '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sierre, Switzerland","","","","business rules; business process; compliance validation; OCL; UML","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDPY2Q7Y","journalArticle","2023","Zamudio Padilla, Juan Diego; Wang, Liuqin","Binary Semantic Pattern Rules for Chinese-English Machine Translation Based on Machine Learning Algorithms","ACM Trans. Asian Low-Resour. Lang. Inf. Process.","","2375-4699","10.1145/3626095","https://doi.org/10.1145/3626095","With the increase of internationalization and the exponential growth of intercultural communication, the importance of interlingual translation has become increasingly prominent. Machine translation has been a booming area of research as technology has advanced. Due to the complexity of language ability and limited understanding of language laws, there are challenges for machine translation. This paper focused on how to construct and apply binary semantic pattern rules through machine learning to improve the translation effect in Chinese-English machine translation. The research results of this paper would contribute to the further development and improvement of Chinese-English machine translation technology. In order to produce high-quality translation results, research in machine translation has recognized the need to analyze and understand the semantics of natural language. To address the important issue of lexical and syntactic ambiguity, representations of binary semantic pattern rules have been developed to formally describe these rules. Based on this, this paper designed and implemented a corpus-based binary semantic rule extraction and optimization algorithm, which used machine learning algorithms to automatically detect the semantic rules of two or more than two phrases in the Chinese corpus, and then automatically optimized and converted them according to the statistical results, and realized the design of Chinese-English machine translation system. The article evaluated the quality of machine translation to test the effectiveness of machine translation binary semantic pattern rules based on machine learning algorithms. The study found that compared with the rule set A, the rule sets B and C obtained automatically by the rule mining algorithm had significantly improved accuracy, both reaching more than 90%. This showed that the binary semantic pattern rule mining algorithm and optimization algorithm proposed in this paper were reasonable.","2023-10","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","","","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Association Rules; Binary Semantic Pattern Rules; Chinese and English Corpora; Machine Learning; Machine Translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LG9C3FZM","conferencePaper","2014","Li, Toby Jia-Jun; Sen, Shilad; Hecht, Brent","Leveraging advances in natural language processing to better understand Tobler's first law of geography","Proceedings of the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems","978-1-4503-3131-9","","10.1145/2666310.2666493","https://doi.org/10.1145/2666310.2666493","Tobler's First Law of Geography (TFL) is one of the key reasons why ""spatial is special"". The law, which states that ""everything is related to everything else, but near things are more related than distant things"", is central to the management, presentation, and analysis of geographic information. However, despite the importance of TFL, we have a limited general understanding of its domain-neutral properties. In this paper, we leverage recent advances in the natural language processing domain of semantic relatedness estimation to, for the first time, robustly evaluate the extent to which relatedness between spatial entities decreases over distance in a domain-neutral fashion. Our results reveal that, in general, TFL can indeed be considered a globally recognized domain-neutral property of geographic information but that there is a distance beyond which being nearer, on average, no longer means being more related.","2014","2025-02-19 14:42:27","2025-02-19 14:42:27","","513–516","","","","","","","SIGSPATIAL '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Dallas, Texas","","","","distance; semantic relatedness; Tobler's first law of geography","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5TBNXG8W","conferencePaper","1977","Godoy, H. C.; Franklin, G. B.; Bottorff, P. S.","Automatic checking of logic design structures For compliance with testability ground rules","Proceedings of the 14th Design Automation Conference","","","","","Specification of a set of design ground rules greatly simplifies the problems of testing and test generation for complex logic structures. This paper describes a fast and effective method for testing compliance of logic network designs to testability ground rules. The technique used is similar to logic simulation and may be performed as part of the design verification process. Very large designs may be checked quickly. The system provides an effective early warning tool for the logic designer and test engineer.","1977","2025-02-19 14:42:27","2025-02-19 14:42:27","","469–478","","","","","","","DAC '77","","","","IEEE Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AW6PTPWX","conferencePaper","2017","Verheij, Bart","Formalizing arguments, rules and cases","Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law","978-1-4503-4891-1","","10.1145/3086512.3086533","https://doi.org/10.1145/3086512.3086533","Legal argument is typically backed by two kinds of sources: cases and rules. In much AI &amp; Law research, the formalization of arguments, rules and cases has been investigated. In this paper, the tight formal connections between the three are developed further, in an attempt to show that cases can provide the logical basis for establishing which rules and arguments hold in a domain. We use the recently proposed formalism of case models, that has been applied previously to evidential reasoning and ethical systems design. In the present paper, we discuss with respect to case-based modeling how the analogy and distinction between cases can be modeled, and how arguments can be grounded in cases. With respect to rule-based modeling, we discuss conditionality, generality and chaining. With respect to argument-based modeling, we discuss rebutting, undercutting and undermining attack. We evaluate the approach by developing a case model of the rule-based arguments and attacks in Dutch tort law. In this way, we illustrate how statutory, rule-based law from the civil law tradition can be formalized in terms of cases.","2017","2025-02-19 14:42:27","2025-02-19 14:42:27","","199–208","","","","","","","ICAIL '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: London, United Kingdom","","","","case-based reasoning; argumentation; rule-based reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZBELNH8","conferencePaper","2015","Islam, Mohammad Badiul; Governatori, Guido","RuleOMS: a rule-based online management system","Proceedings of the 15th International Conference on Artificial Intelligence and Law","978-1-4503-3522-5","","10.1145/2746090.2746120","https://doi.org/10.1145/2746090.2746120","We propose an architecture for a rule-based online management systems (RuleOMS). Typically, many domain areas face the problem that stakeholders maintain databases of their business core information and they have to take decisions or create reports according to guidelines, policies or regulations. To address this issue we propose the integration of databases, in particular relational databases, with a logic reasoner and rule engine. We argue that defeasible logic is an appropriate formalism to model rules, in particular when the rules are meant to model regulations. The resulting RuleOMS provides an efficient and flexible solution to the problem at hand using defeasible inference. A case study of an online child care management system is used to illustrate the proposed architecture.","2015","2025-02-19 14:42:27","2025-02-19 14:42:27","","187–191","","","","","","","ICAIL '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5GZR2LAN","journalArticle","2022","Ahmetoglu, Alper; Seker, M. Yunus; Piater, Justus; Oztop, Erhan; Ugur, Emre","DeepSym: Deep Symbol Generation and Rule Learning for Planning from Unsupervised Robot Interaction","J. Artif. Int. Res.","","1076-9757","10.1613/jair.1.13754","https://doi.org/10.1613/jair.1.13754","Symbolic planning and reasoning are powerful tools for robots tackling complex tasks. However, the need to manually design the symbols restrict their applicability, especially for robots that are expected to act in open-ended environments. Therefore symbol formation and rule extraction should be considered part of robot learning, which, when done properly, will offer scalability, flexibility, and robustness. Towards this goal, we propose a novel general method that finds action-grounded, discrete object and effect categories and builds probabilistic rules over them for non-trivial action planning. Our robot interacts with objects using an initial action repertoire that is assumed to be acquired earlier and observes the effects it can create in the environment. To form action-grounded object, effect, and relational categories, we employ a binary bottleneck layer in a predictive, deep encoderdecoder network that takes the image of the scene and the action applied as input, and generates the resulting effects in the scene in pixel coordinates. After learning, the binary latent vector represents action-driven object categories based on the interaction experience of the robot. To distill the knowledge represented by the neural network into rules useful for symbolic reasoning, a decision tree is trained to reproduce its decoder function. Probabilistic rules are extracted from the decision paths of the tree and are represented in the Probabilistic Planning Domain Definition Language (PPDDL), allowing off-the-shelf planners to operate on the knowledge extracted from the sensorimotor experience of the robot. The deployment of the proposed approach for a simulated robotic manipulator enabled the discovery of discrete representations of object properties such as ‘rollable’ and ‘insertable’. In turn, the use of these representations as symbols allowed the generation of effective plans for achieving goals, such as building towers of the desired height, demonstrating the effectiveness of the approach for multi-step object manipulation. Finally, we demonstrate that the system is not only restricted to the robotics domain by assessing its applicability to the MNIST 8-puzzle domain in which learned symbols allow for the generation of plans that move the empty tile into any given position.","2022-12","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","","75","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QF287PUR","conferencePaper","2006","Kurtev, Ivan; van den Berg, Klaas; Jouault, Frédéric","Evaluation of rule-based modularization in model transformation languages illustrated with ATL","Proceedings of the 2006 ACM Symposium on Applied Computing","1-59593-108-2","","10.1145/1141277.1141563","https://doi.org/10.1145/1141277.1141563","This paper studies ways for modularizing transformation definitions in current rule-based model transformation languages. Two scenarios are shown in which the modular units are identified on the base of the relations between source and target metamodels and on the base of generic transformation functionality. Both scenarios justify modularization by requiring adaptability and reusability in transformation definitions. To enable representation and composition of the identified units, a transformation language must provide proper modular constructs and mechanisms for their integration. We evaluate several implementations of the scenarios by applying different transformation techniques: usage of explicit and implicit rule calls, and usage of rule inheritance. ATLAS Transformation Language (ATL) is used to illustrate these implementations. The experience with these scenarios shows that current languages provide a reasonably full set of modular constructs but may have problems in handling some composition tasks.","2006","2025-02-19 14:42:27","2025-02-19 14:42:27","","1202–1209","","","","","","","SAC '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Dijon, France","","","","adaptability; ATL; model transformations; modularity; reusability; transformation languages","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VR9FAVLR","conferencePaper","2024","Yu, Hua","Research on the Application of Association Rule Algorithm Based on FP-Growth in College English Information Teaching","Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning","979-8-4007-0976-0","","10.1145/3677779.3677783","https://doi.org/10.1145/3677779.3677783","The application of information technology is extremely common, especially in education and teaching, where teachers can more efficiently and quickly impart knowledge to students, allowing them to have a deeper understanding of the content they have learned in the classroom. This technology not only makes the teaching process more convenient for teachers, but also enables students to acquire more relevant knowledge. Through information-based education, the quality and efficiency of English education in universities can be improved.&nbsp;In the association rule algorithm, cognitive principles and communicative principles can provide a very reasonable explanation for the information-based education of college English. In order to improve students' English usage and communication skills, college English teachers should not only make use of information technology as much as possible during lectures, in order to comprehensively enhance students' language thinking, but also select suitable English education resources in a targeted manner.","2024","2025-02-19 14:42:27","2025-02-19 14:42:27","","23–27","","","","","","","CMNM '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Xi'an, China","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KP69BZHF","conferencePaper","2004","Horrocks, Ian; Patel-Schneider, Peter F.","A proposal for an owl rules language","Proceedings of the 13th International Conference on World Wide Web","1-58113-844-X","","10.1145/988672.988771","https://doi.org/10.1145/988672.988771","Although the OWLWeb Ontology Language adds considerable expressive power to the Semantic Web it does have expressive limitations, particularly with respect to what can be said about properties. Wepresent ORL (OWL Rules Language), a Horn clause rules extension to OWL that overcomes many of these limitations. ORL extends OWL in a syntactically and semantically coherent manner: the basic syntax for ORL rules is an extension of the abstract syntax for OWL DL and OWLLite; ORL rules are given formal meaning via an extension of the OWLDL model-theoretic semantics; ORL rules are given an XML syntax basedon the OWL XML presentation syntax; and a mapping from ORL rules to RDF graphs is given based on the OWL RDF/XML exchange syntax. Wediscuss the expressive power of ORL, showing that the ontology consistency problem is undecidable, provide several examples of ORLusage, and discuss how reasoning support for ORL might be provided.","2004","2025-02-19 14:42:27","2025-02-19 14:42:27","","723–731","","","","","","","WWW '04","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: New York, NY, USA","","","","semantic web; model-theoretic semantics; representation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SG5XJVFC","conferencePaper","2013","Riveret, Régis; Contissa, Giuseppe; Rotolo, Antonino; Pitt, Jeremy V.","Law enforcement in norm-governed learning agents","Proceedings of the 2013 International Conference on Autonomous Agents and Multi-Agent Systems","978-1-4503-1993-5","","","","We study law enforcement mechanisms within a population of norm-governed learning agents. We show that a traditional analysis based on expected utility can be misleading, because learning agents tend to comply even though their surveillance is stopped. This has significant implications for the design of self-organising institutions with endogenous resources, where the cost of monitoring and norm enforcement has to be taken into consideration.","2013","2025-02-19 14:42:27","2025-02-19 14:42:27","","1151–1152","","","","","","","AAMAS '13","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: St. Paul, MN, USA","","","","reinforcement learning; law enforcement; social simulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C22RHIVR","conferencePaper","2015","Beris, Odette; Beautement, Adam; Sasse, M. Angela","Employee Rule Breakers, Excuse Makers and Security Champions: Mapping the risk perceptions and emotions that drive security behaviors","Proceedings of the 2015 New Security Paradigms Workshop","978-1-4503-3754-0","","10.1145/2841113.2841119","https://doi.org/10.1145/2841113.2841119","We introduce a new methodology for identifying the factors that drive employee security behaviors in organizations, based on a well-known paradigm from psychology, the Johari Window. An analysis of 93 interviews with staff from 2 multinational organizations revealed that security behavior is driven by a combination of risk understanding and emotional stance towards security policy. Furthermore, we found that a quantitative analysis of these dimensions is capable of differentiating between the staff populations of the two organizations. Organization B showed a healthier set of security behaviors, as a result of its employees having better risk understanding and a more positive emotional stance. The framework distinguishes between 16 theoretical behavioral types, (3 of which are rule breakers, excuse makers and security champions). It can be used to identify groups of employees that potentially pose a risk to the organization, as well as those with beneficial skills and expertise. This allows highly specific messages to be targeted to change the risk perception and emotional stance of such groups. Assuming the organization has ensured security hygiene (i.e. its policies can be complied with in the context of productive activity), this can shift behavior towards compliance. Our framework thus offers diagnostic and intervention-shaping tools for the next step in improving security culture.","2015","2025-02-19 14:42:27","2025-02-19 14:42:27","","73–84","","","","","","","NSPW '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Twente, Netherlands","","","","Emotion; Information Security; Affect; Risk Perception; Risk Understanding; Security Policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D2RGRUPW","conferencePaper","2009","Lynch, Collin; Ashley, Kevin; Pinkwart, Niels; Aleven, Vincent","Toward assessing law students' argument diagrams","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568264","https://doi.org/10.1145/1568234.1568264","The development of graphical argument models is an active and growing area of research in Artificial Intelligence and Law. The aim is to develop models which may be readily used by legal professionals and novices to produce and parse arguments. If this goal is to be realized it is important to develop models that human reasoners can manipulate and assess consistently. We report on an ongoing study of graph agreement in the context of the LARGO system.","2009","2025-02-19 14:42:27","2025-02-19 14:42:27","","222–223","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","argument diagrams; argument models; hypothetical legal reasoning; intelligent tutoring systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Q7KFJA5","conferencePaper","2022","Irion, Kristina","Algorithms Off-limits? If digital trade law restricts access to source code of software then accountability will suffer","Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency","978-1-4503-9352-2","","10.1145/3531146.3533212","https://doi.org/10.1145/3531146.3533212","Free trade agreements are increasingly used to construct an additional layer of protection for source code of software. This comes in the shape of a new prohibition for governments to require access to, or transfer of, source code of software, subject to certain exceptions. A clause on software source code is also part and parcel of an ambitious set of new rules on trade-related aspects of electronic commerce currently negotiated by 86 members of the World Trade Organization. Our understanding to date of how such a commitment inside trade law impacts on governments right to regulate digital technologies and the policy space that is allowed under trade law is limited. Access to software source code is for example necessary to meet regulatory and judicial needs in order to ensure that digital technologies are in conformity with individuals’ human rights and societal values. This article will unpack and analyze the implications of such a source code clause for current and future digital policies by governments that aim to ensure transparency, fairness and accountability of computer and machine learning algorithms.","2022","2025-02-19 14:42:27","2025-02-19 14:42:27","","1561–1570","","","","","","","FAccT '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Republic of Korea","","","","Fairness; Accountability; Transparency; Application Programming Interface; Computer algorithms; Digital policy; International trade law; Software; Source code","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AUAPX6FF","conferencePaper","2009","Bench-Capon, Trevor; Modgil, Sanjay","Case law in extended argumentation frameworks","Proceedings of the 12th International Conference on Artificial Intelligence and Law","978-1-60558-597-0","","10.1145/1568234.1568248","https://doi.org/10.1145/1568234.1568248","In this paper we discuss how recent developments in argumentation frameworks, most notably Extended Argumentation Frameworks, can inform the representation of a body of case law using abstract argumentation techniques. This builds on previous work which has first used abstract Argumentation Frameworks, and then Value based Argumentation Frameworks for this purpose.Extended Argumentation Frameworks augment Argumentation Frameworks to not only allow arguments to be attacked, but also attacks to be attacked. This allows argumentation based reasoning about information normally assumed to be metalevel to the object level domain of argumentation, including argumentation over preferences, values and the audience based ranking of values promoted by arguments. The Extended Argumentation Frameworks can then be rewritten as standard Argumentation Frameworks, so that cases, and values and their rankings relevant to the cases, can be reasoned about using standard dialogue games for Argumentation Frameworks. In this way precedents can be represented as collections of arguments and dialogues using these arguments. Now, when confronted with a new case, these dialogues may be used to identify ways of deploying the arguments in the new case so as to reach a favourable position.","2009","2025-02-19 14:42:27","2025-02-19 14:42:27","","118–127","","","","","","","ICAIL '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2S5ATXW","conferencePaper","2014","Pruijt, Leo J.; Köppe, Christian; van der Werf, Jan Martijn; Brinkkemper, Sjaak","HUSACCT: architecture compliance checking with rich sets of module and rule types","Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering","978-1-4503-3013-8","","10.1145/2642937.2648624","https://doi.org/10.1145/2642937.2648624","Architecture Compliance Checking (ACC) is an approach to verify the conformance of implemented program code to high-level models of architectural design. Static ACC focuses on the module views of architecture and especially on rules constraining the modular elements. This paper presents HUSACCT, a static ACC tool that adds extensive support for semantically rich modular architectures (SRMAs) to the current practice of static ACC tools. An SRMA contains modules of semantically different types, like layers and components, which are constrained by rules of different types. HUSACCT provides support for five commonly used types of modules and eleven types of rules. We describe and illustrate how basic and extensive support of these types is provided and how the support can be configured. In addition, we discuss the internal architecture of the tool.","2014","2025-02-19 14:42:27","2025-02-19 14:42:27","","851–854","","","","","","","ASE '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vasteras, Sweden","","","","architecture compliance; software architecture; static analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJXZJGLA","conferencePaper","2011","Krötzsch, Markus; Maier, Frederick; Krisnadhi, Adila; Hitzler, Pascal","A better uncle for OWL: nominal schemas for integrating rules and ontologies","Proceedings of the 20th International Conference on World Wide Web","978-1-4503-0632-4","","10.1145/1963405.1963496","https://doi.org/10.1145/1963405.1963496","We propose a description-logic style extension of OWL 2 with nominal schemas which can be used like ""variable nominal classes"" within axioms. This feature allows ontology languages to express arbitrary DL-safe rules (as expressible in SWRL or RIF) in their native syntax. We show that adding nominal schemas to OWL 2 does not increase the worst-case reasoning complexity, and we identify a novel tractable language SROELV3(∩, x) that is versatile enough to capture the lightweight languages OWL EL and OWL RL.","2011","2025-02-19 14:42:27","2025-02-19 14:42:27","","645–654","","","","","","","WWW '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hyderabad, India","","","","datalog; description logic; semantic web rule language; sroiq; tractability; web ontology language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPHX2HKW","conferencePaper","2009","Stieghahn, Michael; Engel, Thomas","Law-aware access control for international financial environments","Proceedings of the Eighth ACM International Workshop on Data Engineering for Wireless and Mobile Access","978-1-60558-712-7","","10.1145/1594139.1594151","https://doi.org/10.1145/1594139.1594151","Financial institutions are restricted by legislation and have to ensure that mobile access to data is legal in a defined context. However, today's access control solutions work but cannot decide whether an access is legal. Especially when an access from different countries is required different legislations have to be taken into account. In this paper, we address the problem of a law-compliant access in international financial environments. We present an extension to context-aware access control systems so that they incorporate legal constraints. To this end, we introduce different facets of context information, their interrelations, and describe their necessity for a law-aware access control. Finally, by using an international banking application scenario, we demonstrate how a system that follows our approach can decide about access.","2009","2025-02-19 14:42:27","2025-02-19 14:42:27","","33–40","","","","","","","MobiDE '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Providence, Rhode Island","","","","access control; context-awareness; legal constraints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y5G9MZDN","conferencePaper","2018","Carbonaro, Antonella; Reda, Roberto","A Dietary Consultation System using Semantic Rules and Reasoning Based Approach","Proceedings of the 4th EAI International Conference on Smart Objects and Technologies for Social Good","978-1-4503-6581-9","","10.1145/3284869.3284929","https://doi.org/10.1145/3284869.3284929","Ontologies play an important role in knowledge-intensive contexts such as nutrition, personalised dietary, diet-sensitive disease conditions management and sport activities. Ontologies offer a shared data model for concept integration making possible to actuate automatic data analysis processes such as inference reasoning and allow interoperable communication among heterogeneous systems. In this paper, we propose Food Data Manager, a dietary consultation system which aims to improve the life quality of both healthy people and individuals affected by chronic diet-related diseases. Food Data Manager is an ontology-based system whereby we can automatically reason with food and its properties through inference engines in order to better assist users in making the correct choices for their particular health status, age, lifestyle, preferences, etc. In particular, we developed a set of semantic rules to transfer human dietary and nutrition expertise into machine understandable knowledge.","2018","2025-02-19 14:42:27","2025-02-19 14:42:27","","314–315","","","","","","","Goodtechs '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bologna, Italy","","","","dietary; health informatics; ontology-based data representation; semantic web technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LHMKIPE6","journalArticle","2024","Majumdar, Rupak; Sathiyanarayana, V. R.","Positive Almost-Sure Termination: Complexity and Proof Rules","Proc. ACM Program. Lang.","","","10.1145/3632879","https://doi.org/10.1145/3632879","We study the recursion-theoretic complexity of Positive Almost-Sure Termination (PAST) in an imperative programming language with rational variables, bounded nondeterministic choice, and discrete probabilistic choice. A program terminates positive almost-surely if, for every scheduler, the program terminates almost-surely and the expected runtime to termination is finite. We show that PAST for our language is complete for the (lightface) co-analytic sets (Π11-complete). This is in contrast to the related notions of Almost-Sure Termination (AST) and Bounded Termination (BAST), both of which are arithmetical (Π20- and Σ20-complete respectively). Our upper bound implies an effective procedure to reduce reasoning about probabilistic termination to non-probabilistic fair termination in a model with bounded nondeterminism, and to simple program termination in models with unbounded nondeterminism. Our lower bound shows the opposite: for every program with unbounded nondeterministic choice, there is an effectively computable probabilistic program with bounded choice such that the original program is terminating if, and only if, the transformed program is PAST. We show that every program has an effectively computable normal form, in which each probabilistic choice either continues or terminates execution immediately, each with probability 1/2. For normal form programs, we provide a sound and complete proof rule for PAST. Our proof rule uses transfinite ordinals. We show that reasoning about PAST requires transfinite ordinals up to ω1CK; thus, existing techniques for probabilistic termination based on ranking supermartingales that map program states to reals do not suffice to reason about PAST.","2024-01","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","POPL","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","computational complexity; demonic non-determinism; positive almost-sure termination; probabilistic programs; program reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLHJNZC2","conferencePaper","2011","Green, Nancy L.","Causal argumentation schemes to support sense-making in clinical genetics and law","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018365","https://doi.org/10.1145/2018358.2018365","With some sense-making software, investigators can use causal networks to visualize possible stories explaining the evidence. Despite the different domains, there are interesting correspondences between that type of application and a proposed intelligent learning environment (ILE) in which science students could visualize and debate causal scenarios accounting for clinical findings. The proposed ILE will extend the design of the GenIE Assistant, a system to generate first-draft genetic counseling letters. This paper compares the underlying computational models of sense-making software and the GenIE Assistant. Then it discusses refinements of the Assistant's causal argumentation schemes to support debate in the ILE. The refinements are at a level of abstraction that seem applicable to computational models for sense-making and evidential reasoning in law.","2011","2025-02-19 14:42:27","2025-02-19 14:42:27","","56–60","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","causal argumentation schemes; evidential reasoning; sense-making","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4RCT63KU","conferencePaper","2012","Faure, Cyril; Pernet, Nicolas","Propagation rules of real-time constraints on physical systems simulators in a hardware-in-the loop context","Proceedings of the 20th International Conference on Real-Time and Network Systems","978-1-4503-1409-1","","10.1145/2392987.2392991","https://doi.org/10.1145/2392987.2392991","The conception of a Hardware-in-the-loop system requires the antagonist compliance of simulations with real-time constraints. Namely, specific parts of complex embedded systems are simulated using physical continuous models execution called simulators. So-called ""real-time simulations"" thus strongly interact through data exchange with the real components in the loop imposing restrictions on computations. In this paper, we show that inferring these constraints from those imposed by data transfers is not trivial. Indeed, present commercial code generation tools from physical models do not tackle this problem appropriately. We consequently introduce the notion of mesh constraints, as temporal points where simulated time has to match real-time. We then propose propagation rules to compute these mesh constraints when simulated parts consist of several simulators. The resulting constraints lead to less drastically constrained task sets, potentially allowing more efficient scheduling.","2012","2025-02-19 14:42:27","2025-02-19 14:42:27","","31–40","","","","","","","RTNS '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pont à Mousson, France","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3MZHAJBF","conferencePaper","2013","Tumova, Jana; Hall, Gavin C.; Karaman, Sertac; Frazzoli, Emilio; Rus, Daniela","Least-violating control strategy synthesis with safety rules","Proceedings of the 16th International Conference on Hybrid Systems: Computation and Control","978-1-4503-1567-8","","10.1145/2461328.2461330","https://doi.org/10.1145/2461328.2461330","We consider the problem of automatic control strategy synthesis, for discrete models of robotic systems, to fulfill a task that requires reaching a goal state while obeying a given set of safety rules. In this paper, we focus on the case when the said task is not feasible without temporarily violating some of the rules. We propose an algorithm that synthesizes a motion which violates only lowest priority rules for the shortest amount of time. Although the proposed algorithm can be applied in a variety of control problems, throughout the paper, we motivate this problem with an autonomous car navigating in an urban environment while abiding by the rules of the road, such as ""always stay in the right lane"" and ""do not enter the sidewalk."" We evaluate the algorithm on a case study with several illustrative scenarios.","2013","2025-02-19 14:42:27","2025-02-19 14:42:27","","1–10","","","","","","","HSCC '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Philadelphia, Pennsylvania, USA","","","","control strategy synthesis; formal specification; least-violating planning; robot path planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMTNQ2PH","journalArticle","2017","Santolucito, Mark; Zhai, Ennan; Dhodapkar, Rahul; Shim, Aaron; Piskac, Ruzica","Synthesizing configuration file specifications with association rule learning","Proc. ACM Program. Lang.","","","10.1145/3133888","https://doi.org/10.1145/3133888","System failures resulting from configuration errors are one of the major reasons for the compromised reliability of today's software systems. Although many techniques have been proposed for configuration error detection, these approaches can generally only be applied after an error has occurred. Proactively verifying configuration files is a challenging problem, because 1) software configurations are typically written in poorly structured and untyped “languages”, and 2) specifying rules for configuration verification is challenging in practice. This paper presents ConfigV, a verification framework for general software configurations. Our framework works as follows: in the pre-processing stage, we first automatically derive a specification. Once we have a specification, we check if a given configuration file adheres to that specification. The process of learning a specification works through three steps. First, ConfigV parses a training set of configuration files (not necessarily all correct) into a well-structured and probabilistically-typed intermediate representation. Second, based on the association rule learning algorithm, ConfigV learns rules from these intermediate representations. These rules establish relationships between the keywords appearing in the files. Finally, ConfigV employs rule graph analysis to refine the resulting rules. ConfigV is capable of detecting various configuration errors, including ordering errors, integer correlation errors, type errors, and missing entry errors. We evaluated ConfigV by verifying public configuration files on GitHub, and we show that ConfigV can detect known configuration errors in these files.","2017-10","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","OOPSLA","1","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Association Rule Learning; Configuration Files; Configuration Verification; Program Synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5BIT7WSB","conferencePaper","2022","Heider, Michael; Stegherr, Helena; Wurth, Jonathan; Sraj, Roman; Hähner, Jörg","Separating rule discovery and global solution composition in a learning classifier system","Proceedings of the Genetic and Evolutionary Computation Conference Companion","978-1-4503-9268-6","","10.1145/3520304.3529014","https://doi.org/10.1145/3520304.3529014","While utilization of digital agents to support crucial decision making is increasing, trust in suggestions made by these agents is hard to achieve. However, it is essential to profit from their application, resulting in a need for explanations for both the decision making process and the model. For many systems, such as common black-box models, achieving at least some explainability requires complex post-processing, while other systems profit from being, to a reasonable extent, inherently interpretable. We propose a rule-based learning system specifically conceptualised and, thus, especially suited for these scenarios. Its models are inherently transparent and easily interpretable by design. One key innovation of our system is that the rules' conditions and which rules compose a problem's solution are evolved separately. We utilise independent rule fitnesses which allows users to specifically tailor their model structure to fit the given requirements for explainability.","2022","2025-02-19 14:42:27","2025-02-19 14:42:27","","248–251","","","","","","","GECCO '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts","","","","explainable AI; evolutionary machine learning; interpretable models; learning classifier systems; rule-based learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XHRPCK2","conferencePaper","2011","Yoshino, Hajime","The systematization of law in terms of the validity","Proceedings of the 13th International Conference on Artificial Intelligence and Law","978-1-4503-0755-0","","10.1145/2018358.2018376","https://doi.org/10.1145/2018358.2018376","In legal praxis, it is important to decide what legal relations exist in a legal problem-event on the one hand and to decide what legal rules are applicable to decide it in terms of the validation by contract through constitution or convention on the other hand. These dimensions are strongly related with each other. This paper clarifies the logical structure of a legal system to decide the above two dimension in unified reasoning in terms of the validity of legal sentences. It provides a logical model of reasoning the validity of legal sentences for a unified legal reasoning system, in which legal relations according to the time progress of legal problem-events are decided and at the same time the applicability of relevant legal rules to decide them is decided. We demonstrate the legitimacy and efficiency of this model by applying it to concrete examples and showing how legal meta-sentences and legal meta-inference work in this model.","2011","2025-02-19 14:42:27","2025-02-19 14:42:27","","121–125","","","","","","","ICAIL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","legal reasoning; legal system; basic norm; CISG; contract; meta-inference; meta-rule; systematization of law; validity of law","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGVWJDSI","conferencePaper","2014","Shenvi, Ajit Ashok","Navigating the maze: journey towards an optimal process framework for regulated medical software","Proceedings of the 7th India Software Engineering Conference","978-1-4503-2776-3","","10.1145/2590748.2590769","https://doi.org/10.1145/2590748.2590769","Medical software development poses an interesting challenge from the process and Quality Management System (QMS) perspective. Being software, on one hand there are several process models/frameworks available in the industry practice, all claiming to be the ultimate pinnacle and this list gets supplemented as more research happens in the area of software engineering. On the other hand, healthcare is a regulated industry governed by region specific regulations. These regulations are not standardized across the globe which makes it quite challenging for a medical device manufacturer to abide by the corresponding country specific regulations where the product is going to be launched. For e.g. US is regulated by Quality Systems requirements of FDA and 510(k) approval process, Europe is governed by CE marking and ISO 13485 standard, China has its SFDA requirements whereas Japan follows PAL regulations. With the software content in the medical device increasing and number of recalls/field issues in medical products being traced to software, the regulators are becoming increasingly stricter when it comes to processes that govern design and development of medical software.Although there are many similarities in all these standards/models as the genesis of all of them is the PDCA (Plan-Do-Check-Act) approach, there are subtle important differences as well because each is optimized for a certain purpose. If regulatory standards are more focused on product safety and risk management, the CMMI® is more oriented towards continuous improvements. There is also lot of utility in the techniques proposed by the Agile and the Six-Sigma methodologies but then by itself these cannot become the complete Quality System. The situation is further aggravated by the fact that every stakeholder has different expectation from the software project teams for e.g. a project manager may want to follow iterative strategy to manage project risks better but the regulators on the other hand may expect documentation/evidences in a water-fall like manner, the top management may expect the team to adhere to all possible standards/models whereas the project team would want to follow as minimum requirements as possible and so on.This paper has tried to depict the challenges and dilemmas faced by medical software development teams because of availability of various models/standards/frameworks and the corresponding pros and cons of each. To navigate through this maze, it starts first by looking at the process landscape with the purpose of these various models/standards, and then tries to analyze the comparisons that have been done amongst the various models/standards in a number of published technical papers. Based on the experience of using some of these, the paper presents the insight in the form of propositions and recommends QMS architecture – both structural and operational that can be used by any medical software teams. The QMS based on the proposed structure has led to effort savings, stood the test of time in satisfying majority of the stakeholder needs and simultaneously not compromised on the regulatory aspects. The positive trends on the various performance indicators stand a testimony to the successful implementation of an optimal process framework for regulated medical software.","2014","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","","","","","","ISEC '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chennai, India","","","","Compliance; regulations; CMMI®; ISO; medical device; quality management system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MJ4V4I43","conferencePaper","1979","Liechenstein, Michael I.","Analytic and discrete simulation results for a stochastic model of law enforcement and speed limit compliance","Proceedings of the 12th Annual Symposium on Simulation","","","","","An aggregate stochastic model of driver behavior is postulated and analyzed to determine the expected steady-state level of driver compliance with the speed limit as well as the duration of the transient period. The expected steady-state proportion of complying motorists is related to the probability of police surveillance and to two behavioral parameters of the driver population: mean compliance level following operation of a radar trap and mean percentage decrease in compliance following non-operation. The model's utility in cost/benefit analysis of police operations is elaborated, including other effects of speeding such as accident mortality, morbidity, and rate of energy usage. Applications of the model to more serious law-enforcement issues as well as entirely different contexts such as marketing are briefly explored.","1979","2025-02-19 14:42:27","2025-02-19 14:42:27","","1–11","","","","","","","ANSS '79","","","","IEEE Press","","","","","","","","","Place: Tampa, Florida, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QE5BS9J5","conferencePaper","2014","Kang, Yong-Bin; Krishnaswamy, Shonali; Li, Yuan-Fang","A Meta-reasoner to Rule Them All: Automated Selection of OWL Reasoners Based on Efficiency","Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management","978-1-4503-2598-1","","10.1145/2661829.2662079","https://doi.org/10.1145/2661829.2662079","It has been shown, both theoretically and empirically, that reasoning about large and expressive ontologies is computationally hard. Moreover, due to the different reasoning algorithms and optimisation techniques employed, each reasoner may be efficient for ontologies with different characteristics. Based on recently-developed prediction models for various reasoners for reasoning performance, we present our work in developing a meta-reasoner that automatically selects from a number of state-of-the-art OWL reasoners to achieve optimal efficiency. Our preliminary evaluation shows that the meta-reasoner significantly and consistently outperforms 6 state-of-the-art reasoners and it achieves a performance close to the hypothetical gold standard reasoner.","2014","2025-02-19 14:42:27","2025-02-19 14:42:27","","1935–1938","","","","","","","CIKM '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Shanghai, China","","","","ontology; meta-reasoner; owl reasoner; prediction models; the sematic web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YNAGCANI","conferencePaper","2013","Kamma, Damodaram; Geetha, G.; Neela, J. Padma","Countering Parkinson's law for improving productivity","Proceedings of the 6th India Software Engineering Conference","978-1-4503-1987-4","","10.1145/2442754.2442768","https://doi.org/10.1145/2442754.2442768","Improving productivity is one of the basic goals of any software development company. One possible reason for productivity being lower than what is possible may be due to Parkinson's law, which states that work expands to fill the time available for its completion. In a software project this means that if more than needed time is given to a programmer, the extra time will not be revealed as ""free time"" on the programmer's weekly activity reports, but will result in the programmer consuming all the allotted time resulting in loss of productivity. A simple approach of allotting less time may not work as there are often small reasons relating to clarifications/coordination that provide the ""reason"" to a programmer for taking more time for completing a task. Therefore, to counter the effect of Parkinson's law, we therefore, took a two pronged approach: 1) allocating 33% less time than the estimated effort for a task and 2) facilitating issue resolution that may impede progress through a 15-min time-boxed daily meeting. We conducted an experiment for about six months in seven software projects in the real environment to study the impact of this approach. We found an improvement of at least 15% in productivity of the programmers compared to their baseline productivity without any degradation in quality of the programs developed by them. Results were validated with a statistical significance value of P &lt; 0.05 using Minitab tool. The views of project managers and programmers on the use of this approach, along with few limitations of this study, are discussed in the paper.","2013","2025-02-19 14:42:27","2025-02-19 14:42:27","","91–96","","","","","","","ISEC '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: New Delhi, India","","","","effort; Parkinson's law; productivity; programmers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XTM953IT","conferencePaper","2011","Arboleda, Hugo; Royer, Jean-Claude","Component types qualification in Java legacy code driven by communication integrity rules","Proceedings of the 4th India Software Engineering Conference","978-1-4503-0559-4","","10.1145/1953355.1953377","https://doi.org/10.1145/1953355.1953377","Component Based Software Engineering is a way to improve software modularization and to embed architectural concerns in the source code. Making explicit the architectural concerns in code helps to mitigate the problem of architectural erosion. The restructuring of legacy code with components in mind requires the use of tools to assess compliance with component programming principles. The property of communication integrity is one of the major principles for implementing software architectures. However, there is a paucity of tools for assessing the quality of code components. To cope with this issue, we define a component model in Java and a tool for identifying component types, which relies on a set of rules to statically check potential violations of the communication integrity property in Java source code. We illustrate its application with a case study and report the results of our experiments with it.","2011","2025-02-19 14:42:27","2025-02-19 14:42:27","","155–164","","","","","","","ISEC '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Thiruvananthapuram, Kerala, India","","","","architecture; assessing quality; communication integrity property; component based programming; component type; data type","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LFWH42B","conferencePaper","1993","Hafner, Carole D.; Wise, Virginia J.","SmartLaw: adapting “classic” expert system techniques for the legal research domain","Proceedings of the 4th International Conference on Artificial Intelligence and Law","0-89791-606-9","","10.1145/158976.158993","https://doi.org/10.1145/158976.158993","This report describes research in progress on the development of a computer expert system (SmartLaw) for giving advice on legal research problems. Legal research exhibits many of the characteristics of a suitable domain for expert system development; however, it also poses unique challenges for knowledge-based system design. To meet these challenges, we use a four-level knowledge structure of research STRATEGIES, GOALS, RESOURCES and PLANS, with three processing components: a rule-based backward-chaining reasoning component, a database component, and a hypertext component. This paper explains our evolving model of legal research knowledge and describes the architecture and implementation of a working prototype of the SmartLaw system.","1993","2025-02-19 14:42:27","2025-02-19 14:42:27","","133–141","","","","","","","ICAIL '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHWM8FDE","journalArticle","2013","Grau, Bernardo Cuenca; Horrocks, Ian; Krötzsch, Markus; Kupke, Clemens; Magka, Despoina; Motik, Boris; Wang, Zhe","Acyclicity notions for existential rules and their application to query answering in ontologies","J. Artif. Int. Res.","","1076-9757","","","Answering conjunctive queries (CQs) over a set of facts extended with existential rules is a prominent problem in knowledge representation and databases. This problem can be solved using the chase algorithm, which extends the given set of facts with fresh facts in order to satisfy the rules. If the chase terminates, then CQs can be evaluated directly in the resulting set of facts. The chase, however, does not terminate necessarily, and checking whether the chase terminates on a given set of rules and facts is undecidable. Numerous acyclicity notions were proposed as sufficient conditions for chase termination. In this paper, we present two new acyclicity notions called model-faithful acyclicity (MFA) and model-summarising acyclicity (MSA). Furthermore, we investigate the landscape of the known acyclicity notions and establish a complete taxonomy of all notions known to us. Finally, we show that MFA and MSA generalise most of these notions.Existential rules are closely related to the Horn fragments of the OWL 2 ontology language; furthermore, several prominent OWL 2 reasoners implement CQ answering by using the chase to materialise all relevant facts. In order to avoid termination problems, many of these systems handle only the OWL 2 RL profile of OWL 2; furthermore, some systems go beyond OWL 2 RL, but without any termination guarantees. In this paper we also investigate whether various acyclicity notions can provide a principled and practical solution to these problems. On the theoretical side, we show that query answering for acyclic ontologies is of lower complexity than for general ontologies. On the practical side, we show that many of the commonly used OWL 2 ontologies are MSA, and that the number of facts obtained by materialisation is not too large. Our results thus suggest that principled development of materialisation-based OWL 2 reasoners is practically feasible.","2013-05","2025-02-19 14:42:27","2025-02-19 14:42:27","","741–808","","1","47","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVAB2C9S","journalArticle","2015","Oberortner, Ernst; Bhatia, Swapnil; Lindgren, Erik; Densmore, Douglas","A Rule-Based Design Specification Language for Synthetic Biology","J. Emerg. Technol. Comput. Syst.","","1550-4832","10.1145/2641571","https://doi.org/10.1145/2641571","Synthetic Biology is an engineering discipline where parts of DNA sequences are composed into novel, complex systems that execute a desired biological function. Functioning and well-behaving biological systems adhere to a certain set of biological “rules”. Data exchange standards and Bio-Design Automation (BDA) tools support the organization of part libraries and the exploration of rule-compliant compositions. In this work, we formally define a design specification language, enabling the integration of biological rules into the Synthetic Biology engineering process. The supported rules are divided into five categories: Counting, Pairing, Positioning, Orientation, and Interactions. We formally define the semantics of each rule, characterize the language's expressive power, and perform a case study in that we iteratively design a genetic Priority Encoder circuit following two alternative paradigms—rule-based and template-driven. Ultimately, we touch a method to approximate the complexity and time to computationally enumerate all rule-compliant designs. Our specification language may or may not be expressive enough to capture all designs that a Synthetic Biologist might want to describe, or the complexity one might find through experiments. However, computational support for the acquisition, specification, management, and application of biological rules is inevitable to understand the functioning of biology.","2015-12","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","3","11","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","design; language; rule; specification; Synthetic biology; template","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLSJ7XDP","conferencePaper","2017","Maurus, Samuel; Plant, Claudia","Let's See Your Digits: Anomalous-State Detection using Benford's Law","Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","978-1-4503-4887-4","","10.1145/3097983.3098101","https://doi.org/10.1145/3097983.3098101","Benford's Law explains a curious phenomenon in which the leading digits of ""naturally-occurring"" numerical data are distributed in a precise fashion. In this paper we begin by showing that system metrics generated by many modern information systems like Twitter, Wikipedia, YouTube and GitHub obey this law. We then propose a novel unsupervised approach called BenFound that exploits this property to detect anomalous system events. BenFound tracks the ""Benfordness"" of key system metrics, like the follower counts of tweeting Twitter users or the change deltas in Wikipedia page edits. It then applies a novel Benford-conformity test in real-time to identify ""non-Benford events"". We investigate a variety of such events, showing that they correspond to unnatural and often undesirable system interactions like spamming, hashtag-hijacking and denial-of-service attacks. The result is a technically-uncomplicated and effective ""red flagging"" technique that can be used to complement existing anomaly-detection approaches. Although not without its limitations, it is highly efficient and requires neither obscure parameters, nor text streams, nor natural-language processing.","2017","2025-02-19 14:42:27","2025-02-19 14:42:27","","977–986","","","","","","","KDD '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Halifax, NS, Canada","","","","anomaly detection; benford's law; data streams; nonparametric statistical tests; time series data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4MXC3NZ7","conferencePaper","2018","Bhattacharyya, Abhidip; Chittimalli, Pavan Kumar; Naik, Ravindra","Relation Identification in Business Rules for Domain-specific Documents","Proceedings of the 11th Innovations in Software Engineering Conference","978-1-4503-6398-3","","10.1145/3172871.3172884","https://doi.org/10.1145/3172871.3172884","This paper focuses on an approach to mine business rules from documents and facilitates a methodology to represent them in a formal notation. Businesses are operated abiding by some rules and complying with respect to regulation and guidelines. The business rules are often written using English in operating procedures, terms and conditions, and various other supporting documents. The manual analysis of these rules for activities like impact analysis, maintenance, business transformation leads to potential discrepancies, ambiguities, and quality issues. In this paper, we discuss our approach of mining relations among the rule intents (atomic facts) defined for business rules. We also present our preliminary studies on a couple of openly available documents.","2018","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","","","","","","ISEC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hyderabad, India","","","","Natural Language Processing; Business Rule Extraction; Document Mining; Maximum Entropy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ANKL853J","conferencePaper","2005","Love, Nathaniel; Genesereth, Michael","Computational law","Proceedings of the 10th International Conference on Artificial Intelligence and Law","1-59593-081-7","","10.1145/1165485.1165517","https://doi.org/10.1145/1165485.1165517","Computational law is an approach to automated legal reasoning focusing on semantically rich laws, regulations, contract terms, and business rules in the context of electronically-mediated actions. Current computational tools for electronic commerce fall short of the demands of business, organizations, and individuals conducting complex transactions over the web. However, the growth of semantic data in the world of electronic commerce and online transactions, coupled with grounded rulesets that explicitly reference that data, provides a setting where applying automated reasoning to law can yield fruitful results, reducing inefficiencies, enabling transactions and empowering individuals with knowledge of how laws affect their behavior.","2005","2025-02-19 14:42:27","2025-02-19 14:42:27","","205–209","","","","","","","ICAIL '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bologna, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MIWZ69CX","conferencePaper","2018","Buchwald, Sebastian; Fried, Andreas; Hack, Sebastian","Synthesizing an instruction selection rule library from semantic specifications","Proceedings of the 2018 International Symposium on Code Generation and Optimization","978-1-4503-5617-6","","10.1145/3168821","https://doi.org/10.1145/3168821","Instruction selection is the part of a compiler that transforms intermediate representation (IR) code into machine code. Instruction selectors build on a library of hundreds if not thousands of rules. Creating and maintaining these rules is a tedious and error-prone manual process. In this paper, we present a fully automatic approach to create provably correct rule libraries from formal specifications of the instruction set architecture and the compiler IR. We use a hybrid approach that combines enumerative techniques with template-based counterexample-guided inductive synthesis (CEGIS). Thereby, we overcome several shortcomings of existing approaches, which were not able to handle complex instructions in a reasonable amount of time. In particular, we efficiently model memory operations. Our tool synthesized a large part of the integer arithmetic rules for the x86 architecture within a few days where existing techniques could not deliver a substantial rule library within weeks. Using the rule library, we generate a prototype instruction selector that produces code on par with a manually-tuned instruction selector. Furthermore, using 63012 test cases generated from the rule library, we identified 29498 rules that both Clang and GCC miss.","2018","2025-02-19 14:42:27","2025-02-19 14:42:27","","300–313","","","","","","","CGO '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vienna, Austria","","","","Program Synthesis; Instruction Selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRBE9WFE","conferencePaper","2024","Amagai, Sogo; Maret, Pierre; Singh, Kamal","Improving maintainability of calendar-based IoT-driven office with knowledge graph and rule-based reasoning","Proceedings of the 13th International Conference on the Internet of Things","979-8-4007-0854-1","","10.1145/3627050.3630731","https://doi.org/10.1145/3627050.3630731","Designing smart Internet of Things (IoT)-driven offices has recently gained considerable attention. Such smart offices are expected to enhance worker productivity and economise electricity for sustainability. However, there are several open issues related to the maintenance of IoT applications. In this study, we implement a calendar-based IoT-driven office exploiting knowledge graphs and rule-based reasoning. The smart IoT-driven office consists of micro-controllers (MCUs) with sensors and actuators, and a controller running on PC. These smart nodes send sensor data which in turn is represented as a Knowledge graph. This has different advantages in terms of interoperability, ease of integration with other systems and improved device compatibility. Decision-making is carried out by a rule-based reasoner. The reasoning process of a rule-based reasoner is more transparent than some machine learning approaches. This allows for easy configuration and adaptation of rules.","2024","2025-02-19 14:42:27","2025-02-19 14:42:27","","170–173","","","","","","","IoT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Nagoya, Japan","","","","Internet of Things; rule-based reasoning; Knowledge graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6WSJG9Y","conferencePaper","1969","Joshi, Aravind K.","Properties of formal grammars with mixed types of rules and their linguistic relevance","Proceedings of the 1969 Conference on Computational Linguistics","","","10.3115/990403.990450","https://doi.org/10.3115/990403.990450","In this paper, we will study a class of formal grammars with mixed types of rules. The reason for considering such grammars is that no single style (i.e., formal character of rules) of formal grammars is able to represent the various aspects of language structure in a natural way. Various considerations for setting up such grammars have been discussed. Generation schemes which map strings in the language of one mixed grammar into strings in the language of another mixed grammar (both strings being 'well-formed') have been studied. Linguistic relevance of these concepts has also been discussed.","1969","2025-02-19 14:42:27","2025-02-19 14:42:27","","1–18","","","","","","","COLING '69","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Sång-Säby, Sweden","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNHVF8VY","conferencePaper","2010","Meneely, Andrew; Williams, Laurie","Strengthening the empirical analysis of the relationship between Linus' Law and software security","Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement","978-1-4503-0039-1","","10.1145/1852786.1852798","https://doi.org/10.1145/1852786.1852798","Open source software is often considered to be secure because large developer communities can be leveraged to find and fix security vulnerabilities. Eric Raymond states Linus' Law as ""many eyes make all bugs shallow"", reasoning that a diverse set of perspectives improves the quality of a software product. However, at what point does the multitude of developers become ""too many cooks in the kitchen"", causing the system's security to suffer as a result? In a previous study, we quantified Linus' Law and ""too many cooks in the kitchen"" with developer activity metrics and found a statistical association between these metrics and security vulnerabilities in the Linux kernel. In the replication study reported in this paper, we performed our analysis on two additional projects: the PHP programming language and the Wireshark network protocol analyzer. We also updated our Linux kernel case study with 18 additional months of newly-discovered vulnerabilities. In all three case studies, files changed by six developers or more were at least four times more likely to have a vulnerability than files changed by fewer than six developers. Furthermore, we found that our predictive models improved on average when combining data from multiple projects, indicating that models can be transferred from one project to another.","2010","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","","","","","","ESEM '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bolzano-Bozen, Italy","","","","contribution network; developer network; metric; vulnerability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLGNR67E","conferencePaper","2010","Hayden, David S.; Zhou, Liqing; Astrauskas, Michael J.; Black, John A.","Note-taker 2.0: the next step toward enabling students who are legally blind to take notes in class","Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility","978-1-60558-881-0","","10.1145/1878803.1878828","https://doi.org/10.1145/1878803.1878828","In-class note-taking is a vital learning activity in secondary and post-secondary classrooms. The process of note-taking helps students stay focused on the instruction, forces them to cognitively process what is being presented, and better retain what has been taught, even if they never refer to their notes after the class. However, note-taking is difficult for students with low vision, or who are legally blind for two reasons. First, they are less able to see what is being presented at the front of them room, and second, they must repeatedly switch between the far-sight task of viewing the front of the room, and the near-sight task of taking notes. This paper describes ongoing research aimed at developing a portable assistive device (called the Note-Taker) that a student can take to class, to assist in the process of taking notes. It describes the principles that have guided the development of the proof-of-concept Note-Taker prototype and the Note-Taker 2.0 prototype. Initial testing of those prototypes has been encouraging, but some significant problems remain to be solved. Proposed solutions are currently being implemented, and appear to be effective. If ongoing usability testing confirms their effectiveness, they will be implemented on the planned Note-Taker 3.0 prototype.","2010","2025-02-19 14:42:27","2025-02-19 14:42:27","","131–138","","","","","","","ASSETS '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Orlando, Florida, USA","","","","lecture notes; legal blindness; low vision; note-taker; note-taking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZX8VV4I","conferencePaper","2011","Rozsnyai, Szabolcs; Slominski, Aleksander; Lakshmanan, Geetika T.","Discovering event correlation rules for semi-structured business processes","Proceedings of the 5th ACM International Conference on Distributed Event-Based System","978-1-4503-0423-8","","10.1145/2002259.2002272","https://doi.org/10.1145/2002259.2002272","In this paper we describe an algorithm to discover event correlation rules from arbitrary data sources. Correlation rules can be useful for determining relationships between events in order to isolate instances of a running business process for the purposes of monitoring, discovery and other applications. We have implemented our algorithm and validate our approach on events generated by a simulator that implements a real-world inspired export compliance regulations scenario consisting of 24 activities and corresponding event types. This simulated scenario involves a wide range of heterogeneous systems (e.g. Order Management, Document Management, E-Mail, and Export Violation Detection Services) as well as workflow-supported human-driven interactions (Process Management System). Experimental results demonstrate that our algorithm achieves a high level of accuracy in the detection of correlation rules. This paper confirms that our algorithm is a step towards semi-automating the task of detecting correlations. We also demonstrate how correlation rules discovered by our algorithm can be used to create aggregation nodes that allow more efficient querying, filtering and analytics. The results in this paper encourage future directions such as distributed statistics calculation, and scalability in terms of handling massive data sets.","2011","2025-02-19 14:42:27","2025-02-19 14:42:27","","75–86","","","","","","","DEBS '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: New York, New York, USA","","","","complex event processing; correlation discovery. business process discovery; data mining; event analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6MH5BVWL","conferencePaper","2013","Salodkar, Nitin; Rajagopalan, Subramanian; Bhattacharya, Sambuddha; Batterywala, Shabbir","Automatic design rule correction in presence of multiple grids and track patterns","Proceedings of the 50th Annual Design Automation Conference","978-1-4503-2071-9","","10.1145/2463209.2488766","https://doi.org/10.1145/2463209.2488766","Traditionally, automatic design rule correction (DRC) problem is modeled as a Linear Program (LP) with design rules as difference constraints under minimum perturbation objective. This yields Totally Uni-Modular (TUM) constraint matrices thereby guaranteeing integral grid-compliant solutions with LP solvers. However, advanced technology nodes introduce per-layer grids or discrete tracks that result into non-TUM constraint matrices for the DRC problem. Consequently, LP solvers do not guarantee integral solutions. In this work, we propose a novel formulation using an 'un-rolling' technique. Our formulation guarantees TUM constraint matrices and hence integral multiple grid/track compliant solutions. We demonstrate its efficacy on layouts at advanced nodes.","2013","2025-02-19 14:42:27","2025-02-19 14:42:27","","","","","","","","","DAC '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Austin, Texas","","","","difference constraints; integer linear program; layout automation; linear program; total uni-modularity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHEMNFH9","conferencePaper","2006","Thielecke, Hayo","Frame rules from answer types for code pointers","Conference Record of the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages","1-59593-027-2","","10.1145/1111037.1111065","https://doi.org/10.1145/1111037.1111065","We define a type system, which may also be considered as a simple Hoare logic, for a fragment of an assembly language that deals with code pointers and jumps. The typing is aimed at local reasoning in the sense that only the type of a code pointer is needed, and there is no need to know the whole code itself. The main features of the type system are separation logic connectives for describing the heap, and polymorphic answer types of continuations for keeping track of jumps. Specifically, we address an interaction between separation and answer types: frame rules for local reasoning in the presence of jumps are recovered by instantiating the answer type. However, the instantiation of answer types is not sound for all types. To guarantee soundness, we restrict instantiation to closed types, where the notion of closedness arises from biorthogonality (in a sense inspired by Krivine and Pitts). A machine state is orthogonal to a disjoint heap if their combination does not lead to a fault. Closed types are sets of machine states that are orthogonal to a set of heaps. We use closed types as well-behaved answer types.","2006","2025-02-19 14:42:27","2025-02-19 14:42:27","","309–319","","","","","","","POPL '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Charleston, South Carolina, USA","","","","Hoare logic; code pointers; continuations; polymorphism; typed assembly language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQ7RHMMP","conferencePaper","2001","Henderson, John; Bench-Capon, Trevor","Dynamic arguments in a case law domain","Proceedings of the 8th International Conference on Artificial Intelligence and Law","1-58113-368-5","","10.1145/383535.383542","https://doi.org/10.1145/383535.383542","In this paper we describe an approach to reasoning with cases which takes into account the view that case law evolves through a series of decisions. This is in contrast to approaches which take as a starting point a set of decided cases, with no account taken of the order in which they were decided. The model of legal reasoning we follow is based on Levi's account which shows how decided cases often need to be reinterpreted in the light of subsequent decisions, so that features of cases wax and wane in importance. Our aim is to reproduce the arguments that could have been used in a given case, rather than to apply a retrospective understanding of the law to them. A second novel feature is that we use a general purpose ontology to describe the cases, rather than one developed specifically to model the pertinent cases. The paper describes a prototype implementation, and uses an example to illustrate how our approach works. After this case by case description we make some remarks on the insights gained, and draw some conclusions.","2001","2025-02-19 14:42:27","2025-02-19 14:42:27","","60–69","","","","","","","ICAIL '01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: St. Louis, Missouri, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NHZU4I5P","conferencePaper","2010","Shenvi, Ajit Ashok","Medical software: a regulatory process framework","Proceedings of the 3rd India Software Engineering Conference","978-1-60558-922-0","","10.1145/1730874.1730897","https://doi.org/10.1145/1730874.1730897","Healthcare industry is governed by regulations which are region or country specific. Since it deals directly with human lives, if a medical device, be it standalone or a connected system or a Healthcare informatics package, is to be launched in a particular country/region, it has to abide by the corresponding medical regulations. However these regulations are not standardized across the globe and that makes it challenging for a medical device manufacturer to abide by the corresponding country specific regulations where the product is going to be launched. For e.g. US is regulated by Quality Systems requirements of FDA and 510 K approval, Europe is governed by CE marking and ISO 13485 standard, China has its SFDA requirements whereas Japan follows PAL regulations.Software is at the heart of all these medical equipments. More and more of the medical devices and the corresponding clinical applications and workflows are now controlled by software. Right from capturing the images generated by the scanner to the processing of these images and subsequent post processing for clinical decision making is done by software. The Picture Archival and Communication system (PACS) system which is the backbone of healthcare Informatics in hospitals has software at its core. So automatically all the software that is written for these products comes under the purview of these medical regulations. Infact the Global Harmonization Task force specifically includes ""software"" in its definition of medical devices.Software development in many organizations is governed by ""software engineering principles"" applied through a SEI-CMMI model which lays strong emphasis on establishing sound process framework to ensure a good software quality. So on one hand we have a CMMI based Quality system and on other hand the development and maintenance of ""medical software"" has to abide by the regulatory structure posed by FDA, ISO 13485 etc. This raises certain fundamental questions for organizations dealing with development and maintenance of ""medical software"" – Are these Quality systems requirements too diverse or is there any overlap? How much exactly is this overlap? Is it possible to marry both these worlds of CMMI and the regulatory standards and have a common process framework for the organization? If there is an already existing CMMI based system then is it possible to extend it to include the ISO and FDA aspects? And if yes how can this be done? As the medical software industry matures, more and more standards will get added to the regulatory requirement – in such a scenario, how does one keep the scalability and integrity of the Quality system? and other similar questions?.This paper is an attempt to answer these questions by sharing the experience of deploying ISO 13485 and FDA CFR 820 elements in an existing CMMI based Quality Management System for development and maintenance of medical software. It begins by painting the regulatory landscape across the globe – America, Europe, Asia, goes onto explaining briefly the structure of ISO 13485, and FDA Quality systems requirements and summarizes the approach followed by Philips-Healthcare Bangalore centre to achieve the ISO certification in a CMMI based process framework. The paper finally details out a granular mapping of the ISO 13485 clauses to the CMMI Process areas including Generic and Specific practices. This will help any CMMI based organization dealing with medical software to easily map and extend their existing practices to the required regulatory standards and achieve the corresponding certification.","2010","2025-02-19 14:42:27","2025-02-19 14:42:27","","119–124","","","","","","","ISEC '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Mysore, India","","","","regulations; clauses; cmmi; fda; ghtf; iso; process areas; quality policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H7G8A3VJ","conferencePaper","2005","Stranieri, Andrew; Yearwood, John","The integration of narrative and argumentation for a scenario based learning environment in law","Proceedings of the 10th International Conference on Artificial Intelligence and Law","1-59593-081-7","","10.1145/1165485.1165524","https://doi.org/10.1145/1165485.1165524","Narrative or story telling has long been used to structure and organise human experience. In contrast to logical models of reasoning, narrative models enable complex situations to be understood and recalled by humans readily. There is also some indication that narrative models represent the way in which jurors weigh up the veracity of legal evidence. In this work a narrative model is integrated into a logical reasoning model for the purpose of advancing a learning environment that promises to be engaging and effective. The narrative model includes a representation of the point of a story and a simple story grammar. The learning environment is designed to enable the automated generation of plausible scenarios representing a variety of family law property division cases told from the point of view of numerous characters.","2005","2025-02-19 14:42:27","2025-02-19 14:42:27","","232–233","","","","","","","ICAIL '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bologna, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DEG9WHNR","conferencePaper","2006","Frühwirth, Thom","Constraint handling rules: the story so far","Proceedings of the 8th ACM SIGPLAN International Conference on Principles and Practice of Declarative Programming","1-59593-388-3","","10.1145/1140335.1140337","https://doi.org/10.1145/1140335.1140337","Rule-based programming experiences renaissance due to its applications in areas such as Business Rules, Semantic Web, Computational Biology, Verification and Security. Executable rules are used in declarative programming languages, in program transformation and analysis, and for reasoning in artificial intelligence applications.Constraint Handling Rules (CHR) [6, 8, 11] is a concurrent committed-choice constraint logic programming language consisting of guarded rules that transform multi-sets of atomic formulas (constraints) into simpler ones until exhaustion. CHR was initially developed for solving constraints, but has matured into a general-purpose concurrent constraint language over the last decade, because it can embed many rule-based formalisms and describe algorithms in a declarative way. The clean semantics of CHR facilitates non-trivial program analysis and transformation","2006","2025-02-19 14:42:27","2025-02-19 14:42:27","","13–14","","","","","","","PPDP '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Venice, Italy","","","","applications; computational logic; concurrency; constraint programming; constraint solving; executable specification; program analysis; rule-based programming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LGVTQVKE","conferencePaper","2021","Celis, L. Elisa; Hays, Chris; Mehrotra, Anay; Vishnoi, Nisheeth K.","The Effect of the Rooney Rule on Implicit Bias in the Long Term","Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency","978-1-4503-8309-7","","10.1145/3442188.3445930","https://doi.org/10.1145/3442188.3445930","The Rooney Rule, originally proposed to counter implicit bias in hiring, has been implemented in the private and public sector in various settings. This rule requires that a decision-maker include at least one candidate from an underrepresented group in their shortlist of candidates. Recently, [42] proposed a mathematical model of implicit bias and studied the effectiveness of the Rooney Rule when applied to a single selection decision. However, selection decisions often occur repeatedly over time; e.g., a software firm is continuously hiring employees or a university makes admissions decisions every year. Further, it has been observed that, given consistent counterstereotypical feedback, implicit biases against underrepresented candidates can change.In this paper, we propose a model of how a decision-maker's implicit bias changes over time given their hiring decisions either with or without the Rooney Rule in place. Our model draws from the work of [42] and the literature on opinion dynamics. Our main result is that, for this model, when the decision-maker is constrained by the Rooney Rule, their implicit bias roughly reduces at a rate that is inverse of the size of the shortlist—independent of the total number of candidates, whereas without the Rooney Rule, the rate is inversely proportional to the number of candidates. Thus, our model predicts that when the number of candidates is much larger than the size of the shortlist, the Rooney Rule enables a significantly faster reduction in implicit bias, providing additional reason in favor of instating it as a strategy to mitigate implicit bias. Towards empirically evaluating the long-term effect of the Rooney Rule in repeated selection decisions, we conduct an iterative candidate selection experiment on Amazon Mechanical Turk. We observe that, indeed, decision-makers subject to the Rooney Rule select more minority candidates in addition to those required by the rule itself than they would if no rule is in effect, and in fact are able to do so without considerably decreasing the utility of candidates selected.","2021","2025-02-19 14:42:28","2025-02-19 14:42:28","","678–689","","","","","","","FAccT '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJ8SNP9B","journalArticle","2017","Siirtola, Antti; Tripakis, Stavros; Heljanko, Keijo","When Do We Not Need Complex Assume-Guarantee Rules?","ACM Trans. Embed. Comput. Syst.","","1539-9087","10.1145/3012280","https://doi.org/10.1145/3012280","We study the need for complex circular assume-guarantee (AG) rules in formalisms that already provide the simple precongruence rule. We first investigate the question for two popular formalisms: Labeled Transition Systems (LTSs) with weak simulation and Interface Automata (IA) with alternating simulation. We observe that, in LTSs, complex circular AG rules cannot always be avoided, but, in the IA world, the simple precongruence rule is all we need. Based on these findings, we introduce modal IA with cut states, a novel formalism that not only generalizes IA and LTSs but also allows for compositional reasoning without complex AG rules.","2017-01","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","2","16","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Circular assume-guarantee reasoning; compositional reasoning; cut state; modal interface automata; refinement checking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UV2B99LT","conferencePaper","2015","Alviano, Mario; Pieris, Andreas","Default Negation for Non-Guarded Existential Rules","Proceedings of the 34th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems","978-1-4503-2757-2","","10.1145/2745754.2745758","https://doi.org/10.1145/2745754.2745758","The problem of query answering under the well-founded and stable model semantics for normal existential rules, that is, existential rules enriched with default negation, has recently attracted a lot of interest from the database and KR communities. In particular, it has been thoroughly studied for classes of normal existential rules that are based on restrictions that guarantee the tree-likeness of the underlying models; a prime example of such a restriction is guardedness. However, little is known about classes of existential rules that significantly deviate from the above paradigm. A prominent example of such a formalism is the class of existential rules that is based on the notion of stickiness, which enforces restrictions on the forms of joins in the rule-bodies. It is the precise aim of the current work to extend sticky existential rules with default negation, and perform an in-depth analysis of the complexity of conjunctive query answering under the well-founded and stable model semantics. We show that an effective way for bridging the gap between stickiness and the well-founded semantics exists, and we provide data and combined complexity results. However, there is no way to reconcile stickiness and the stable model semantics. The reason for this surprising negative result should be found in the fact that sticky existential rules are powerful enough for expressing cartesian products, a construct that forms a prime example of non-guardedness.","2015","2025-02-19 14:42:28","2025-02-19 14:42:28","","79–90","","","","","","","PODS '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Melbourne, Victoria, Australia","","","","complexity; datalog-based languages; default negation; query answering; stable model semantics; well-founded semantics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WA9K9XVU","conferencePaper","1999","Elhadi, Mohamed T.; Vamos, Tibor","Bankruptcy case law: a hybrid IR-CBR approach","Proceedings of the 7th International Conference on Artificial Intelligence and Law","1-58113-165-8","","10.1145/323706.323786","https://doi.org/10.1145/323706.323786","We briefly present a description of an on-going work in applying a combined IR-CBR approach to legal information processing in bankruptcy law. Our underlying model is based on how lawyers do Legal Research as part of the Legal Reasoning process. In particular we suggest an IR technique derived from our assumption and based on actual statute text rather than case documents' text.","1999","2025-02-19 14:42:28","2025-02-19 14:42:28","","134–135","","","","","","","ICAIL '99","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Oslo, Norway","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5J3BXWGP","conferencePaper","2014","Woensel, William Van; Haider, Newres Al; Roy, Patrice C.; Ahmad, Ahmad Marwan; Abidi, Syed S. R.","A Comparison of Mobile Rule Engines for Reasoning on Semantic Web Based Health Data","Proceedings of the 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 01","978-1-4799-4143-8","","10.1109/WI-IAT.2014.25","https://doi.org/10.1109/WI-IAT.2014.25","Semantic Web technology is used extensively in the health domain, due to its ability to specify expressive, domain-specific data, as well as its capacity to facilitate data integration between heterogeneous, health-related sources. In the health domain, mobile devices are an essential part of patient self-management approaches, where local clinical decision support is applied to ensure that patients receive timely clinical findings. Currently, increases in mobile device capabilities have enabled the deployment of Semantic Web technologies on mobile platforms, enabling the consumption of rich, semantically described health data. To make this semantic health data available to local decision support as well, Semantic Web reasoning should be deployed on mobile platforms. However, there is currently a lack of software solutions and performance analysis of mobile, Semantic Web reasoning engines. This paper presents and compares the mobile benchmarks of 4 reasoning engines, applied on a dataset and rule set for patients with A trial Fibrillation (AF). In particular, these benchmarks investigate the scalability of the mobile reasoning processes, and study reasoning performance for different process flows in decision support. For the purpose of these benchmarks, we extended a number of existing rule engines and RDF stores with Semantic Web reasoning capabilities.","2014","2025-02-19 14:42:28","2025-02-19 14:42:28","","126–133","","","","","","","WI-IAT '14","","","","IEEE Computer Society","USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"67T267LV","journalArticle","2023","Calautti, Marco; Milani, Mostafa; Pieris, Andreas","Semi-Oblivious Chase Termination for Linear Existential Rules: An Experimental Study","Proc. VLDB Endow.","","2150-8097","10.14778/3611479.3611493","https://doi.org/10.14778/3611479.3611493","The chase procedure is a fundamental algorithmic tool in databases that allows us to reason with constraints, such as existential rules, with a plethora of applications. It takes as input a database and a set of constraints, and iteratively completes the database as dictated by the constraints. A key challenge, though, is the fact that it may not terminate, which leads to the problem of checking whether it terminates given a database and a set of constraints. In this work, we focus on the semi-oblivious version of the chase, which is well-suited for practical implementations, and linear existential rules, a central class of constraints with several applications. In this setting, there is a mature body of theoretical work that provides syntactic characterizations of when the chase terminates, algorithms for checking chase termination, and precise complexity results. Our main objective is to experimentally evaluate the existing chase termination algorithms with the aim of understanding which input parameters affect their performance, clarifying whether they can be used in practice, and revealing their performance limitations.","2023-07","2025-02-19 14:42:28","2025-02-19 14:42:28","","2858–2870","","11","16","","","","","","","","","","","","","","","","","Publisher: VLDB Endowment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW8SZX9C","journalArticle","2011","Analyti, Anastasia; Antoniou, Grigoris; Damasio, Carlos Viegas","MWeb: A principled framework for modular web rule bases and its semantics","ACM Trans. Comput. Logic","","1529-3785","10.1145/1877714.1877723","https://doi.org/10.1145/1877714.1877723","We present a principled framework for modular Web rule bases, called MWeb. According to this framework, each predicate defined in a rule base is characterized by its defining reasoning mode, scope, and exporting rule base list. Each predicate used in a rule base is characterized by its requesting reasoning mode and importing rule base list. For legal MWeb modular rule bases S, the MWebAS and MWebWFS semantics of each rule base s ∈ S with respect to S are defined model-theoretically. These semantics extend the answer set semantics (AS) and the well-founded semantics with explicit negation (WFSX) on ELPs, respectively, keeping all of their semantical and computational characteristics. Our framework supports: (1) local semantics and different points of view, (2) local closed-world and open-world assumptions, (3) scoped negation-as-failure, (4) restricted propagation of local inconsistencies, and (5) monotonicity of reasoning, for fully shared predicates.","2011-01","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","2","12","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","local closed-world and open-world assumptions; local semantics; Modular Web rule bases; scoped negation-as-failure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHHQ743C","conferencePaper","2023","Sidji, Matthew; Smith, Wally; Rogerson, Melissa J.","The Hidden Rules of Hanabi: How Humans Outperform AI Agents","Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems","978-1-4503-9421-5","","10.1145/3544548.3581550","https://doi.org/10.1145/3544548.3581550","Games that feature multiple players, limited communication, and partial information are particularly challenging for AI agents. In the cooperative card game Hanabi, which possesses all of these attributes, AI agents fail to achieve scores comparable to even first-time human players. Through an observational study of three mixed-skill Hanabi play groups, we identify the techniques used by humans that help to explain their superior performance compared to AI. These concern physical artefact manipulation, coordination play, role establishment, and continual rule negotiation. Our findings extend previous accounts of human performance in Hanabi, which are purely in terms of theory-of-mind reasoning, by revealing more precisely how this form of collective decision-making is enacted in skilled human play. Our interpretation points to a gap in the current capabilities of AI agents to perform cooperative tasks.","2023","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","","","","","","CHI '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hamburg, Germany","","","","theory of mind; boardgames; Human-AI Interaction; Human-AI Teaming; Human-Computer Interaction; social roles; teaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ARHH5MRE","journalArticle","2019","Corno, Fulvio; De Russis, Luigi; Monge Roffarello, Alberto","RecRules: Recommending IF-THEN Rules for End-User Development","ACM Trans. Intell. Syst. Technol.","","2157-6904","10.1145/3344211","https://doi.org/10.1145/3344211","Nowadays, end users can personalize their smart devices and web applications by defining or reusing IF-THEN rules through dedicated End-User Development (EUD) tools. Despite apparent simplicity, such tools present their own set of issues. The emerging and increasing complexity of the Internet of Things, for example, is barely taken into account, and the number of possible combinations between triggers and actions of different smart devices and web applications is continuously growing. Such a large design space makes end-user personalization a complex task for non-programmers, and motivates the need of assisting users in easily discovering and managing rules and functionality, e.g., through recommendation techniques. In this article, we tackle the emerging problem of recommending IF-THEN rules to end users by presenting RecRules, a hybrid and semantic recommendation system. Through a mixed content and collaborative approach, the goal of RecRules is to recommend by functionality: it suggests rules based on their final purposes, thus overcoming details like manufacturers and brands. The algorithm uses a semantic reasoning process to enrich rules with semantic information, with the aim of uncovering hidden connections between rules in terms of shared functionality. Then, it builds a collaborative semantic graph, and it exploits different types of path-based features to train a learning to rank algorithm and compute top-N recommendations. We evaluate RecRules through different experiments on real user data extracted from IFTTT, one of the most popular EUD tools. Results are promising: they show the effectiveness of our approach with respect to other state-of-the-art algorithms and open the way for a new class of recommender systems for EUD that take into account the actual functionality needed by end users.","2019-09","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","5","10","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Internet of Things; End-user development; hybrid recommender system; top-N recommendations; trigger-action programming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2BS8KWA","conferencePaper","2008","Faro, Sebastiano; Nannucci, Roberta","Trans-European access to national case law: the Caselex project","Proceedings of the 2nd International Conference on Theory and Practice of Electronic Governance","978-1-60558-386-0","","10.1145/1509096.1509112","https://doi.org/10.1145/1509096.1509112","Starting from the description of the reasons why the transnational access to case law is important especially in the context of European legal systems, some major information systems providing access to this type of data are presented. Then, Caselex (Case Law Exchange), a project financed by the EU Commission aiming at deploying a service equipped with a variety of semantic tools facilitating the transnational and multilingual access to national case law, is highlighted. It has been developed by a strong public-private partnership and has as major targets legal professional categories as well as citizens.","2008","2025-02-19 14:42:28","2025-02-19 14:42:28","","76–81","","","","","","","ICEGOV '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cairo, Egypt","","","","European case law; public-private partnership; semantic retrieval tools; transnational access to legal information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NWDVAYDL","journalArticle","2022","Geng, Zixuan; Schleich, Maximilian; Suciu, Dan","Computing Rule-Based Explanations by Leveraging Counterfactuals","Proc. VLDB Endow.","","2150-8097","10.14778/3570690.3570693","https://doi.org/10.14778/3570690.3570693","Sophisticated machine models are increasingly used for high-stakes decisions in everyday life. There is an urgent need to develop effective explanation techniques for such automated decisions. Rule-Based Explanations have been proposed for high-stake decisions like loan applications, because they increase the users' trust in the decision. However, rule-based explanations are very inefficient to compute, and existing systems sacrifice their quality in order to achieve reasonable performance. We propose a novel approach to compute rule-based explanations, by using a different type of explanation, Counterfactual Explanations, for which several efficient systems have already been developed. We prove a Duality Theorem, showing that rule-based and counterfactual-based explanations are dual to each other, then use this observation to develop an efficient algorithm for computing rule-based explanations, which uses the counterfactual-based explanation as an oracle. We conduct extensive experiments showing that our system computes rule-based explanations of higher quality, and with the same or better performance, than two previous systems, MinSetCover and Anchor.","2022-11","2025-02-19 14:42:28","2025-02-19 14:42:28","","420–432","","3","16","","","","","","","","","","","","","","","","","Publisher: VLDB Endowment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTVLB6RZ","conferencePaper","2002","Oliveira, Stanley R. M.; Zaïane, Osmar R.","Foundations for an access control model for privacy preservation in multi-relational association rule mining","Proceedings of the IEEE International Conference on Privacy, Security and Data Mining - Volume 14","0-909925-92-5","","","","Recent data mining algorithms have been designed for application domains that involve several types of objects stored in multiple relations in relational databases. This fact has motivated the increasing number of successful applications of relational data mining over recent years. On the other hand, such applications have introduced a new threat to privacy and information security since from non-sensitive data one is able to infer sensitive information, including personal information, facts or even patterns that are not supposed to be disclosed. The existing access control models adopted to successfully manage the access of information in complex systems present some limitations in the context of data mining tasks. The main reason is that such models were designed to protect the access to explicit data (e.g. tables, attributes, views, etc), whereas data mining tasks deal with the discovery of implicit data (e.g. patterns). In this paper, we take a first step toward an access control model for ensuring privacy in relational data mining, notably in multi-relational association rules (MRAR). In this model, users associated with different mining access levels, even using the same algorithm, are allowed to mine different sets of association rules. We provide the groundwork to build our access control model over existing technologies and discuss some directions for future work.","2002","2025-02-19 14:42:28","2025-02-19 14:42:28","","19–26","","","","","","","CRPIT '14","","","","Australian Computer Society, Inc.","AUS","","","","","","","","event-place: Maebashi City, Japan","","","","security; access control; data mining; mining access control; privacy preservation in association rule mining; privacy preserving data mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYV4CQXP","conferencePaper","2009","Utting, Mark; Malik, Petra; Toyn, Ian","Transformation rules for Z","Proceedings of the Fifteenth Australasian Symposium on Computing: The Australasian Theory - Volume 94","978-1-920682-75-0","","","","Z is a formal specification language combining typed set theory, predicate calculus, and a schema calculus. This paper describes an extension of Z that allows transformation and reasoning rules to be written in a Z-like notation. This gives a high-level, declarative, way of specifying transformations of Z terms, which makes it easier to build new Z manipulation tools. We describe the syntax and semantics of these rules, plus some example reasoning engines that use sets of rules to manipulate Z terms. The utility of these rules is demonstrated by discussing two sets of rules. One set defines expansion of Z schema expressions. The other set is used by the ZLive animator to preprocess Z expressions into a form more suitable for animation.","2009","2025-02-19 14:42:28","2025-02-19 14:42:28","","73–82","","","","","","","CATS '09","","","","Australian Computer Society, Inc.","AUS","","","","","","","","event-place: Wellington, New Zealand","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCKAHJW5","journalArticle","1994","Kaplan, Ronald M.; Kay, Martin","Regular models of phonological rule systems","Comput. Linguist.","","0891-2017","","","This paper presents a set of mathematical and computational tools for manipulating and reasoning about regular languages and regular relations and argues that they provide a solid basis for computational phonology. It shows in detail how this framework applies to ordered sets of context-sensitive rewriting rules and also to grammars in Koskenniemi's two-level formalism. This analysis provides a common representation of phonological constraints that supports efficient generation and recognition by a single simple interpreter.","1994-09","2025-02-19 14:42:28","2025-02-19 14:42:28","","331–378","","3","20","","","","","","","","","","","","","","","","","Place: Cambridge, MA, USA Publisher: MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYECGFUP","conferencePaper","2001","Bench-Capon, Trevor; Sartor, Giovanni","Theory based explanation of case law domains: 38","Proceedings of the 8th International Conference on Artificial Intelligence and Law","1-58113-368-5","","10.1145/383535.383537","https://doi.org/10.1145/383535.383537","In this paper we put forward a formal description of theories which can be used to record understanding of, and explain decisions in, case law domains. We believe that reasoning with cases involves all of theory construction, use and evaluation, and that awareness of the theory which provides a context for case based arguments is essential to understanding such arguments. Moreover, our account of these theories includes a systematic link between factors and values, which we believe is necessary to explain why some arguments prove to be more persuasive than others. We begin by formalising the various elements that the theories contain, and then provide a set of theory constructors which allow theories to built up from the background of decided cases. We show how such theories can be used to explain decisions on particular cases. We discuss how theories can be compared and evaluated. We then show how the argument moves of HYPO and CATO can be understood in terms of our framework. We conclude with a brief discussion of an implementation of the framework, and a summary of the major features of our approach.","2001","2025-02-19 14:42:28","2025-02-19 14:42:28","","12–21","","","","","","","ICAIL '01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: St. Louis, Missouri, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRL4J8HA","conferencePaper","2009","Martin, Fabienne; Spohr, Dennis; Stein, Achim","Disambiguation of polysemous verbs for rule-based inferencing","Proceedings of the Eighth International Conference on Computational Semantics","978-90-74029-34-6","","","","We present an approach to disambiguating verb senses which differ w.r.t. the inferences they allow. It combines standard ontological tools and formalisms with a formal semantic analysis and is hence more formalised and more detailed than existing lexical semantic resources like WordNet and FrameNet [Fellbaum, 1998, Baker et al., 1998]. The resource presented here implements formal semantic descriptions of verbs in the Web Ontology Language (OWL) and exploits its reasoning potential based on Description Logics (DL) for the disambiguation of verbs in context, since before the correct sense of a verb can be reliably determined, its syntactic arguments have to be disambiguated first. We present details on this process, which is based on a mapping from the French Euro WordNet [Vossen, 1998] to SUMO [Niles and Pease, 2003]. Moreover, we focus on the selectional restrictions of verbs w.r.t. the ontological type of their arguments, as well as their representation as necessary and sufficient conditions in the TBox. After a DL reasoner has identified the verb sense on the basis of these conditions, we make use of the more expressive Semantic Web Rule Language to calculate the inferences that are permitted on the selected interpretation.","2009","2025-02-19 14:42:28","2025-02-19 14:42:28","","222–234","","","","","","","IWCS-8 '09","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Tilburg, The Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLYDP8JH","conferencePaper","2018","Wang, Xing; Sun, Yixin; Tang, Xiaoliang; Chen, Ji; Jin, Jiuxiang","Interchange of criminal rules between CLRL and LKIF","Proceedings of 2018 International Conference on Mathematics and Artificial Intelligence","978-1-4503-6420-1","","10.1145/3208788.3208802","https://doi.org/10.1145/3208788.3208802","There is much fuzzy and non-monotonic knowledge in the Semantic Web Criminal Law Area. In recent years, the problem of fuzzy rules interchange has become one of the most important problems in the Semantic Web. Aiming at the problem of heterogeneous fuzzy rule interchange in the Semantic Web, which is based on the proposed Semantic Web Criminal Law Rule Language (CLRL), and based on the rules and norms of XML. We construct the rule mapping between the CLRL and Legal Knowledge Interchange Format (LKIF), and propose a heterogeneous fuzzy criminal law rules interchange architecture (CRIAXS), which supports the bidirectional rule interchange between legal rules. We also analyze the problem of information loss caused by the different language expression ability in the process of legal knowledge interchange, and put forward to the solution. Based on the above description, the prototype system CRIAXS which is based on the JavaScript language has been achieved on the HBuilder platform. We also verify the correctness and stability of the system through multiple conversion examples. The results show that the architecture and the implemented system which laysa solid foundation for the rule-based reasoning, has a good solution to the communication problem between heterogeneous systems, and it has a wide range of application prospects.","2018","2025-02-19 14:42:28","2025-02-19 14:42:28","","79–84","","","","","","","ICMAI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chengdu, China","","","","semantic web; CLRL; CRIAXS; fuzzy rule interchange; LKIF","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8IW43UY5","journalArticle","2017","Ghiani, Giuseppe; Manca, Marco; Paternò, Fabio; Santoro, Carmen","Personalization of Context-Dependent Applications Through Trigger-Action Rules","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/3057861","https://doi.org/10.1145/3057861","Our life is characterized by the presence of a multitude of interactive devices and smart objects exploited for disparate goals in different contexts of use. Thus, it is impossible for application developers to predict at design time the devices and objects users will exploit, how they will be arranged, and in which situations and for which objectives they will be used. For such reasons, it is important to make end users able to easily and autonomously personalize the behaviour of their Internet of Things applications, so that they can better comply with their specific expectations. In this paper, we present a method and a set of tools that allow end users without programming experience to customize the context-dependent behaviour of their Web applications through the specification of trigger-action rules. The environment is able to support end-user specification of more flexible behaviour than what can be done with existing commercial tools, and it also includes an underlying infrastructure able to detect the possible contextual changes in order to achieve the desired behaviour. The resulting set of tools is able to support the dynamic creation and execution of personalized application versions more suitable for users’ needs in specific contexts of use. Thus, it represents a contribution to obtaining low threshold/high ceiling environments. We also report on an example application in the home automation domain, and a user study that has provided useful positive feedback.","2017-04","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","2","24","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","internet of things; End-user development; trigger-action programming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JJX9MVWJ","journalArticle","2019","Jacobs, Bart","The mathematics of changing one's mind, via Jeffrey's or via Pearl's update rule","J. Artif. Int. Res.","","1076-9757","10.1613/jair.1.11349","https://doi.org/10.1613/jair.1.11349","Evidence in probabilistic reasoning may be 'hard' or 'soft', that is, it may be of yes/no form, or it may involve a strength of belief, in the unit interval [0, 1]. Reasoning with soft, [0, 1]-valued evidence is important in many situations but may lead to different, confusing interpretations. This paper intends to bring more mathematical and conceptual clarity to the field by shifting the existing focus from specification of soft evidence to accomodation of soft evidence. There are two main approaches, known as Jeffrey's rule and Pearl's method; they give different outcomes on soft evidence. This paper argues that they can be understood as correction and as improvement. It describes these two approaches as different ways of updating with soft evidence, highlighting their differences, similarities and applications. This account is based on a novel channel-based approach to Bayesian probability. Proper understanding of these two update mechanisms is highly relevant for inference, decision tools and probabilistic programming languages.","2019-05","2025-02-19 14:42:28","2025-02-19 14:42:28","","783–806","","1","65","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GVRLA3LS","conferencePaper","2023","Correia, João; Pereira, Vítor; Rocha, Miguel","Combining Evolutionary Algorithms with Reaction Rules Towards Focused Molecular Design","Proceedings of the Genetic and Evolutionary Computation Conference","979-8-4007-0119-1","","10.1145/3583131.3590413","https://doi.org/10.1145/3583131.3590413","Designing novel small molecules with desirable properties and feasible synthesis continues to pose a significant challenge in drug discovery, particularly in the realm of natural products. Reaction-based gradient-free methods are promising approaches for designing new molecules as they ensure synthetic feasibility and provide potential synthesis paths. However, it is important to note that the novelty and diversity of the generated molecules highly depend on the availability of comprehensive reaction templates. To address this challenge, we introduce ReactEA, a new open-source evolutionary framework for computer-aided drug discovery that solely utilizes biochemical reaction rules. ReactEA optimizes molecular properties using a comprehensive set of 22,949 reaction rules, ensuring chemical validity and synthetic feasibility. ReactEA is versatile, as it can virtually optimize any objective function and track potential synthetic routes during the optimization process. To demonstrate its effectiveness, we apply ReactEA to various case studies, including the design of novel drug-like molecules and the optimization of pre-existing ligands. The results show that ReactEA consistently generates novel molecules with improved properties and reasonable synthetic routes, even for complex tasks such as improving binding affinity against the PARP1 enzyme when compared to existing inhibitors.","2023","2025-02-19 14:42:28","2025-02-19 14:42:28","","900–909","","","","","","","GECCO '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Lisbon, Portugal","","","","evolutionary algorithms; drug discovery; reaction rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RRJDCDJ2","conferencePaper","2021","Campi, Alessandro; Palese, Corrado","Twitter Association Rule Mining using Clustering and Graph Databases","Proceedings of the 2021 5th International Conference on Information System and Data Mining","978-1-4503-8954-9","","10.1145/3471287.3471309","https://doi.org/10.1145/3471287.3471309","In this scenario, the need to efficiently analyze this kind of data is increasing because of characteristics of such big data, especially their huge and sometimes unpredictable variety. Twitter alone, with 320 M active users every month and more than 500 M tweets per day, could represent an important source of information. For this research, we are focusing solely on social networks. The reason for this choice is that they are increasingly becoming a platform where people will comfortably update their status and share or retrieve information about the world in real time. Often news is spreading through them faster than in traditional channels because user capillarity worldwide makes it possible. In particular, we will focus on Twitter, because its micro-blogging nature makes it suitable for this kind of purpose. It questions the concept of a small private community of friends in favor of less private, less personal broadcast communications of common interest. Another reason why we chose Twitter is because semantic value of hashtags, their power in summarizing tweet content and the spreading model through the social network that allows us to highlight clusters of topics by focusing on these tags.One of the objectives of this thesis is to show how data mining can provide useful techniques to deal with these huge datasets for retrieving information to detect and analyze trending topics and the corresponding user's interactions with them. We identified in Association Rules identification and evolution in time, a systematic approach to conduct the analysis.","2021","2025-02-19 14:42:28","2025-02-19 14:42:28","","90–95","","","","","","","ICISDM '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Silicon Valley, CA, USA","","","","Social media; Clustering; Association rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLFUQTFP","conferencePaper","2023","Kang, Inwon; Han, Qishen; Xia, Lirong","Learning to Explain Voting Rules","Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems","978-1-4503-9432-1","","","","Explaining the outcome of an election is a crucial task to address, especially in the case of complex voting rules. For those without a background in social choice, understanding the result of an election with a complex voting rule can be difficult. One possible way of explaining a voting rule is by using a decision tree structure, allowing the reader to follow the reasoning behind the outcome.This work proposes a methodology for explaining voting rules using decision-tree-based classifiers. Using simple features, the classifiers can be trained to a high accuracy while maintaining a human-readable size. We test this framework with well-established voting rules – Copeland, Kemeny-Young, Ranked Pairs and Schulze – to generate explanations for each election's outcome. We experiment with different decision tree algorithms on a synthetic dataset to generate explanations for the election outcome. We find that Copeland and Schulze under three candidates can be learned perfectly using an optimized decision tree algorithm, while cases of other rules have high accuracy experimentally.","2023","2025-02-19 14:42:28","2025-02-19 14:42:28","","2883–2885","","","","","","","AAMAS '23","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: London, United Kingdom","","","","artificial intelligence; machine learning; explainable ai; explainable voting; social choice; xai","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VE6JY5T9","conferencePaper","2024","Zeng, Wei","Correlation between Injection and Production Parameters in Oilfield Based on Association Rule Mining","Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications","979-8-4007-1814-4","","10.1145/3662739.3672333","https://doi.org/10.1145/3662739.3672333","In today's world where the demand for oil and natural gas is increasing, it is particularly important to effectively utilize oil and natural gas resources. This article uses association rule mining technology to analyze the correlation between oilfield water injection (WI) and mining process parameters, in order to reveal the inherent relationship between each process parameter. On this basis, based on Apriori's data mining method, the cleaning and preprocessing of historical data in the oilfield production process were achieved. By establishing a parameter related network, the interaction between main factors such as WI pressure, WI pressure, and differential pressure of oil wells was studied, as well as their impact on single well productivity. As the WI flow rate increased from 50 cubic meters per hour to 62 cubic meters per hour during the research period, the article found that this increase was closely related to the synchronous increase in WI pressure. The WI parameters have a significant positive impact on the production capacity of oil wells. By adjusting the WI parameters reasonably, a good increase in production can be achieved. The research results of this article can provide scientific data support and decision-making basis for safety production, improving production efficiency, reducing production costs, and improving economic benefits in the process of oilfield exploitation.","2024","2025-02-19 14:42:28","2025-02-19 14:42:28","","648–654","","","","","","","MIDA '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ningbo, China","","","","apriori method; association rule mining; correlation analysis; oilfield injection production parameters; water injection flow rate","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLXVP7W6","conferencePaper","2024","Teng, Lihui","Reservoir Attribute Association Analysis Algorithm for Enhanced Oil Recovery Based on Association Rule Mining","Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications","979-8-4007-1814-4","","10.1145/3662739.3672313","https://doi.org/10.1145/3662739.3672313","The traditional method of reservoir attribute association analysis is inefficient and inaccurate, and there is an urgent need for more accurate and effective analysis methods to guide reservoir development and management. This article aims to explore how to use association rule mining to improve oil recovery and mining efficiency. In this article, a reservoir attribute association analysis algorithm based on association rule mining technology is adopted, and the data mining technology is applied for oil exploration. This algorithm helps oil exploration engineers better understand reservoir characteristics and production conditions by mining association rules between different attributes, thereby improving oil recovery. The experimental results show that the average actual recovery under the simulation of the reservoir attribute association analysis algorithm based on association rule mining for enhanced recovery is 12.46% higher than that under the simulation of the single reservoir attribute association analysis algorithm. An effective algorithm for reservoir attribute association analysis can help oilfield developers better understand reservoir characteristics and development potential, thereby formulating more reasonable development plans and improving development efficiency.","2024","2025-02-19 14:42:28","2025-02-19 14:42:28","","588–595","","","","","","","MIDA '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ningbo, China","","","","Apriori Algorithm; Association Rule Mining; Oil Recovery; Reservoir Attribute Association Analysis Algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMF5X27P","journalArticle","2003","Douceur, John R.","Is remote host availability governed by a universal law?","SIGMETRICS Perform. Eval. Rev.","","0163-5999","10.1145/974036.974039","https://doi.org/10.1145/974036.974039","The availability of peer-to-peer and other distributed systems depends not only on the system architecture but also on the availability characteristics of the hosts participating in the system. This paper constructs a model of remote host availability, derived from measurement studies of four host populations. It argues that hosts are incompletely partitioned into two behavioral classes, one in which they are cycled on/off periodically and one in which they are nominally kept on constantly. Within a class, logarithmic availability generally follows a uniform distribution; however, the underlying reason for this is not readily apparent.","2003-12","2025-02-19 14:42:28","2025-02-19 14:42:28","","25–29","","3","31","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTHF5RKE","conferencePaper","2021","Xiao, Wei; Mehdipour, Noushin; Collin, Anne; Bin-Nun, Amitai Y.; Frazzoli, Emilio; Tebbens, Radboud Duintjer; Belta, Calin","Rule-based optimal control for autonomous driving","Proceedings of the ACM/IEEE 12th International Conference on Cyber-Physical Systems","978-1-4503-8353-0","","10.1145/3450267.3450542","https://doi.org/10.1145/3450267.3450542","We develop optimal control strategies for Autonomous Vehicles (AVs) that are required to meet complex specifications imposed by traffic laws and cultural expectations of reasonable driving behavior. We formulate these specifications as rules, and specify their priorities by constructing a priority structure, called &lt;u&gt;T&lt;/u&gt;otal &lt;u&gt;OR&lt;/u&gt;der over e&lt;u&gt;Q&lt;/u&gt;uivalence classes (TORQ). We propose a recursive framework, in which the satisfaction of the rules in the priority structure are iteratively relaxed based on their priorities. Central to this framework is an optimal control problem, where convergence to desired states is achieved using Control Lyapunov Functions (CLFs), and safety is enforced through Control Barrier Functions (CBFs). We also show how the proposed framework can be used for after-the-fact, pass/fail evaluation of trajectories - a given trajectory is rejected if we can find a controller producing a trajectory that leads to less violation of the rule priority structure. We present case studies with multiple driving scenarios to demonstrate the effectiveness of the proposed framework.","2021","2025-02-19 14:42:28","2025-02-19 14:42:28","","143–154","","","","","","","ICCPS '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Nashville, Tennessee","","","","autonomous driving; Lyapunov methods; priority structure; safety","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3BHJUWV","conferencePaper","2010","AL Faresi, Ahmed; Wijesekera, Duminda; Moidu, Khaled","A comprehensive privacy-aware authorization framework founded on HIPAA privacy rules","Proceedings of the 1st ACM International Health Informatics Symposium","978-1-4503-0030-8","","10.1145/1882992.1883093","https://doi.org/10.1145/1882992.1883093","Health care entities publish privacy polices that are aligned with government regulations such as Health Insurance Portability and Accountability Act (HIPPA) and promise to use and disclose health data according to the stated policies. However actual practices may deliberately or unintentionally violate these policies. To ensure enforcement of such policies and ultimately HIPAA compliancy there is a need to develop an enforcement mechanism. In this paper we extend our work on IT-enforceable policies, submitted to the International Journal of Medical Informatics. The submitted work involved a detailed analysis of HIPPA privacy rules to extract object related conditions needed to make a disclosure decision. In this paper we extend this work to propose machine enforceable policies that embody HIPAA privacy disclosure rules and a health care entity access control rules. We also propose a comprehensive access/privacy control architecture that enforces the proposed polices. The architectural model is designed to allow for a dynamic configuration of policies without reconfiguring the architecture responsible for enforcement. Both the proposed policies and the architecture allow for multiple stakeholders to adjust the privacy preferences to manage the disclosure of data by adjusting the designated parameters in their respective policies. The objective of this study is to provide a comprehensive model for privacy protection, access and logging of PHI, that is HIPAA compliant.","2010","2025-02-19 14:42:28","2025-02-19 14:42:28","","637–646","","","","","","","IHI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Arlington, Virginia, USA","","","","privacy policy; hipaa; access control; ehr; itepp; phi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VEMUD2R","conferencePaper","2003","Greenwood, Katie; Capon, Trevor Bench; McBurney, Peter","Towards a computational account of persuasion in law","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047792","https://doi.org/10.1145/1047788.1047792","In this paper we attempt to give an account of reasoning with legal cases contextualised within a general theory of persuasion in practical reasoning. We begin by presenting our general theory, concentrating on the variety of ways in which a particular position can be attacked. We then apply our theory to the legal domain, illustrating our approach by a case study based on the well known CATO system. From this we conclude that it is possible to see reasoning with legal cases as a particular instantiation of our general theory. We identify some points of interest for discussion, and conclude by stating our intended directions for future work.","2003","2025-02-19 14:42:28","2025-02-19 14:42:28","","22–31","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJIVL45F","conferencePaper","1987","Maida, A. S.","A uniform architecture for rule-based meta-reasoning and representation: a case study","Proceedings of the 1987 Fall Joint Computer Conference on Exploring Technology: Today and Tomorrow","0-8186-0811-0","","","","This Paper describes an elegant architecture for reasoning with meta representations. The architecture uses the same inference engine both for reasoning/representation and meta reasoning/representation. The resulting system is very good at reasoning about its representations as long as it does not have to directly modify its control structure.We have examined this architecture for application to the domain of belief reasoning. Such a system seems well matched to belief reasoning applications where the process of simply reasoning about another agent's beliefs would never directly change that other agent's beliefs. We have concluded that even in such a promising domain, a uniform architecture seems too costly in terms of various practical considerations including: clarity, speed, and parallelizability. Although, we consider this only one particular case study, it is hard to imagine an application area more well suited to the features that this architecture can offer. As such we would expect less encouraging results in other domains.","1987","2025-02-19 14:42:28","2025-02-19 14:42:28","","652–657","","","","","","","ACM '87","","","","IEEE Computer Society Press","Washington, DC, USA","","","","","","","","event-place: Dallas, Texas, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQPEAQ4R","conferencePaper","2024","Wang, Decheng; Chen, Yan","Correlation Analysis of Computer Curriculums Based on Clustering and Association Rules","Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence","979-8-4007-1615-7","","10.1145/3660043.3660096","https://doi.org/10.1145/3660043.3660096","The current curriculum holds great significance in the talent training program of universities, as its reasonable structure directly impacts the quality of talent development. However, the curriculum is primarily based on the expertise and experience of administrators, experts, and teachers. In light of this, this paper proposes an analysis method for curriculum scores based on clustering and association rules to address the learning situation and improvement needs of computer science and technology students within their training programs. Specifically focusing on 2018 undergraduate Curriculum scores as research objects, K-means algorithm is used to discretize grade information, and Apriori algorithm is used for data mining in order to derive association rules between curriculums in this paper. This enables us to analyze both inter-curriculum relationships and curriculum importance. The mined rules not only provide valuable reference information for designing and enhancing teaching schemes but also contribute towards optimizing professional curriculum systems. Ultimately, they play a pivotal role in improving teaching quality as well as students' learning outcomes.","2024","2025-02-19 14:42:28","2025-02-19 14:42:28","","294–299","","","","","","","ICIEAI '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Xiamen, China","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPUDBHAF","journalArticle","2018","Torre-Bastida, Ana I.; Bermúdez, Jesús; Illarramendi, Arantza","A Rule-Based Transducer for Querying Incompletely Aligned Datasets","ACM Trans. Web","","1559-1131","10.1145/3228328","https://doi.org/10.1145/3228328","A growing number of Linked Open Data sources (from diverse provenances and about different domains) that can be freely browsed and searched to find and extract useful information have been made available. However, access to them is difficult for different reasons. This study addresses access issues concerning heterogeneity. It is common for datasets to describe the same or overlapping domains while using different vocabularies. Our study presents a transducer that transforms a SPARQL query suitably expressed in terms of the vocabularies used in a source dataset into another SPARQL query suitably expressed for a target dataset involving different vocabularies. The transformation is based on existing alignments between terms in different datasets. Whenever the transducer is unable to produce a semantically equivalent query because of the scarcity of term alignments, the transducer produces a semantic approximation of the query to avoid returning the empty answer to the user. Transformation across datasets is achieved through the management of a wide range of transformation rules. The feasibility of our proposal has been validated with a prototype implementation that processes queries that appear in well-known benchmarks and SPARQL endpoint logs. Results of the experiments show that the system is quite effective in achieving adequate transformations.","2018-09","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","4","12","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","linked open data; query transformation; RDF; Semantic web; SPARQL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L2FKTFMR","conferencePaper","2019","Zhang, Wen; Paudel, Bibek; Wang, Liang; Chen, Jiaoyan; Zhu, Hai; Zhang, Wei; Bernstein, Abraham; Chen, Huajun","Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning","The World Wide Web Conference","978-1-4503-6674-8","","10.1145/3308558.3313612","https://doi.org/10.1145/3308558.3313612","Reasoning is essential for the development of large knowledge graphs, especially for completion, which aims to infer new triples based on existing ones. Both rules and embeddings can be used for knowledge graph reasoning and they have their own advantages and difficulties. Rule-based reasoning is accurate and explainable but rule learning with searching over the graph always suffers from efficiency due to huge search space. Embedding-based reasoning is more scalable and efficient as the reasoning is conducted via computation between embeddings, but it has difficulty learning good representations for sparse entities because a good embedding relies heavily on data richness. Based on this observation, in this paper we explore how embedding and rule learning can be combined together and complement each other's difficulties with their advantages. We propose a novel framework IterE iteratively learning embeddings and rules, in which rules are learned from embeddings with proper pruning strategy and embeddings are learned from existing triples and new triples inferred by rules. Evaluations on embedding qualities of IterE show that rules help improve the quality of sparse entity embeddings and their link prediction results. We also evaluate the efficiency of rule learning and quality of rules from IterE compared with AMIE+, showing that IterE is capable of generating high quality rules more efficiently. Experiments show that iteratively learning embeddings and rules benefit each other during learning and prediction.","2019","2025-02-19 14:42:28","2025-02-19 14:42:28","","2366–2377","","","","","","","WWW '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Francisco, CA, USA","","","","knowledge graph; reasoning; embedding; rule learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGD74TRI","conferencePaper","2022","He, Zhuolun; Ma, Yuzhe; Yu, Bei","X-Check: GPU-Accelerated Design Rule Checking via Parallel Sweepline Algorithms","Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design","978-1-4503-9217-4","","10.1145/3508352.3549383","https://doi.org/10.1145/3508352.3549383","Design rule checking (DRC) is essential in physical verification to ensure high yield and reliability for VLSI circuit designs. To achieve reasonable design cycle time, acceleration for computationally intensive DRC tasks has been demanded to accommodate the ever-growing complexity of modern VLSI circuits. In this paper, we propose X-Check, a GPU-accelerated design rule checker. X-Check integrates novel parallel sweepline algorithms, which are both efficient in practice and with nontrivial theoretical guarantees. Experimental results have demonstrated significant speedup achieved by X-Check compared with a multi-threaded CPU checker.","2022","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","","","","","","ICCAD '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJZRBXZ3","conferencePaper","2019","Ghosh, Bishwamittra; Meel, Kuldeep S.","IMLI: An Incremental Framework for MaxSAT-Based Learning of Interpretable Classification Rules","Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","978-1-4503-6324-2","","10.1145/3306618.3314283","https://doi.org/10.1145/3306618.3314283","The wide adoption of machine learning in the critical domains such as medical diagnosis, law, education had propelled the need for interpretable techniques due to the need for end users to understand the reasoning behind decisions due to learning systems. The computational intractability of interpretable learning led practitioners to design heuristic techniques, which fail to provide sound handles to tradeoff accuracy and interpretability. Motivated by the success of MaxSAT solvers over the past decade, recently MaxSAT-based approach, called MLIC, was proposed that seeks to reduce the problem of learning interpretable rules expressed in Conjunctive Normal Form (CNF) to a MaxSAT query. While MLIC was shown to achieve accuracy similar to that of other state of the art black-box classifiers while generating small interpretable CNF formulas, the runtime performance of MLIC is significantly lagging and renders approach unusable in practice. In this context, authors raised the question: Is it possible to achieve the best of both worlds, i.e., a sound framework for interpretable learning that can take advantage of MaxSAT solvers while scaling to real-world instances? In this paper, we take a step towards answering the above question in affirmation. We propose IMLI: an incremental approach to MaxSAT based framework that achieves scalable runtime performance via partition-based training methodology. Extensive experiments on benchmarks arising from UCI repository demonstrate that IMLI achieves up to three orders of magnitude runtime improvement without loss of accuracy and interpretability.","2019","2025-02-19 14:42:28","2025-02-19 14:42:28","","203–210","","","","","","","AIES '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Honolulu, HI, USA","","","","classification rules; interpretable model; maxsat-based formulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RC5J3BRX","conferencePaper","2011","Lang, Jérôme; Pigozzi, Gabriella; Slavkovik, Marija; van der Torre, Leendert","Judgment aggregation rules based on minimization","Proceedings of the 13th Conference on Theoretical Aspects of Rationality and Knowledge","978-1-4503-0707-9","","10.1145/2000378.2000407","https://doi.org/10.1145/2000378.2000407","Many voting rules are based on some minimization principle. Likewise, in the field of logic-based knowledge representation and reasoning, many belief change or inconsistency handling operators also make use of minimization. Surprisingly, minimization has not played a major role in the field of judgment aggregation, in spite of its proximity to voting theory and logic-based knowledge representation and reasoning. Here we make a step in this direction and study six judgment aggregation rules; two of them, based on distances, have been previously defined; the other four are new, and all inspired both by voting theory and knowledge representation and reasoning. We study the inclusion relationships between these rules and address some of their social choice theoretic properties.","2011","2025-02-19 14:42:28","2025-02-19 14:42:28","","238–246","","","","","","","TARK XIII","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Groningen, The Netherlands","","","","aggregation rules; distance-based merging; judgment aggregation; voting theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTVERIIL","conferencePaper","2021","Li, Zhenghui; Yu, Wei; Lv, Feiya","Motor Rotor Fault Diagnosis Method Based on Belief Rule Base Inference","2021 2nd International Conference on Artificial Intelligence and Information Systems","978-1-4503-9020-0","","10.1145/3469213.3470692","https://doi.org/10.1145/3469213.3470692","This paper presents a belief rule base (BRB) method for diagnosing motor rotor fault. The BRB is used to model the complex non-linear relationship between the abnormal vibration features of motor rotor and its fault type. Firstly, a belief rule base inference model is constructed based on the variation of vibration amplitude of multi-frequency components caused by motor rotor fault. The input of the model is 1X∼3X frequency domain amplitude change and time domain vibration displacement amplitude change, and the output of the model is the type of motor rotor fault. The belief rules activated by the inputs are combined by the evidential reasoning (ER) algorithm so as to obtain the fused belief structure about the fault, and then, the accurate diagnose result can be calculated from the fused result. The diagnosis results can not only judge the fault type, but also give the probability of potential fault. The model parameters are open and interpretable. Finally, in the experiment of fault diagnosis of motor rotor, the effectiveness of the proposed method is illustrated.","2021","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","","","","","","ICAIIS 2021","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chongqing, China","","","","Machine learning; Belief rule base; Fault diagnosis; Motor rotor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RIEDM8CC","conferencePaper","2020","Koster, Raphael; Hadfield-Menell, Dylan; Hadfield, Gillian K.; Leibo, Joel Z.","Silly Rules Improve the Capacity of Agents to Learn Stable Enforcement and Compliance Behaviors","Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems","978-1-4503-7518-4","","","","Howcan societies learn to enforce and comply with social norms? Many if not most human norms are functional. Rules that punish non-cooperative behavior, for example, support cooperation. An intriguing feature of human normativity is that many social norms concern behaviors that have no direct impact on material wellbeing. Examples include rules about what color clothing one wears to a funeral [7] or whether one uses one's left or right hand in particular tasks [2]. Such apparently pointless rules are ubiquitous, often acquiring great social meaning despite the absence of functionality. Hadfield-Menell et al. (2019) call these norms ""silly rules"" and distinguish them from ""important rules,"" such as rules that govern resource sharing or prohibit harmful conduct, that directly impact welfare [3].","2020","2025-02-19 14:42:28","2025-02-19 14:42:28","","1887–1888","","","","","","","AAMAS '20","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Auckland, New Zealand","","","","norms; deep reinforcement-learning; multi-agent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2A6UKAV5","conferencePaper","2013","Lotzmann, Ulf; Wimmer, Maria A.","Evidence Traces for Multi-agent Declarative Rule-Based Policy Simulation","Proceedings of the 2013 IEEE/ACM 17th International Symposium on Distributed Simulation and Real Time Applications","978-0-7695-5138-8","","10.1109/DS-RT.2013.20","https://doi.org/10.1109/DS-RT.2013.20","In the field of policy modeling, a trend to growing complexity and complication of simulation models can be observed. One of the reasons for this development is the fact that for many policy cases of practical interest there are no theories available from which ""simple"" simulation models could be derived. Instead a sometimes vast amount of information-scenarios describing stakeholders views, documents providing background information - has to be taken into account by the simulation model. Methods and tools for utilizing such evidence bases have a great importance for the success of respective modeling activities. This paper outlines a novel approach in that regard which has been developed within the OCOPOMOproject and basically consists of a policy development process specification, and a software toolbox supporting this process. Main focus of this paper are simulation related aspects of both the process and the toolbox, with the aim to demonstrate the impact of trace ability for modeling, simulation and result analysis.","2013","2025-02-19 14:42:28","2025-02-19 14:42:28","","115–122","","","","","","","DS-RT '13","","","","IEEE Computer Society","USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BYGHZR5I","journalArticle","2014","Schiffel, Stephan; Thielscher, Michael","Representing and reasoning about the rules of general games with imperfect information","J. Artif. Int. Res.","","1076-9757","","","A general game player is a system that can play previously unknown games just by being given their rules. For this purpose, the Game Description Language (GDL) has been developed as a high-level knowledge representation formalism to communicate game rules to players. In this paper, we address a fundamental limitation of state-of-the-art methods and systems for General Game Playing, namely, their being confined to deterministic games with complete information about the game state. We develop a simple yet expressive extension of standard GDL that allows for formalising the rules of arbitrary finite, n-player games with randomness and incomplete state knowledge. In the second part of the paper, we address the intricate reasoning challenge for general game-playing systems that comes with the new description language. We develop a full embedding of extended GDL into the Situation Calculus augmented by Scherl and Levesque's knowledge fluent. We formally prove that this provides a sound and complete reasoning method for players' knowledge about game states as well as about the knowledge of the other players.","2014-01","2025-02-19 14:42:28","2025-02-19 14:42:28","","171–206","","1","49","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FIEXPEHF","conferencePaper","2003","Murata, Takahiro; Minsky, Naftaly H.","On shouting ""Fire!"": regulating decoupled communication in distributed systems","Proceedings of the ACM/IFIP/USENIX 2003 International Conference on Middleware","3-540-40317-5","","","","Decoupled communication, which requires no direct association between the producers of information and its consumers – as under the publish/subscribe (P/S) middleware – is often essential for the integration of distributed and heterogeneous applications. But the indefinite, and potentially global, reach of decoupled communication – the very reason for its power – has a dark side, which may complicate the system using it, making it less predictable, more brittle, and less safe. Just think about the effect of shouting ""fire"" in a packed theatre, particularly, but not only, if it is a false alarm.It is our thesis that the inherent drawbacks of decoupled communication can be tamed by decentralized regulation of its use. We show how such regulation can be carried out scalably by means of a distributed control mechanism called Law-Governed Interaction (LGI), and a middleware called Moses that implements this mechanism. Along the way, we illustrate the importance of such regulation, and its effectiveness, by considering the treatment of alarms in a large hospital.","2003","2025-02-19 14:42:28","2025-02-19 14:42:28","","222–241","","","","","","","Middleware '03","","","","Springer-Verlag","Berlin, Heidelberg","","","","","","","","event-place: Rio de Janeiro, Brazil","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SCWINBER","conferencePaper","2007","Moradi, Farshad; Ayani, Rassul; Tan, Gary","A Rule-based Approach to Syntactic and Semantic Composition of BOMs","Proceedings of the 11th IEEE International Symposium on Distributed Simulation and Real-Time Applications","0-7695-3011-7","","10.1109/DS-RT.2007.10","https://doi.org/10.1109/DS-RT.2007.10","Creating simulation models via composition of predefined and reusable components is an efficient way of reducing costs and time associated with the simulation model development process. However, in order to successfully compose models one has to solve the issues of syntactic and semantic composability of components. HLA is the most widely used architecture for distributed simulations today. It provides a simulation environment and standards for specifying simulation parts and interactions between simulation parts. But it provides little support for semantic composability. The Base Object Model (BOM) standard is an attempt to ease reusability and composition of simulation models. However, BOMs do not contain sufficient information for defining concepts and terms in order to avoid ambiguity, and provide no methods for matching conceptual models (state machines). In this paper, we present our approach for enhancement of the semantic contents of BOMs and propose a three-layer model for syntactic and semantic matching of BOMs. The semantic enhancement includes ontologies for entities, event and interactions in each component. We also present an OWL-S description for each component including the statemachines. The three-layer model consists of syntactic matching, static semantic matching and dynamic semantic matching utilising a set of rules for reasoning about the compositions. We also describe our discovery and matching rules, which have been implemented in the Jess inference engine. In order to test our approach we have defined some simulation scenarios and implemented BOMs as building blocks for development of those scenarios, one of which has been presented in this paper. Our result shows that the three-layer model is promising and can improve and simplify composition of BOM-based components.","2007","2025-02-19 14:42:28","2025-02-19 14:42:28","","145–155","","","","","","","DS-RT '07","","","","IEEE Computer Society","USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NC3QFZTD","conferencePaper","2013","Pillat, Raquel M.; Basso, Fabio P.; Oliveira, Toacy C.; Werner, Cláudia M. L.","Ensuring consistency of feature-based decisions with a business rule system","Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems","978-1-4503-1541-8","","10.1145/2430502.2430523","https://doi.org/10.1145/2430502.2430523","Feature Models are widely used in some domains to represent variabilities and support decisions that configure a specific combination of domain elements. A feature configuration is created by selecting a features set that satisfies constraints imposed by the model. However, especially regarding complex or large models, end users are prone to making inconsistent decisions. In these cases, an automated support to assist users while resolving decision conflicts and restoring the configuration's validity is highly desirable. Thus, this paper proposes a flexible approach to ensure the consistency of feature configurations which is based on a Business Rules Management System (BRMS). Such systems are essential components in the world of business decision support applications due to facilities provided for constraints specification and execution management. The proposed approach shows how existing BRMS can be effectively used in a feature configuration process to resolve decision conflicts and restore the configuration correctness after user's illegal decisions while helping him/her to reason about possibilities that the model offers and to understand the impact of each decision-making. The main advantage of using a BRMS to specify and manage feature model constraints is the facility with which such complex activities can be supported. This paper reports preliminary research results achieved with the proposed approach.","2013","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","","","","","","VaMoS '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pisa, Italy","","","","business rule system; consistency management; feature-based decisions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NT344YF4","conferencePaper","2021","Heger, Jens; Voss, Thomas","Dynamically changing sequencing rules with reinforcement learning in a job shop system with stochastic influences","Proceedings of the Winter Simulation Conference","978-1-7281-9499-8","","","","Sequencing operations can be difficult, especially under uncertain conditions. Applying decentral sequencing rules has been a viable option; however, no rule exists that can outperform all other rules under varying system performance. For this reason, reinforcement learning (RL) is used as a hyper heuristic to select a sequencing rule based on the system status. Based on multiple training scenarios considering stochastic influences, such as varying inter arrival time or customers changing the product mix, the advantages of RL are presented. For evaluation, the trained agents are exploited in a generic manufacturing system. The best agent trained is able to dynamically adjust sequencing rules based on system performance, thereby matching and outperforming the presumed best static sequencing rules by ≈ 3%. Using the trained policy in an unknown scenario, the RL heuristic is still able to change the sequencing rule according to the system status, thereby providing robust performance.","2021","2025-02-19 14:42:28","2025-02-19 14:42:28","","1608–1618","","","","","","","WSC '20","","","","IEEE Press","","","","","","","","","Place: Orlando, Florida","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C9HEWCEW","conferencePaper","2019","Borrego, Agustín; Ayala, Daniel; Hernández, Inma; Rivero, Carlos R.; Ruiz, David","Generating Rules to Filter Candidate Triples for their Correctness Checking by Knowledge Graph Completion Techniques","Proceedings of the 10th International Conference on Knowledge Capture","978-1-4503-7008-0","","10.1145/3360901.3364418","https://doi.org/10.1145/3360901.3364418","Knowledge Graphs (KGs) contain large amounts of structured information. Due to their inherent incompleteness, a process known as KG completion is often carried out to find the missing triples in a KG, usually by training a fact checking model that is able to discern between correct and incorrect knowledge. After the fact checking model has been trained and evaluated, it has to be applied to a set of candidate triples, and those that are considered correct are added to the KG as new knowledge. However, this process needs a set of candidate triples of a reasonable size that represents possible new knowledge, in order to be evaluated by the fact checking task and, if considered to be correct, added to the KG, enriching it. Current approaches for selecting candidate triples for their correctness checking either use the full set possible missing candidate triples (and thus provide no filtering) or apply very basic rules to filter out unlikely candidates, which may have a negative effect on the completion performance as very few candidate triples are filtered out. In this paper we present CHAI, a method for producing more complex rules that are able to filter candidate triples by combining a set of criteria to optimize a fitness function. Our experiments show that CHAI is able to generate rules that, when applied, yield smaller candidate sets than similar proposals while still including promising candidate triples.","2019","2025-02-19 14:42:28","2025-02-19 14:42:28","","115–122","","","","","","","K-CAP '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Marina Del Rey, CA, USA","","","","candidate filtering; knowledge graph completion; knowledge graphs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H5ZA9ZD2","conferencePaper","2020","Huynh, Viet-Ngu Cong; Lee, Keon Myung","Solving the Multi-class Classification Task in Spiking Neural Network by using Supervised Spiking Learning Rule with a Consistent Competitive Mechanism","Proceedings of the International Conference on Research in Adaptive and Convergent Systems","978-1-4503-8025-6","","10.1145/3400286.3418274","https://doi.org/10.1145/3400286.3418274","In recent years, spiking neural networks (SNNs), a computing model inspired by the brain's ability to code and process information in the time domain with great computational power, has drawn a lot of attention from researchers for learning applications. For training in SNNs, several supervised spiking learning rules have been proposed, however, applying these learning algorithms to real-world problems yet remains an open issue. For this reason, this paper presents a new spiking neural network for the handwritten digit dataset classification problem. Our proposed network is trained by using the spike-based NormAD algorithm with a consistent winner-take-all mechanism. The experiment has shown a promising performance just after one epoch passing over the test dataset.","2020","2025-02-19 14:42:28","2025-02-19 14:42:28","","77–81","","","","","","","RACS '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gwangju, Republic of Korea","","","","artificial intelligence; Brain-inspired network; SNN; spiking neural network; supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q653RHNV","conferencePaper","2011","Singh, Amit Kumar; Tyagi, Barjeev; kumar, Vishal","Fuzzy rule-based controller for binary distillation column","Proceedings of the International Conference on Advances in Computing and Artificial Intelligence","978-1-4503-0635-5","","10.1145/2007052.2007086","https://doi.org/10.1145/2007052.2007086","In this paper a fuzzy logic based control scheme has been proposed for distillation column. Fuzzy Inference Systems (FIS) is proposed to adjust the manipulated variables to get the desired composition of products for a binary distillation column. To control the top and bottom product composition two separate fuzzy inference systems has been designed. The scheme uses fuzzy rules and reasoning to determine the desired outputs based on the error signal and its first difference","2011","2025-02-19 14:42:28","2025-02-19 14:42:28","","166–169","","","","","","","ACAI '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rajpura/Punjab, India","","","","distillation column control; fuzzy inference systems; reflux flow rate","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SUJ8D8GU","journalArticle","2020","Ahmadi, Naser; Huynh, Viet-Phi; Meduri, Vamsi; Ortona, Stefano; Papotti, Paolo","Mining Expressive Rules in Knowledge Graphs","J. Data and Information Quality","","1936-1955","10.1145/3371315","https://doi.org/10.1145/3371315","We describe RuDiK, an algorithm and a system for mining declarative rules over RDF knowledge graphs (KGs). RuDiK can discover rules expressing both positive relationships between KG elements, e.g., “if two persons share at least one parent, they are likely to be siblings,” and negative patterns identifying data contradictions, e.g., “if two persons are married, one cannot be the child of the other” or “the birth year for a person cannot be bigger than her graduation year.” While the first kind of rules identify new facts in the KG, the second kind enables the detection of incorrect triples and the generation of (training) negative examples for learning algorithms. High-quality rules are also critical for any reasoning task involving the KGs.Our approach increases the expressive power of the supported rule language w.r.t. the existing systems. RuDiK discovers rules containing (i) comparisons among literal values and (ii) selection conditions with constants. Richer rules increase the accuracy and the coverage over the facts in the KG for the task at hand. This is achieved with aggressive pruning of the search space and with disk-based algorithms, which enable the execution of the system in commodity machines. Also, RuDiK is robust to errors and missing data in the input graph. It discovers approximate rules with a measure of support that is aware of the quality issues. Our experimental evaluation with real-world KGs shows that RuDiK does better than existing solutions in terms of scalability and that it can identify effective rules for different target applications.","2020-05","2025-02-19 14:42:28","2025-02-19 14:42:28","","","","2","12","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","knowledge graphs; graph dependencies; Rule mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C4UD8CA9","journalArticle","1987","Dhar, Vasant; Pople, Harry E.","Rule-based versus structure-based models for explaining and generating expert behavior","Commun. ACM","","0001-0782","10.1145/214762.214773","https://doi.org/10.1145/214762.214773","Flexible representations are required in order to understand and generate expert behavior. Although production rules with quantifiers can encode experiential knowledge, they often have assumptions implicit in them, making them brittle in problem scenarios where these assumptions do not hold. Qualitative models achieve flexibility by representing the domain entities and their interrelationships explicitly. However, in problem domains where assumptions underlying such models change periodically, it is necessary to be able to synthesize and maintain qualitative models in response to the changing assumptions. In this paper we argue for a representation that contains partial model components that are synthesized into qualitative models containing entities and relationships relevant to the domain. The model components can be replaced and rearranged in response to changes in the task environment. We have found this ""model constructor"" to be useful in synthesizing models that explain and generate expert behavior, and have explored its ability to support decision making in the problem domain of business resource planning, where reasoning is based on models that evolve in response to changing external conditions or internal policies.","1987-06","2025-02-19 14:42:29","2025-02-19 14:42:29","","542–555","","6","30","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JBD85D4","conferencePaper","2016","Xu, Shenghua; Tang, Minqian; Xiao, Lin","The evaluation and improvement of traffic rule: based on intelligent information processing","Proceedings of the 1st International Conference on Intelligent Information Processing","978-1-4503-4799-0","","10.1145/3028842.3028870","https://doi.org/10.1145/3028842.3028870","By reverse the abscissa and ordinate axis of the coordinate system, we get the N-R, Vi-R, and the Dh-R curve. The related polynomial regression equations of the curves are obtained using the excel. Combine with the traffic influencing factors, we have the traffic integration index model which shows the changes of R influenced by these factors. We find the most powerful influencing factor (N) by sensitive analysis as the main optimization direction to design new rules. Our new rule applies in extremely heavy traffic with the consideration of speed and vehicle type limits and no overtaking behaviors. Using hypothetic-deductive reasoning, we prove the new rule to be more effective. When applying the keep-left-except-to-pass rule, the values of Vi and the traffic influencing factors won't change, thus the I model could be effectively used without any changes. For the new rule, the only necessary adjustment is to let the n-th lane's direction being reversed. The fully control of the intelligent system makes it possible for the overtaking and lane-changing behavior forbidden in the new rule. To meet this change, we set the acceleration-changing rule (only for heavy duty car from the slow lane) and the deceleration-changing rule (only for middle-sized vehicle from the fast lane). Based on the observing data we have the time-velocity and the time-vehicle distance curve. The adjustments are proved to be necessary and reasonable by graphic analysis.","2016","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","ICIIP '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Wuhan, China","","","","real traffic capacity; space-occupation ratio; traffic rule; vehicle headway distance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WC4ARTTN","conferencePaper","2009","Sherr, Micah; Shah, Gaurav; Cronin, Eric; Clark, Sandy; Blaze, Matt","Can they hear me now? a security analysis of law enforcement wiretaps","Proceedings of the 16th ACM Conference on Computer and Communications Security","978-1-60558-894-0","","10.1145/1653662.1653724","https://doi.org/10.1145/1653662.1653724","Although modern communications services are susceptible to third-party eavesdropping via a wide range of possible techniques, law enforcement agencies in the US and other countries generally use one of two technologies when they conduct legally-authorized interception of telephones and other communications traffic. The most common of these, designed to comply with the 1994 Communications Assistance for Law Enforcement Act(CALEA), use a standard interface provided in network switches.This paper analyzes the security properties of these interfaces. We demonstrate that the standard CALEA interfaces are vulnerable to a range of unilateral attacks by the intercept target. In particular, because of poor design choices in the interception architecture and protocols, our experiments show it is practical for a CALEA-tapped target to overwhelm the link to law enforcement with spurious signaling messages without degrading her own traffic, effectively preventing call records as well as content from being monitored or recorded. We also identify stop-gap mitigation strategies that partially mitigate some of our identified attacks.","2009","2025-02-19 14:42:29","2025-02-19 14:42:29","","512–523","","","","","","","CCS '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, Illinois, USA","","","","calea; law enforcement wiretaps; wiretapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YLNPEM7G","conferencePaper","2016","Shi, Hui; Maly, Kurt; Chong, Dazhi; Yan, Gongjun; He, Wu","Backward Chaining Ontology Reasoning Systems with Custom Rules","Proceedings of the 25th International Conference Companion on World Wide Web","978-1-4503-4144-8","","10.1145/2872518.2890521","https://doi.org/10.1145/2872518.2890521","In the semantic web, content is tagged with ""meaning"" or ""semantics"" to facilitate machine processing and web searching. In general, question answering systems that are built on top of reasoning and inference face a number of difficult issues. In this paper, we analyze scalability issues faced by a question answering system used by a knowledge base with science information that has been harvested from the web. Using this system, we will be able to answer questions that contain qualitative descriptors such as ""groundbreaking"", ""top researcher"", and ""tenurable at university x"". This question answering system has been built using ontologies, reasoning systems and custom based rules for the reasoning system. Furthermore, we evaluated the performance of our optimized backward chaining engine on supporting custom rules and designed the experimental environment including scalable datasets, rule sets, query sets and metrics and compared the experimental results with other in-memory ontology reasoning systems. The results show that our developed backward chaining ontology reasoning system has better scalability than in-memory reasoning systems.","2016","2025-02-19 14:42:29","2025-02-19 14:42:29","","381–387","","","","","","","WWW '16 Companion","","","","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","","","","","","","","event-place: Montréal, Québec, Canada","","","","ontology; semantic web; backward chaining reasoner; benchmark; custom rules; ontology reasoning system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQCV2E6W","conferencePaper","2010","Buczak, Anna L.; Gifford, Christopher M.","Fuzzy association rule mining for community crime pattern discovery","ACM SIGKDD Workshop on Intelligence and Security Informatics","978-1-4503-0223-4","","10.1145/1938606.1938608","https://doi.org/10.1145/1938606.1938608","Current manual inspection of crime data by analysts is limited, primarily due to the amount of data that can be processed concurrently and in a reasonable time frame. Further, complex relationships between various crime attributes can be overlooked by human analysts. Providing automated knowledge discovery tools becomes attractive to accelerate the efforts of local law enforcement. In this paper, we study the application of fuzzy association rule mining for community crime pattern discovery. Discovered rules are presented and discussed at regional and national levels. Rules found to hold in all states, be consistent across all regions, and subsets of regions are also discussed. A relative support metric was defined to extract rare, novel rules from thousands of discovered rules. Such an approach relieves the need of law enforcement personnel to sift through uninteresting, obvious rules in order to find interesting and meaningful crime patterns of importance to their community.","2010","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","ISI-KDD '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington, D.C.","","","","community-based crime; crime data mining; fuzzy association rules; rule pruning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BXP2GC5","journalArticle","1996","Wolverton, Michael","Book review: Case-Based Reasoning in Design by Mary Lou Maher, M. Bala Balachandran, and Dong Mei Zhang (Lawrence Erlbaum Associates, 1995)","SIGART Bull.","","0163-5719","10.1145/239616.1066355","https://doi.org/10.1145/239616.1066355","Developing computer programs that support the design process has long been an area of study in Artificial Intelligence. Theorem provers, rule-based expert systems, and constraint satisfaction programs have been popular platforms with which to support design since almost the beginning of AI/design research, and more recently analogical or case-based reasoning have shown promise as a substitute for or a complement to those and other technologies. In their new book, Maher, Balachandran, and Zhang give an in-depth look at this newer topic of research—incorporating case-based reasoning in design support programs. The authors, all current or former researchers at the University of Sydney's Key Centre of Design Computing, focus on their own research in the area, describing the techniques for case representation, case recall, and case adaptation they have developed for design, and presenting implemented systems that use these techniques to support design.","1996-07","2025-02-19 14:42:29","2025-02-19 14:42:29","","24–25","","3","7","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C5YTWWF2","conferencePaper","2022","Gaggi, Ombretta; Perinello, Lorenzo","Improving accessibility of web accessibility rules","Proceedings of the 2022 ACM Conference on Information Technology for Social Good","978-1-4503-9284-6","","10.1145/3524458.3547267","https://doi.org/10.1145/3524458.3547267","Accessibility is still an open issue since, despite the increasing attention at a legislative, academic, and social level, a wide range of sites are still not able to meet the minimum level of accessibility requirements. For this reason, we implemented MyWcag4All, a website that tries to foster accessibility culture allowing developers to track a site’s accessibility at all stages of its development and providing access to a set of useful information like accessibility tests, testing tools, and official guidelines. Moreover, it contains gamification elements to increase the engagement of users in passing all the accessibility tests.","2022","2025-02-19 14:42:29","2025-02-19 14:42:29","","167–174","","","","","","","GoodIT '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Limassol, Cyprus","","","","accessibility test; wcag; web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLKA74ZJ","journalArticle","1997","Meurers, W. Detmar; Minnen, Guido","A computational treatment of lexical rules in HPSG as covariation in lexical entries","Comput. Linguist.","","0891-2017","","","This paper proposes a new computational treatment of lexical rules as used in the HPSG framework. A complier is described which translates a set of lexical rules and their interaction into a definite clause encoding, which is called by the base lexical entries in the lexicon. This way, the disjunctive possibilities arising from lexical rule application are encoded as systematic covariation in the specification of lexical entries. The compiler ensures the automatic transfer of properties not changed by a lexical rule. Program transformation techniques are used to advance the encoding. The final output of the compiler constitutes an efficient computational counterpart of the linguistic generalizations captured by lexical rules and allows on-the-fly application of lexical rules.","1997-12","2025-02-19 14:42:29","2025-02-19 14:42:29","","543–568","","4","23","","","","","","","","","","","","","","","","","Place: Cambridge, MA, USA Publisher: MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V77DHYUB","conferencePaper","1987","O'Neil, D. P.","A process specification of expert lawyer reasoning","Proceedings of the 1st International Conference on Artificial Intelligence and Law","0-89791-230-6","","10.1145/41735.41742","https://doi.org/10.1145/41735.41742","The ability to think like a lawyer is an often heard phrase but a vaguely understood phenomena. What is lawyer reasoning? Does it differ from reasoning in other fields and disciplines? This paper begins to answer these questions by explicating the problem solving and reasoning processes of an experienced practicing attorney and law professor in the field of housing law. A particularly noteworthy finding of these investigations involves the subject's construction and use of “component” mental models and “stories”. The active construction of mental models and the coherence of stories comprise the expert's problem solving and ald indexing and retrieval of legal theories from previous case experiences in episodic memory. These characteristics have strong architectural consequences for the use of artificial intelligence tools and techniques in law. Parallels are drawn between the approach taken in this study of lawyer reasoning and the growing body of research on “mental models”. Current efforts aimed at specifying the conceptual differences between novice and expert practitioners are outlined.","1987","2025-02-19 14:42:29","2025-02-19 14:42:29","","52–59","","","","","","","ICAIL '87","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YAKIABX9","conferencePaper","2021","Brandl, Florian; Brandt, Felix; Peters, Dominik; Stricker, Christian","Distribution Rules Under Dichotomous Preferences: Two Out of Three Ain't Bad","Proceedings of the 22nd ACM Conference on Economics and Computation","978-1-4503-8554-1","","10.1145/3465456.3467653","https://doi.org/10.1145/3465456.3467653","We consider a setting in which agents contribute amounts of a divisible resource (such as money or time) to a common pool, which is used to finance projects of public interest. How the collected resources are to be distributed among the projects is decided by a distribution rule that takes as input a set of approved projects for each agent. An important application of this setting is donor coordination, which allows philanthropists to find an efficient and mutually agreeable distribution of their donations. We analyze various distribution rules (including the Nash product rule and the conditional utilitarian rule) in terms of classic as well as new axioms, and propose the first fair distribution rule that satisfies efficiency and monotonicity. Our main result settles a long-standing open question of Bogomolnaia, Moulin, and Stong (2005) by showing that no strategyproof and efficient rule can guarantee that at least one approved project of each agent receives a positive amount of the resource. The proof reasons about 386 preference profiles and was obtained using a computer-aided method involving SAT solvers.","2021","2025-02-19 14:42:29","2025-02-19 14:42:29","","158–179","","","","","","","EC '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Budapest, Hungary","","","","fairness; efficiency; collective choice; economic design; sat-solving; strategyproofness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C9X2GR7W","conferencePaper","2020","Blum, Erica; Kiayias, Aggelos; Moore, Cristopher; Quader, Saad; Russell, Alexander","The combinatorics of the longest-chain rule: linear consistency for proof-of-stake blockchains","Proceedings of the Thirty-First Annual ACM-SIAM Symposium on Discrete Algorithms","","","","","The blockchain data structure maintained via the longest-chain rule—popularized by Bitcoin—is a powerful algorithmic tool for consensus algorithms. Such algorithms achieve consistency for blocks in the chain as a function of their depth from the end of the chain. While the analysis of Bitcoin guarantees consistency with error 2−k for blocks of depth O(k), the state-of-the-art of proof-of-stake (PoS) blockchains suffers from a quadratic dependence on k: these protocols, exemplified by Ouroboros (Crypto 2017), Ouroboros Praos (Eurocrypt 2018) and Sleepy Consensus (Asiacrypt 2017), can only establish that depth Θ(k2) is sufficient. Whether this quadratic gap is an intrinsic limitation of PoS—due to issues such as the nothing-at-stake problem—has been an urgent open question, as deployed PoS blockchains further rely on consistency for protocol correctnes.We give an axiomatic theory of blockchain dynamics that permits rigorous reasoning about the longest-chain rule and achieve, in broad generality, Θ(k) dependence on depth in order to achieve consistency error 2−k. In particular, for the first time we show that PoS protocols can match proof-of-work protocols for linear consistency.We analyze the associated stochastic process, give a recursive relation for the critical functionals of this process, and derive tail bounds in both i.i.d. and martingale settings via associated generating functions.","2020","2025-02-19 14:42:29","2025-02-19 14:42:29","","1135–1154","","","","","","","SODA '20","","","","Society for Industrial and Applied Mathematics","USA","","","","","","","","event-place: Salt Lake City, Utah","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PS3V2GSJ","conferencePaper","2021","Leiva, Luis A.; Arapakis, Ioannis; Iordanou, Costas","My Mouse, My Rules: Privacy Issues of Behavioral User Profiling via Mouse Tracking","Proceedings of the 2021 Conference on Human Information Interaction and Retrieval","978-1-4503-8055-3","","10.1145/3406522.3446011","https://doi.org/10.1145/3406522.3446011","This paper aims to stir debate about a disconcerting privacy issue on web browsing that could easily emerge because of unethical practices and uncontrolled use of technology. We demonstrate how straightforward is to capture behavioral data about the users at scale, by unobtrusively tracking their mouse cursor movements, and predict user's demographics information with reasonable accuracy using five lines of code. Based on our results, we propose an adversarial method to mitigate user profiling techniques that make use of mouse cursor tracking, such as the recurrent neural net we analyze in this paper. We also release our data and a web browser extension that implements our adversarial method, so that others can benefit from this work in practice.","2021","2025-02-19 14:42:29","2025-02-19 14:42:29","","51–61","","","","","","","CHIIR '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Canberra ACT, Australia","","","","privacy; ethics; mouse cursor tracking; user profiling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3RKBUAI","conferencePaper","2022","Estevez, Elsa; Janowski, Tomasz; Roseth, Benjamin David","Validating the Rules of Government Automation","Proceedings of the 23rd Annual International Conference on Digital Government Research","978-1-4503-9749-0","","10.1145/3543434.3543654","https://doi.org/10.1145/3543434.3543654","There is growing evidence on the benefits and risks of government automation, and how should government organizations proceed with automation when the benefits outweigh the risks. This evidence was recently consolidated into the ""rules of government automation"", part of the project funded by the Inter-American Development Bank. The project uncovered that the combined nature of government work and its transformation into digital government create many opportunities for automation. However, such opportunities can be only realized when the right automation technology becomes available and when government organizations are willing, capable, and authorized to introduce it, considering the impact on the organization and its stakeholders and the balance of benefits and risks brought about by this impact. The aim of the workshop is to validate the above “rules of government automation”. To this end, the participants will bring to the workshop their own government automation cases, from practice or research, establish thorough inspection and guided reasoning whether the rules hold for their cases, refine them otherwise, and iteratively agree on the refined rules across all cases. The workshop will also initiate the planning of a special issue of Government Information Quarterly to advance the theory and practice of government automation.","2022","2025-02-19 14:42:29","2025-02-19 14:42:29","","489–491","","","","","","","dg.o '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Republic of Korea","","","","Privacy; Security; Distrust; e-Democracy; Internet Voting; Perception; Trust","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LH3TG4NQ","journalArticle","2020","Ahmadi, Naser; Truong, Thi-Thuy-Duyen; Dao, Le-Hong-Mai; Ortona, Stefano; Papotti, Paolo","RuleHub: A Public Corpus of Rules for Knowledge Graphs","J. Data and Information Quality","","1936-1955","10.1145/3409384","https://doi.org/10.1145/3409384","Entity-centric knowledge graphs (KGs) are now popular to collect facts about entities. KGs have rich schemas with a large number of different types and predicates to describe the entities and their relationships. On these rich schemas, logical rules are used to represent dependencies between the data elements. While rules are useful in query answering, data curation, and other tasks, they usually do not come with the KGs. Such rules have to be manually defined or discovered with the help of rule mining methods. We believe this rule-collection task should be done collectively to better capitalize our understanding of the data and to avoid redundant work conducted on the same KGs. For this reason, we introduce RuleHub, our extensible corpus of rules for public KGs. RuleHub provides functionalities for the archival and the retrieval of rules to all users, with an extensible architecture that does not constrain the KG or the type of rules supported. We are populating the corpus with thousands of rules from the most popular KGs and report on our experiments on automatically characterizing the quality of a rule with statistical measures.","2020-10","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","4","12","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","knowledge graphs; graph dependencies; Rule mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4IJDF64V","conferencePaper","2013","Tromp, Erik; Pechenizkiy, Mykola","RBEM: a rule based approach to polarity detection","Proceedings of the Second International Workshop on Issues of Sentiment Discovery and Opinion Mining","978-1-4503-2332-1","","10.1145/2502069.2502077","https://doi.org/10.1145/2502069.2502077","We propose the Rule-Based Emission Model (RBEM) algorithm for polarity detection. RBEM uses several kinds of heuristic rules to create an emissive model on polarity patterns. We extensively experiment with our approach on English and Dutch messages extracted from Twitter. Thus we also illustrate that RBEM can be used in multilingual settings and is applicable to social media characterized by use of not always regular language constructs. We demonstrate that designing such an algorithm instead of applying the state-of-the art general purpose classification techniques is a reasonable choice for the automated sentiment classification in practice. Using RBEM we can design a competitive multilingual sentiment classification system showing promising accuracy results of 78.8% on the considered datasets. We provide some further evidence that RBEM-based systems are easy to debug, improve over time and adapt to new application domains.","2013","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","WISDOM '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, Illinois","","","","emission model; multi-lingual sentiment analysis; rule-based polarity detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FC2L4Z58","conferencePaper","1997","Motakis, Iakovos; Zaniolo, Carlo","Temporal aggregation in active database rules","Proceedings of the 1997 ACM SIGMOD International Conference on Management of Data","0-89791-911-4","","10.1145/253260.253359","https://doi.org/10.1145/253260.253359","An important feature of many advanced active database prototypes is support for rules triggered by complex patterns of events. Their composite event languages provide powerful primitives for event-based temporal reasoning. In fact, with one important exception, their expressive power matches and surpasses that of sophisticated languages offered by Time Series Management Systems (TSMS), which have been extensively used for temporal data analysis and knowledge discovery. This exception pertains to temporal aggregation, for which, current active database systems offer only minimal support, if any.In this paper, we introduce the language TREPL, which addresses this problem. The TREPL prototype, under development at UCLA, offers primitives for temporal aggregation that exceed the capabilities of state-of-the-art composite event languages, and are comparable to those of TSMS languages. TREPL also demonstrates a rigorous and general approach to the definition of composite event language semantics. The meaning of a TREPL rule is formally defined by mapping it into a set of Datalog1S rules, whose logic-based semantics characterizes the behavior of the original rule. This approach handles naturally temporal aggregates, including user-defined ones, and is also applicable to other composite event languages, such as ODE, Snoop and SAMOS.","1997","2025-02-19 14:42:29","2025-02-19 14:42:29","","440–451","","","","","","","SIGMOD '97","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tucson, Arizona, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVJ2DLTI","conferencePaper","2019","de Oliveira, Rafael Pereira; Baião, Fernanda; Almeida, Ana Carolina; Schwabe, Daniel; Lifschitz, Sérgio","Outer-Tuning: an integration of rules, ontology and RDBMS","Proceedings of the XV Brazilian Symposium on Information Systems","978-1-4503-7237-4","","10.1145/3330204.3330270","https://doi.org/10.1145/3330204.3330270","Database tuning is a crucial task to address the performance of information systems that deal with a considerable amount of information stored in databases. Current tuning tools are very platform-specific and do not provide adequate support for the database administrator to reason about performance improvement suggestions. In this paper, we discuss several architectural and implementation decisions of Outer-Tuning, our framework that supports database tuning. Outer-Tuning follows a model-driven development and a modular architecture design, which enabled several benefits. This paper contributes with: (i) the architectural design model adopted in Outer-Tuning, which combines imperative and declarative programming; (ii) the discussions and steps to integrate several software components; and (iii) the actual framework implementation. We assess our framework with an experiment using the TPC-H benchmark. The results evidence that Outer-Tuning infers useful tuning actions and supports the DBA by providing a more semantic environment to create and adapt tuning heuristics using concepts closer to his/her domain, and also relevant information on the rationale of the tuning actions through a friendly web interface.","2019","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","SBSI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aracaju, Brazil","","","","components; database system; frameworks; tuning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UBP8WIWX","conferencePaper","2007","Looks, Moshe; Goertzel, Ben; de Souza Coelho, Lucio; Mudado, Mauricio; Pennachin, Cassio","Clustering gene expression data via mining ensembles of classification rules evolved using moses","Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation","978-1-59593-697-4","","10.1145/1276958.1277041","https://doi.org/10.1145/1276958.1277041","A novel approach, model-based clustering, is described foridentifying complex interactions between genes or gene-categories based on static gene expression data. The approach deals with categorical data, which consists of a set of gene expressionprofiles belonging to one category, and a set belonging to anothercategory. An evolutionary algorithm (Meta-Optimizing Semantic Evolutionary Search, or MOSES) is used to learn an ensemble of classification models distinguishing the two categories, based on inputs that are features corresponding to gene expression values. Each feature is associated with a model-based vector, which encodes quantitative information regarding the utilization of the feature across the ensembles of models. Two different ways of constructing these vectors are explored. These model-based vectors are then clustered using a variant of hierarchical clustering called Omniclust. The result is a set of model-based clusters, in which features are gathered together if they are often considered together by classification models – which may be because they're co-expressed, or may be for subtler reasons involving multi-gene interactions. The method is illustrated by applying it to two datasets regarding human gene expression, one drawn from brain cells and pertinent to the neurogenetics of aging, and the other drawn from blood cells and relating to differentiating between types of lymphoma. We find that, compared to traditional expression-based clustering, the new method often yields clusters that have higher mathematical quality (in the sense of homogeneity and separation) and also yield novel and meaningful insights into the underlying biological processes.","2007","2025-02-19 14:42:29","2025-02-19 14:42:29","","407–414","","","","","","","GECCO '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: London, England","","","","empirical study; heuristics; optimization; representations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VPS4G9P2","conferencePaper","2013","Araujo, Denis A. de; Rigo, Sandro J.; Muller, Carolina; Chishman, Rove","Automatic Information Extraction from Texts with Inference and Linguistic Knowledge Acquisition Rules","Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 03","978-0-7695-5145-6","","10.1109/WI-IAT.2013.171","https://doi.org/10.1109/WI-IAT.2013.171","In this paper we present a novel methodology for automatic information extraction from natural language texts, based on the integration of linguistic rules, multiple ontologies and inference resources, integrated with an abstraction layer for linguistic annotation and data representation. The methodology allows ontology population with instances of events. The main contribution presented is related to the exploration of the flexibility of linguistic rules and domain knowledge representation, through their manipulation and integration by a reasoning system. The results from the case study indicate that the proposed approach is effective for the legal domain.","2013","2025-02-19 14:42:29","2025-02-19 14:42:29","","151–154","","","","","","","WI-IAT '13","","","","IEEE Computer Society","USA","","","","","","","","","","","","reasoning; information extraction; natural language processing; ontolog","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RIJAX8M6","journalArticle","1995","Truszkowski, Walt","Book review: Adaptive Reasoning for Real-World Problems by Roy M. Turner (Lawrence Earlbaum Associates, 1994)","SIGART Bull.","","0163-5719","10.1145/201977.1065562","https://doi.org/10.1145/201977.1065562","In view of the growing popularity of agent-based systems this book is very timely. ""Adaptive Reasoning for Real-World Problems"" discusses practical approaches to realizing adaptive systems based on current agent concepts. The book discusses, in detail, the nature and types of knowledge that computer-based agents need to access and manage in order to be able to effectively function in a changing operational environment. It identifies the types of knowledge required for adaptive problem solving: procedural, contextual, and strategic, and addresses, in detail, appropriate ways of structuring knowledge for use by the adaptive agent. Procedural knowledge refers to implicit or explicit actions required to achieve a goal. Contextual knowledge is that knowledge which establishes the problem-solving context in which the agent (or reasoner) finds itself and in which it must operate. Strategic knowledge refers to that knowledge which the agent can use to control or modify its problem-solving behaviors. In Turner's system each of these types of knowledge is represented in a schema: ""...an explicit, declaratively-represented packet of knowledge representing either a pattern encountered (or expected) in the world or a pattern of action for the reasoner to take. A schema can be either provided to a reasoner by another agent or learned from experience.""","1995-04","2025-02-19 14:42:29","2025-02-19 14:42:29","","53–54","","2","6","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPRJX2RQ","conferencePaper","2021","Wu, Yang; Zou, Wentao; Liu, Shuangquan; Jiang, Yan; Shao, Qizhuan; Zhou, Han","Rule-based data verification method in electricity spot market","2021 2nd International Conference on Artificial Intelligence and Information Systems","978-1-4503-9020-0","","10.1145/3469213.3470246","https://doi.org/10.1145/3469213.3470246","In the electric power spot market, input data quality is critical to an accurate and reliable clearing result. Missing and abnormal data will lead to the result that the clearing algorithm diverges or the results mismatch reality. This would seriously affect power system security and reduce the efficiency of the market. Therefore, to ensure a smooth convergence of the algorithm and reasonable results, this paper proposes a rule-based verification method for the input data in the power spot market. Data integrity and logical verification rules are established. During the verification process, information will be divided into different warning levels and displayed so that users can modify relevant data according to the actual situation.","2021","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","ICAIIS 2021","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chongqing, China","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UTZW6GUT","conferencePaper","2010","Popa, Lucian; Egi, Norbert; Ratnasamy, Sylvia; Stoica, Ion","Building extensible networks with rule-based forwarding","Proceedings of the 9th USENIX Conference on Operating Systems Design and Implementation","","","","","We present a network design that provides flexible and policy-compliant forwarding. Our proposal centers around a new architectural concept: that of packet rules. A rule is a simple if-then-else construct that describes the manner in which the network should - or should not - forward packets. A packet identifies the rule by which it is to be forwarded and routers forward each packet in accordance with its associated rule. Each packet rule is certified, guaranteeing that all parties involved in forwarding a packet agree with the packet's rule. Packets containing uncertified rules are simply dropped in the network. We present the design, implementation and evaluation of a Rule-Based Forwarding (RBF) architecture. We demonstrate flexibility by illustrating how RBF supports a variety of use cases including content caching, middlebox selection and DDoS protection. Using our prototype router implementation we show that the overhead RBF imposes is within the capabilities of modern network equipment.","2010","2025-02-19 14:42:29","2025-02-19 14:42:29","","379–392","","","","","","","OSDI'10","","","","USENIX Association","USA","","","","","","","","event-place: Vancouver, BC, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J385644Y","conferencePaper","2016","Terdjimi, Mehdi; Médini, Lionel; Mrissa, Michael","HyLAR+: Improving Hybrid Location-Agnostic Reasoning with Incremental Rule-based Update","Proceedings of the 25th International Conference Companion on World Wide Web","978-1-4503-4144-8","","10.1145/2872518.2890542","https://doi.org/10.1145/2872518.2890542","Web applications that rely on datasets of limited sizes to handle small but frequent updates and numerous queries have no simple way to define where data should be stored and processed. We propose a reasoning framework that can be integrated in Web applications and is able to perform the same reasoning tasks on both client or server sides. This framework embeds a rule-based reasoning engine that uses an algorithm relying on both incremental reasoning and named graphs. We evaluate the performance of our approach and compare the effects of incremental reasoning and named graphs in different experimental conditions. Results show that our reasoner can significantly reduce response times to INSERT and DELETE queries. During the demo we will exhibit how it can be used to perform reasoning tasks based on client-generated information and improve Web applications with location-agnostic reasoning.","2016","2025-02-19 14:42:29","2025-02-19 14:42:29","","259–262","","","","","","","WWW '16 Companion","","","","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","","","","","","","","event-place: Montréal, Québec, Canada","","","","reasoning; semantic web; rule-based reasoning; client-side reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z7LJQ6SW","journalArticle","1994","Prasetya, I. S. W. B.","Error in the UNITY substitution rule for subscripted operators","Form. Asp. Comput.","","0934-5043","10.1007/BF01211309","https://doi.org/10.1007/BF01211309","UNITY, introduced by Chandy and Misra [ChM88], is a programming logic intended to reason about temporal properties of distributed programs. Despite the fact that UNITY does not have the full power of, for example, linear temporal logic, it enjoys popularity due to its simplicity.There was however a serious problem with the Substitution Rule. The logic is incomplete without the rule, and with the rule it is inconsistent.Latterly Beverly Sanders introduced the concept of strongest invariant and proposed a new definition for UNITY [San91] that fixes the problem with the Substitution Rule. For the benefit of program union, she also introduced the concept of subscripted properties and claimed a generalized version of Substitution Rule for the subscripted properties.This report presents an example that shows that the latter claim is false. A proposal as how to fix this follows.","1994-07","2025-02-19 14:42:29","2025-02-19 14:42:29","","466–470","","4","6","","","","","","","","","","","","","","","","","Place: Berlin, Heidelberg Publisher: Springer-Verlag","","","","Distributed programming; Substitution Rule in UNITY; UNITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JXN84HM9","conferencePaper","2015","Shokoohi-Yekta, Mohammad; Chen, Yanping; Campana, Bilson; Hu, Bing; Zakaria, Jesin; Keogh, Eamonn","Discovery of Meaningful Rules in Time Series","Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","978-1-4503-3664-2","","10.1145/2783258.2783306","https://doi.org/10.1145/2783258.2783306","The ability to make predictions about future events is at the heart of much of science; so, it is not surprising that prediction has been a topic of great interest in the data mining community for the last decade. Most of the previous work has attempted to predict the future based on the current value of a stream. However, for many problems the actual values are irrelevant, whereas the shape of the current time series pattern may foretell the future. The handful of research efforts that consider this variant of the problem have met with limited success. In particular, it is now understood that most of these efforts allow the discovery of spurious rules. We believe the reason why rule discovery in real-valued time series has failed thus far is because most efforts have more or less indiscriminately applied the ideas of symbolic stream rule discovery to real-valued rule discovery. In this work, we show why these ideas are not directly suitable for rule discovery in time series. Beyond our novel definitions/representations, which allow for meaningful and extendable specifications of rules, we further show novel algorithms that allow us to quickly discover high quality rules in very large datasets that accurately predict the occurrence of future events.","2015","2025-02-19 14:42:29","2025-02-19 14:42:29","","1085–1094","","","","","","","KDD '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sydney, NSW, Australia","","","","motif discovery; prediction; rule discovery; time series","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TD727ZZK","journalArticle","1989","Ladner, Richard E.","Computer accessibility for federal workers with disabilities: it's the law","Commun. ACM","","0001-0782","10.1145/65971.65974","https://doi.org/10.1145/65971.65974","In 1986, Congress passed Public Law 99-506, the ""Rehabilitation Act Amendments of 1986."" This law, amending the famous Rehabilitation Act of 1973, contains a small section, titled ""Electronic Equipment Accessibility,"" Section 508, which may have significant impact on the design of computer systems and their accessibility by workers with disabilities. The bill became law when it was signed by former President Reagan on October 21, 1986.The purpose of this article is to inform concerned computer professionals of Section 508, outline the guidelines and regulations pursuant to the law, describe some of the reaction to the guidelines and regulations, and describe some of the challenges for the future in meeting the computer accessibility needs of users with disabilities.Section 508 was developed because it was realized that government offices were rapidly changing into electronic offices with microcomputers on every desk. In order for persons with disabilities to keep their jobs or gain new employment in the government, Congress decided it was necessary to make provisions to guarantee accessibility to microcomputers and other electronic office equipment. The driving principle behind Section 508 can be found in Section 504 of the Rehabilitation Act of 1973 which states:No otherwise qualified handicapped individual in the United States . . . shall, solely by reason of his handicap, be excluded from the participation in, be denied the benefits of, or be subjected to discrimination under any program or activity receiving Federal financial assistance.It should be stated off the top that the scope of Section 508 is not as broad as Section 504. In particular, Section 508 only applies to direct purchases by the federal government and not to purchases made by all programs receiving government funding.Section 508 does not specify what the guidelines should be nor does it delineate a philosophy on which to base the guidelines. A committee established by the National Institute on Disability and Rehabilitation Research (NIDRR) and the General Services, Administration (GSA), in consultation with the electronics industry, rehabilitation engineers, and disabled computer professionals worked for a year developing the philosophy and guidelines which will significantly affect the purchase of electronic office equipment, including computers and software, by the federal government, the largest computer customer in the world.","1989-08","2025-02-19 14:42:29","2025-02-19 14:42:29","","952–956","","8","32","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TGGPBTBD","conferencePaper","2012","Nagesh, Ajay; Ramakrishnan, Ganesh; Chiticariu, Laura; Krishnamurthy, Rajasekar; Dharkar, Ankush; Bhattacharyya, Pushpak","Towards efficient named-entity rule induction for customizability","Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning","","","","","Generic rule-based systems for Information Extraction (IE) have been shown to work reasonably well out-of-the-box, and achieve state-of-the-art accuracy with further domain customization. However, it is generally recognized that manually building and customizing rules is a complex and labor intensive process. In this paper, we discuss an approach that facilitates the process of building customizable rules for Named-Entity Recognition (NER) tasks via rule induction, in the Annotation Query Language (AQL). Given a set of basic features and an annotated document collection, our goal is to generate an initial set of rules with reasonable accuracy, that are interpretable and thus can be easily refined by a human developer. We present an efficient rule induction process, modeled on a four-stage manual rule development process and present initial promising results with our system. We also propose a simple notion of extractor complexity as a first step to quantify the interpretability of an extractor, and study the effect of induction bias and customization of basic features on the accuracy and complexity of induced rules. We demonstrate through experiments that the induced rules have good accuracy and low complexity according to our complexity measure.","2012","2025-02-19 14:42:29","2025-02-19 14:42:29","","128–138","","","","","","","EMNLP-CoNLL '12","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Jeju Island, Korea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFC75X6X","conferencePaper","2009","Ye, Xin; Wang, Na; Wang, Yanzhang; Li, Hui; Han, Shengju","Research and Application on Business Rules for One-Stop Administrative Permit System","Proceedings of the 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology - Volume 03","978-0-7695-3801-3","","10.1109/WI-IAT.2009.309","https://doi.org/10.1109/WI-IAT.2009.309","Administrative permit businesses are modeled based on business objects. An extended NAM based on the roles, business objects and time constraint is proposed in this paper. Based on the extended NAM, on the one hand, the description of business rules among objects and the corresponding reasoning mechanisms are proposed. On the other hand, description of business rules during in object processing is proposed. In the end, the general business process of one-stop administrative permit system is proposed, so that the approval businesses dispersed in various departments are integrated and the flexibility of the system can be increased.","2009","2025-02-19 14:42:29","2025-02-19 14:42:29","","393–396","","","","","","","WI-IAT '09","","","","IEEE Computer Society","USA","","","","","","","","","","","","business rule; norm analysis method; one-stop administrative permit system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6IB972Q","conferencePaper","2014","Dimou, Anastasia; Vander Sande, Miel; De Nies, Tom; Mannens, Erik; Van de Walle, Rik","RDF mapping rules refinements according to data consumers' feedback","Proceedings of the 23rd International Conference on World Wide Web","978-1-4503-2745-9","","10.1145/2567948.2577332","https://doi.org/10.1145/2567948.2577332","The missing feedback loop is considered the reason for broken Data Cycles on current Linked Open Data ecosystems. Read-Write platforms are proposed, but they are restricted to capture modifications after the data is released as Linked Data. Triggering though a new iteration results in loosing the data consumers' modifications, as a new version of the source data is mapped, overwriting the currently published. We propose a prime solution that interprets the data consumers' feedback to update the mapping rules. This way, data publishers initiate a new iteration of the Data Cycle considering the data consumers' feedback when they map a new version of the published data.","2014","2025-02-19 14:42:29","2025-02-19 14:42:29","","249–250","","","","","","","WWW '14 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Korea","","","","linked data life cycles; provenance; read-write web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43NLBX8U","conferencePaper","1987","Rissland, E. L.; Ashley, K. D.","A case-based system for trade secrets law","Proceedings of the 1st International Conference on Artificial Intelligence and Law","0-89791-230-6","","10.1145/41735.41743","https://doi.org/10.1145/41735.41743","In this paper, we give an overview of our case-based reasoning program, HYPO, which operates in the field of trade secret law. We discuss key ingredients of case-based reasoning, in general, and the correspondence of these to elements of HYPO. We conclude with an extended example of HYPO working through a hypothetical trade secrets case, patterned after an actual case.","1987","2025-02-19 14:42:29","2025-02-19 14:42:29","","60–66","","","","","","","ICAIL '87","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBAEZ9QL","conferencePaper","2020","Fehringer, Benedict C. O. F.","One threshold to rule them all? Modification of the Index of Pupillary Activity to optimize the indication of cognitive load","ACM Symposium on Eye Tracking Research and Applications","978-1-4503-7134-6","","10.1145/3379156.3391341","https://doi.org/10.1145/3379156.3391341","Cognitive load is an important source of information in performance situations. One promising non-invasive method is pupillometry. The Index of Pupillary Activity [IPA, Duchowski et&nbsp;al. 2018] performs a wavelet transformation on changes of pupillary dilations to detect high frequencies. This index is inspired by the Index of Cognitive Activity [ICA, Marshall 2000]. The IPA value is the sum of peaks exceeding a predefined threshold. The present study shows that it appears reasonable to adapt this threshold corresponding to the task. Fifty-five participants performed a spatial thinking test with six difficulty levels and two simple fixation tasks. Six different IPA values resulting from different thresholds were computed. The distributions of these IPA values of the eight conditions were analyzed regarding the validity to indicate different levels of cognitive load, corresponding to accuracy data. The analyses revealed that different thresholds are sensitive for different cognitive load levels. Contra-intuitive results were also obtained.","2020","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","ETRA '20 Short Papers","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Stuttgart, Germany","","","","cognitive load; Index of Pupillary Activity; Pupillometry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IA9NLDU4","journalArticle","2008","Analyti, Anastasia; Antoniou, Grigoris; Damásio, Carlos Viegas; Wagner, Gerd","Extended RDF as a semantic foundation of rule markup languages","J. Artif. Int. Res.","","1076-9757","","","Ontologies and automated reasoning are the building blocks of the Semantic Web initiative. Derivation rules can be included in an ontology to define derived concepts, based on base concepts. For example, rules allow to define the extension of a class or property, based on a complex relation between the extensions of the same or other classes and properties. On the other hand, the inclusion of negative information both in the form of negation-as-failure and explicit negative information is also needed to enable various forms of reasoning. In this paper, we extend RDF graphs with weak and strong negation, as well as derivation rules. The ERDF stable model semantics of the extended framework (Extended RDF) is defined, extending RDF(S) semantics. A distinctive feature of our theory, which is based on Partial Logic, is that both truth and falsity extensions of properties and classes are considered, allowing for truth value gaps. Our framework supports both closed-world and open-world reasoning through the explicit representation of the particular closed-world assumptions and the ERDF ontological categories of total properties and total classes.","2008-05","2025-02-19 14:42:29","2025-02-19 14:42:29","","37–94","","1","32","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJZW5IMR","conferencePaper","1996","Cherniack, Mitch; Zdonik, Stanley B.","Rule languages and internal algebras for rule-based optimizers","Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data","0-89791-794-4","","10.1145/233269.233356","https://doi.org/10.1145/233269.233356","Rule-based optimizers and optimizer generators use rules to specify query transformations. Rules act directly on query representations, which typically are based on query algebras. But most algebras complicate rule formulation, and rules over these algebras must often resort to calling to externally defined bodies of code. Code makes rules difficult to formulate, prove correct and reason about, and therefore compromises the effectiveness of rule-based systems.In this paper we present KOLA: a combinator-based algebra designed to simplify rule formulation. KOLA is not a user language, and KOLA's variable-free queries are difficult for humans to read. But KOLA is an effective internal algebra because its combinator-style makes queries manipulable and structurally revealing. As a result, rules over KOLA queries are easily expressed without the need for supplemental code. We illustrate this point, first by showing some transformations that despite their simplicity, require head and body routines when expressed over algebras that include variables. We show that these transformations are expressible without supplemental routines in KOLA. We then show complex transformations of a class of nested queries expressed over KOLA. Nested query optimization, while having been studied before, have seriously challenged the rule-based paradigm.","1996","2025-02-19 14:42:29","2025-02-19 14:42:29","","401–412","","","","","","","SIGMOD '96","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, Quebec, Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FU4XQ5FN","conferencePaper","2006","Yang, Jinlin; Evans, David; Bhardwaj, Deepali; Bhat, Thirumalesh; Das, Manuvir","Perracotta: mining temporal API rules from imperfect traces","Proceedings of the 28th International Conference on Software Engineering","1-59593-375-1","","10.1145/1134285.1134325","https://doi.org/10.1145/1134285.1134325","Dynamic inference techniques have been demonstrated to provide useful support for various software engineering tasks including bug finding, test suite evaluation and improvement, and specification generation. To date, however, dynamic inference has only been used effectively on small programs under controlled conditions. In this paper, we identify reasons why scaling dynamic inference techniques has proven difficult, and introduce solutions that enable a dynamic inference technique to scale to large programs and work effectively with the imperfect traces typically available in industrial scenarios. We describe our approximate inference algorithm, present and evaluate heuristics for winnowing the large number of inferred properties to a manageable set of interesting properties, and report on experiments using inferred properties. We evaluate our techniques on JBoss and the Windows kernel. Our tool is able to infer many of the properties checked by the Static Driver Verifier and leads us to discover a previously unknown bug in Windows.","2006","2025-02-19 14:42:29","2025-02-19 14:42:29","","282–291","","","","","","","ICSE '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Shanghai, China","","","","dynamic analysis; specification inference; temporal properties","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UHUDMW54","journalArticle","2017","Clements, Austin T.; Kaashoek, M. Frans; Kohler, Eddie; Morris, Robert T.; Zeldovich, Nickolai","The scalable commutativity rule: designing scalable software for multicore processors","Commun. ACM","","0001-0782","10.1145/3068914","https://doi.org/10.1145/3068914","Developing software that scales on multicore processors is an inexact science dominated by guesswork, measurement, and expensive cycles of redesign and reimplementation. Current approaches are workload-driven and, hence, can reveal scalability bottlenecks only for known workloads and available software and hardware. This paper introduces an interface-driven approach to building scalable software. This approach is based on the scalable commutativity rule, which, informally stated, says that whenever interface operations commute, they can be implemented in a way that scales. We formalize this rule and prove it correct for any machine on which conflict-free operations scale, such as current cache-coherent multicore machines. The rule also enables a better design process for scalable software: programmers can now reason about scalability from the earliest stages of interface definition through software design, implementation, and evaluation.","2017-07","2025-02-19 14:42:29","2025-02-19 14:42:29","","83–90","","8","60","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YI4YVCCH","conferencePaper","2008","Fordyce, Ken; Bixby, Robert; Burda, Richard","Technology that upsets the social order: a paradigm shift in assigning lots to tools in a wafer fabricator – the transition from rules to optimization","Proceedings of the 40th Conference on Winter Simulation","978-1-4244-2708-6","","","","Historically the dominant decision technology to make dispatch decisions was ""rules"" which involves the following basic computational mechanisms: merge, select, sort, and if/then/else in a decision tree. Although rules do a reasonable job they fundamentally lack a robust ability to: (a) look across time, (b) look across tools at a tool set, (c) create an anticipated sequence of events at a tool set over some time horizon, (d) establish a formal metric and (f) search alternatives. However, standard wisdom was the rapid pace of change and short time interval between dispatch decisions precluded the use of optimization to build dispatch applications. Although this barrier was legitimate in the 1980s and most of the 1990s based on limitations in hardware and software (algorithms); the real barrier today is cultural; not technical. From 2004–2007, IBM and ILOG jointly worked to deploy the ILOG optimization product FPO to key tools sets in IBM's 300mm fab resulting in substantial improvements in performance and significantly reduced overhead to adapt to changing circumstances. This paper will cover the fundamentals of the paradigm shift.","2008","2025-02-19 14:42:29","2025-02-19 14:42:29","","2277–2285","","","","","","","WSC '08","","","","Winter Simulation Conference","","","","","","","","","Place: Miami, Florida","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WBTUNW28","conferencePaper","2004","D'Hondt, Maja; Gybels, Kris; Jonckers, Viviane","Seamless integration of rule-based knowledge and object-oriented functionality with linguistic symbiosis","Proceedings of the 2004 ACM Symposium on Applied Computing","1-58113-812-1","","10.1145/967900.968168","https://doi.org/10.1145/967900.968168","Software applications often contain implicit knowledge in addition to functionality which is inherently object-oriented. Many approaches and systems exist that focus on separating rule-based knowledge from object-oriented functionality and representing it explicitly in a logic reasoning system. Support for seamless integration of this knowledge with the object-oriented functionality improves software development and evolution. Our hypothesis is that a linguistic symbiosis is required between the logic reasoning and object-oriented programming paradigms in order to achieve seamless integration.This paper presents a symbiotic extension of SOUL, a system which implements a logic programming language and a production system in Smalltalk. The presence of these two logic reasoning systems in SOUL ensures a comprehensive coverage of rule-based reasoning styles, more specifically forward and backward chaining. Our approach is evaluated by means of two case studies. We summarise a comprehensive survey, which shows that existing systems do not fully support seamless integration.","2004","2025-02-19 14:42:29","2025-02-19 14:42:29","","1328–1335","","","","","","","SAC '04","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Nicosia, Cyprus","","","","rule-based systems; linguistic symbiosis; multi-paradigm programming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SNJXPT4R","journalArticle","2009","Fan, Wenfei; Jia, Xibei; Li, Jianzhong; Ma, Shuai","Reasoning about record matching rules","Proc. VLDB Endow.","","2150-8097","10.14778/1687627.1687674","https://doi.org/10.14778/1687627.1687674","To accurately match records it is often necessary to utilize the semantics of the data. Functional dependencies (FDs) have proven useful in identifying tuples in a clean relation, based on the semantics of the data. For all the reasons that FDs and their inference are needed, it is also important to develop dependencies and their reasoning techniques for matching tuples from unreliable data sources. This paper investigates dependencies and their reasoning for record matching. (a) We introduce a class of matching dependencies (MDs) for specifying the semantics of data in unreliable relations, defined in terms of similarity metrics and a dynamic semantics. (b) We identify a special case of MDs, referred to as relative candidate keys (RCKs), to determine what attributes to compare and how to compare them when matching records across possibly different relations. (c) We propose a mechanism for inferring MDs, a departure from traditional implication analysis, such that when we cannot match records by comparing attributes that contain errors, we may still find matches by using other, more reliable attributes. (d) We provide an O(n2) time algorithm for inferring MDs, and an effective algorithm for deducing a set of RCKs from MDs. (e) We experimentally verify that the algorithms help matching tools efficiently identify keys at compile time for matching, blocking or windowing, and that the techniques effectively improve both the quality and efficiency of various record matching methods.","2009-08","2025-02-19 14:42:29","2025-02-19 14:42:29","","407–418","","1","2","","","","","","","","","","","","","","","","","Publisher: VLDB Endowment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SEQR9QMV","conferencePaper","2013","Wu, Haijiang; Liu, Jie; Ye, Dan; Zhong, Hua; Wei, Jun","A distributed rule execution mechanism based on MapReduce in sematic web reasoning","Proceedings of the 5th Asia-Pacific Symposium on Internetware","978-1-4503-2369-7","","10.1145/2532443.2532457","https://doi.org/10.1145/2532443.2532457","Rule execution is the core step of rule-based semantic web reasoning. However, most existing approaches are centralized, which cannot scale out to reason big semantic web datasets. In this paper, we described a kind of semantic web rule execution mechanism using MapReduce programming model, which not only can handle RDFS and OWL ter Horst semantic rules, but also can be used in SWRL reasoning. Theoretical analysis is present on the scalability of this rule execution mechanism. Result shows that it can scale well as Mapreduce framework.","2013","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","Internetware '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Changsha, China","","","","reasoning; rule; distributed system; MapReduce; rule execution; sematic web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLQ2MWKJ","conferencePaper","2015","Pierce, Maria E.; Warnke, Tom; Helms, Tobias; Uhrmacher, Adelinde M.; Krumme, Uwe; Hammer, Cornelius","Individual-based cod simulation with ML-Rules","Proceedings of the 2015 Winter Simulation Conference","978-1-4673-9741-4","","","","A dramatic increase in malnourished cod can presently be observed in the Eastern Baltic. Simulation studies help unraveling possible reasons behind this. Particularly, individual-based modeling approaches are promising as they facilitate taking into account the heterogeneity of the cod population, where size, temperature etc. determine behavior patterns. Thus, we develop an individual-based model of cod implemented in the rule-based multi-level modeling language ML-Rules that allows to specify dynamically nested entities with attributes and complex multi-level reaction rules. By using this language, we are able to deal with several challenges when modeling such complex systems, e.g., dynamic structures, complex interaction rates and interdependencies. Here, we discuss the current state of our model that already represents a near realistic cod metabolism and we discuss how ML-Rules helped to solve emerged challenges.","2015","2025-02-19 14:42:29","2025-02-19 14:42:29","","3192–3193","","","","","","","WSC '15","","","","IEEE Press","","","","","","","","","Place: Huntington Beach, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NCTQLMAV","conferencePaper","2015","Nawal, Sad Houari; Noria, Taghezout","An agent based approach for security integration in Business Rules Management System","Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication","978-1-4503-3458-7","","10.1145/2816839.2816919","https://doi.org/10.1145/2816839.2816919","The roots of business rules come from the Artificial Intelligence community, where they have been successfully applied as a way of representing knowledge. In the knowledge-based systems, the knowledge and reasoning of a human expert can be captured and stored in a form of complex networks of rules. Therefore, the manipulation of the business expert's knowledge generates an imperious need for information security and associated technologies. The notion of cryptography has emerged as a basic concept in the business rules modeling.In this paper, we propose to handle the security aspect by using an encryption algorithm. To do so, we simulate some encryption algorithms such us DES, Blowfish, RC4, AES and RSA.One of our objectives is to provide an original approach for security integration in Business Rules Management System design which should serve all objectives of all parties in the enterprise (Business analysts, Experts, Risk manager, etc). We propose to integrate an agent-based approach in the framework. This solution is utilizing a security agent (SA) with domain ontology. This agent applies an encryption/decryption algorithm to allow confidentiality, authenticity and integrity of the most important business rules.We performed some experiments to find the better encryption algorithm which provides improvement in terms of response time, space memory and security.","2015","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","IPAC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Batna, Algeria","","","","Ontologies; Business rules (BR); Business Rules Management System (BRMS); Encryption algorithms; Security agent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FKLDYL8P","conferencePaper","2017","Gyrard, Amelie; Serrano, Martin; Jares, Joao Bosco; Datta, Soumya Kanti; Ali, Muhammad Intizar","Sensor-based Linked Open Rules (S-LOR): An Automated Rule Discovery Approach for IoT Applications and its use in Smart Cities","Proceedings of the 26th International Conference on World Wide Web Companion","978-1-4503-4914-7","","10.1145/3041021.3054716","https://doi.org/10.1145/3041021.3054716","This paper introduces an automated rule discovery approach for IoT device data (S-LOR: Sensor-based Linked Open Rules) and its use in smart cities. S-LOR is built following Linked Open Data (LOD) standards and provides support for semantics-based mechanisms to share, reuse and execute logical rules for interpreting data produced by IoT systems. S-LOR follows LOD principles for data re-usability, semantics-based reasoning and interoperability. In this paper, S-LOR main capability is demonstrated in the context of enabling semantics-based reasoning mechanisms and tools according to application-demand and user requirements. S-LOR (i) supports an automated interpretation of IoT data by executing rules, and (ii) allows an automated rule discovery interface. The implemented S-LOR mechanism can automatically process and interpret data from IoT devices by using rule-based discovery paradigm. Its extension called Linked Open Reasoning (LOR) enables and encourages re-usability of reasoning mechanisms and tools for different IoT smart city applications. The use cases described in this paper fits in the domain of smart city applications within Internet of Things deployed systems.","2017","2025-02-19 14:42:29","2025-02-19 14:42:29","","1153–1159","","","","","","","WWW '17 Companion","","","","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","","","","","","","","event-place: Perth, Australia","","","","internet of things; reasoning; knowledge; semantic web technologies; semantic web of things","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M543QE79","journalArticle","2016","Lev, Omer; Rosenschein, Jeffrey S.","Convergence of iterative scoring rules","J. Artif. Int. Res.","","1076-9757","","","In multiagent systems, social choice functions can help aggregate the distinct preferences that agents have over alternatives, enabling them to settle on a single choice. Despite the basic manipulability of all reasonable voting systems, it would still be desirable to find ways to reach plausible outcomes, which are stable states, i.e., a situation where no agent would wish to change its vote. One possibility is an iterative process in which, after everyone initially votes, participants may change their votes, one voter at a time. This technique, explored in previous work, converges to a Nash equilibrium when Plurality voting is used, along with a tie-breaking rule that chooses a winner according to a linear order of preferences over candidates.In this paper, we both consider limitations of the iterative voting method, as well as expanding upon it. We demonstrate the significance of tie-breaking rules, showing that no iterative scoring rule converges for all tie-breaking. However, using a restricted tie-breaking rule (such as the linear order rule used in previous work) does not by itself ensure convergence. We prove that in addition to plurality, the veto voting rule converges as well using a linear order tie-breaking rule. However, we show that these two voting rules are the only scoring rules that converge, regardless of tie-breaking mechanism.","2016-09","2025-02-19 14:42:29","2025-02-19 14:42:29","","573–591","","1","57","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6UMJLKU","conferencePaper","1990","Gamble, Rose F.","Transforming rule-based programs: from the sequential to the parallel","Proceedings of the 3rd International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems - Volume 2","0-89791-372-8","","10.1145/98894.98939","https://doi.org/10.1145/98894.98939","Conflict resolution is a form of global control used in production systems to achieve an efficient sequential execution of a rule-based program. This type of control is not used in parallel production system models[6, 13]. Instead, only those programs are executed which make no assumptions regarding conflict resolution. Therefore, the initial sequential rule-based programs are either executed in parallel without their conflict resolution strategy, which normally results in incorrect behavior, or the programs are transformed in an ad hoc manner to execute on a particular parallel production system model. As a result, these programs do not exhibit the parallelism hoped for [10, 13].We believe that a second reason behind the lack of parallelism is that no formal methods of verifying the correctness of rule-based programs are utilized. Correctness is especially important when conflict resolution is no longer utilized, because it necessary to transform sequential rule-based programs into equivalent programs without conflict resolution. Also, the parallel execution of a rule-based program is more complex and demands these formal methods even more than its sequential counterpart.We are concerned with designing and developing correct rule-based programs for parallel execution. In this paper, we show the difficulty in transforming a simple sequential rule-based program to a new version of the program with no conflict resolution. Also, we show that the use of a new programming paradigm and language may result in more efficient programs which are provably correct, and can be executed in parallel.","1990","2025-02-19 14:42:29","2025-02-19 14:42:29","","854–863","","","","","","","IEA/AIE '90","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Charleston, South Carolina, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7WYZ5QAY","conferencePaper","2019","Abbasi, Bushra Zaheer","Fuzzy-rule based approach for feature selection in text classification: student research abstract","Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","978-1-4503-5933-7","","10.1145/3297280.3297643","https://doi.org/10.1145/3297280.3297643","A well representing feature set that has enough differentiating power plays an important role in classification. The existing techniques for feature set selection are mostly statistical. They only make decision between a feature inclusion or exclusion without taking into account the importance of human thinking and reasoning that surely effect the results of classification and prediction. In this paper, I propose a new method of feature selection and employed it via Fuzzy Set Theory (FST). The effectiveness of proposed method is evaluated in terms of improving the classifier's performance as compared to state of the art methods such as Gini Index, Information Gain, and Document Frequency. A case study is performed with widely known classifiers Naive Bayes, Support Vector Machine and Random Forest in the context of classification of software design patterns. The promising results indicate the applicability of proposed method in context of automated systems of certain domains.","2019","2025-02-19 14:42:29","2025-02-19 14:42:29","","553–555","","","","","","","SAC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Limassol, Cyprus","","","","evaluation; classification; feature selection; fuzzy set theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NHBVTMCM","conferencePaper","2015","Hansen, Thomas Dueholm; Zwick, Uri","An Improved Version of the Random-Facet Pivoting Rule for the Simplex Algorithm","","978-1-4503-3536-2","","10.1145/2746539.2746557","https://doi.org/10.1145/2746539.2746557","The Random-Facet pivoting rule of Kalai and of Matousek, Sharir and Welzl is an elegant randomized pivoting rule for the simplex algorithm, the classical combinatorial algorithm for solving linear programs (LPs). The expected number of pivoting steps performed by the simplex algorithm when using this rule, on any linear program involving n inequalities in d variables, is 2O(√(n-d),log(d/√n-d,), where log n=max1,log n. A dual version of the algorithm performs an expected number of at most 2O(√d,log((n-d)/√d,) dual pivoting steps. This dual version is currently the fastest known combinatorial algorithm for solving general linear programs. Kalai also obtained a primal pivoting rule which performs an expected number of at most 2O(√d,log n) pivoting steps. We present an improved version of Kalai's pivoting rule for which the expected number of primal pivoting steps is at most min2O(√(n-d),log(d/(n-d),),2O(√d,log((n-d)/d","2015","2025-02-19 14:42:29","2025-02-19 14:42:29","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EVY7F4WX","conferencePaper","2002","Antoniou, G.; Arief, M.","Executable declarative business rules and their use in electronic commerce","Proceedings of the 2002 ACM Symposium on Applied Computing","1-58113-445-2","","10.1145/508791.508794","https://doi.org/10.1145/508791.508794","Business rules are statements which are used to run the activities of an organization. In the era of electronic commerce it is important for these rules to be represented explicitly, and to be automatically applicable. In this paper we argue that methods from the field of knowledge representation can be used for this purpose. In particular, we propose the use of defeasible reasoning, a simple but efficient reasoning method based on rules and priorities. We motivate the use of defeasible reasoning, give examples, describe two case studies, and outline current and future work in our research.","2002","2025-02-19 14:42:29","2025-02-19 14:42:29","","6–10","","","","","","","SAC '02","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Madrid, Spain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2QIJZ8Q","conferencePaper","2014","Voufo, Larisse; Zalewski, Marcin; Lumsdaine, Andrew","Scoping rules on a platter: a framework for understanding and specifying name binding","Proceedings of the 10th ACM SIGPLAN Workshop on Generic Programming","978-1-4503-3042-8","","10.1145/2633628.2633633","https://doi.org/10.1145/2633628.2633633","We present a simple and generic way to reason about name binding. Name binding is an essential component of every nontrivial programming language, matching uses of names, references, with the things that they name, declarations, based on scoping rules defined by the language. The definition of name binding is often entangled with the language-specific details, which makes abstract and comparative analysis of competing designs challenging. We present a framework that allows to abstract the fundamental notions of references, declarations, and scopes, and to express scoping rules in terms of four scope combinators and three properties of a specific programming language encapsulated in a concept named Language. Using this framework, we clarify complex scoping rules like argument-dependent lookup in C++, investigate the implications of the concepts feature for C++, and introduce a novel scoping rule named weak hiding. In an ideal world, specifications could be formulated based on our framework, and compilers could use such formulation to unambiguously implement name binding. While our examples are primarily centered around C++ and lexical scoping, our framework has applications in other languages and dynamic scoping.","2014","2025-02-19 14:42:29","2025-02-19 14:42:29","","59–70","","","","","","","WGP '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","c++; combinators; concepts; name binding; name lookup; name resolution; scoping rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6PJUEDV","conferencePaper","1983","Bhavsar, Dilip K.","Design For Test Calculus: An algorithm for DFT rules checking","Proceedings of the 20th Design Automation Conference","0-8186-0026-8","","","","A new one-pass algorithm for checking networks for compliance to a set of Design for Test (DFT) rules is presented. The algorithm is based on a “Design For Test Calculus” which defines various types of signals and nodes in the network, signal sets attached to node's inputs and outputs, and rules for transferring signal sets through nodes. The rule checking is accomplished by examining the characteristic contents of the signal sets transferred. The calculus is capable of handling a wide variety of “test point flip-flops” and test access schemes, and has features that make hierarchical rule checking feasible.","1983","2025-02-19 14:42:29","2025-02-19 14:42:29","","300–307","","","","","","","DAC '83","","","","IEEE Press","","","","","","","","","Place: Miami Beach, Florida, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3562ARZI","conferencePaper","2015","el Bolock, Alia; Abdennadher, Slim","Towards automatic poetry generation using constraint handling rules","Proceedings of the 30th Annual ACM Symposium on Applied Computing","978-1-4503-3196-8","","10.1145/2695664.2695742","https://doi.org/10.1145/2695664.2695742","In this paper, we discuss the incremental implementation of an autonomous system, capable of generating unique yet meaningful poetry, using Constraint Handling Rules. The system consists of a reasoner, which is responsible for ensuring the grammaticality, poeticness and meaningfulness of the resulting poems, without depending on any external corpora. This is achieved, by incrementally pruning a customized lexicon, to satisfy the constraints enforced by the three modules, until an output poem is produced.","2015","2025-02-19 14:42:30","2025-02-19 14:42:30","","1868–1873","","","","","","","SAC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salamanca, Spain","","","","constraint programming; computational creativity; computational linguistics; constraint handling rules; natural language generation; poetry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REC5DT9P","conferencePaper","2010","Doppa, Janardhan Rao; NasrEsfahani, Mohammad; Sorower, Mohammad S.; Dietterich, Thomas G.; Fern, Xiaoli; Tadepalli, Prasad","Towards learning rules from natural texts","Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading","","","","","In this paper, we consider the problem of inductively learning rules from specific facts extracted from texts. This problem is challenging due to two reasons. First, natural texts are radically incomplete since there are always too many facts to mention. Second, natural texts are systematically biased towards novelty and surprise, which presents an unrepresentative sample to the learner. Our solutions to these two problems are based on building a generative observation model of what is mentioned and what is extracted given what is true. We first present a Multiple-predicate Bootstrapping approach that consists of iteratively learning if-then rules based on an implicit observation model and then imputing new facts implied by the learned rules. Second, we present an iterative ensemble colearning approach, where multiple decision-trees are learned from bootstrap samples of the incomplete training data, and facts are imputed based on weighted majority.","2010","2025-02-19 14:42:30","2025-02-19 14:42:30","","70–77","","","","","","","FAM-LbR '10","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Los Angeles, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6X8EC6J","conferencePaper","2008","Strauss, Martin; Kipp, Michael","ERIC: a generic rule-based framework for an affective embodied commentary agent","Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 1","978-0-9817381-0-9","","","","We present ERIC, an affective embodied agent for realtime commentary in many domains. The underlying architecture is rule-based, generic, and lightweight - based on Java/Jess modules. Apart from reasoning about dynamically changing events, the system can produce coherent natural language and non-verbal behaviour, based on a layered model of affect (personality, mood, emotion). We show how reasoning, template-based natural language generation and affective appraisal can be implemented within the same rule-based paradigm. To make the system domain independent we worked on two different domains, a virtual horse race and a multi-player tank battle game. We empirically evaluated the genericness of the system by measuring the effort it takes to change the domain, and discuss the results.","2008","2025-02-19 14:42:30","2025-02-19 14:42:30","","97–104","","","","","","","AAMAS '08","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Estoril, Portugal","","","","natural language generation; affect; commentary agents; discourse coherence; embodied characters; embodied conversational agents; event recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZUZYRZT","conferencePaper","2007","Holzmann, Clemens","Rule-based reasoning about qualitative spatiotemporal relations","Proceedings of the 5th International Workshop on Middleware for Pervasive and Ad-Hoc Computing: Held at the ACM/IFIP/USENIX 8th International Middleware Conference","978-1-59593-930-2","","10.1145/1376866.1376875","https://doi.org/10.1145/1376866.1376875","This paper is about a novel rule-based approach for reasoning about qualitative spatiotemporal relations among technology-rich autonomous objects, to which we refer to as artifacts. The objective of our work is to provide means for defining spatiotemporal constraints - i.e. logical combinations of spatial relations to artifacts at certain time intervals - at a high level of abstraction, and to recognize relative situations therewith. Such constraints are defined with rules that infer high-level relationships for newly recognized situations, which in turn can be used in other constraints. At any time, the history of known relationships can be queried in order to trigger predefined actions. We decided for qualitative abstractions of both spatial and temporal relationships, as they reflect the semantics of natural language terms and thus facilitate dealing with relationships at the application programming level. The core concepts of this reasoning approach are presented, and the implementation of a middleware for spatiotemporal reasoning as well as evaluation results are discussed.","2007","2025-02-19 14:42:30","2025-02-19 14:42:30","","49–54","","","","","","","MPAC '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Newport Beach, California","","","","rule-based reasoning; qualitative representation; spatial context; spatiotemporal relations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HC5G4DN2","conferencePaper","2013","Talbot, Christine; Youngblood, G. Michael","Shakespearean spatial rules","Proceedings of the 2013 International Conference on Autonomous Agents and Multi-Agent Systems","978-1-4503-1993-5","","","","Many games and simulations utilize modularized low-level code to move characters about in an environment. This requires extensive technical skill to translate basic high-level actions, as well as extensive time to write code, which includes very detailed instructions on what and when actions will occur across all agents. Other options exist such as mocap files; however, most are not highly dynamic, concerned with spatial positioning, or require human intervention to solve the problem.This paper presents an approach that utilizes play-scripts and natural language processing, along with some spatial reasoning rules to control characters in a virtual environment. Rules around grouping of characters, conversational space, theatre, and general behaviors are key in fully interpreting a play-script into movements on stage. These rules help us to achieve similar blocking for the Shakespearian play Hamlet, performed by virtual characters, as the director Sir Gielgud produced for his 1964 production of Hamlet.","2013","2025-02-19 14:42:30","2025-02-19 14:42:30","","587–594","","","","","","","AAMAS '13","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: St. Paul, MN, USA","","","","natural language processing; agent planning; agent reasoning; bml realizer; hamlet; plays; shakespeare; smartbody; spatial reasoning; speech act theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AKP2LYZ4","conferencePaper","2017","Wang, Long; Qian, Yanling; Liu, Yanbin; Meng, Qingzhi; Xu, Tengfei","Information extraction method and its application in Chinese equipment technical manual based on rule-matching","Proceedings of the 6th International Conference on Software and Computer Applications","978-1-4503-4857-7","","10.1145/3056662.3056670","https://doi.org/10.1145/3056662.3056670","Technical manual is vital source of fault diagnosis and maintenance knowledge. To deal with the mass of manual text, which influence the speed of knowledge acquisition, and then effect the diagnostic efficiency, this paper proposes a method for extracting information of Chinese technical manual text based on rule-matching. With the help of domain ontology and syntactic analysis, extracting rules could be established to extract manual text information, and reasoning algorithm based on hierarchical directed graph is built to assist the fault diagnosis. The information extraction method presented in this paper can supply knowledge to maintenance staff and help to diagnose the fault automatically.","2017","2025-02-19 14:42:30","2025-02-19 14:42:30","","92–97","","","","","","","ICSCA '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bangkok, Thailand","","","","ontology; information extraction; Chinese syntactic analysis; equipment technical manual; rule matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XD63J3ZX","conferencePaper","2011","Hassanpour, Saeed; Das, Amar K.","An intelligent interface for rule elicitation","Proceedings of the Sixth International Conference on Knowledge Capture","978-1-4503-0396-5","","10.1145/1999676.1999710","https://doi.org/10.1145/1999676.1999710","Rule bases are increasingly being used as knowledge resources for reasoning in Semantic Web applications. How-ever, a major obstacle to the wider use of rule bases is the difficulty of acquiring rules from domain experts. In this work, we present a predictive editing method, also known as autocompletion, to facilitate the elicitation of rules specified in the Semantic Web Rule Language (SWRL). Our method uses six different approaches for predictive editing based on frequency, position, structure, and domain-range information. We have implemented our method as a part of Protégé SWRL editor plug in. Initial usage of our method shows that a combined approach accurately recommends the most relevant rule predicates in the rule specification process.","2011","2025-02-19 14:42:30","2025-02-19 14:42:30","","171–172","","","","","","","K-CAP '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Banff, Alberta, Canada","","","","ontology; OWL; SWRL; autocomplete; predictive editing; rule base; rule elicitation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EXQTJJPK","conferencePaper","2018","Baba, Tokiya; Kusu, Kazuma; Hatano, Kenji","An Approach for Unknown Word Processing based on Japanese Phonological Rules","Proceedings of the 20th International Conference on Information Integration and Web-Based Applications &amp; Services","978-1-4503-6479-9","","10.1145/3282373.3282853","https://doi.org/10.1145/3282373.3282853","A morphological analyzer is one of the essential tools for natural language processing in studying Asian languages. One of the errors in morphological analysis is the existence of unknown words. Unknown words are not contained in dictionaries of the morphological analyzer, Consequently, many researchers usually construct rules for detecting morphemes from the unknown words based on knowledge obtained from error analyses. However, the constructed rules in previous researches might be insufficient in both quality and quantity, because these rules were usually found by computationally or manually visual recognition. For this reason, we propose a method for constructing rules based on phonology concerned with the systematic organization of sounds in languages. Phonology covers every linguistic analysis at all levels of language where sound is considered to be structured for conveying linguistic meaning. We deal with obvious rules in phonology such as vowel coalescence, haplology, prosodic shortening, prosodic lengthening, and the generated pattern of onomatopoeia. We evaluate if a morphological analyzer detect known words which are converted into unknown words accurately by our method.","2018","2025-02-19 14:42:30","2025-02-19 14:42:30","","350–354","","","","","","","iiWAS2018","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Yogyakarta, Indonesia","","","","Derivative words; Phonology; Unknown words processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EKCERC9F","conferencePaper","2017","Potgieter, Pieter; Blignaut, Pieter","Using eye-tracking to assess the application of divisibility rules when dividing a multi-digit dividend by a single digit divisor","Proceedings of the South African Institute of Computer Scientists and Information Technologists","978-1-4503-5250-5","","10.1145/3129416.3129427","https://doi.org/10.1145/3129416.3129427","The Department of Basic Education in South Africa has identified certain problem areas in Mathematics of which the factorisation of numbers was specifically identified as a problem area for Grade 9 learners. The building blocks for factorisation should already have been established in Grades 4, 5 and 6. Knowing the divisibility rules, will assist learners to simplify mathematical calculations such as factorisation of numbers, manipulating fractions and determining if a given number is a prime number. When a learner has to indicate, by only giving the answer, if a dividend is divisible by a certain single digit divisor, the teacher has no insight in the learner's reasoning. If the answer is correct, the teacher does not know if the learner guessed the answer or applied the divisibility rule correctly or incorrectly.A pre-post experiment design was used to investigate the effect of revision on the difference in gaze behaviour of learners before and after revision of divisibility rules. The gaze behaviour was analysed before they respond to a question on divisibility.It is suggested that if teachers have access to learners' answers, motivations and gaze behaviour, they can identify if learners (i) guessed the answers, (ii) applied the divisibility rules correctly, (iii) applied the divisibility rules correctly but made mental calculation errors, or (iv) applied the divisibility rules wrongly.","2017","2025-02-19 14:42:30","2025-02-19 14:42:30","","","","","","","","","SAICSIT '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Thaba 'Nchu, South Africa","","","","divisibility rules; eye-tracking; mathematics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GCLRPQDU","journalArticle","2010","Lang, Tobias; Toussaint, Marc","Planning with noisy probabilistic relational rules","J. Artif. Int. Res.","","1076-9757","","","Noisy probabilistic relational rules are a promising world model representation for several reasons. They are compact and generalize over world instantiations. They are usually interpretable and they can be learned effectively from the action experiences in complex worlds. We investigate reasoning with such rules in grounded relational domains. Our algorithms exploit the compactness of rules for efficient and fexible decision-theoretic planning. As a first approach, we combine these rules with the Upper Confidence Bounds applied to Trees (UCT) algorithm based on look-ahead trees. Our second approach converts these rules into a structured dynamic Bayesian network representation and predicts the effects of action sequences using approximate inference and beliefs over world states. We evaluate the effectiveness of our approaches for planning in a simulated complex 3D robot manipulation scenario with an articulated manipulator and realistic physics and in domains of the probabilistic planning competition. Empirical results show that our methods can solve problems where existing methods fail.","2010-09","2025-02-19 14:42:30","2025-02-19 14:42:30","","1–49","","1","39","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBBA7RCL","journalArticle","2002","Baget, Jean-Françs; Mugnier, Marie-Laure","Extensions of simple conceptual graphs: the complexity of rules and constraints","J. Artif. Int. Res.","","1076-9757","","","Simple conceptual graphs are considered as the kernel of most knowledge representation formalisms built upon Sowa's model. Reasoning in this model can be expressed by a graph homomorphism called projection, whose semantics is usually given in terms of positive, conjunctive, existential FOL. We present here a family of extensions of this model, based on rules and constraints, keeping graph homomorphism as the basic operation. We focus on the formal definitions of the different models obtained, including their operational semantics and relationships with FOL, and we analyze the decidability and complexity of the associated problems (consistency and deduction). As soon as rules are involved in reasonings, these problems are not decidable, but we exhibit a condition under which they fall in the polynomial hierarchy. These results extend and complete the ones already published by the authors. Moreover we systematically study the complexity of some particular cases obtained by restricting the form of constraints and/or rules.","2002-06","2025-02-19 14:42:30","2025-02-19 14:42:30","","425–465","","1","16","","","","","","","","","","","","","","","","","Place: El Segundo, CA, USA Publisher: AI Access Foundation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3CCZFHIV","conferencePaper","2009","Turchin, Yulia; Gal, Avigdor; Wasserkrug, Segev","Tuning complex event processing rules using the prediction-correction paradigm","Proceedings of the Third ACM International Conference on Distributed Event-Based Systems","978-1-60558-665-6","","10.1145/1619258.1619272","https://doi.org/10.1145/1619258.1619272","There is a growing need for the use of active systems, systems that act automatically based on events. In many cases, providing such active functionality requires materializing (inferring) the occurrence of relevant events. A widespread paradigm for enabling such materialization is Complex Event Processing (CEP), a rule based paradigm, which currently relies on domain experts to fully define the relevant rules. These experts need to provide the set of basic events which serves as input to the rule, their inter-relationships, and the parameters of the events for determining a new event materialization. While it is reasonable to expect that domain experts will be able to provide a partial rules specification, providing all the required details is a hard task, even for domain experts. Moreover, in many active systems, rules may change over time, due to the dynamic nature of the domain. Such changes complicate even further the specification task, as the expert must constantly update the rules. As a result, we seek additional support to the definition of rules, beyond expert opinion. This work presents a mechanism for automating both the initial definition of rules and the update of rules over time. This mechanism combines partial information provided by the domain expert with machine learning techniques, and is aimed at improving the accuracy of event specification and materialization. The proposed mechanism consists of two main repetitive stages, namely rule parameter prediction and rule parameter correction. The former is performed by updating the parameters using an available expert knowledge regarding the future changes of parameters. The latter stage utilizes expert feedback regarding the actual past occurrence of events and the events materialized by the CEP framework to tune rule parameters. We also include possible implementations for both stages, based on a statistical estimator and evaluate our outcome using a case study from the intrusion detection domain.","2009","2025-02-19 14:42:30","2025-02-19 14:42:30","","","","","","","","","DEBS '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Nashville, Tennessee","","","","complex event processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7E8WTC8H","journalArticle","2013","Qiao, Ying; Han, QiNan; Wang, Hongan; Li, Xiang; Zhong, Kang; Zhang, Keming; Liu, Jian; Guo, Anxiang","RTRS: a novel real-time reasoning system based on active rules","SIGAPP Appl. Comput. Rev.","","1559-6915","10.1145/2505420.2505426","https://doi.org/10.1145/2505420.2505426","Event streaming processing (ESP) has been well investigated in recent years. Many approaches have been proposed on this aspect. However, none of them considers the timing constraints held by high-level reactive applications. In this paper, we propose a real-time reasoning system based on active rules (i.e., event-condition-action rules), called RTRS, to make automatic decisions about how to react to continuously arriving events (i.e., event streams) so that the deadlines of inference delay for rules can be met as much as possible. A series of simulations are conducted to evaluate the performance of RTRS. Simulation results show that the heuristic searching policy used by the inference algorithm – RTEIA, which is the core of RTRS, effectively improves the number of times that rules are fired within the deadlines of their inference delay (NAFS).","2013-06","2025-02-19 14:42:30","2025-02-19 14:42:30","","66–76","","2","13","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","event streams; event-condition-action rules; heuristic searching; inference; real-time; timing constraints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFY7WMCR","conferencePaper","2015","Cepukenas, Julius; Lin, Chenghua; Sleeman, Derek","Applying Rule Extraction &amp; Rule Refinement techniques to (Blackbox) Classifiers","Proceedings of the 8th International Conference on Knowledge Capture","978-1-4503-3849-3","","10.1145/2815833.2816950","https://doi.org/10.1145/2815833.2816950","Black-box classifiers are able to classify unseen instances, once they have been trained on an appropriate (domain) dataset. Such classifiers have the advantage of being generally very efficient but the disadvantage of not being able to explain their processes to a user. For these reasons, over the last decade or so, a number of rule extraction algorithms have been developed which are able to extract a rule-set from classifiers. The focus of this project has been to re-implement a state-of-the-art rule extraction system, OSRE [1], and then to show that when the extracted rules are refined by the Knowledge Refinement system, FIXIT, that the refinement process, in virtually all cases, improves the fidelity of the refined rule-set when compared with the rule-set extracted by OSRE. A statistically significant difference between these two approaches has been demonstrated.We investigated 4 classifiers (2 blackbox (Neural Networks &amp; SVM), 1 Bayesian classifier &amp; 1 (Decision-Tree-based) whitebox) and 4 domains, so a total of 16 Classifier-Dataset combinations were considered. In only 1 case (6.25%) was the result slightly worse; 5 cases (31.25%) were the same (these could not be improved), and the remaining 10 cases (62.5%) show significant improvements. In the future, we intend using similar approaches to improve the accuracy of the classification; this study focuses on fidelity.","2015","2025-02-19 14:42:30","2025-02-19 14:42:30","","","","","","","","","K-CAP '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Palisades, NY, USA","","","","Expertize Capture; KB Refinement; Rule Extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DADI5MD","journalArticle","1968","Banzhaf, John F.","When your computer needs a lawyer","Commun. ACM","","0001-0782","10.1145/363567.363573","https://doi.org/10.1145/363567.363573","Possible liability for negligence, for other torts (such as slander of credit) and for liability under theories of express or implied warranty (guarantees) are discussed, and legal complications are explained, so that users, operators, owners, and leasors of computers may be alerted to potential legal problems. Focus is also on troublespots in contracting for data processing services, in automating record keeping operations, in deciding whether or not to automate certain operations, and in complying with statutes and regulations relating to record keeping. Information is given on patents, copyrights and trade secret protection for programs, and the problem of using copyrighted material in information storage and retrieval systems, including the pending copyright and patent revision bills.","1968-08","2025-02-19 14:42:30","2025-02-19 14:42:30","","543–549","","8","11","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","legal; regulations; simulation; law; accounting; constacts; copying; copyrights; crime; criminals; evidence; evidence copying; guarantees; income tax; lawyer; liabilty; negligence; patents; record keeping records; slander of credit; standard of care; torts; trade secrets; warrantees","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQNVJ8K9","journalArticle","2013","Brunato, Mauro; Battiti, Roberto","Learning and intelligent optimization (LION): one ring to rule them all","Proc. VLDB Endow.","","2150-8097","10.14778/2536222.2536247","https://doi.org/10.14778/2536222.2536247","Almost by definition, optimization is a source of a tremendous power for automatically improving processes, decisions, products and services. But its potential is still largely unexploited in most real-world contexts. One of the main reasons blocking its widespread adoption is that standard optimization assumes the existence of a function f(x) to be minimized, while in most real-world business contexts this function does not exist or is extremely difficult and costly to build by hand. Machine learning (ML) comes to the rescue: the function (the model) can be built by machine learning starting from abundant data. By Learning and Intelligent Optimization (LION) we mean this combination of learning from data and optimization which can be applied to complex, dynamic, stochastic contexts. This combination dramatically increases the automation level and puts more power directly in the hands of decision makers without resorting to intermediate layers of data scientists (LION has a huge potential for a self-service usage). Reaching this goal is a huge challenge and it will require research at the boundary between two areas, machine learning and optimization, which have been traditionally separated.","2013-08","2025-02-19 14:42:30","2025-02-19 14:42:30","","1176–1177","","11","6","","","","","","","","","","","","","","","","","Publisher: VLDB Endowment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M74JUKJM","conferencePaper","2011","Li, Minyi; Vo, Quoc Bao; Kowalczyk, Ryszard","Majority-rule-based preference aggregation on multi-attribute domains with CP-nets","The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 2","0-9826571-6-1","","","","This paper studies the problem of majority-rule-based collective decision-making where the agents' preferences are represented by CP-nets (Conditional Preference Networks). As there are exponentially many alternatives, it is impractical to reason about the individual full rankings over the alternative space and apply majority rule directly. Most existing works either do not consider computational requirements, or depend on a strong assumption that the agents have acyclic CP-nets that are compatible with a common order on the variables. To this end, this paper proposes an efficient SAT-based approach, called MajCP (Majority-rule-based collective decision-making with CP-nets), to compute the majority winning alternatives. Our proposed approach only requires that each agent submit a CP-net; the CP-net can be cyclic, and it does not need to be any common structures among the agents' CP-nets. The experimental results presented in this paper demonstrate that the proposed approach is computationally efficient. It offers several orders of magnitude improvement in performance over a Brute-force algorithm for large numbers of variables.","2011","2025-02-19 14:42:30","2025-02-19 14:42:30","","659–666","","","","","","","AAMAS '11","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Taipei, Taiwan","","","","CP-nets; majority rule; preference aggregation; voting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBCPXZFQ","conferencePaper","2013","Ait Elhara, Ouassim; Auger, Anne; Hansen, Nikolaus","A median success rule for non-elitist evolution strategies: study of feasibility","Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation","978-1-4503-1963-8","","10.1145/2463372.2463429","https://doi.org/10.1145/2463372.2463429","Success rule based step-size adaptation, namely the one-fifth success rule, has shown to be effective for single parent evolution strategies (ES), e.g. the (1+1)-ES. The success rule remains feasible in non-elitist single parent strategies, where the target success rate must be roughly inversely proportional to the population size. This success rule is, however, not easily applicable to multi-parent strategies. In this paper, we introduce the median success rule for step-size adaptation, applicable to non-elitist multi-recombinant evolution strategies. The median success rule compares the median fitness of the population to a fitness from the previous iteration. The comparison fitness is chosen to achieve a target success rate of 1/2, thereby a deviation from the target can be measured reliably in comparatively few iteration steps. As a prerequisite for feasibility of the median success rule, we studied the way the fitness comparison quantile depends on the search space dimension, the population size, the parent number, the recombination weights and the objective function. The findings are encouraging: the choice of the comparison quantile appears to be relatively uncritical and experiments on a variety of functions, also in combination with CMA, reveal reasonable behavior.","2013","2025-02-19 14:42:30","2025-02-19 14:42:30","","415–422","","","","","","","GECCO '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Amsterdam, The Netherlands","","","","adaptation; evolution strategies; median success rule; step-size control","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYXI9T3I","conferencePaper","2004","D'Hondt, Maja; Jonckers, Viviane","Hybrid aspects for weaving object-oriented functionality and rule-based knowledge","Proceedings of the 3rd International Conference on Aspect-Oriented Software Development","1-58113-842-3","","10.1145/976270.976287","https://doi.org/10.1145/976270.976287","Software applications often consist of implicit knowledge for making decisions or giving advice in addition to object-oriented functionality. A rule-based system can be employed for representing and reasoning with this knowledge. Although several hybrid systems exist that combine object-oriented programming and rule-based reasoning, a survey we conducted reveals that both paradigms are not well integrated and programs are tightly coupled.We propose hybrid aspects for integrating object-oriented programming and rule-based reasoning. As expected, hybrid aspects specify join points where normal execution is interrupted and advice is executed. However, since two different languages are involved, we need join point models for both and advice that activates both. As such, we complement a simple join point model for object-oriented programming with a join point model for rule-based reasoning. Hybrid advice is independent of the interrupted language and supports sending messages as well as activating rules. It uses values of either language transparently.We present OReA, an implementation of hybrid aspects for weaving Smalltalk and a rule-based system. We discuss and illustrate two applications of hybrid aspects.","2004","2025-02-19 14:42:30","2025-02-19 14:42:30","","132–140","","","","","","","AOSD '04","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Lancaster, UK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7BJU9F5L","conferencePaper","2011","Shi, Hui; Maly, Kurt; Zeil, Steven; Zubair, Mohammad","Comparison of ontology reasoning systems using custom rules","Proceedings of the International Conference on Web Intelligence, Mining and Semantics","978-1-4503-0148-0","","10.1145/1988688.1988708","https://doi.org/10.1145/1988688.1988708","In the semantic web, content is tagged with ""meaning"" or ""semantics"" that allows for machine processing when implementing systems that search the web. General question/answer systems that are built on top of reasoning and inference face a number of difficult issues. In this paper we analyze scalability issues in the context of a question/answer system (called ScienceWeb) in the domain of a knowledge base of science information that has been harvested from the web. In ScienceWeb we will be able to answer questions that contain qualitative descriptors such as ""groundbreaking"", ""top researcher"", and ""tenurable at university x"". ScienceWeb is being built using ontologies, reasoning systems and custom based rules for the reasoning system. In this paper we address the scalability issue for a variety of supporting systems for ontologies and reasoning. In particular, we study the impact of using custom inference rules that are needed when processing queries in ScienceWeb.","2011","2025-02-19 14:42:30","2025-02-19 14:42:30","","","","","","","","","WIMS '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sogndal, Norway","","","","ontology; semantic web; custom rules; ontology reasoning system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q9P2NS8V","journalArticle","1987","Schikuta, Erich","An exemplary approach to the education of rule-based languages","SIGCSE Bull.","","0097-8418","10.1145/24728.24737","https://doi.org/10.1145/24728.24737","In this paper an exemplary approach to the education of rule-oriented languages will be presented and a method will be proposed to organize lectures on rule-oriented languages.The author of this paper developed the SIEGER-System, which serves as an assistance for such lectures. It is the implementation of a practical rule-based system using PROLOG, a rule-based language.The system is excellently suitable to show the analogy of the metalingual rule-system description and the formal PROLOG definition, and the equality of the natural way of the system usage and the automatic PROLOG-backtracking algorithm.For this reason the above mentioned exemplary approach in connection with this system is outstandingly appropriate for the education of computer science students.","1987-06","2025-02-19 14:42:30","2025-02-19 14:42:30","","43–45","","2","19","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PSRHID3F","conferencePaper","2010","Oliveira Filho, Antonio","Change impact analysis from business rules","Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2","978-1-60558-719-6","","10.1145/1810295.1810389","https://doi.org/10.1145/1810295.1810389","Impact analysis is the identification of the potential consequences of a change, or estimating what needs to be modified to accomplish a change, including related costs and schedule estimates. In this work, we distinguish between two kinds of concerns related to impact analysis: (1) business-specific concerns, those related to stakeholders interested in checking if other business rules are impacted by the change and also need to be modified; and (2) software-specific concerns, those related to stakeholders interested in the impacted software artifacts that need to be modified. Several traceability techniques have been studied and none of them supported impact analysis that dealt with business-specific concerns with reasonable values of precision and recall for the discovered impacts. Our research work aims to support business-specific concerns during impact analysis, by proposing and evaluating a traceability technique that resorts on a new traceability model defined over business rules, with expected precision and recall values of 100%.","2010","2025-02-19 14:42:30","2025-02-19 14:42:30","","353–354","","","","","","","ICSE '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cape Town, South Africa","","","","business rules; business concerns; impact analysis; traceability techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5C7DHW5","conferencePaper","2015","Samsonov, Pavel Andreevich; Tang, Xun; Schöning, Johannes; Kuhn, Werner; Hecht, Brent","You Can't Smoke Here: Towards Support for Space Usage Rules in Location-aware Technologies","Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems","978-1-4503-3145-6","","10.1145/2702123.2702269","https://doi.org/10.1145/2702123.2702269","Recent work has identified the lack of space usage rule (SUR) data – e.g. ""no smoking"", ""no campfires"" – as an important limitation of online/mobile maps that presents risks to user safety and the environment. In order to address this limitation, a large-scale means of mapping SURs must be developed. In this paper, we introduce and motivate the problem of mapping space usage rules and take the first steps towards identifying solutions. We show how computer vision can be employed to identify SUR indicators in the environment (e.g. ""No Smoking"" signs) with reasonable accuracy and describe techniques that can assign each rule to the appropriate geographic feature.","2015","2025-02-19 14:42:30","2025-02-19 14:42:30","","971–974","","","","","","","CHI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Republic of Korea","","","","computer vision; geohci; mobile maps; no smoking; space usage rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KI4NDKXD","conferencePaper","1993","Brant, David A.; Miranker, Daniel P.","Index support for rule activation","Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data","0-89791-592-5","","10.1145/170035.170047","https://doi.org/10.1145/170035.170047","Integrated rule and database systems are quickly moving from the research laboratory into commercial systems. However, the current generation of prototypes are designed to work with small rule sets involving limited inferencing. The problem of supporting large complex rule programs within database management systems still presents significant challenges. The basis for many of these challenges is providing support for rule activation. Rule activation is defined as the process of determining which rules are satisfied and what data satisfies them. In this paper we present performance results for the DATEX database rule system and its novel indexing technique for supporting rule activation. Our approach assumes that both the rule program and the database must be optimized synergistically. However, as an experimental result we have determined that DATEX requires very few changes to a standard DBMS environment, and we argue that these changes are reasonable for the problems being solved. Based on the performance of DATEX we believe we have demonstrated a satisfactory solution to the rule activation problem for complex rule programs operating within a database system.","1993","2025-02-19 14:42:30","2025-02-19 14:42:30","","42–48","","","","","","","SIGMOD '93","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington, D.C., USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3TMYG4F","conferencePaper","2012","Bao, Zhuowei; Kimelfeld, Benny; Li, Yunyao","Automatic suggestion of query-rewrite rules for enterprise search","Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval","978-1-4503-1472-5","","10.1145/2348283.2348363","https://doi.org/10.1145/2348283.2348363","Enterprise search is challenging for several reasons, notably the dynamic terminology and jargon that are specific to the enterprise domain. This challenge is partly addressed by having domain experts maintaining the enterprise search engine and adapting it to the domain specifics. Those administrators commonly address user complaints about relevant documents missing from the top matches. For that, it has been proposed to allow administrators to influence search results by crafting query-rewrite rules, each specifying how queries of a certain pattern should be modified or augmented with additional queries. Upon a complaint, the administrator seeks a semantically coherent rule that is capable of pushing the desired documents up to the top matches. However, the creation and maintenance of rewrite rules is highly tedious and time consuming. Our goal in this work is to ease the burden on search administrators by automatically suggesting rewrite rules. This automation entails several challenges. One major challenge is to select, among many options, rules that are “natural” from a semantic perspective (e.g., corresponding to closely related and syntactically complete concepts). Towards that, we study a machine-learning classification approach. The second challenge is to accommodate the cross-query effect of rules—a rule introduced in the context of one query can eliminate the desired results for other queries and the desired effects of other rules. We present a formalization of this challenge as a generic computational problem. As we show that this problem is highly intractable in terms of complexity theory, we present heuristic approaches and optimization thereof. In an experimental study within IBM intranet search, those heuristics achieve near-optimal quality and well scale to large data sets.","2012","2025-02-19 14:42:30","2025-02-19 14:42:30","","591–600","","","","","","","SIGIR '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","enterprise search; query reformulation; query-rewrite rules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2KA98HJ","conferencePaper","2008","Ananthanarayanan, Rema; Chenthamarakshan, Vijil; Deshpande, Prasad M; Krishnapuram, Raghuram","Rule based synonyms for entity extraction from noisy text","Proceedings of the Second Workshop on Analytics for Noisy Unstructured Text Data","978-1-60558-196-5","","10.1145/1390749.1390756","https://doi.org/10.1145/1390749.1390756","Identification of named entities such as person, organization and product names from text is an important task in information extraction. In many domains, the same entity could be referred to in multiple ways due to variations introduced by different user groups, variations of spellings across regions or cultures, usage of abbreviations, typographical errors and other reasons associated with conventional usage. Identifying a piece of text as a mention of an entity in such noisy data is difficult, even if we have a dictionary of possible entities. Previous approaches treat the synonym problem as part entity disambiguation and use learning-based methods that use the context of the words to identify synonyms. In this paper, we show that existing domain knowledge, encoded as rules, can be used effectively to address the synonym problem to a considerable extent. This makes the disambiguation task simpler, without the need for much training data. We look at a subset of application scenarios in named entity extraction, categorize the possible variations in entity names, and define rules for each category. Using these rules, we generate synonyms for the canonical list and match these synonyms to the actual occurrence in the data sets. In particular, we describe the rule categories that we developed for several named entities and report the results of applying our technique of extracting named entities by generating synonyms for two different domains.","2008","2025-02-19 14:42:30","2025-02-19 14:42:30","","31–38","","","","","","","AND '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore","","","","named entity extraction; product name extraction; synonym generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQ6YGQBW","conferencePaper","2011","Iftikhar, Nadeem; Pedersen, Torben Bach","A rule-based tool for gradual granular data aggregation","Proceedings of the ACM 14th International Workshop on Data Warehousing and OLAP","978-1-4503-0963-9","","10.1145/2064676.2064678","https://doi.org/10.1145/2064676.2064678","In order to keep more detailed data available for longer periods, old data has to be reduced gradually to save space and improve query performance, especially on resource-constrained systems with limited storage and query processing capabilities. In this regard, some hand-coded data aggregation solutions have been developed; however, their actual usage have been limited, for the reason that hand-coded data aggregation solutions have proven themselves too complex to maintain. Maintenance need to occur as requirements change frequently and the existing data aggregation techniques lack flexibility with regards to efficient requirements change management. This paper presents an effective rule-based tool for data reduction based on gradual granular data aggregation. With the proposed solution, data can be maintained at different levels of granularity. The solution is based on high-level data aggregation rules. Based on these rules, data aggregation code can be auto-generated. The solution is effective, easy-to-use and easy-to-maintain. In addition, the paper also demonstrates the use of the proposed tool based on a farming case study using standard database technologies. The results show productivity of the proposed tool-based solution in terms of initial development time, maintenance time and alteration time as compared to a hand-coded solution.","2011","2025-02-19 14:42:30","2025-02-19 14:42:30","","1–8","","","","","","","DOLAP '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland, UK","","","","data reduction; gradual data aggregation; rule-based data aggregation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WQ84AX86","conferencePaper","2012","Djenouri, Y.; Drias, H.; Habbas, Z.; Mosteghanemi, H.","Bees Swarm Optimization for Web Association Rule Mining","Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology - Volume 03","978-0-7695-4880-7","","10.1109/WI-IAT.2012.148","https://doi.org/10.1109/WI-IAT.2012.148","This paper deals with Association Rules Mining algorithms for very large databases and especially for those existing on the web. The numerous polynomial exact algorithms already proposed in literature treated somehow in an efficient way data sets with reasonable size. However they are not capable to cope with a huge amount of data in the web context where the respond time must be very short. This paper, mainly proposes two new Association Rules Mining algorithms based on Genetic metaheuristic and Bees Swarm Optimization respectively. Experimental results show that concerning both the fitness criterion and the CPU time, IARMGA algorithm improved AGA and ARMGA two other versions based on genetic algorithm already proposed in the literature. Moreover, the same experience shows that concerning the fitness criterion, BSO-ARM achieved slightly better than all the genetic approaches. On the other hand, BSO-ARM is more time consuming. In all cases, we observed that the developed approaches yield useful association rules in a short time when comparing them with previous works.","2012","2025-02-19 14:42:30","2025-02-19 14:42:30","","142–146","","","","","","","WI-IAT '12","","","","IEEE Computer Society","USA","","","","","","","","","","","","Association rule mining; BSO metaheuristic; Genetic metaheuristic; Optimization Problem; Solution Quality; Web Mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MSBC88BH","conferencePaper","2013","Qiao, Ying; Leng, Chang; Wang, Hongan; Liu, Jian","Developing a real-time inference approach for rule-based reasoning systems","Proceedings of the 2013 Research in Adaptive and Convergent Systems","978-1-4503-2348-2","","10.1145/2513228.2513303","https://doi.org/10.1145/2513228.2513303","Rule-based reasoning systems play importance roles for many real-time intelligent systems that need to take time-critical actions in response to the continuously arriving events. In this paper, we propose a novel inference approach, called RTINF to make the reasoning system meet its hard deadlines. A series of simulation studies are conducted to evaluate the performance of RTINF.","2013","2025-02-19 14:42:30","2025-02-19 14:42:30","","22–27","","","","","","","RACS '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Montreal, Quebec, Canada","","","","rule-based reasoning; event-condition-action rules; event; real-time scheduling; rule graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VAZAKT3E","journalArticle","1992","Widom, Jennifer","A denotational semantics for the Starburst production rule language","SIGMOD Rec.","","0163-5808","10.1145/140979.140980","https://doi.org/10.1145/140979.140980","Researchers often complain that the behavior of database production rules is difficult to reason about and understand, due in part to the lack of formal declarative semantics. It has even been claimed that database production rule languages inherently cannot be given declarative semantics, in contrast to, e.g., deductive database rule languages. In this short paper we dispute this claim by giving a denotational semantics for the Starburst database production rule language.","1992-09","2025-02-19 14:42:30","2025-02-19 14:42:30","","4–9","","3","21","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAPARAKA","conferencePaper","2013","Gaspers, Serge; Kalinowski, Thomas; Narodytska, Nina; Walsh, Toby","Coalitional manipulation for Schulze's rule","Proceedings of the 2013 International Conference on Autonomous Agents and Multi-Agent Systems","978-1-4503-1993-5","","","","Schulze's rule is used in the elections of a large number of organizations including Wikimedia and Debian. Part of the reason for its popularity is the large number of axiomatic properties, like monotonicity and Condorcet consistency, which it satisfies. We identify a potential shortcoming of Schulze's rule: it is computationally vulnerable to manipulation. In particular, we prove that computing an unweighted coalitional manipulation (UCM) is polynomial for any number of manipulators. This result holds for both the unique winner and the co-winner versions of UCM. This resolves an open question in [14]. We also prove that computing a weighted coalitional manipulation (WCM) is polynomial for a bounded number of candidates. Finally, we discuss the relation between the unique winner UCM problem and the co-winner UCM problem and argue that they have substantially different necessary and sufficient conditions for the existence of a successful manipulation.","2013","2025-02-19 14:42:30","2025-02-19 14:42:30","","431–438","","","","","","","AAMAS '13","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: St. Paul, MN, USA","","","","social choice; voting; manipulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S8UL8MH7","conferencePaper","1990","Merz, Chris; Bond, W. E.; St. Clair, Dan","Matching interval-valued-argument propositions in rule-based systems","Proceedings of the 1990 ACM Annual Conference on Cooperation","0-89791-348-5","","10.1145/100348.100400","https://doi.org/10.1145/100348.100400","Inference engines for rule-based systems attempt to match facts in working memory with rule antecedents. Rules for which matching can be performed are considered for execution (firing). Matching is well defined when the arguments of each proposition used in facts and rules can assume only a single value [Forgy 1982]. However, the matching of propositions whose arguments can assume interval values, interval-valued-argument propositions, requires expansion of the standard definition of pattern matching. The complexity of the problem is compounded by the fact that two intervals may be related in a number of ways. This paper describes a powerful knowledge representation which can be used for expressing interval-valued arguments. In addition, it specifies an approach for performing matching between interval-valued-argument propositions. This approach was inspired by the authors' need to perform matching on propositions whose arguments were ranges of real values and by J.F. Allen's work in temporal reasoning [Allen 1983]. It represents an expansion of current matching techniques. Several examples are provided to illustrate the power and utility of this approach. Many of these concepts have been implemented in a rule-based expert system shell called the Generalized Adaptive Learning Environment (GALE), a research tool being used to study machine learning in diagnostic expert systems.","1990","2025-02-19 14:42:30","2025-02-19 14:42:30","","343–350","","","","","","","CSC '90","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington, D.C., USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LKTEXBML","conferencePaper","2002","Abrahams, Alan; Eyers, David; Bacon, Jean","An asynchronous rule-based approach for business process automation using obligations","Proceedings of the 2002 ACM SIGPLAN Workshop on Rule-Based Programming","1-58113-606-4","","10.1145/570186.570195","https://doi.org/10.1145/570186.570195","The Edee architecture provides a mechanism for explicitly and uniformly capturing business occurrences, and provisions of contracts, policies, and law. Edee is able to reason about the interactions of intra-, inter-, and extra-organizational policy, and execute business procedures informed by the combined legal effects of these diverse rules. We show through an example how Edee's asynchronous approach, namely to initiate actions only after consulting the database to determine active obligations, differs from the traditional synchronous approach in which procedural side-effects are initiated when clauses of rules are evaluated. The example show-cases both conflict detection and resolution in Edee. Edee's novel mechanism for business process automation is based on assessment of legal status and directives, and can be contrasted to the conventional task-dependency and process-synchronization approach employed in other workflow systems.","2002","2025-02-19 14:42:30","2025-02-19 14:42:30","","93–103","","","","","","","RULE '02","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Pittsburgh, Pennsylvania","","","","conflict detection; conflict resolution; contracts; policies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LU3JTQFV","conferencePaper","2009","Mansouri, Haïthem; Kleinermann, Frederic; De Troyer, Olga","Detecting inconsistencies in the design of virtual environments over the web using domain specific rules","Proceedings of the 14th International Conference on 3D Web Technology","978-1-60558-432-4","","10.1145/1559764.1559781","https://doi.org/10.1145/1559764.1559781","Nowadays, 3D Virtual Environments (VEs) are being used over the web for various purposes such as education, collaborative working or social networking. Unfortunately, the development process of such environments remains a demanding task, often accessible only to VE experts despite the availability of a number of Virtual Reality (VR) authoring tools. On the other hand, VE experts are seldom domain experts. This implies that their knowledge on specific domains can most of the time be limited. This could lead to design errors or, as in most cases, longer development times and efforts as the development process become an iterative one involving many revisions. One way of accelerating this process is by making it possible to capture a specific knowledge of a domain and later use this knowledge to automatically check that the design of the VE meets the requirements of the domain. This way, we ensure the conformity of the VE to the requirements of the domain for which it is being developed and by extension also to the customer's requirements. As a result, development times and efforts can significantly be shortened, while reducing the likelihood of error making. This paper describes an extension to an existing approach called VR-WISE that focuses on reducing development times and efforts of VEs using domain oriented terminology and ontologies.","2009","2025-02-19 14:42:30","2025-02-19 14:42:30","","101–109","","","","","","","Web3D '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Darmstadt, Germany","","","","domain specific rules; semantics; virtual environments; virtual reality; X3D","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KJ2HHZK","conferencePaper","2001","Joshi, Mahesh V.; Agarwal, Ramesh C.; Kumar, Vipin","Mining needle in a haystack: classifying rare classes via two-phase rule induction","Proceedings of the 2001 ACM SIGMOD International Conference on Management of Data","1-58113-332-4","","10.1145/375663.375673","https://doi.org/10.1145/375663.375673","Learning models to classify rarely occurring target classes is an important problem with applications in network intrusion detection, fraud detection, or deviation detection in general. In this paper, we analyze our previously proposed two-phase rule induction method in the context of learning complete and precise signatures of rare classes. The key feature of our method is that it separately conquers the objectives of achieving high recall and high precision for the given target class. The first phase of the method aims for high recall by inducing rules with high support and a reasonable level of accuracy. The second phase then tries to improve the precision by learning rules to remove false positives in the collection of the records covered by the first phase rules. Existing sequential covering techniques try to achieve high precision for each individual disjunct learned. In this paper, we claim that such approach is inadequate for rare classes, because of two problems: splintered false positives and error-prone small disjuncts. Motivated by the strengths of our two-phase design, we design various synthetic data models to identify and analyze the situations in which two state-of-the-art methods, RIPPER and C4.5 rules, either fail to learn a model or learn a very poor model. In all these situations, our two-phase approach learns a model with significantly better recall and precision levels. We also present a comparison of the three methods on a challenging real-life network intrusion detection dataset. Our method is significantly better or comparable to the best competitor in terms of achieving better balance between recall and precision.","2001","2025-02-19 14:42:30","2025-02-19 14:42:30","","91–102","","","","","","","SIGMOD '01","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Santa Barbara, California, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZI77IFN","conferencePaper","2005","Sherwani, Naveed; Mack, Susan Lippincott; Alexanian, Alex; Buch, Premal; Guardiani, Carlo; Lehon, Harold; Rabkin, Peter; Sharan, Atul","DFM rules!","Proceedings of the 42nd Annual Design Automation Conference","1-59593-058-2","","10.1145/1065579.1065625","https://doi.org/10.1145/1065579.1065625","For sub-100nm processes, predictions are putting initial process yields in the single digits. At the same time, at 130nm, we saw that two chips designed with the same methodology and same design rules could deliver completely different manufacturing yields.This panel will discuss the reasons for these phenomena and talk about future trends in DFM that will need to be addressed for success below 100nm.","2005","2025-02-19 14:42:30","2025-02-19 14:42:30","","168–169","","","","","","","DAC '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Anaheim, California, USA","","","","design for manufacturability; yield optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWWFLMBA","journalArticle","2003","Berndtsson, Mikael; Calestam, Bengt","Graphical notations for active rules in UML and UML-A","SIGSOFT Softw. Eng. Notes","","0163-5948","10.1145/638750.638774","https://doi.org/10.1145/638750.638774","Active rules (i.e., event condition action rules, triggers) have been put forward as a technique for reacting to important events, and thereby avoiding polling or embedding rule processing in applications. Despite the promises of active rules technology, the usage of active rules is low in practice. It has often been claimed (by database researchers) that the reason why few active rules applications have been built is due to the lack of support in analysis and design phases. Hence, there are very few notations or guidelines available for software engineers who develop active rules applications.In this paper, we propose modelling templates for UML state-charts and UML-A statecharts for how software engineers can capture the fundamentals of active rules. By following the proposed modelling templates and notations for active rules, it will be easier for software engineers to develop applications that rely on active rules technology.","2003-03","2025-02-19 14:42:30","2025-02-19 14:42:30","","2","","2","28","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5IRBPPI","conferencePaper","1998","Cherniack, Mitch; Zdonik, Stan","Changing the rules: transformations for rule-based optimizers","Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data","0-89791-995-5","","10.1145/276304.276311","https://doi.org/10.1145/276304.276311","Rule-based optimizers are extensible because they consist of modifiable sets of rules. For modification to be straightforward, rules must be easily reasoned about (i.e., understood and verified). At the same time, rules must be expressive and efficient (to fire) for rule-based optimizers to be practical. Production-style rules (as in [15]) are expressed with code and are hard to reason about. Pure rewrite rules (as in [1]) lack code, but cannot atomically express complex transformations (e.g., normalizations). Some systems allow rules to be grouped, but sacrifice efficiency by providing limited control over their firing. Therefore, none of these approaches succeeds in making rules expressive, efficient and understandable.We propose a language (COKO) for expressing an alternative form of input to a rule-based optimizer. A COKO transformation consists of a set of declarative (KOLA) rewrite rules and a (firing) algorithm that specifies their firing. It is straightforward to reason about COKO transformations because all query modification is expressed with declarative rewrite rules. Firing is specified algorithmically with an expressive language that provides direct control over how query representations are traversed, and under what conditions rules are fired. Therefore, COKO achieves a delicate balance of understandability, efficiency and expressivity.","1998","2025-02-19 14:42:30","2025-02-19 14:42:30","","61–72","","","","","","","SIGMOD '98","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seattle, Washington, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHJNLLTK","conferencePaper","2011","Gordon, Jonathan; Schubert, Lenhart K.","Discovering commonsense entailment rules implicit in sentences","Proceedings of the TextInfer 2011 Workshop on Textual Entailment","978-1-937284-15-2","","","","Reasoning about ordinary human situations and activities requires the availability of diverse types of knowledge, including expectations about the probable results of actions and the lexical entailments for many predicates. We describe initial work to acquire such a collection of conditional (if–then) knowledge by exploiting presuppositional discourse patterns (such as ones involving 'but', 'yet', and 'hoping to') and abstracting the matched material into general rules.","2011","2025-02-19 14:42:30","2025-02-19 14:42:30","","59–63","","","","","","","TIWTE '11","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Edinburgh, Scotland","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AP2TAECK","conferencePaper","2014","Barkhordari, Mohammadhossein; Niamanesh, Mahdi","ScadiBino: An effective MapReduce-based association rule mining method","Proceedings of the Sixteenth International Conference on Electronic Commerce","978-1-4503-2618-6","","10.1145/2617848.2617853","https://doi.org/10.1145/2617848.2617853","Current data mining algorithms are impractical for huge amounts of data because they are time consuming and therefore inefficient. Association rule mining is one of the most famous data mining algorithms. Many parallel and distributed methods have been proposed for association rule mining. However, these methods are not suited to big data for a number of reasons, such as improper data location, data skewness, lack of load balancing, lack of support for generalized association rule mining, and lack of an obvious method for rule extraction. The MapReduce-based architecture is a parallel and distributable solution for association rule mining. To improve the performance of MapReduce, proposed methods for association rules need to be customized. The performance of iterative algorithms in MapReduce architectures may not be optimum. Two main issues affect the performance of MapReduce architectures: data placement and network traffic. In this paper, a scalable and distributable binominal association rule mining method (ScaDiBino ARM) is proposed. This method converts input data items to binominal format to take advantage of scalable and distributable attributes of MapReduce structures. The proposed method was evaluated by applying it to real traffic data of a mobile operator to enable it to recommend values added services (VAS) to its customers. The results show that the rule extraction time improved significantly after applying the proposed rule mining method.","2014","2025-02-19 14:42:30","2025-02-19 14:42:30","","1–8","","","","","","","ICEC '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Philadelphia, PA, USA","","","","Data mining; Big data; Association rules; MapReduce","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WD2JPR8U","journalArticle","1996","Baralis, Elena; Ceri, Stefano; Paraboschi, Stefano","Modularization techniques for active rules design","ACM Trans. Database Syst.","","0362-5915","10.1145/227604.227605","https://doi.org/10.1145/227604.227605","Active database systems can be used to establish and enforce data management policies. A large amount of the semantics that normally needs to be coded in application programs can be abstracted and assigned to active rules. This trend is sometimes called “knowledge independence” a nice consequence of achieving full knowledge independence is that data management policies can then effectively evolve just by modifying rules instead of application programs. Active rules, however, may be quite complex to understand and manage: rules react to arbitrary event sequences, they trigger each other, and sometimes the outcome of rule processing may depend on the order in which events occur or rules are scheduled. Although reasoning on a large collection of rules is very difficult, the task becomes more manageable when the rules are few. Therefore, we are convinced that modularization, similar to what happens in any software development process, is the key principle for designing active rules; however, this important notion has not been addressed so far. This article introduces a modularization technique for active rules called stratification; it presents a theory of stratification and indicates how stratification can be practically applied. The emphasis of this article is on providing a solution to a very concrete and practical problem; therefore, our approach is illustrated by several examples.","1996-03","2025-02-19 14:42:30","2025-02-19 14:42:30","","1–29","","1","21","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","static analysis; active database systems; database rule processing; modularization; termination","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHBQET9E","conferencePaper","2011","Hu, Beibei; Hidders, Jan; Cimiano, Philipp","A rule engine for relevance assessment in a contextualized information delivery system","Proceedings of the 16th International Conference on Intelligent User Interfaces","978-1-4503-0419-1","","10.1145/1943403.1943461","https://doi.org/10.1145/1943403.1943461","In order to support police officers in their daily activities, we have designed a rule-based system which can deliver contextualized information to police officers, thus supporting decision making. In particular, we present a framework that has been designed on the basis of requirements elicited in a previous study, focusing on the rule language and the engine that essentially defines and allows to configure the behaviour of the system. The rules consist of a body which specifies conditions that need to be fulfilled in a certain context. The head of the rules specifies how the relevance ratings of certain information items for specific users need to be updated given that the conditions in the body are met. On the basis of cumulated ratings, the system generates a user- and context specific ranking of information items. Quantitative evaluations in terms of precision and recall with respect to a gold standard determined in cooperation with police officers show that the system can cater for the requirements of our end users and yields reasonable precision and recall values.","2011","2025-02-19 14:42:30","2025-02-19 14:42:30","","343–346","","","","","","","IUI '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Palo Alto, CA, USA","","","","semantic web; rule-based systems; RDF; SPARQL; context-aware information systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L9P42TZ6","conferencePaper","2000","Fleury, Ann E.","Programming in Java: student-constructed rules","Proceedings of the Thirty-First SIGCSE Technical Symposium on Computer Science Education","1-58113-213-1","","10.1145/330908.331854","https://doi.org/10.1145/330908.331854","Java is becoming a popular first programming language for university students. One reason for its popularity is its power as an object-oriented language. This study examined beginning students' understanding of the construction and use of objects in Java. During tape-recorded interviews, students were asked to predict which programs from a collection of similar programs would work according to specification and which would not. This paper will discuss those interviews, including the most common false assumptions or “student-constructed rules” invoked by the students and the implications of the interviews for instruction.","2000","2025-02-19 14:42:30","2025-02-19 14:42:30","","197–201","","","","","","","SIGCSE '00","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Austin, Texas, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S4JTCTH2","journalArticle","2010","Fan, Wenfei; Li, Jianzhong; Ma, Shuai; Tang, Nan; Yu, Wenyuan","Towards certain fixes with editing rules and master data","Proc. VLDB Endow.","","2150-8097","10.14778/1920841.1920867","https://doi.org/10.14778/1920841.1920867","A variety of integrity constraints have been studied for data cleaning. While these constraints can detect the presence of errors, they fall short of guiding us to correct the errors. Indeed, data repairing based on these constraints may not find certain fixes that are absolutely correct, and worse, may introduce new errors when repairing the data. We propose a method for finding certain fixes, based on master data, a notion of certain regions, and a class of editing rules. A certain region is a set of attributes that are assured correct by the users. Given a certain region and master data, editing rules tell us what attributes to fix and how to update them. We show how the method can be used in data monitoring and enrichment. We develop techniques for reasoning about editing rules, to decide whether they lead to a unique fix and whether they are able to fix all the attributes in a tuple, relative to master data and a certain region. We also provide an algorithm to identify minimal certain regions, such that a certain fix is warranted by editing rules and master data as long as one of the regions is correct. We experimentally verify the effectiveness and scalability of the algorithm.","2010-09","2025-02-19 14:42:30","2025-02-19 14:42:30","","173–184","","1–2","3","","","","","","","","","","","","","","","","","Publisher: VLDB Endowment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LLBMBK6","conferencePaper","2004","Ryan, Michael T.; Kolodner, Janet L.","Using 'rules of thumb' practices to enhance conceptual understanding and scientific reasoning in project-based inquiry classrooms","Proceedings of the 6th International Conference on Learning Sciences","","","","","With foundations in scientific argumentation/discourse literature and transfer literature, this study describes the potential of a new ritualized and repeated classroom activity, the Rules of Thumb practice, in developing the conceptual understanding, scientific reasoning, and transfer ability of physical science students in project-based inquiry classrooms (e.g., Learning By Design). Teachers employ an experimental Rules of Thumb practice with more or less fidelity to develop student science talk (defined as the skill or act of communicating and explaining, both in written and/or verbal form, the science concepts and principles within a context in an abstract, generalized form) using scaffolded, iterative instructional practices. Comparison and experimental classrooms completed two post-treatment writing assessments, which were coded and analyzed. This paper presents the results of that analysis and reports that the Rules of Thumb practice may have an effect in developing conceptual understanding, scientific reasoning, and transfer ability and that teacher implementation of the Rules of Thumb practice does indeed affect student outcomes.","2004","2025-02-19 14:42:30","2025-02-19 14:42:30","","449–456","","","","","","","ICLS '04","","","","International Society of the Learning Sciences","","","","","","","","","Place: Santa Monica, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RHLRW6U8","conferencePaper","2005","Rothlauf, Franz; Schunk, Daniel; Pfeiffer, Jella","Classification of human decision behavior: finding modular decision rules with genetic algorithms","Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation","1-59593-010-8","","10.1145/1068009.1068346","https://doi.org/10.1145/1068009.1068346","In search tasks, for example when individuals search for the best price of a product, individuals are confronted in sequential steps with different situations and they have to decide whether to continue or stop searching. The decision behavior of individuals in such search tasks is described by a search strategy.This paper presents a new approach of finding high-quality search strategies by using genetic algorithms (GAs). Only the structure of the search strategies and the basic building blocks (price thresholds and price patterns) that can be used for the search strategies are pre-specified. It is the purpose of the GA to construct search strategies that well describe human search behavior. The search strategies found by the GA are able to predict human behavior in search tasks better than traditional search strategies from the literature which are usually based on theoretical assumptions about human behavior in search tasks. Furthermore, the found search strategies are reasonable in the sense that they can be well interpreted, and generally that means they describe the search behavior of a larger group of individuals and allow some kind of categorization and classification.The results of this study open a new perspective for future research in developing behavioral strategies. Instead of deriving search strategies from theoretical assumptions about human behavior, researchers can directly analyze human behavior in search tasks and find appropriate and high-quality search strategies. These can be used for gaining new insights into the motivation behind human search and for developing new theoretical models about human search behavior.","2005","2025-02-19 14:42:30","2025-02-19 14:42:30","","2021–2028","","","","","","","GECCO '05","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington DC, USA","","","","genetic algorithms; human decision behavior; search strategy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TXC4BJ2P","conferencePaper","2009","Yeh, Che-Hua; Ng, Wai-Seng; Barsky, Brian A.; Ouhyoung, Ming","An esthetics rule-based ranking system for amateur photos","ACM SIGGRAPH ASIA 2009 Sketches","978-1-4503-7936-6","","10.1145/1667146.1667177","https://doi.org/10.1145/1667146.1667177","With the current widespread use of digital cameras, the process of selecting and maintaining personal photos is becoming an onerous task. To our knowledge, there has been little research on photo evaluation based on computational esthetics. Photographers around the world have established some general rules for taking good photos. Building upon artistic theories and human visual perception is difficult since the results tend to be subjective. Although automatically ranking award-wining professional photos may not be a sensible pursuit, such an approach may be reasonable for photos taken by amateurs. In the next section, we introduce rules for such a system.","2009","2025-02-19 14:42:30","2025-02-19 14:42:30","","","","","","","","","SIGGRAPH ASIA '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Yokohama, Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPR6XKH7","conferencePaper","2003","Han, Zaw Z.; Khine, Tin Tin; Ahmad, Imtinan; Shrestha, Sunil; Leff, Laurence L.","Interoperability from electronic commerce to litigation using XML rules","Proceedings of the 9th International Conference on Artificial Intelligence and Law","1-58113-747-8","","10.1145/1047788.1047809","https://doi.org/10.1145/1047788.1047809","We used the XML Rule system earlier described in [6] to simulate litigation arising from electronic commerce in a purchase order situation. This work is distinguished by using XML documents that comply with standards issued by standards-issuing organizations.","2003","2025-02-19 14:42:30","2025-02-19 14:42:30","","93–94","","","","","","","ICAIL '03","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Scotland, United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJ3FV4IP","conferencePaper","2006","Llorà, Xavier; Sastry, Kumara","Fast rule matching for learning classifier systems via vector instructions","Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation","1-59593-186-4","","10.1145/1143997.1144244","https://doi.org/10.1145/1143997.1144244","Over the last ten years XCS has become the standard for Michigan-style learning classifier systems (LCS). Since the initial CS-1 work conceived by Holland, classifiers (rules) have widely used a ternary condition alphabet 0,1,# for binary input problems. Most of the freely available implementations of this ternary alphabet in XCS rely on character-based encodings—easy to implement, not memory efficient, and expensive to compute. Profiling of freely available XCS implementations shows that most of their execution time is spent determining whether a rule is match or not, posing a serious threat to XCS scalability. In the last decade, multimedia and scientific applications have pushed CPU manufactures to include native support for vector instruction sets. This paper presents how to implement efficient condition encoding and fast rule matching strategies using vector instructions. The paper elaborates on Altivec (PowerPC G4, G5) and SSE2 (Intel P4/Xeon and AMD Opteron) instruction sets producing speedups of XCS matching process beyond ninety times. Moreover, such a vectorized matching code will allow to easily scale beyond tens of thousands of conditions in a reasonable time. The proposed fast matching scheme also fits in any other LCS other than XCS.","2006","2025-02-19 14:42:30","2025-02-19 14:42:30","","1513–1520","","","","","","","GECCO '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seattle, Washington, USA","","","","learning classifier systems; Altivec; fast rule matching; SSE2; vector operations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2BU5PT3","conferencePaper","2002","Rizvi, Shariq J.; Haritsa, Jayant R.","Maintaining data privacy in association rule mining","Proceedings of the 28th International Conference on Very Large Data Bases","","","","","Data mining services require accurate input data for their results to be meaningful, but privacy concerns may influence users to provide spurious information. We investigate here, with respect to mining association rules, whether users can be encouraged to provide correct information by ensuring that the mining process cannot, with any reasonable degree of certainty, violate their privacy. We present a scheme, based on probabilistic distortion of user data, that can simultaneously provide a high degree of privacy to the user and retain a high level of accuracy in the mining results. The performance of the scheme is validated against representative real and synthetic datasets.","2002","2025-02-19 14:42:30","2025-02-19 14:42:30","","682–693","","","","","","","VLDB '02","","","","VLDB Endowment","","","","","","","","","Place: Hong Kong, China","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCHT3CSR","conferencePaper","2007","Xia, Lirong; Lang, Jérôme; Ying, Mingsheng","Sequential voting rules and multiple elections paradoxes","Proceedings of the 11th Conference on Theoretical Aspects of Rationality and Knowledge","978-1-4503-7841-3","","10.1145/1324249.1324286","https://doi.org/10.1145/1324249.1324286","Multiple election paradoxes arise when voting separately on each issue from a set of related issues results in an obviously undesirable outcome. Several authors have argued that a sufficient condition for avoiding multiple election paradoxes is the assumption that voters have separable preferences. We show that this extremely demanding restriction can be relaxed into the much more reasonable one: there exists a linear order x1 &gt; … &gt; xp on the set of issues such that for each voter, every issue xi is preferentially independent of xi+1, …, xp given x1, …, xi-1. This leads us to define a family of sequential voting rules, defined as the sequential composition of local voting rules. These rules relate to the setting of conditional preference networks (CP-nets) recently developed in the Artificial Intelligence literature. We study in detail how these sequential rules inherit, or do not inherit, the properties of their local components. We focus on the case of multiple referenda, corresponding to multiple elections with binary issues.","2007","2025-02-19 14:42:31","2025-02-19 14:42:31","","279–288","","","","","","","TARK '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Brussels, Belgium","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNMGWQ7S","conferencePaper","1992","Fisher, Gene L.; Busse, Dale E.; Wolber, David A.","Adding rule-based reasoning to a demonstrational interface builder","Proceedings of the 5th Annual ACM Symposium on User Interface Software and Technology","0-89791-549-6","","10.1145/142621.142632","https://doi.org/10.1145/142621.142632","This paper presents a demonstrational interface builder with improved reasoning capabilities. The system is comprised of two major components: an interactive display manager and a rule-based reasoner. The display manager provides facilities to draw the physical appearance of an interface and define interface behavior by graphical demonstration. The behavior is defined using a technique of stimulus-response demonstrations. With this technique, an interface developer first demonstrates a stimulus that represents an action that an end user will perform on the interface. After the stimulus, the developer demonstrates the response(s) that should result from the given stimulus. As the behavior is demonstrated, the reasoner observes the demonstrations and draws inferences to expedite behavior definition. The inferences entail generalizing from specific behavior demonstrations and identifying constraints that define the generalized behavior. Once behavior constraints are identified, the reasoner sends them to the display manager to complete the definition process. When the interface is executed by an end-user, the display manager uses the constraints to implement the run-time behavior of the interface.","1992","2025-02-19 14:42:31","2025-02-19 14:42:31","","89–97","","","","","","","UIST '92","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Monteray, California, USA","","","","direct manipulation; interface builders; programming by demonstration; UIMSs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZIPVR44","conferencePaper","2004","Xiao, Jing; Chua, Tat-Seng; Cui, Hang","Cascading use of soft and hard matching pattern rules for weakly supervised information extraction","Proceedings of the 20th International Conference on Computational Linguistics","","","10.3115/1220355.1220433","https://doi.org/10.3115/1220355.1220433","Current rule induction techniques based on hard matching (i.e., strict slot-by-slot matching) tend to fare poorly in extracting information from natural language texts, which often exhibit great variations. The reason is that hard matching techniques result in relatively high precision but low recall. To tackle this problem, we take advantage of the newly proposed soft pattern rules which offer high recall through the use of probabilistic matching. We propose a bootstrapping framework in which soft and hard matching pattern rules are combined in a cascading manner to realize a weakly supervised rule induction scheme. The system starts with a small set of hand-tagged instances. At each iteration, we first generate soft pattern rules and utilize them to tag new training instances automatically. We then apply hard pattern rule induction on the overall tagged data to generate more precise rules, which are used to tag the data again. The process can be repeated until satisfactory results are obtained. Our experimental results show that our bootstrapping scheme with two cascaded learners approaches the performance of a fully supervised information extraction system while using much fewer hand-tagged instances.","2004","2025-02-19 14:42:31","2025-02-19 14:42:31","","542–es","","","","","","","COLING '04","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Geneva, Switzerland","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2XG49UXK","conferencePaper","1964","London, Ralph L.","A computer program for discovering and proving recognition rules for Backus Normal Form grammars","Proceedings of the 1964 19th ACM National Conference","978-1-4503-7918-2","","10.1145/800257.808887","https://doi.org/10.1145/800257.808887","This paper is based upon a running computer program which will discover rules for the recognition of grammatical strings when given a simple Backus Normal Form (BNF) grammar [10]. The program attempts to prove that these rules are both necessary and sufficient to characterize grammatical strings. The main mathematical techniques that are mechanized are induction and case analysis. In addition, the program is capable of producing counter-examples.There are two reasons for writing this program. First, we are interested in constructing efficient recognizers for simple BNF grammars. Second, the task of proving that a proposed recognizer is indeed a recognizer is sufficiently complex and difficult to make it a convenient area for proving theorems by machines, especially theorems whose proofs may use fairly involved case analysis.","1964","2025-02-19 14:42:31","2025-02-19 14:42:31","","11.301–11.307","","","","","","","ACM '64","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IKB9NU4L","conferencePaper","1988","Kiernan, Gerald; Koltun, Arnold; Psihountas, George; Schwartz, Edward","Some techniques for minimizing and optimizing the rule base of an expert system","Proceedings of the 1988 ACM Sixteenth Annual Conference on Computer Science","0-89791-260-8","","10.1145/322609.322642","https://doi.org/10.1145/322609.322642","The construction of an expert system can be divided into two somewhat independent phases, knowledge engineering and software engineering. In the knowledge engineering phase, the heuristics and the data base for the system must be deduced through interviews with a domain expert. In the software engineering phase, a working program must be constructed. In a rule-based system this working program consists of a set of rules that embody the heuristics and data base of the expert. In the course of constructing an expert system that gives academic advice to Mathematics and Computer Science majors1 we have found some methods for structuring the rule base and for structuring the rules within the rule base that have proven to be very useful. We will discuss some of these methods.Conceptually, rules in such a system consist of if-then statements. Each rule has a single consequent and usually several general antecedents and some specific antecedents. When the goal of the system is to make determinations in its knowledge domain (for example, to give advice), it searches the rule base for a rule with an appropriate consequent. A rule fires when it is reached by such a search and all of its antecedents are true. If any antecedent is not true, the rule does not fire and the search continues. A first principle, then, in the construction of a rule base is that every possible problem configuration for the system's knowledge domain should cause some rule in the rule base to fire, i.e. the rule base should be complete. We have developed some pictorial representations, called “k-trees” and “question lattices”, that we describe elsewhere1 that help us to check the completeness of the rule base. At worst, there should be a rule that fires when there is insufficient information to make a determination.It is apparent that the order of the rules in the rule base is very important to the performance of the system. Creating the rule base is a kind of programming. It would seem that with such limited programming constructs available only simple programming techniques would be needed. This, in fact, is not the case. Performance and accuracy of the expert system depend in large part upon the organization of the rule base. Organizing the rule base is an important programming technique. There are a variety of methods for structuring the rule base that minimize the size of the final system and that cause the system to ask questions in the appropriate order. One way to decrease the size of a rule base is to use “mop-up” rules. When rules are grouped by goals there is often one consequent that appears with greater frequency than any other. All of the rules with this particular consequent can be replaced by a single rule with that consequent and set of general antecedents and no specific antecedents. This new “mop-up” rule is then placed after all of the more specific rules in the rule base. A small specific example from our expert academic advising system will illustrate the point. A student at Manhattanville College must complete a senior thesis in his or her first area (major). There are, therefore, essentially four rules involved in giving advice on the senior thesis to a senior Mathematics or Computer Science Major. The rules are: If it is fall of the senior year and a senior thesis has not been completed, the student should be advised that the thesis must be completed some time in the senior year.If it is fall of the senior year and a senior thesis has been completed (this can happen because some zealous students actually write their senior theses in the spring of their junior year), the student should be commented for the completion of the work.If it is spring of the senior year and a senior thesis has not been completed, the student should be advised that his or her senior thesis must be completed this term.If it is spring of the senior year and a senior thesis has been completed, the student should be commended for the completion of the work. Clearly, rules 2 and 4 have identical antecedents. Figure 1 shows the way these rules actually appear in the computer science section of our expert system. Notice that in the system, rules 2 and 4 have been combined in the third rule in the figure. The new rule is a “mop-up” rule for this recommendation. The new rule comes after the other two and has fewer antecedents. This rule will fire if neither of the other two do. This “mop-up” rule has saved one rule, a 25% savings. That number seems rather silly in such a small example but, in our experience, “mop-up” rules generally represent savings of between 20% and 40% in the rules of a specific grouping.Another way to reduce the size of the rule base is to notice that often entire groupings of rules are duplicated with the exception of only one or two specific antecedents. When this occurs it is possible to perform a “contraction” on the grouping of rules. This is done by replacing the property or properties that differ among the rules in the groupings by a new property that summarizes the existing properties. This new property must be added to the taxonomy. This is a simple process, however, and is a natural step in the development of an expert system. The new “summary” property is then evaluated by several rules. Once this property has been evaluated, the groupings of rules that were formerly needed can be replaced by a single grouping of the size of one of the former groupings. A savings is realized whenever fewer rules are required to instantiate the new property than were needed in the groupings that were eliminated. While potential contractions are most easily spotted when the rules are represented pictorially1, we will present an example of rules that evaluate one of these “summary” properties and indicate how this property creates a contraction that saves a large number of rules. We have a sequence of four intermediate level computer science courses that alternate through the fall and spring semesters of consecutive years. The recommendations that the advising system gives that need knowledge about those courses, therefore, would require four groupings of rules; one set for each of the possible courses under consideration. We realized that except for the specific intermediate level course involved as an antecedent, the four groupings were identical. We, therefore, defined a new property called current that represents the currently offered course. The rules that instantiate current are shown in figure 2. Notice, the last rule in figure 2 is another example of a “mop-up” rule. Here, one rule replaces four. When they are written out, each grouping of rules initially contains 21 rules. When the specific courses in the groupings are replaced by current the four groupings “contract” to one. The 5 rules in figure 2 thus replace 63 rules.Another concern is the ordering of antecedents within individual rules. This ordering effects both the efficiency of the rule base and the way in which the expert system asks questions. In general, a rule is most efficient when its most general antecedents precede its more specific antecedents. The reason for this is that there is usually no sense in checking many specific antecedents if a rule will fail to fire because a general antecedent is not satisfied. The system tries to check for the truth of antecedents in the order in which the antecedents appear in the rules. As soon as an antecedent is found to be false, the system determines that the rule will not fire and continues its search of the rule base. In order to test whether a rule fires, considerable amounts of computation may have to be done and many questions may have to be asked. If this work can be avoided simply because a general antecedent that is already instantiated (or that must be instantiated for future use) is false, then that antecedent should precede any others in the rule. If antecedents are evaluated by questions, the order of the antecedents helps to determine the order in which questions will be asked.Frequently, many of the properties in an expert system are, in some way, interrelated. Knowing the value of one of these properties often allows us to compute the values of all or some of the others by auxiliary rules in the rule base. If this is the case, we certainly wish to avoid having the system ask the user redundant questions. Moreover, we may wish to ask different users questions about the related properties in different orders. An example of such inter-related properties from the mathematics portion of our advising system are the properties of whether a student has completed calculus 1, calculus 2, and calculus 3. Since each of the preceding courses is a prerequisite for the following one in the sequence, the inter-relationships among these courses are the obvious ones. The auxiliary rules that embody these relationships are shown in figure 3. We have set up our system so that it tries to instantiate the properties call, cal2, and cal3 first by rules and then by asking questions. Looking at these rules we see that they force questions to be asked by the system in a different order depending upon whether the user is or is not a freshman. If a student is not a freshman the rules force questions to be asked first about calculus 3, then about calculus 2, and then about calculus 1. Otherwise, the questions are asked in the opposite order. These auxiliary rules force questions to be asked in the desired order and insure that redundant questions are not asked.Having said all of this, there remains the question of whether rule-base size should always be minimized. We believe the answer to this question is no. Often entire rules and antecedents in rules are redundant and can be eliminated by the kind of ordering techniques that we have described. Nevertheless, we often choose to leave these rules and/or antecedents in the rule-base as internal self-documentation. This makes the rule base much more readable and understandable. The cost in time of search must be weighed against the value of the internal documentation and seems to be justified unless system performance degrades unacceptably.","1988","2025-02-19 14:42:31","2025-02-19 14:42:31","","218–222","","","","","","","CSC '88","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Atlanta, Georgia, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JU2YUT89","conferencePaper","1983","Guenthner, Franz; Lehmann, Hubert","Rules for pronominalization","Proceedings of the First Conference on European Chapter of the Association for Computational Linguistics","","","10.3115/980092.980117","https://doi.org/10.3115/980092.980117","Rigorous interpretation of pronouns in possible when syntax, semantics, and pragmatics of a discourse can be reasonably controlled. Interaction with a database provides such an environment. In the framework of the User Specialty Languages system and Discourse Representation Theory, we formulate strict and preferential rules for pronominalization and outline a procedure to find proper assignments of referents to pronouns.","1983","2025-02-19 14:42:31","2025-02-19 14:42:31","","144–151","","","","","","","EACL '83","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Pisa, Italy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L2J6G4BF","conferencePaper","1989","Biswas, G.; Yu, X.","A rule network for efficient implementation of a mixed-initiative reasoning scheme","Proceedings of the 17th Conference on ACM Annual Computer Science Conference","0-89791-299-3","","10.1145/75427.75441","https://doi.org/10.1145/75427.75441","MIDST (Mixed Inferencing Dempster Shafer Tool) is a rule-based expert system shell that incorporates mixed-initiative reasoning and uncertain reasoning based on the Dempster-Shafer evidence combination scheme. This paper discusses the design and implementation of a rule network for MIDST that facilitates an efficient implementation of the mixed-initiative reasoning scheme.","1989","2025-02-19 14:42:31","2025-02-19 14:42:31","","123–130","","","","","","","CSC '89","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Louisville, Kentucky","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPLESMB8","conferencePaper","1988","Srinivasan, S.; Dey, Pradip; Hayashi, Yoichi","A flexible interactive control structure for rule-based systems","Proceedings of the 1988 ACM Sixteenth Annual Conference on Computer Science","0-89791-260-8","","10.1145/322609.322791","https://doi.org/10.1145/322609.322791","Flexibility in control mechanism will allow solutions of a much wider range of problems with the expert system technology than currently possible. In order to provide flexibility in control mechanism deviations from the standard fixed control (recognize-act cycle) should be allowed. As a first step toward achieving this we develop a flexible interactive backtracking strategy that can deviate significantly from the fixed control structure of rule-based systems. This paper describes a general purpose tool for developing expert systems called PRO2. PRO2 has an effective, intelligent and flexible backtracking control mechanism which makes the system more dependable and flexible. It has a reasonably efficient backtracking facility that is used when the user is not satisfied with the solution and requests for alternatives. Thus, the system provides a greater opportunity to find an acceptable solution if the user is not satisfied with the earlier solution provided. The system also provides an interactive conflict resolution facility.","1988","2025-02-19 14:42:31","2025-02-19 14:42:31","","447–453","","","","","","","CSC '88","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Atlanta, Georgia, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSULUNCH","conferencePaper","1995","Tajchman, Gary; Jurafsky, Daniel; Fosler, Eric","Learning phonological rule probabilities from speech corpora with exploratory computational phonology","Proceedings of the 33rd Annual Meeting on Association for Computational Linguistics","","","10.3115/981658.981659","https://doi.org/10.3115/981658.981659","This paper presents an algorithm for learning the probabilities of optional phonological rules from corpora. The algorithm is based on using a speech recognition system to discover the surface pronunciations of words in speech corpora; using an automatic system obviates expensive phonetic labeling by hand. We describe the details of our algorithm and show the probabilities the system has learned for ten common phonological rules which model reductions and coarticulation effects. These probabilities were derived from a corpus of 7203 sentences of read speech from the Wall Street Journal, and are shown to be a reasonably close match to probabilities from phonetically hand-transcribed data (TIMIT). Finally, we analyze the probability differences between rule use in male versus female speech, and suggest that the differences are caused by differing average rates of speech.","1995","2025-02-19 14:42:31","2025-02-19 14:42:31","","1–8","","","","","","","ACL '95","","","","Association for Computational Linguistics","USA","","","","","","","","event-place: Cambridge, Massachusetts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPTH5567","journalArticle","1989","Gupta, A.; Forgy, C.; Newell, A.","High-speed implementations of rule-based systems","ACM Trans. Comput. Syst.","","0734-2071","10.1145/63404.63405","https://doi.org/10.1145/63404.63405","Rule-based systems are widely used in artificial intelligence for modeling intelligent behavior and building expert systems. Most rule-based programs, however, are extremely computation intensive and run quite slowly. The slow speed of execution has prohibited the use of rule-based systems in domains requiring high performance and real-time response. In this paper we explore various methods for speeding up the execution of rule-based systems. In particular, we examine the role of parallelism in the high-speed execution of rule-based systems and study the architectural issues in the design of computers for rule-based systems. Our results show that contrary to initial expectations, the speed-up that can be obtained from parallelism is quite limited, only about tenfold. The reasons for the small speed-up are: (1) the small number of rules relevant to each change to data memory; (2) the large variation in the processing requirements of relevant rules; and (3) the small number of changes made to data memory between synchronization steps. Furthermore, we observe that to obtain this limited factor of tenfold speed-up, it is necessary to exploit parallelism at a very fine granularity. We propose that a suitable architecture to exploit such fine-grain parallelism is a shared-memory multiprocessor with 32-64 processors. Using such a multiprocessor, it is possible to obtain execution speeds of about 3800 rule-firings/set. This speed is significantly higher than that obtained by other proposed parallel implementations of rule-based systems.","1989-05","2025-02-19 14:42:31","2025-02-19 14:42:31","","119–146","","2","7","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJ37BDFX","conferencePaper","1986","Gupta, A.; Forgy, C.; Newell, A.; Wedig, R.","Parallel algorithms and architectures for rule-based systems","Proceedings of the 13th Annual International Symposium on Computer Architecture","0-8186-0719-X","","","","Rule-based systems, on the surface, appear to be capable of exploiting large amounts of parallelism—it is possible to match each rule to the data memory in parallel. In practice, however, we show that the speed-up from parallelism is quite limited, less than 10-fold. The reasons for the small speed-up are: (1) the small number of rules relevant to each change to data memory; (2) the large variation in the processing required by the relevant rules; and (3) the small number of changes made to data memory between synchronization steps. Furthermore, we observe that to obtain this limited factor of 10-fold speed-up, it is necessary to exploit parallelism at a very fine granularity. We propose that a suitable architecture to exploit such fine-grain parallelism is a bus-based shared-memory multiprocessor with 32-64 processors. Using such a multiprocessor (with individual processors working at 2 MIPS), it is possible to obtain execution speeds of about 3800 rule-firings/sec. This speed is significantly higher than that obtained by other proposed parallel implementations of rule-based systems.","1986","2025-02-19 14:42:31","2025-02-19 14:42:31","","28–37","","","","","","","ISCA '86","","","","IEEE Computer Society Press","Washington, DC, USA","","","","","","","","event-place: Tokyo, Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z738RTE6","conferencePaper","1982","Abbott, Rebecca A.; Greene, Timothy J.","Determination of appropriate dynamic slack sequencing rules for an industrial flow shop via discrete simulation","Proceedings of the 14th Conference on Winter Simulation - Volume 1","","","","","This paper presents an application of combined discrete and network simulation modelling to determine and validate an appropriate sequencing technique for a modified flow shop. The research was based upon a study of a modified flow shop at the International Business Machines, Federal Systems Division (IBM/FSD), Manassas, Virginia, manufacturing Facility. The company's concerns were directed towards enhancing the real-time scheduling of a man and machine dependent flow shop where meeting customer due dates was vital. In this manufacturing facility it is necessary to rework all parts that do not initially meet stringent quality control specifications until those parts do meet those quality limits. Therefore another reason for analyzing different sequencing rules was the necessity to better control the rework activity.The sequencing technique currently used at this facility is based on Earliest Due Date scheduling. With the cooperation of the production control organization at IBM/FSD, Manassas, a simulation study was performed in order to determine if an enhancement to the current system could be found. The objective of the research was to determine which due date based sequencing technique would best meet the overriding production control criteria of the IBM/FSD flow shop. The company's production control objectives were to minimize number of tardy jobs, total amount of job tardiness, and total amount of in–process inventory.The flow shop was modelled using SLAM simulation language. The flow shop was both machine and man dependent requiring both entities to be modelled. A time-consuming task encountered in the development of this model, and with the development of many other simulation models which attempt to represent real world systems, was the task of obtaining data in the proper format to analytically determine the control parameters for the model. This paper presents and discusses some of the difficulties encountered with the data interpretation.Also included in the paper is a discussion of the due date based sequencing techniques studied and the usefulness of simulation to determine and validate the appropriate sequencing technique.","1982","2025-02-19 14:42:31","2025-02-19 14:42:31","","223–231","","","","","","","WSC '82","","","","Winter Simulation Conference","","","","","","","","","Place: San Diego, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LRJ9XID","journalArticle","1984","Pasik, Alexander; Schor, Marshall","Table-driven rules in expert systems","SIGART Bull.","","0163-5719","10.1145/1056648.1056650","https://doi.org/10.1145/1056648.1056650","The structure and organization of expert systems can be usefully modeled after corresponding human experts. Often this modeling degrades because of insufficient expressive power in production system languages. Relational table techniques provide additional abstraction capabilities and are useful in extending the expressiveness of production system rules; the resulting systems can be easier to build, understand and debug because they can reflect more accurately human methods of reasoning. The number of superfluous rules is reduced by organizing much of the problem domain knowledge in relations in working memory. The relational table methods also provide a tool for the interfacing of knowledge bases and databases.","1984-01","2025-02-19 14:42:31","2025-02-19 14:42:31","","31–33","","87","","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTJUN3KZ","conferencePaper","1994","Warwick, Shelly","Abstraction, ethics and software: why don't the rules work?","Proceedings of the Conference on Ethics in the Computer Age","0-89791-644-1","","10.1145/199544.199551","https://doi.org/10.1145/199544.199551","A theory is presented that one of the reasons why the use of unlicensed software is so widespread and unstigmatized is that legislatures, courts and other bodies which create policy operate at a higher level of abstraction than do individuals, and that abstraction is a key factor in the divergence of societal behavior from that condoned by legal statute. This theory is explored through a pilot study consisting of medium depth interviews with two volunteers who had used unlicensed software. Their attitudes, understanding of the law, and characterization of their use of unlicensed software as based on “need” is reported. In addition, the concept of face is examined, and how it is maintained while violating law. It is suggested that further studies, using multiple methodologies, (in-depth interview, focus groups, and surveys) be conducted prior to developing further policy or legislation regarding intellectual property protection for software.","1994","2025-02-19 14:42:31","2025-02-19 14:42:31","","10–14","","","","","","","ECA '94","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Galtinburg, Tennessee, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37R9B67F","conferencePaper","1983","Reinke, Thomas R.","Technology design rules - a user's perspective","Proceedings of the 20th Design Automation Conference","0-8186-0026-8","","","","The interaction of IC design rules and CAD has several perspectives: the CAD developer strives to design “technology independent” software, the CAD support group wants software that is easy to modify for new technologies and changing design rules, the CAD user (designer) wants software that he can modify for technology changes.From a user's perspective existing CAD is already reasonably technology independent. Simulators require additions of new elements as technologies change, but the changes are infrequent. Existing physical design tools are generally generic, only techniques or technology tables need be altered as technologies change. The ability of existing CAD tools to react to changing IC technology is not optimum, but the current problems are workable and represent only a small portion of a typical custom IC development project.","1983","2025-02-19 14:42:31","2025-02-19 14:42:31","","394","","","","","","","DAC '83","","","","IEEE Press","","","","","","","","","Place: Miami Beach, Florida, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CNHEVNLD","journalArticle","1981","Lee, John A. N.","Response to the Federal Trade Commission's proposed ruling on standards and certification","Commun. ACM","","0001-0782","10.1145/358669.358686","https://doi.org/10.1145/358669.358686","In December 1978, the Federal Trade Commission issued a notice of intention of rulemaking in regard to the matter of Standards and Certification. In cooperation with the American National Standards Institute, of which ACM is a member, the ACM Standards Committee prepared a response to that notice and submitted it to the Commission in April 1979. The response gives a summary of the ACM Standards Committee position on a standards regulation and affords insights into the process by which procedures evolve in this area. For this reason, the response is reproduced here as a report.","1981-06","2025-02-19 14:42:31","2025-02-19 14:42:31","","375–380","","6","24","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","regulations; FTC; standards development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""